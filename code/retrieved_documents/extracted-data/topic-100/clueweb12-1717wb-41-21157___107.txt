see the section onit below.
if you have fedora linux, life is really simple.
math functions: the usual exp(), log(), log10() , sqrt() etc. are available, as well as min() , max(), sum(), sort() , round(), floor() etc.
in any subsequent  statistical analyses, r would do its best to cope with the missing data, in the  obvious manners.
[1] 4 here is what happened: we first told r that we would define a function oddcount() of one argument x.
downloading from the web: however, the package you want may not be in your r installation.
a call to .libpaths() again, without an argument, will show you a list  of all the places r now will look at for loading a package when requested.
but the graphics are for the output, e.g. plots, not for  the input.
here we used the built-in function round(), but you can do the same thing with functions that you write yourself.
say the answers for (a), which are yes, no and not sure, are coded 1, 2 and 3, respectively, while for (b) the codes are 1 for
bootstrap statistics : original bias std.
if you want the lines "connecting the dots" but don't want the  dots themselves, includetype="l" in your call to lines(): > plot(x,y,type="l") > lines(x,z,type="l") the call to plot() both initiates the plot and draws the  first curve.
here is an example, finding p(z  count  for (i in seq(1,1000)) + if (rnorm(1)  count/1000
for that reason, you might want to put all the commands you're using to build up a graph in a file, and then usesource() to execute them.
if there are r commands you would like to have executed at the beginning  of every r session, you can place them in a file.
for example, say we have a 3x2 matrix z, whose second  column we wish to fill as follows: for each element in the first column, if it  is at least 2, set the corresponding element in the second column to 1;  otherwise set that element to 0.
for more details, see the extensive online help, e.g. by typing d(1)> ?
of course, we  could get both the cloud and the smoothed curve: plot(x,y) lines(lowess(x,y))
for instance, suppose you wish to generate multivariate normal random vectors.
we might be doing regression of the first column against the second.
if we answery, then the next time we run r, all those objects will automatically be loaded.
what is the probability that that second marble is blue?
we  then calledlines() to add exam1's curve to the graph.
would assign all of your objects to list, thus removing everything.
choose a directory in which you wish to install the package (and maybe others in the future), say/a/b/c.
to cancel a breakpoint, say at line 12, issue bp(12,f).
the idea of a data frame is to encapsulate such data, along with  variable names and even line names, into one object.
there are precompiled binaries for windows, linux and macos x at the r  home page.
choose  a directory in which you wish to install the package (and maybe others in the  future), say/a/b/c.
type `q()' to quit r. >
then install mvbutils, then debug: > install.packages("mvbutils","/myr") > install.packages("debug","/myr")
as the cantonese say, yauh peng, yauh leng --"both inexpensive and beautiful.
the problem is that lmout$coefficients consists not only of the coefficients themselves, but also the names  of the corresponding predictor variables.
y test for equality x =
codes: 0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 residual standard error: 16.31 on 53 degrees of freedom multiple r-squared: 0.5183, adjusted r-squared: 0.5092 f-statistic: 57.03 on 1 and 53 df, p-value: 5.85e-10 so for example, we estimate that exam 1 scores explain about 50% of the variation in exam 3 scores.
here is the  straightforward way: sim3  source("oc.r") here's another example, to automate the saving of a graph which is  displayed on the screen: # prints the currently displayed graph, on device number dvnum, to the #  file filename; dvnum will typically be 2; filename must be the name of # a pdf  file, quoted; it closes the pdf file and restores dvnum as the # current device  prpdf  fit1  fit1$coefficients  (intercept) exam1 3.7008841 0.7458898 we can do the same thing in functions we write ourselves.
a common way of doing this is to use thelines() function.
you can check which  packages are currently loaded by typing > .path.package() loading from your hard drive: if you need a package which is in your r installation but not loaded into  memory yet, you must request it.
for instance, if you have a long vectorx and wish to display it one screen at a time, then instead of typing > x type > page(x) set the hit q to quit the pager, type "/abc" to search for the  string "abc" in the pager output, etc.
again, that will already  be taken care of by the spreadsheet or whatever generated the file in the first  place, but i mention it because you will need to use the quotes in your r  commands.
error t1* 5 0.2375 1.708637 normally, we would assign the result of boot() to an object, as we did withb above.
for example, > z  z x1 x2 1 1 3 2 2 4 note the use of the cbind() function, described in our  section titled"adding more rows or columns" above.
a second r session (10 minutes): here we will do some multivariate analysis, and also introduce data  frames, which allow a richer structure than simply using individual vectors.
entering the debugger with the debug() function: one of the tools r offers for debugging your r code is debug() .
a somewhat more sophisticated example (they can become quite complex)
for example: > a  b   solve(a,b)
the call > trace(f,t) would instruct r to call the function t() every time we  enter the functionr().
in some cases, you  will need additional arguments, which you can place following the function name  in your call toapply().
y, statistic =  mdn, r = 200)
as you can see, other than the first record, which contains the names of the columns (i.e. the variables), each line contains the three exam scores for one student.
in the original frame.
then you can invoke  various debugging operations, such as: you can single-step through the code by hitting the enter key.
built-in data sets: r includes a few real data sets, for use in teaching or in testing  software.
since we were still in the body of the function, r reminded us of that by  using + as its prompt instead of the usual >.
the libraries are visible as subdirectories of your library directory in your r installation tree, e.g. /usr/lib/r/library.
if you want another browser  used, say lynx, type > help.start(browser="lynx")
now, we superimpose the fitted regression line onto that plot: > abline(fit1) the name of this function is meant to suggest, "draw a line with y  intercepta and slope b."
when source() is executed, the code in the specified file  is run.
but you can learn a lot  from tutorials on the web.
we could re-establish the screen as the current device, then copy it to the pdf device: > dev.set(2) x11 2 > dev.copy(which=3) pdf 3 note carefully that the pdf file is not usable until we close it, which we do as follows: > dev.set(3) pdf 3 > dev.off() x11 2
of course, we can add labels to the table and do various statistical analyses on it, not covered here.
be careful to do it right.
this can be especially useful  for graphics functions.
the left brace  demarcates the start of the body of the function.
* y multiplication x / y division x ^ y exponentiation x
you must warn r ahead of time that you instead a variable to be one of these types.
say for instance we wish to use the coefficients to  predict the y values at a few points of particular interest, say  w[1],...,w[25].
[1] 5 4 3 2 1 beware of the operator precedence: > i  1:i-1 [1] 0 1 miscellaneous vector operations: the rep() ("repeat") function allows us to  conveniently put the same constant into long vectors.
[3,] 3 6 > apply(z,2,mean)
this example will place things into even sharper focus: > z  j  8 > j [1] true false  true true >
also, some special math functions are described when you invoke help() with the argument arithmetic.
for instance, would place a legend at the point (2000,31162) in the graph, with a little line of type 1 and label of "cs".
the latter is commonly included in linux distributions, and is freely downloadable for all the major platforms.
a call to .libpaths() again, without an argument, will show you a list of all the places r now will look at for loading a package when requested.
it is extremely easy to set up and use.
then we may not be able to simply take their inner products with the coefficient vector, e.g. > w[1] %*% lmout$coefficients may be rejected by r.
it's also useful if you are not quite sure what an r library function does; by looking at the code you may understand it better.
vectors indices begin at 1.
[1] true  false true true evaluation of the expression z*z > 8 gave us a vector  of booleans!
here is an operator for the symmetric difference between two sets (i.e. all the elements in exactly one of the two operand sets): > "%sdf%"  x %sdf%
[1] 1  > g  g(f1,3,2)
but i  often work with government databases, and they tend to release these as either  straight excel files, or as.csv files.
you can get a lot more if you set r up to dump frames on a crash: > options(error=dump.frames)
[,1] [,2] [1,] 1 3  [2,] 2 4 > y  y x1 x2 1 1 3 2 2 4 as you can see, the column names will be x1, x2, ...
it works in a manner similar to c debuggers such as gdb.
for example, text(2.5,4,"abc") would write the text "abc" at the point (2.5,4) in the graph.
for instance,dnorm() gives the normal density, pnorm() gives the normal cdf and rnorm() generates normally-distributed random variates.
[3,] 3 6 9 > w[w[,2] > 4,]
for example, consider this (compound) command: nrow(subset(x03,z==1))
[,1] [,2] [1,] 0.5 0.5 [2,] -0.5 0.5 the function write.table() works very much like read.table().
for example, > z  z x1 x2 1 1 3 2 2 4 note the use of the cbind() function, described in our section titled"adding more rows or columns" above.
rprofile either in your home directory or in the directory from which you are running r.
typing locator(1) will tell r that you will click in 1 place in the graph.
(the "[1]" helps users read voluminous output consisting of many rows.
here are the commands we issue: > d1 = density(testscores$exam1,from=0,to=100) > d2 = density(testscores$exam2,from=0,to=100) > plot(d2,main="",xlab="") > lines(d1)
for instance, instead of retrieving the means of the  three variables individually, by callingmean() on each vector,  we can get the whole group of means via one single command: > colmeans(testscores) exam1 exam2 exam3 62.14545 51.27273 50.05455
now you are ready to debug.
[3,] 3 na > z[,2] = 2,1,0) >
again, that will already be taken care of by the spreadsheet or whatever generated the file in the first place, but i mention it because you will need to use the quotes in your r commands.
changing character sizes: the cex() function: the cex() ("character expand") function allows  you to expand or shrink characters within a graph, very useful.
(if you had not already entered it viadebug()), and can  proceed as described above.
the latter is commonly included  in linux distributions, and is freely downloadable for all the major platforms.
you can use the function help.search() to do a  "google"-style search through r's documentation in order to determine  which function will play a desired role.
[1] 4 might as well find the mean and standard deviation: > mean(x)
[1] 3 -7 3 13 here we want to find the numbers 15-12 = 3, 8-15 = -7, etc.
we could re-establish the screen as the current device, then copy it to  the pdf device: > dev.set(2) x11 2 > dev.copy(which=3) pdf 3 note carefully that the pdf file is not usable until we close it, which we  do as follows: > dev.set(3) pdf 3 > dev.off() x11 2
the call lowess(x,y) returns the pairs of points on the  regression curve, and thenplot() plots them.
adding text: the text() function: use the text() function to place some text anywhere in  the current graph.
we now have two devices open, as we can confirm: > dev.list() x11 pdf 2 3 our first device, the screen, is named x11 when r runs on unix; it is  device number 2.
the key point is that r functions operate on vectors, in an elementwise fashion.
if you just want  the count and don't want to create a new table, you should use this approach.
so, here the call tocbind() combines the two  vectors into one matrix, whose first column is the first vector and the second  column is the second vector.
it suffers from a less-than-perfect display, but is definitely worthwhile.
first, the scatter plot: > plot(testscores$exam1,testscores$exam3) a scatter plot window then pops up.
in this case, say we have asked five people (a) "do you plan to vote for candidate x?"
r functions can be called from python, and vice versa, using the rpy package.
for instance, > legend(2000,31162,legend="cs",lty=1) would place a legend at the point (2000,31162) in the graph, with a little  line of type 1 and label of "cs".
such a function is called a generic function.
(in excel, one can  export to this format.)
say you wanted to plot the function g(t)
here's how we could do it: > x  y  y
so, for instance, the callabline(2,5) will draw the line y = 2 + 5x.
all graphics output will now go to this file instead of to the screen.
in order to get a certain string placed exactly where you want it, you may need to engage in some trial and error.
among the components of that object areb$t, which is a matrix whose i-th row gives the value of the statistic as found on the i-th bootstrap resampling, and b$t0, which is the value of our statistic on the original data set.
to "browse," go to the place in your r directory tree where the base is stored.
but i often work with government databases, and they tend to release these as either straight excel files, or as.csv files.
suppose i wish to create five files, q1.pdf through q5.pdf, consisting of histograms of 100 random n(0,i2)  variates.
say the answers for (a), which are yes, no and not sure, are  coded 1, 2 and 3, respectively, while for (b) the codes are 1 for
suppose we have a data array y of length 100, from which we wish to estimate a population median, usingy, and have a standard error as well.
so, x[sample(c(1,2,3),2), ] was x[c(3,1), ], i.e. the 2x2 matrix consisting of the  third row and then the first row ofx.
this is the classical "two-dimensional file" notion,  i.e. each line in our file contains the data for one observation from our  sample.
z[, 1] ~ z[, 2] + z[, 3])
[39] 30 44 86 35 95 98 50 50 34 100 57 99 67 77 70 53 38 (the [1] means that items 1-19 start here, the [20] means
a nice function is legend(), which is used to add a  legend to a multicurve graph.
note that r definitely does have graphics--tons of it.
you can invent your own operators!
suppose we have a data array y of length 100, from which  we wish to estimate a population median, usingy, and have a  standard error as well.
the points() function adds a set of (x,y)-points, with labels for each, to the currently displayed graph.
you can skip to the end of the "current context" (a loop or a  function) by typing c.
since all normal r operations and functions are still available to you,  you can query the value of a variable, just type its name, as you would in  ordinary interactive usage of r. (if the variable's name is one of the debug() commands, though, say c, you'll need to do  something likeprint(c) to print it out.)
inside that package is a function, boot(), which will do  the work of bootstrapping.
see the material on .csv files below for details.)
[1] 1 > v [1] 2 > f function(x) { y  f(5)
the object orientation also allows you to combine several commands, each  one using the output of the last, with the resulting combination being quite  powerful and extremely flexible.
then the the coefficients, residuals etc. are all accessible as components of this objectlmout, in lmout$coefficients, lmout$residuals etc.
if you apply it to a simple list of numbers, you get a simple plot of  them, but if you apply it to the output of a regression analysis, you get a set  of plots of various aspects of the regression output.
here we used the built-in function round(), but you can  do the same thing with functions that you write yourself.
this is the classical "two-dimensional file" notion, i.e. each line in our file contains the data for one observation from our sample.
(without specifyingtype="l", only the points would have been plotted.)
[1] 62 74 50 62 39 60 48 80 49 49 100 30 61 100 82 37 54 65 36
these values change to 1 and 0 in arithmetic expressions, e.g. > 1  (1  (1  (1  (1   3 %in% 1:5
[1] 1.527525 if we had wanted to save the mean in a variable instead of just printing it to the screen, we could do, say, > y  y
the object orientation also allows you to combine several commands, each one using the output of the last, with the resulting combination being quite powerful and extremely flexible.
these are interpreted as (x,y) pairs representing points to be added to the current graph, with lines connecting the points.
this example will place things into even sharper focus: > z  j  8 > j [1] true false true true > y  y[j] [1] 1 30 5 we may just want to find the positions within z at which the condition occurs.
after we finally entered a right brace to end the function body, r resumed the > prompt.
the call > trace(f,t) would instruct r to call the function t() every time we enter the functionr().
(you do not need to have read that section to follow the material here.)
we could also close the device by exiting r, though it's probably better  to proactively close.)
(again, it won't be very fancy for the time being, since we are using default values, but you can make it fancy with some added commands when you learn more about r.)
[1] 22 32 the numbers of rows and columns in a matrix can be obtained through the nrow() and ncol() functions, e.g. >
this is handy if you're using a function that you've written but have forgotten what its arguments are, for instance.
in any subsequent statistical analyses, r would do its best to cope with the missing data, in the obvious manners.
say for instance the file has variablesx, y and "abc def".
as you can see, other than the first record, which contains the names of  the columns (i.e. the variables), each line contains the three exam scores for  one student.
you can print the values of variables as you usually do  in r's interactive mode.
for instance, in our earlier example data frame testscores from our second 5-minute example above: we saw in our 10-minute introduction above how to create a data frame by reading from a data file.
it features a pop-up window in which you can watch your progress as you step through your source code, gives you the ability to easily set breakpoints, etc.
[1] 1 > v [1] 2 > y  error: object "y" not found arithmetic and boolean operators and values: x + y addition x - y subtraction x
once you do so, r will tell you the exact coordinates of the point you clicked on.
functions can be used as arguments, assigned, etc.
but if our file had contained any code not in a function, it would have been executed.
note that we do not need to qualify the name exam2 when  usingsubset().
for example, we could put the above commands in a file,testscores.r , with contents d1 = density(testscores$exam1,from=0,to=100) d2 = density(testscores$exam2,from=0,to=100) plot(d2,main="",xlab="") lines(d1) to execute these commands, we would type > source("testscores.r")
codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 residual standard error: 16.31  on 53 degrees of freedom multiple r-squared: 0.5183, adjusted r-squared: 0.5092  f-statistic: 57.03 on 1 and 53 df, p-value: 5.85e-10 so for example, we estimate that exam 1 scores explain about 50% of the  variation in exam 3 scores.
termed  thebrowser in r.
the same operations we discussed in our section above titled "vector  slicing" apply to matrices.
you thus do  not have to recreate the objects again from scratch if you wish to continue  work from before.
[1] 5 4 3 2 1 beware of the operator precedence: > i  1:i-1
so you can see that the evaluation of z[z*z > 8] first  produced a vector of booleans, which we then applied in a slicing operation in z.
[1]  2 8 9 writing efficient r code: try to avoid writing large loops, instead of having r's rich functionality  do the work for you.
see examples in the sections below titled simulation programming and "graphing explicit functions".
the functional programming aspect of importance to most users will be that  one applies an operation to an entire list of elements, one by one, making  things extremely convenient.
subtracting these two vectors then gave us the differences we wanted.
here data is contained within the utils package.
however, you can  change them, e.g. > z x1 x2 1 1 3 2 2 4 > names(z)  z col 1 col 2 1 1 3 2 2 4 tables: consider the data matrix 1 1 1 2 2 2 3 1 2 2 where in the usual statistical fashion each row represents one subject  under study.
generating arithmetic sequences with the seq() function: the seq() ("sequence") generates an arithmetic  sequence, e.g.: > seq(5,8)
the  first record of the.csv file has the names of the variables.
but what if we wish to save what's already on the  screen?
the functional programming aspect of importance to most users will be that one applies an operation to an entire list of elements, one by one, making things extremely convenient.
in this case, say we have asked five people (a) "do you plan  to vote for candidate x?"
plotting multiple curves, using the lines() function: the plot() function works in stages, i.e. you can build  up a graph in stages by giving more and more commands.
the functionmvrnorm() in  the packagemass does this.
that items 20-38 start here, etc.)
we leave by calling the quit function (or optionally by hitting ctrl-d in unix): > q() save workspace image?
but if the argument to the call is a regression object, e.g.fit1 above, then abline() knows to use the regression coefficients as the intercept and slope of the line to be drawn.
we leave by  calling the quit function (or optionally by hitting ctrl-d in unix): > q() save workspace image?
see the section on startup  files below.
there are a number of r tutorials and manuals which have been written, many of which are linked to on the r web page (click on manuals | contributed documentation).
by  contrast, if you call thelm() regression function in r, the  function returns anobject containing all the results--estimated  coefficients, their standard errors, residuals, etc.
bootstrap operations: the bootstrap is a resampling method for performing statistical  inference in analytically intractable situations.
[,1] [,2] [1,] 1 4 [2,] 3 6 filtering: another idea borrowed from functional programming is filtering of vectors,  e.g. > z  w  8] > w [1] 5 -3 8 here is what happened above: we asked r to find all the elements of z whose squares were greater than 8, and then form a new  vector from them (which we assigned tow).
or, if we wish, we can get a ton of information in one fell swoop, the way  we do in other statistical packages: > summary(fit1) call: lm(formula =
more on the functional programming nature of r: elementwise operations on vectors: the key point is that r functions operate on vectors, in an elementwise  fashion.
par will  give you documentation on the various graphics parameters, but it is rather  overwhelming.
the body of a for, if or similar statement does not need braces if it consists of a single statement.
this rather vague statement will be clarified as things unfold here, so don't worry about it now.
yet at the same time we can work them as numbers; r will be smart enough to leave the names out of things then.
r has no "undo" command (though theess interface to r described below does).
when browser() is called, you do indeed enter the browser
now let's make a simple data set, a vector in r parlance, consisting of the numbers 1, 2 and 4, and name itx: > x  q  x
it of course  means that there will be one iteration of the loop for each component of the  vectorx, with n taking on the values of those  components.
see the online help pages for details, e.g. by typing > help(pnorm)
as mentioned in my introduction, r is rather polymorphic, in the sense that the same function has different operation for different classes.
one can applyplot(), for example, to many types of objects, getting an appropriate plot for each.
we can use the table() function to convert this data to contingency table format: > ct  ct
we include code (outside of that function) debug(f)
[,1] [,2] [1,] 1 3 [2,] 2 4 note that when we then printed out y, r showed us its  notation for rows and columns.
this is one of the very few differences between r and s.
for example, in testscores, we can add a variable which is the difference between exams 1 and 2: > testscores$diff21  attach(testscores)
[,1] [,2] [,3] [1,] 1 1 1
it of course means that there will be one iteration of the loop for each component of the vectorx, with n taking on the values of those components.
the boolean values are true and false.
we load that package, and usehelp() to see what's in it, in this case various data sets.
we draw a marble at  random from urn 1 and transfer it to urn 2, and then draw a marble at random  from urn 2.
r programming: r is a full programming language, similar to scripting languages such as  perl and python.
would be that in which our data is a data frame, sayd consisting of 100 rows of two columns.
[,1] [,2] [1,] 1 3 [2,] 2 4 > y  y x1 x2 1 1 3 2 2 4 as you can see, the column names will be x1, x2, ...
[1] 1 you can view the code for a function (either one you wrote, or one in r), e.g. > f1 function(a,b) return(a+b)
the left brace demarcates the start of the body of the function.
more on the object orientation of r: managing your objects: the ls() command will list all of your current objects.
we could define it as follows: > mdn  b  b ordinary nonparametric bootstrap call: boot(data =
this  function is sometimes more convenient to use when writing r programs.
in other words, in the first iteration,n = x[1],  in the second iterationn = x[2], etc. looping with while and repeat are also  available, complete withbreak, e.g. > i  while(1) { + i  10) break + }  >
we then calledlines() to add exam1's curve to the graph.
you then pick and choose  which parts of that object to extract, as you wish.
computer scientists would say that r is polymorphic, which means that the same function can be applied to different types of objects, with results tailored to the different object types.
start r, by typing r on the command line (unix) or in a windows run  window.
the problem is that lmout$coefficients consists not only of the coefficients themselves, but also the names of the corresponding predictor variables.
we first read in the data from the file exams into a data frame which we'll nametestscores: > testscores  testscores$exam1
here's how: for concreteness, suppose our file is named d.csv.
also, if you prefer the more sophisticated kernel method for estimating a density, r offers thedensity() function, an example of which is in our section below titled"plotting multiple curves, using the lines() function ".
[,3] [1,] 0.5 1.000 1.50
this one won't be very pretty, but r has all kinds of bells and whistles you can use optionally.
[1] 3 solving systems of linear equations: the function solve() will solve systems of linear  equations, and even find matrix inverses.
and (b) "did you vote in the last election?"
they are nowhere near what a good debugging tool offers, but with skillful usage they can be effective.
the example() function will actually run the examples  shown in the output ofhelp().
a nice function is legend(), which is used to add a legend to a multicurve graph.
it is different from them in these senses: (if you wish to learn r from the perspective of a programmer---whether professional or ``amateur''---you may prefer to read my writeupr for programmers instead of the tutorial here.)
note, though, that if you want to single-step after hitting a breakpoint, you must typen for the first step, though you can just hit the enter key for subsequent steps.
seethe section titled  "r programming below.
this command tells r that from now on, when we refer, for example, to exam3, we mean testscores$exam3: > mean(exam3)
use the text() function to place some text anywhere in the current graph.
here's another example: > y  y
that is accessible fromr home page, but  it's easier to use theinstall.packages() function.
in our case here, we just had a function in the file, so the effect was for r to read the function in to its list of functions.
the internal structure ofd2 contains vectors of x and y coordinates needed byplot() to draw the figure.
for example, > rm(list =
we used r's vector filtering to avoid a loop, and even though r  internally will loop through the array, it will do so much faster than we would  with an explicit loop in our r code.
object "exam3" not found let's see how well the third exam score can be predicted from the first, using a linear regression function: > fit1  fit1$coefficients (intercept) exam1 3.7008841 0.7458898 note the effect of object orientation here.
say for  example we suspect that our bug is in the functionf().
no such help is needed here, but you will see the need later in oursecond  example.)
this is a very important feature; see more in our section"session data" below.
this  quantity is easy to find analytically, but we'll use simulation.
the call tolines() then adds  the second curve.
the call sample(c(1,2,3),2) tells r to take a sample of size 2 without replacement (the default) from c(1,2,3).
here are the main points: > mtrace(f) do this for each function at which you want a breakpoint.
so, here the call tocbind() combines the two vectors into one matrix, whose first column is the first vector and the second column is the second vector.
y, statistic = mdn, r = 200)
on one machine, i encountered a tcl/tk problem when i  tried to loaddebug.
i will discuss some of the  simpler usage forms here.
on linux machines, you can compile the source yourself by using the usual configure make make install sequence.
[1] 8 8 8 8 function arguments don't change: yet another influence of the functional programming philosophy is that  functions do not change their arguments (unless the result is re-assigned to  the argument).
here is the straightforward way: sim3  source("oc.r") here's another example, to automate the saving of a graph which is displayed on the screen: # prints the currently displayed graph, on device number dvnum, to the # file filename; dvnum will typically be 2; filename must be the name of # a pdf file, quoted; it closes the pdf file and restores dvnum as the # current device prpdf  fit1  fit1$coefficients (intercept) exam1 3.7008841 0.7458898 we can do the same thing in functions we write ourselves.
[,1] [,2] [,3] [1,] 0.5 1.000 1.50 [2,] 0.5 0.625 0.75 note that if the function to be applied returns a vector of k components, the result of apply() will have k rows.
consider for instance the plot() function.
in the  case above, i could changef1() by typing > f1  x1  x2  y  lm(y ~ x1+x2) call: lm(formula =
[1] 8 8 8 8 yet another influence of the functional programming philosophy is that functions do not change their arguments (unless the result is re-assigned to the argument).
we can get around this if we use attach().
you can use the matrix transpose functiont() to change it.
[2,] 11 12 > x[sample(c(1,2,3),2), ]
if you're doing anything with random numbers, you'll need to be able to  reproduce the same stream of numbers each time you run your program during the  debugging session.
you could just usesample() for this, but r has a package,boot, which automates the procedure for you.
we wrote one r statement per  line.
say for instance we wish to use the coefficients to predict the y values at a few points of particular interest, say w[1],...,w[25].
my tutorial is designed to play a role complementary to those others.
if we have an estimator but  no standard error, we get one by resampling from our sample data many times,  calculating the estimator each time, and then taking the standard deviation of  all those generated values.
we might be doing regression of the  first column against the second.
note that we do not need to qualify the name exam2 when usingsubset().
"r by example", a quick chart on how to do various tasks in r,  nicely categorized r reference card, 4 pages, very handy r programming the programming section of zoonekynd's tutorial (includes some material  on oop)
[1] 0.016 0.000 0.018 0.000 0.000
we then called plot() to draw the curve for exam2.
you can do this by specifying the xlim and/or ylim parameters in your call to plot() or points().
(t2+1)0.5 for t between 0 and  5.
getting a response which contains this excerpt: mvrnorm(mass) simulate from a multivariate normal distribution this tells us that the function mvrnorm() will do the  job, and it is in the packagemass.
they can be abbreviated tot and f, but must be capitalized.
[1] 1.527525 if we had wanted to save the mean in a variable instead of just printing  it to the screen, we could do, say, > y  y
to cancel all mtrace() breaks, issue mtrace.off() .
these values change to 1 and 0 in arithmetic expressions, e.g. > 1  (1  (1  (1  (1  3 %in% 1:5 [1] true there are set operations, e.g. > x  y  union(x,y)
in this manner, we get a uniform interface to different classes.
by contrast, if you call thelm() regression function in r, the function returns anobject containing all the results--estimated coefficients, their standard errors, residuals, etc.
to set them externally, see thetrace() function described below.
this will add that new directory to the ones r was already using.
we can also coerce a matrix to a data frame, e.g. > x  x
the idea of a data frame is to encapsulate such data, along with variable names and even line names, into one object.
as with most of the other graphics functions, there are lots of options,  e.g. point color, background color, etc.
you'll get a greeting, and then the r prompt, the >: r : copyright 2005, the r foundation for statistical computing version  2.1.1 (2005-06-20), isbn 3-900051-07-0 ...
we can perform various operations on matrices, e.g. matrix multiplication,  matrix scalar multiplication and matrix addition: > y %*%
to see the various types and their codes.
y test for greater-than-or-equal x & y boolean and x | y boolean or !x boolean negation x %in%
[3,] 3 na > z[,2] = 2,1,0)  >
for example, the reason why elementwise addition of 4 works here, > y+4 [1] 5.2 7.9 4.4 is that the + is actually considered a function!
call locator(2) to get the locations of 2 places, etc.
the internal  linear storage of a matrix is incolumn-major order, meaning that first  all of column 1 is stored, then all of column 2, etc. one of the ways to create a matrix is via the matrix() function, e.g. > y  y
for that reason, you might  want to put all the commands you're using to build up a graph in a file, and  then usesource() to execute them.
the net effect would be to report a count ofz = 1 in  the original frame.
before you loadedmass, "help(mvrnorm)" would have given an error message).
we could do this by the command > trace(gy,browser)
then the the coefficients, residuals etc.
are all  accessible as components of this objectlmout, in lmout$coefficients, lmout$residuals etc.
what is different about this tutorial: there are many excellent tutorials on r on the web, some of which i list  in the section titled"help on the web below.
in its simpler form, arguments are the matrix to be applied to, the dimension--1 for rows, 2 for columns--and the function to be applied.
d2 =  density(testscores$exam2,from=0,to=100)  plot(d2,main="",xlab="") lines(d1)
here is another example: > w  w
this rather vague statement will be clarified as  things unfold here, so don't worry about it now.
in order to get a certain string placed exactly where you want it, you may  need to engage in some trial and error.
[4,] 4 0 0 >  z[,c(2,3)]
yes, we need the testscores$ prefix there on exam2 .
automating actions with the trace() function: the trace() function is quite flexible and powerful,  though it takes some initial effort to learn.
one of  the big advantages of open-source software is that people love to share.
so, for  instance, the callabline(2,5) will draw the line y = 2 + 5x.
in fact, in > round(1.2)
[1] "abc1.500000def" > sprintf("abc%gdef",1.5)
for example, say we have a 3x2 matrix z, whose second column we wish to fill as follows: for each element in the first column, if it is at least 2, set the corresponding element in the second column to 1; otherwise set that element to 0.
if you apply it to a simple list of numbers, you get a simple plot of them, but if you apply it to the output of a regression analysis, you get a set of plots of various aspects of the regression output.
if speed is an issue, such as when working with large data sets or long-running simulations, one must avoid explicit loops as much as possible, because r can do them a lot faster than you can.
[20] 97 60 80 70 50 60 24 60 75 77 71 25 93 80 92 75 26 27 55 [39]  30 44 86 35 95 98 50 50 34 100 57 99 67 77 70 53 38 (the [1] means that items 1-19 start here, the [20] means that items 20-38  start here, etc.)
choose an installation directory, say /myr.
pinpointing locations: the locator() function: typing locator(1) will tell r that you will click in 1 place in the graph.
operations on axes: you may wish to have the ranges on the x- and y-axes of your plot to be  broader or narrower than the default.
this of course  means that the person who wrote the class, knowing the r idiom, would have had  the foresight of writing such a function in the class, knowing that people  would expect one.
then we would have typed 50 na 40 in that line of the exams file.
[1] 0 1 the rep() ("repeat") function allows us to conveniently put the same constant into long vectors.
i could execute the code for (i in 1:5) { fname  sprintf("abc%fdef",1.5)
execution will pause atf(),  and a window will pop up, showing the source code for that function.
[2,] 0.5 0.625 0.75 note that if the function to be applied returns a vector of k components,  the result of apply() will have k rows.
one can  applyplot(), for example, to many types of objects, getting an  appropriate plot for each.
graphical devices and saving graphs to files: r has the notion of a graphics device.
we wrote one r statement per line.
it is automatically invoked  by some r commends, such ashelp(), and you can invoke it  yourself on lengthy output.
but what if we wish to save what's already on the screen?
for  instance, > rm(a,b,x,y,z,uuu) would remove the objects a, b. one of the named arguments of rm() is list , which makes it easier to remove multiple objects.
for instance, in oursecond 5-minute example above: points(testscores$exam1,testscores$exam3,pch="+") would superimpose onto the current graph the points of the exam scores from that example, using "+" signs to mark them.
for example, ylim=c(0,90000) would specify a range on the y-axis of 0 to 90000.
here are the main points: breakpoints are first set at the function level.
the latter reads an ascii data file, and the former writes one.
for instance, let's rewrite the function oddcount() that we wrote above: > oddcount  rr  oddcount(rr)
for instance, inthe section titled  "packages (libraries)" above, we needed a function to generate random  variates from multivariate normal distributions.
one can also use the subset() function for these kinds of tasks: > goodexam2 = 62)
coefficients: (intercept) x1
the internal structure ofd2 contains vectors  of x and y coordinates needed byplot() to draw the figure.
the rbind() and cbind() functions enable one to add rows or columns to a matrix or data frame.
you can use it  as a named parameter in various graphing functions.
at the end of the function, and then have the caller access these items  like this: l  print("abc")
functions for statistical distributions: r has functions available for various aspects of most of the famous  statistical distributions prefix the name byd for the density, p for the c.d.f., q for quantiles and r for simulation.
here is a slightly more complicated example, using a classical problem  from elementary probability courses.
[1] 12 15 18 21 24 27 30 > seq(1.1,2,length=10)
for instance, inthe section titled "packages (libraries)" above, we needed a function to generate random variates from multivariate normal distributions.
here we concatenated what we intended as the first column, the numbers 1 and 2, with what we intended as the second column, 3 and 4.
suppose we have a sequence of numbers for which we want to find successive differences, i.e. the difference between each number and its predecessor.
if you've done this, then after a crash run > debugger() you will then be presented with a choice of levels of function calls to  look at.
[1] 12 13 > z[-1:-2] [1] 13 in such contexts, it is often useful to use the length() function, which gives the length of the vector: > z  z[1:length(z)-1]
[1] 7 2 13 21 24 warning message: longer  object length is not a multiple of shorter object length in: c(1, 2, 4) + c(6,  0, 9, 20, 22) matrices: matrix subscripts begin with 1, so for instance the upper-left corner of  the matrixa is denoted a[1,1].
the expression w[,2]  > 4 gave us the vector c(f,t,t).
in our case here, we just had a function in the file, so the effect was  for r to read the function in to its list of functions.
(unix users will recognize the similarity to unix shell pipe commands.)
y test for  greater-than-or-equal x & y boolean and x | y boolean or !x boolean  negation x %in%
[1] "abc" >  cat("abc\n")
then  we would have typed 50 na 40 in that line of the exams file.
[1] 1 the operation still works, because the number 1.2 is actually considered to be a vector, that happens to consist of a single element 1.2.
we  include code (outside of that function) debug(f) then when f() is executed, you enter the debugger,
urn 1 contains 10 blue marbles and eight blue ones.
i then installed the patched version of 2.5.0, anddebug worked fine.
we can use the table() function to convert this data to  contingency table format: > ct  ct
note also that  a vector is considered a one-row matrix, not a one-column matrix, and thus is  suitable as the left factor in a matrix product, but not directly usable as the  right factor.
error t value pr(>|t|) (intercept) 3.70088 6.52037 0.568 0.573 exam1 0.74589 0.09877 7.552 5.85e-10 *** --- signif.
r includes a few real data sets, for use in teaching or in testing software.
if you want the lines "connecting the dots" but don't want the dots themselves, includetype="l" in your call to lines(): > plot(x,y,type="l") > lines(x,z,type="l") the call to plot() both initiates the plot and draws the first curve.
it includes some material explaining the object-oriented and functional  programming nature of r. much of this material
you'll get a greeting, and then the r prompt, the >: r : copyright 2005, the r foundation for statistical computing version 2.1.1 (2005-06-20), isbn 3-900051-07-0 ...
simulation programming: here is an example, finding p(z  count  for (i in seq(1,1000)) + if (rnorm(1)  count/1000
here are the commands we issue: > d1 = density(testscores$exam1,from=0,to=100) > d2 =  density(testscores$exam2,from=0,to=100)
as described in ther faq, ess offers r users: r support contains code for editing r source code (syntactic indentation and highlighting of source code, partial evaluations of code, loading and error-checking of code, and source code revision maintenance) and documentation (syntactic indentation and highlighting of source code, sending examples to running ess process, and previewing), interacting with an inferior r process from within emacs (command-line editing, searchable command history, command-line completion of r object and file names, quick access to object and search lists, transcript recording, and an interface to the help system), and transcript manipulation (recording and saving transcript files, manipulating and editing saved transcripts, and re-evaluating commands from transcript files).
there is  still a debugging tool available to you after the fact: you can do a "post  mortem" by simply callingtraceback().
for instance, you can change the number of bins by specifying thebreaks variable;hist(z,breaks=12) would draw a histogram of the data z with 12 bins.
look at this: > z  z [1] 5 2 -3 8 > z*z > 8
z[, 1] ~ z[, 2] + z[, 3]) coefficients: (intercept) z[, 2] z[, 3] -1.6779 2.4899 -0.3221 > lm(z[,1] ~ z[,c(2,3)]) call: lm(formula =
this is nice, since it  means that you, as a user, have fewer commands to remember!
[,1] [,2] [1,] 2 6 [2,] 4 8 note that for matrix multiplication in the mathematical sense, the  operator to use is%*%, not *.
i noted in our introductory section, why you should use r, that using the nrow() function in conjunction with filtering provides a way  to obtain a count of records satisfying various conditions.
[1] 1 2 5 8 9 > intersect(x,y)
for example write.table(x,"x.dat",row.names=f,col.names=f) writes the matrix x to a file x.dat,  with no column or row labels.
you can use the function help.search() to do a "google"-style search through r's documentation in order to determine which function will play a desired role.
the first time we did this, the result of that call was the vector  (3,1).
for example, if we wish to save as a pdf file, we do something like  this: > pdf("d12.pdf") this opens a file, which we have chosen here to call d12.pdf .
if you're doing anything with random numbers, you'll need to be able to reproduce the same stream of numbers each time you run your program during the debugging session.
in the following example, we define a function oddcount() while in r's interactive mode, and then call the function on a couple of test cases.
[,1] [,2] [,3] [1,] 2 5 8 [2,] 3 6 9
the command prompt will now be something like browse[1] instead of just >.
my tutorial is designed to  play a role complementary to those others.
coefficients: (intercept) z[, 2] z[, 3] -1.6779 2.4899 -0.3221 > lm(z[,1] ~  z[,c(2,3)]) call: lm(formula =
[5,] 2 2 > table(ct[,1],ct[,2]) 1 2 1 1  1 2 0 2 3 1 0
[1] false > setequal(x,c(1,2,5))
r is a full programming language, similar to scripting languages such as perl and python.
functions are first-class objects: functions can be used as arguments, assigned, etc.
you could just usesample() for  this, but r has a package,boot, which automates the procedure  for you.
y x is a member of the set y
to execute these commands, we would type > source("testscores.r")
in that second call to lm(), we just specified the matrix  consisting of the second and third columns ofz, implicitly  saying that these columns are our predictors.
note that as described here, the breakpoints are hard-coded into the function's source code.
(the "[1]" helps users read voluminous output consisting of many  rows.
so, you can see that the data frame testscores is a way of packaging the vectors of values of the individual variables, plus the associated variable names.
for example write.table(x,"x.dat",row.names=f,col.names=f) writes the matrix x to a file x.dat, with no column or row labels.
for more information on graphics, the command ?
you  then can pick up other features from this document (and others) as the need  arises.
[2,] 31 32  > y[2:3,2]
in many cases, it is better to smooth out the data by fitting a nonparametric regression estimator, such aslowess() : plot(lowess(x,y))
that was our data  in linear form, and then we specified the number of rows and columns.
the fact  that r uses column-major order then determined where these four numbers were  put.
[1] 1 you can view the code for a function (either one you wrote, or one in r),  e.g. > f1 function(a,b) return(a+b)
one can define functions, use constructs such as loops and  conditionals, etc. functions: a short programming example: in the following example, we define a function oddcount() while in r's interactive mode, and then call the function on a couple of test  cases.
[4,] 1 4 0 0 one can refer to the rows and columns of a data frame using two-dimensional array notation.
[,1] [,2] [1,] 1 3  [2,] 2 4
the seq() ("sequence") generates an arithmetic sequence, e.g.: > seq(5,8)
i personally do not use it, but it  clearly has some powerful features for those who wish to put in a bit of time  to learn the package.
extracting numbers from your objects: recall that when one does almost any complex operation in r, the results  are returned packaged as an object.
the table shows that we had, for example, one person who said not sure to  (a) and yes to (a), and two people who answered no to both questions.
type the following: > library(utils) > data > help(data)
use of braces for block definition: the body of a for, if or similar  statement does not need braces if it consists of a single statement.
[y/n/c]: n that last question asked whether we want to save our variables, etc., so that we can resume work later on.
for instance, > rm(a,b,x,y,z,uuu) would remove the objects a, b. one of the named arguments of rm() is list , which makes it easier to remove multiple objects.
another way we could have built y would have been to specify elements individually: > y  y[1,1] = 1 > y[2,1] = 2 > y[1,2] = 3 > y[2,2] = 4 >
but alternatively you  can specify the predictors as a matrix, e.g. > z   lm(z[,1] ~ z[,2]+z[,3]) call: lm(formula
[1] 4 4 17 negative subscripts mean that we want to exclude the given elements in our  output: > z  z[-1]
[4,] 4 0 0 > z[,c(2,3)]
though the terms object-oriened and functional programming may pique the interests of computer scientists, they are actually quite relevant to anyone who uses r.
otherwise, hitting enter immediately after hitting a breakpoint is equivalent to hittingc .
recall too that these boolean constants in r can be abbreviated t and f. say your r code crashes when you are not running the debugger.
a somewhat more sophisticated example (they can become quite complex) would be that in which our data is a data frame, sayd consisting of 100 rows of two columns.
i personally do not use it, but it clearly has some powerful features for those who wish to put in a bit of time to learn the package.
for each one that you choose, you can take a look at the values of the variables there.
for instance, you  know that you can use theplot() function on just about any  object produced by r.
in the example above, instead of writing return(k) we could simply write k this is true for nonscalars too (recall that a scalar is really a one-element vector anyway), e.g.: > r  r(3,2)
[1] 2 5 here is an example of working on rows, using our own function: > f  y  y
suppose we then want to use one of those components as numerical input  into another operation.
to determine what function, if  any, does this, we could type > help.search("multivariate normal")
[3,] 1 3 0 1  [4,] 1 4 0 0 more on data frames: data frames
you could use the following r code: g  curve((x^2+1)^0.5,0,5)
see below for links to some of them.
a first r session (5 minutes): executing r: (if you do not already have r installed, go first to the section below  titledhow to obtain/install r.)
you do have to tell r where to find that package, though, which you can do via the.libpaths() function: > .libpaths("/a/b/c/")
since we specified the matrix entries in the above example, we would not have need to specifyncol; nrow would be enough.
here's how we could do it: > z  z[,1]  z
[1] 4 4 17 negative subscripts mean that we want to exclude the given elements in our output: > z  z[-1]
[1] "abc" > cat("abc\n") abc r includes a number of debugging facilities.
it is indexed to allow you to quickly find how to do something.
the point is that the round() function was applied individually to each element in the vectory.
in urn 2 the mixture is six blue and six yellow.
say you have a function f at which you wish to break.
if you want to install to a nonstandard directory, say /a/b/c, run configure as configure --prefix=/a/b/c using r from emacs: there is a very popular package which allows one to run r (and some other  statistical packages) from within emacs,ess.
the simplest just specifies two arguments, a y-intercept value and a slope.
z[, 1] ~ z[, c(2, 3)]) coefficients: (intercept)
in his  full site a nice short first introduction by m. hlynka of the university of windsor a general tutorial but with lots of graphics and good examples from real  data sets, very nice job, by prof. dong-yun kim of the dept. of math.
as you can see, the function to be applied needs at least one argument, which will play the role of one row or column in the array.
this is especially useful if you will be displaying several curves in the same graph.
say our data is in a matrixx, whose first column consists of 0s and 1s and forms the response variable.
note that if you do not specifyxlim and/or ylim, then draw the largest curve first, so there is room for all of them.
so, load the library: > library(mass) then mvrnorm() will now be ready to use.
the term object-oriented can be explained by example, say  statistical regression.
in the case above, it takes a regression output as its argument.
for instance, let's apply the function for rounding to the nearest  integer to an example vectory: > y  z  z [1] 1 4 0
to determine what function, if any, does this, we could type > help.search("multivariate normal")
for linux, for instance, that is likely /usr/lib/r/library/base or some similar location.
let's now make a scatter plot of the original exam1-exam3 data, together  with the fitted regression line.
leaving r: well, that's the end of this first 5-minute introduction.
the example() function will actually run the examples shown in the output ofhelp().
(as will be its  documentation.
(the function abline() can take on various forms of arguments.
this is a very  important feature; see more in our section"session data" below.
to cancel one for a particular function f, issue mtrace(f,tracing=f).
we can do this usingwhich(): > which(z*z > 8)
# comment: counts the number of odd integers in x > oddcount  oddcount(c(1,3,5))
= (t2+1)0.5 for t between 0 and 5.
not only does this save you programming time, it produces faster code, since r's functions have been written for efficiency.
if we had wanted to regress exam3 against both exam1 and exam2, we would issue the following command: > fit12  plot(c(1,2,3), c(1,2,4)) plots the points (1,1), (2,2) and (3,4).
>  plot(d2,main="",xlab="") > lines(d1) here's what we did: first, we computed nonparametric density estimates  from the two variables, saving them in objectsd1 and d2 for later use.
as another example, let's plot nonparametric density estimates (these are basically smoothed histograms) for exams 1 and 2 from ourexams file in our section titled "a second r session" above in the same graph.
see the online help pages for details, e.g. by typing > help(pnorm) the usual exp(), log(), log10() , sqrt() etc. are available, as well as min() , max(), sum(), sort() , round(), floor() etc.
setting breakpoints with the browser() function: if single-stepping is too tedious, an alternative is to place breakpoints,  by simply inserting the call browser() at the points at which you wish execution to pause.
0.9389 12.0786 32.8163  coefficients: estimate std.
[1] 8 9 > setequal(x,y)
the first few lines in the file are exam1 exam2 exam3 62 70 60 74 34 64 50 35 40 ...
when source() is executed, the code in the specified file is run.
coefficients:  (intercept) x1 x2 0.4286 0.4857 1.1429 using lsfit() instead of lm(): instead of lm(), we can use the "old" linear  model function,lsfit() ("least squares fit").
reading spreadsheet files: i must confess to being a non-spreadsheet user.
if you want another browser used, say lynx, type > help.start(browser="lynx")
here's how it could be done.
for example, we may wish to run an r script that generates a graph output file, and not have to bother with manually running r.
as the last action in this quick introduction to r, let's have r draw a histogram of the data: > hist(x) a window pops up with the histogram in it.
as my sample data set, i have created a file named exams, consisting of grades for the three exams in a certain course (two midterm exams and a final exam).
so, x[sample(c(1,2,3),2), ] was x[c(3,1), ], i.e. the 2x2 matrix consisting of the third row and then the first row ofx.
start r, by typing r on the command line (unix) or in a windows run window.
[,1] [,2] [1,] 11 12 [2,] 21 22
it is different from them in these  senses: (if you wish to learn r from the perspective of a programmer---whether  professional or ``amateur''---you may prefer to read my writeupr for  programmers instead of the tutorial here.)
abc debugging: r includes a number of debugging facilities.
[,1] [,2] [1,] 31 32 [2,] 11 12 >  x[sample(c(1,2,3),2), ]
again since all normal r operations and functions are still available to  you, you can set new breakpoints, etc. to turn off debugging for that function, type > undebug(f) note that if you simultaneously have a separate window open in which you  are editing your source code, each time you reload it usingsource() , the debugging status is lost.
using a linear regression function: > fit1  fit1$coefficients (intercept) exam1 3.7008841 0.7458898 note the effect of object orientation here.
see the section on startup files below.
i discuss a couple of them here.
here are some that i find useful: various r search engines are listed in the the r home page; click on search.
the above set of operations to print a graph can become tedious if used a  lot, so it makes sense to put them into a file.
calling theattributes() function will give you all this, plus the class of the object itself.
one of them,rseek, is one i use.
otherwise, hitting  enter immediately after hitting a breakpoint is equivalent to hittingc .
then go ahead and start your program.
computer scientists would say that r is polymorphic, which means  that the same function can be applied to different types of objects, with  results tailored to the different object types.
text(2.5,4,"abc",cex = 1.5) would print the same text as in our earlier example, but with characters 1.5 times normal size.
first we must define a function which defines the statistic we wish to  compute, which in this case is the median.
the call form is rep(z,k), which creates a vector of k elements, e.g. equal to z. e.g., > x  x
bp ensuring consistency with the set.seed() function:
sometimes it's preferable to automate the process of running r.
object  "exam3" not found introduction to regression in r: let's see how well the third exam score can be predicted from the first,
the call lowess(x,y) returns the pairs of points on the regression curve, and thenplot() plots them.
if you just want the count and don't want to create a new table, you should use this approach.
inf if you want to see all of them.
[1] 1 3 4 also, in our student exam scores example above, we could use the expression > goodexam2 = 62]
we can also create a data frame directly, using the functiondata.frame().
suppose the second exam score for the third student had been missing.
[1] 2 there is no explicit loop in this version of our oddcount() .
for each one that you choose, you can take a look at the values of the  variables there.
[,1] [,2]  [1,] 1 1 [2,] 1 2
type `q()' to quit r. > the  x  q  x
you can get a stack report by typing "where".
the center of the string, in this case "b", would go at that point.
for example, if we wish to save as a pdf file, we do something like this: > pdf("d12.pdf") this opens a file, which we have chosen here to call d12.pdf .
this of course means that the person who wrote the class, knowing the r idiom, would have had the foresight of writing such a function in the class, knowing that people would expect one.
note that r definitely does have  graphics--tons of it.
even operators like + are really functions.
if speed is an  issue, such as when working with large data sets or long-running simulations,  one must avoid explicit loops as much as possible, because r can do them a lot  faster than you can.
a quick way to create the identity matrix of dimension d is diag(d) .
the ls() command will list all of your current objects.
[1] 2.333333 by the way, we use # to write comments, e.g. > y # print out
one can also use the subset() function for these kinds of  tasks: > goodexam2 = 62)
installation: choose an installation directory, say /myr.
other information on startup files, e.g. the file .rdata which records your workspace if you request it to be saved when you exit r, is available by typing help(.rprofile)
if we want r to stop doing that, we use detach(), e.g. > detach() > mean(exam3) error in mean(exam3) :
we could do the following.
for instance, say we wishy to be a two-component  vector with values 5 and 12.
to remove objects you no longer need, use rm().
the simplest just specifies two arguments, a y-intercept value and a  slope.
in fact, what happened above actually occurred at a more fundamental  level.
so, for instance, the above data would show that the third person in our  sample is not planning to vote for x, and did not vote in the last election.
suppose we have a  sequence of numbers for which we want to find successive differences, i.e. the  difference between each number and its predecessor.
but if our file had  contained any code not in a function, it would have been executed.
the last value computed will be returned by default.
it features a pop-up window in which  you can watch your progress as you step through your source code, gives you the  ability to easily set breakpoints, etc.
we use the functiondensity() to generate the estimates.
for example, type > help(sd) or ?
x2 0.4286 0.4857 1.1429 instead of lm(), we can use the "old" linear model function,lsfit() ("least squares fit").
note that we asked r to have blank labels for the figure as a whole and  for the x axis; otherwise, r would have gotten such labels fromd2 , which would have been specific to exam 2.
if we want to have a graph saved to a file, we must set up another  device.
the above set of operations to print a graph can become tedious if used a lot, so it makes sense to put them into a file.
i fixed that (i was on a linux system) by setting the environment variable, in my case by typing % setenv tcl_library /usr/share/tcl8.4 each time you wish to use debug, load it by executing > .libpaths("/myr") > library(debug) or, place these in an r startup file, say .rprofile in the directory in which you want these commands to run automatically.
[1] 8  9 > setequal(x,y)
they are nowhere near what a  good debugging tool offers, but with skillful usage they can be effective.
[1] true > 2 %in% x  [1] true >
here is an operator for the symmetric difference between two  sets (i.e. all the elements in exactly one of the two operand sets): > "%sdf%"  x %sdf%
say for instance the functionf() returns a matrix m and a vectorv.
you can make nicer labels, etc.
you can put any set of r commands in a file, say a.r, and  then have them automatically executed by typing source("a.r")
as mentioned, i've specified the variable names in the first record.
of course, r's functional programming features, described in our section  with that title, provide many ways to help us avoid explicit loops.
just click on download (cran).
you can use the lty parameter in plot() to specify the type of line, e.g solid, dashed, etc.
thus  people all over the world have written their own special-purpose r packages,  placing them in the cran repository.
[,1] [,2] [,3] [1,] 1 4 7  [2,] 2 5 8
it offers very short and quick entry into r.
now, we superimpose the fitted regression line onto that plot: > abline(fit1) the name of this function is meant to suggest, "draw a line with y intercepta and slope b."
3*y [,1] [,2] [1,] 3 9  [2,] 6 12 > y+y
[3,] 3 1 this is not just for compactness of code, but for speed.
thus the overall expression was w[c(f,t,t),], meaning to choose the second and third rows of w. without that final comman, indicating rows, r would have  given us an error message.
we could set  ourstatistic() function to dolm  boot(d,dolm,r=500) note that this example also illustrates the fact that boot() can indeed handle vector-valued statistics.
[,1] [,2] [1,] 1 3 [2,] 2 4
0.9389 12.0786 32.8163 coefficients: estimate std.
smoothing points: the lowess() function: just plotting a cloud of points, whether connected or not, may turn out to  be just an uninformative mess.
then at the r prompt, type > install.packages("mvtnorm","/a/b/c/") this will cause r to automatically go to cran, download the package, compile it, and load it into a new directory/a/b/c/mvtnorm.
[1] 0.028 0.000 0.027 0.000 0.000 > system.time(sim2(1000))
for instance, let's rewrite the function oddcount() that  we wrote above: > oddcount  rr  oddcount(rr)
but the graphics are for the output, e.g. plots, not for the input.
if for instance we had wanted to find the mean score on exam  2, r would find the mean among all students except the third.
in many cases, it is better to smooth out the  data by fitting a nonparametric regression estimator, such aslowess() : plot(lowess(x,y))
text(2.5,4,"abc",cex = 1.5) would print the same text as in our earlier example, but with characters  1.5 times normal size.
k == 5, issue bp(12,k==5).
as another example, let's plot nonparametric density estimates (these are  basically smoothed histograms) for exams 1 and 2 from ourexams file in our section titled "a second r session"  above in the same  graph.
there are many excellent tutorials on r on the web, some of which i list in the section titled"help on the web below.
then at the r prompt, type > install.packages("mvtnorm","/a/b/c/") this will cause r to automatically go to cran, download the package,  compile it, and load it into a new directory/a/b/c/mvtnorm.
insufficiently  explained in many tutorials, and understanding it will enable you to much more  easily learn new r features later on.
we could also close the device by exiting r, though it's probably better to proactively close.)
i will discuss some of the simpler usage forms here.
at this point, you can single-step through your code by repeatedly  hitting the enter key.
the  current line will be highlighted in green.
but if the argument to the call is a regression object, e.g.fit1 above, then abline() knows to use the regression  coefficients as the intercept and slope of the line to be drawn.
you can set finer breakpoints, at the line level, using bp() .
for example, type > help(sd) ?
and as you long as you answer yes to the question "save workspace image?" put to you when you quit the session, r will save all the objects you created in that session, and restore them in your next session.
the internal linear storage of a matrix is incolumn-major order, meaning that first all of column 1 is stored, then all of column 2, etc. one of the ways to create a matrix is via the matrix() function, e.g. > y  y
if you want to know how to  read data into r from a file, or how to manipulate data frames, i may have the  answer here.
(as will be its documentation.
session data: as you proceed through an r session, r will record which commands you  submit.
if there are r commands you would like to have executed at the beginning of every r session, you can place them in a file.
the coefficients themselves  are accompanied within the object by their names, and when we print the  coefficients r knows to print the names with them.
subtracting these two vectors then gave us the  differences we wanted.
i must confess to being a non-spreadsheet user.
and as you long as you answer yes to the question "save workspace  image?"
first we must define a function which defines the statistic we wish to compute, which in this case is the median.
or, if we wish, we can get a ton of information in one fell swoop, the way we do in other statistical packages: > summary(fit1) call: lm(formula =
you can use the matrix  transpose functiont() to change it.
often we will just callplot() first to create the x and  y axes of the graph, and their labels, and then add to it with subsequent calls  to various functions.
inf if you want to see all of  them.
then we would run > lgt  summary(lgt)
error t1* 5 0.2375  1.708637 normally, we would assign the result of boot() to an  object, as we did withb above.
[5,] 2 2 > table(ct[,1],ct[,2]) 1 2 1 1 1 2 0 2 3 1 0
also, a nice feature is that you can edit functions from within r.
[1] "abc1.5def" during a session, you can scroll back and forth in your command history by typing ctrl-p and ctrl-n. you can also use thehistory() command to list your more recent commands (which will be run through thepager).
[1] 1 5 > setdiff(x,y)
packages (libraries): basic notions: r uses packages to store groups of related pieces of software.
getting a response which contains this excerpt: mvrnorm(mass) simulate from a multivariate normal distribution this tells us that the function mvrnorm() will do the job, and it is in the packagemass.
r has the notion of a graphics device.
[1] true false true true evaluation of the expression z*z > 8 gave us a vector of booleans!
thus people all over the world have written their own special-purpose r packages, placing them in the cran repository.
say the second column is  the sole predictor variable.
there are set operations, e.g. > x  y  union(x,y)
(if you do not already have r installed, go first to the section below titledhow to obtain/install r.)
the cex() ("character expand") function allows you to expand or shrink characters within a graph, very useful.
note also the : operator: > 5:8
we load that package, and usehelp() to see what's in  it, in this case various data sets.
all graphics output will now go to this file  instead of to the screen.
this is handy if you're using a function that you've written but have  forgotten what its arguments are, for instance.
as an example, suppose you wish to use the mvtnorm package, which computes multivariate normal cdf's and other quantities.
return values: by the way, you don't need the return().
revelle of the dept. of psychology of northwestern  university; especially good for material on multivariate statistics and  structural equation modeling a rough form of john verzani's book, simpler ; nice coverage of  various statistical procedures a large general reference by vincent zoonekynd; really excellent with as  wide a statistics coverage as i've seen anywhere a nice page on r oop draft of john maindonald's book; he also has scripts, data etc.
you can return to the > prompt by typing q.
then one could write return(list(mat=m, vec=v))
so, when someone develops a new r class for others to use, we can try to apply, say, summary() and reasonably expect it to work.
use t() for matrix transpose.
[1] 1 > v [1] 2 > y error: object "y" not found x + y addition x - y subtraction x
this is especially useful if you will be displaying several curves in the  same graph.
we can load any of them but typing its  name, e.g. > lakehuron string manipulation: r has a number of string manipulation utilities, such as paste() , sprintf(), substr() and strsplit.
when you perform a regression analysis with other  statistical packages, say sas or spss, you get a mountain of output.
in the example above, instead of writing return(k) we could simply write k this is true for nonscalars too (recall that a scalar is really a  one-element vector anyway), e.g.: > r  r(3,2)
this one won't be very pretty,  but r has all kinds of bells and whistles you can use optionally.
[1] 0.832 but as noted in the section titled "writing efficient r code",  you should try to use r's built-in features for greater speed.
saving graphics (and other) command sequences to files: it may be very useful to save your graphics commands to a file.
#  generate 100 n(0,1) variates and plot their histogram dev.off() # close the file we could run it automatically by simply typing r cmd batch --vanilla  x
(in excel, one can export to this format.)
for instance, let's apply the function for rounding to the nearest integer to an example vectory: > y  z  z [1] 1 4 0
so you can see that the evaluation of z[z*z > 8] first produced a vector of booleans, which we then applied in a slicing operation in z.
as you proceed through an r session, r will record which commands you submit.
remember, one can always print an object in r by simply typing its name, so let's print out the third element ofx : > x[3]
set the named argumentmax.show=
just type $ yum install r you can also probably do something like this in ubuntu linux, etc.
[,1] [,2] [1,]  1 4 [2,] 2 5
see our section titledadding more rows and columns for more information on this function.
the total length of this  document in its entirety is not short, but the 5- and 10-minute introductory  sessions below are designed so that you will be using r within minutes.
in  s, packages are calledlibraries, and many of the functions which deal  with them are different from those in r.
objects as a uniform interface: as mentioned in my introduction, r is rather polymorphic, in the sense  that the same function has different operation for different classes.
the coefficients themselves are accompanied within the object by their names, and when we print the coefficients r knows to print the names with them.
our variable names didn't have any embedded spaces in this case, but if they had, we'd need to quote any such name.
to remove the latter, we use the as.numeric() function: > w[1] %*% as.numeric(lmout$coefficients)
if we answery, then the next  time we run r, all those objects will automatically be loaded.
and if w[1] itself had names attached to it, we'd need to use as.numeric() on it too.
you can check which packages are currently loaded by typing > .path.package()
inside that package is a function, boot(), which will do the work of bootstrapping.
when browser() is called, you do indeed enter the browser (if you had not already entered it viadebug()), and can proceed as described above.
to avoid single-stepping, issue go().
since we specified the matrix entries in the above example, we would not  have need to specifyncol; nrow would be  enough.
the function is supposed to count the number of odd numbers in its argument vector.
i fixed that (i was on a linux system) by  setting the environment variable, in my case by typing % setenv tcl_library /usr/share/tcl8.4 each time you wish to use debug, load it by executing > .libpaths("/myr") > library(debug) or, place these in an r startup file, say .rprofile in  the directory in which you want these commands to run automatically.
(r can also use .csv files, from spreadsheets.
here's what we did: first, we computed nonparametric density estimates from the two variables, saving them in objectsd1 and d2 for later use.
this would have the same effect as placing the command browser() in our source code for gy(), but would be quicker  and more convenient than inserting such a line, saving the file and rerunning source() to load in the new version of the file.
no such help is needed here, but you will see the need later in oursecond example.)
d(1)> bp(12) d(1)> ?
(again, it won't be very fancy for the  time being, since we are using default values, but you can make it fancy with  some added commands when you learn more about r.)
[,1] [,2] [1,] 2 6 [2,] 4 8 note that for matrix multiplication in the mathematical sense, the operator to use is%*%, not *.
for  example, we could put the above commands in a file,testscores.r , with contents d1 = density(testscores$exam1,from=0,to=100)
back in the r interactive window,  you'll see a promptd(1)>.
in other words, in the first iteration,n = x[1], in the second iterationn = x[2], etc. looping with while and repeat are also available, complete withbreak, e.g. > i  while(1) { + i  10) break + } >
[1] 5 12 here is a more involved example of this principle.
then install mvbutils, then debug: > install.packages("mvbutils","/myr")
if you can't live without  guis, you should consider using one of the free guis that have been developed  for r, e.g. r commander or  jgr.
we now have two devices open, as we can confirm: > dev.list() x11 pdf 2 3 our first device, the screen, is named x11 when r runs on unix; it is device number 2.
r has functions available for various aspects of most of the famous statistical distributions prefix the name byd for the density, p for the c.d.f., q for quantiles and r for simulation.
[,1] [,2] [1,] 1 4 [2,] 3 6 another idea borrowed from functional programming is filtering of vectors, e.g. > z  w  8] > w [1] 5 -3 8
[1] 1 2 4 yep, sure enough, x consists of the numbers 1, 2 and 4.
the ones automatically loaded when you start r  include thebase subdirectory, but in order to save memory and  time, r does not automatically load all the packages.
[1] 7 2 13 21 24 warning message: longer object length is not a multiple of shorter object length in: c(1, 2, 4) + c(6, 0, 9, 20, 22)
but you may find the locator() function to be a much  quicker way to go.
another way we could have built y would have been to  specify elements individually: > y  y[1,1] = 1 > y[2,1] = 2 >  y[1,2] = 3 > y[2,2] = 4 >
[1] 5 1 the syntax for if-else is like this: > if (r == 4) { + x  u
consider, for instance, this: > x  y  y
introduction to r data files and frames: as my sample data set, i have created a file named exams,  consisting of grades for the three exams in a certain course (two midterm exams  and a final exam).
so, for instance, the above data would show that the third person in our sample is not planning to vote for x, and did not vote in the last election.
the resulting new frame would be fed into nrow(), the function that counts the number of rows in a  frame.
here is what happened above: we asked r to find all the elements of z whose squares were greater than 8, and then form a new vector from them (which we assigned tow).
for instance, instead of retrieving the means of the three variables individually, by callingmean() on each vector, we can get the whole group of means via one single command: > colmeans(testscores) exam1 exam2 exam3 62.14545 51.27273 50.05455
this is one of the very few differences between r and s. in s, packages are calledlibraries, and many of the functions which deal with them are different from those in r.
[3,] 3 1 applying the same function to all rows or all columns of a matrix/data  frame: this is not just for compactness of code, but for speed.
for instance, in our earlier example data frame testscores from our second 5-minute example above: testscores[2,3] would refer to the third score for the  second student testscores[2,] would refer to the set of all scores for  the second student testscores[c(1,2,5),] would refer to the set of all  scores for the first, second and fifth students testscores[10:13,] would refer to the set of all scores  for the tenth through thirteenth students testscores[-2,] would refer to the set of all scores for  all studentsexcept the second creating data frames with the functions data.frame() we saw in our 10-minute introduction above how to create a data frame by  reading from a data file.
we then called plot() to draw the  curve for exam2.
the first argument to lsfit() is a matrix of the predictor variable data, with the ith row consisting of observation number i in our sample.
look carefully at what is happening here.
[1] 4 1 3 the point is that x didn't change.
but alternatively you can specify the predictors as a matrix, e.g. > z  lm(z[,1] ~ z[,2]+z[,3]) call: lm(formula =
again we see polymorphism at work.
exam3 ~ exam1, data = testscores)
you can use it as a named parameter in various graphing functions.
the ones automatically loaded when you start r include thebase subdirectory, but in order to save memory and time, r does not automatically load all the packages.
an index i here would tellboot() that the basic datum is a row, d[i,].
[1] 3 the function solve() will solve systems of linear equations, and even find matrix inverses.
in that second command, the notation m:n means all the integers between m and n inclusive, e.g. > 3:8 [1] 3 4 5 6 7 8 note carefully that duplicates are definitely allowed, e.g. > x  y  y
for a  data frame, for example, these will be the names of the columns.
it may be very useful to save your graphics commands to a file.
note that i have separated fields here by spaces.
variates [1] 1.938179 > qchisq(0.95,1) find 95th percentile of chi-square(2)  [1] 3.841459 there are also functions for the normal distribution, the t, the binomial.
to quit, issue qqq().
then type > mtrace(f) do this for each function at which you want a breakpoint.
seethe section titled "r programming below.
well, that's the end of this first 5-minute introduction.
for instance, say we wishy to be a two-component vector with values 5 and 12.
using r from python (and vice versa footnotes why you should use r: why use anything else?
the latter is searched for such a file first, which allows you to customize for  a particular project.
"its virtues: i should warn you that one submits commands to r via text, rather than mouse clicks in a graphical user interface (gui).
recall that for instance  in ourour section titled "a second r session" above, we first created  a scatter plot and then later superimposed the fitted regression line onto the  same graph.
the above code  would be better written > x  length(x[x  system.time(sim1(1000))
so, when  someone develops a new r class for others to use, we can try to apply, say, summary() and reasonably expect it to work.
the pager: this displays material one screen at a time.
of  course, we can add labels to the table and do various statistical analyses on  it, not covered here.
urn 1 contains 10 blue marbles and eight  blue ones.
let's go further: > z[c(true,false,true,true)]
remember, one can always print an object in r  by simply typing its name, so let's print out the third element ofx : > x[3]
[4,] 4 0 0 > cbind(one,z) one
professor norm matloff dept. of computer science university of california at davis davis, ca 95616 why use anything else?
the last value  computed will be returned by default.
one of the tools r offers for debugging your r code is debug() .
and (b) "did you vote in the last  election?"
put to you when you quit the session, r will save all the objects  you created in that session, and restore them in your next session.
for instance, say we wish to set a  breakpoint at the beginning of the functiongy().
specifying many predictor variables in lm(): the "a ~ b+c+..." notation for specifying a response variable a  and predictor variables b, c, ... is usually nice, but sometimes troublesome if  you have many predictors or you are writing r programs.
if you can't live without guis, you should consider using one of the free guis that have been developed for r, e.g. r commander or jgr.
using r from python (and vice versa): r functions can be called from python, and vice versa, using the rpy  package.
the default device is the screen.
an object consists of a gathering of various kinds of information, with  each kind being called anattribute.
the resulting new frame would be fed into nrow(), the function that counts the number of rows in a frame.
matrix subscripts begin with 1, so for instance the upper-left corner of the matrixa is denoted a[1,1].
we can load any of them but typing its name, e.g. > lakehuron r has a number of string manipulation utilities, such as paste() , sprintf(), substr() and strsplit.
[1] 12 15 18 21 24 27 30  > seq(1.1,2,length=10)
adding points: the points() function: the points() function adds a set of (x,y)-points, with  labels for each, to the currently displayed graph.
after we finally entered a  right brace to end the function body, r resumed the > prompt.
this can be especially useful for graphics functions.
not only does this save you programming time, it produces  faster code, since r's functions have been written for efficiency.
i [1] 13 (of course, break can be used with for too.)
it requires another package, mvbutils, and the tcl/tk scripting and graphics system.
look at it here: > '+'(y,4)
[1] 1 the operation still works, because the number 1.2 is actually considered  to be a vector, that happens to consist of a single element 1.2.
the net effect would be to report a count ofz =
once you do so, r  will tell you the exact coordinates of the point you clicked on.
you may wish to have the ranges on the x- and y-axes of your plot to be broader or narrower than the default.
[,1] [,2] [1,] 1 3 [2,] 2 4 note that when we then printed out y, r showed us its notation for rows and columns.
for instance, you know that you can use theplot() function on just about any object produced by r.
the same is true forprint() and summary().
r version 2.5.0, i found that a bug in r caused the debug package to fail.
[,1] [,2] [1,] 0.5 0.5 [2,] -0.5 0.5 writing a data frame to a file: the function write.table() works very much like read.table().
for example, here we apply the built-in r function mean() to each column of a matrixz.
the table shows that we had, for example, one person who said not sure to (a) and yes to (a), and two people who answered no to both questions.
adding more rows or columns to a matrix/data frame: the rbind() and cbind() functions enable  one to add rows or columns to a matrix or data frame.
the suffix of the name indicates the distribution,  such asnorm, unif, chisq, binom, exp, etc. e.g. for the chi-square distribution: > mean(rchisq(1000,different=2)) find mean of 1000 chi-square(2)
use the apply() function.
for a  regression object, these will be "coefficients",  "residuals" and so on.
* y multiplication x / y division x ^  y exponentiation x %% y mod arithmetic x %/% y integer division x
we could set ourstatistic() function to dolm  boot(d,dolm,r=500) note that this example also illustrates the fact that boot() can indeed handle vector-valued statistics.
here are some that i find useful: general introductions: one by prof. wm.
[2,] 31 32 > y[2:3,2]
at  illinois state university draft of an r-simulation based textbook on statistics, by shravan  vasishth especially good for reference purposes: one at cal tech, complete with an index!
the same operations we discussed in our section above titled "vector slicing" apply to matrices.
i noted in our introductory section, why you should use r, that using the nrow() function in conjunction with filtering provides a way to obtain a count of records satisfying various conditions.
y [,1] [,2] [1,] 7 15 [2,] 10 22 >
the debug package provides a more usable debugging interface than r's built-in facilities do.
again we see  polymorphism at work.
see  the material on .csv files below  for details.)
here we concatenated what we intended as the first column, the numbers 1  and 2, with what we intended as the second column, 3 and 4.
residuals: min 1q median 3q max -42.9132 -11.0895
we can add columns, i.e. new variables, to the data frame.
error t value pr(>|t|) (intercept) 3.70088  6.52037 0.568 0.573 exam1 0.74589 0.09877 7.552 5.85e-10 *** --- signif.
z[, c(2, 3)]1 z[, c(2, 3)]2 -1.6779 2.4899 -0.3221
(without specifyingtype="l", only the  points would have been plotted.)
among the components of that  object areb$t, which is a matrix whose i-th row gives the  value of the statistic as found on the i-th bootstrap resampling, and b$t0, which is the value of our statistic on the original data set.
in that second call to lm(), we just specified the matrix consisting of the second and third columns ofz, implicitly saying that these columns are our predictors.
that is accessible fromr home page, but it's easier to use theinstall.packages() function.
this function will be called by boot() (it is named statistic() in the list of boot()'s formal parameters).
[1] 62 74 50 62 39 60 48 80 49 49 100 30 61 100 82  37 54 65 36
the latter is searched for such a file first, which allows you to customize for a particular project.
do you see what happened in that last action?
( see note library below.)
3*y [,1] [,2] [1,] 3 9 [2,] 6 12 > y+y
say for instance we perform a linear  regression analysis by callinglm(), assigning the result to lmout.
then we may not be able to simply take their inner products  with the coefficient vector, e.g. > w[1] %*% lmout$coefficients may be rejected by r.
we can apply slicing to a matrix instead of just a vector.
these are  interpreted as (x,y) pairs representing points to be added to the current  graph, with lines connecting the points.
note, though, that if you want to single-step after  hitting a breakpoint, you must typen for the first step,  though you can just hit the enter key for subsequent steps.
so, you can see that the data frame testscores is a way  of packaging the vectors of values of the individual variables, plus the  associated variable names.
[2,] 11 12 >  x[sample(c(1,2,3),2), ]
more on vectors, arrays and matrices: type issues: you must warn r ahead of time that you instead a variable to be one of  these types.
the term object-oriented can be explained by example, say statistical regression.
however, the package you want may not be in your r installation.
of course, r's functional programming features, described in our section with that title, provide many ways to help us avoid explicit loops.
the "a ~ b+c+..." notation for specifying a response variable a and predictor variables b, c, ... is usually nice, but sometimes troublesome if you have many predictors or you are writing r programs.
the advantage of this is that if we ever wanted to rerun this sequence of  commands, say with a slightly different set of parameters, we need only edit  the filetestscores.r to reflect the parameter changes and then  run as above.
r has no "undo" command  (though theess interface to r described below does).
you can put any set of r commands in a file, say a.r, and then have them automatically executed by typing source("a.r") r uses packages to store groups of related pieces of software.
note that if you do not specifyxlim and/or ylim, then draw the largest curve first, so there is room for all of  them.
first the subset() function would take the data frame x03, and cull out all those records for which the variable z has the value 1.
in fact, what happened above actually occurred at a more fundamental level.
as you can see, the function to be applied needs at least one argument,  which will play the role of one row or column in the array.
for instance,dnorm() gives the normal density, pnorm() gives the normal cdf and rnorm() generates  normally-distributed random variates.
for instance, suppose you wish to generate  multivariate normal random vectors.
though there are many options, the two basic arguments to lines() are a vector of x values and a vector of y values.
[1] 2.333333 these of course are especially useful when writing programs (see our the section titled "r programming below), but they are useful for interactive use too, since r does record your commands (see"session data" below).
when you perform a regression analysis with other statistical packages, say sas or spss, you get a mountain of output.
but you may find the locator() function to be a much quicker way to go.
[,1] [,2]  [1,] 11 12 [2,] 21 22
an object consists of a gathering of various kinds of information, with each kind being called anattribute.
as with most of the other graphics functions, there are lots of options, e.g. point color, background color, etc.
the first record of the.csv file has the names of the variables.
the line + for (n in x) { will again instantly be recognized by python programmers.
the debug package: the debug package provides a more usable debugging  interface than r's built-in facilities do.
as two-dimensional arrays: one can refer to the rows and columns of a data frame using  two-dimensional array notation.
see our section titledadding more rows and columns  for more information on this function.
the trace() function is quite flexible and powerful, though it takes some initial effort to learn.
in that second command, the notation m:n means all the integers between m  and n inclusive, e.g. > 3:8 [1] 3 4 5 6 7 8 note carefully that duplicates are definitely allowed, e.g. > x  y  y
if for instance we had wanted to find the mean score on exam 2, r would find the mean among all students except the third.
logistic regression is handled as a special case of the generalized linear model.
for a data frame, for example, these will be the names of the columns.
before you loadedmass,  "help(mvrnorm)" would have given an error message).
>  install.packages("debug","/myr") r version 2.5.0, i found that a bug in r caused the debug package to fail.
for instance,[,2] means column  2, as can be seen in this check: > y[,2] [1] 3 4 as you can see, a matrix is really a vector, with extra atributes, the  number of rows and columns.
graphing explicit functions: say you wanted to plot the function g(t) =
often we will just callplot() first to create the x and y axes of the graph, and their labels, and then add to it with subsequent calls to various functions.
note also that a vector is considered a one-row matrix, not a one-column matrix, and thus is suitable as the left factor in a matrix product, but not directly usable as the right factor.
then when f() is executed, you enter the debugger, termed thebrowser in r.
[3,] 31 32 >  x[sample(c(1,2,3),2), ]
for specific online help, invoke help().
for example, in testscores, we can add a variable which is the difference  between exams 1 and 2: > testscores$diff21  attach(testscores)
if we had wanted to regress exam3 against both exam1 and exam2, we would  issue the following command: > fit12  plot(c(1,2,3), c(1,2,4)) plots the points (1,1), (2,2) and (3,4).
if you need a package which is in your r installation but not loaded into memory yet, you must request it.
in some cases, you will need additional arguments, which you can place following the function name in your call toapply().
sd to get information on the sd() function.
one can define functions, use constructs such as loops and conditionals, etc.
if we want to have a graph saved to a file, we must set up another device.
if you've done this, then after a crash run > debugger() you will then be presented with a choice of levels of function calls to look at.
if we have an estimator but no standard error, we get one by resampling from our sample data many times, calculating the estimator each time, and then taking the standard deviation of all those generated values.
to use the package, you must first load it: > library(boot)
%% y mod arithmetic x %/% y integer division x
some nice tutorial material by prof. marasinghe at iowa state; see the  sections titled "programming in r," more programming in r,"  "writing r functions," etc.
the suffix of the name indicates the distribution, such asnorm, unif, chisq, binom, exp, etc. e.g. for the chi-square distribution: > mean(rchisq(1000,different=2)) find mean of 1000 chi-square(2) variates [1] 1.938179 > qchisq(0.95,1) find 95th percentile of chi-square(2)
[1] "abc1.500000def"  > sprintf("abc%gdef",1.5)
let's now make a scatter plot of the original exam1-exam3 data, together with the fitted regression line.
our current device is now the pdf file (which we could confirm by calling dev.cur()).
for instance, if x and y are the vectors  (1.5,2.5) and (3,), then the call > lines(c(1.5,2.5),c(3,3)) would add a line from (1.5,3) to (2.5,3) to the present graph.
[1] 1 2 5  8 9 > intersect(x,y)
the fact that r uses column-major order then determined where these four numbers were put.
the call sample(c(1,2,3),2) tells r to take a sample of size 2 without replacement (the default) from  c(1,2,3).
the names() function will tell us the names of the attributes of the given object.
(you do not need to have read that section to follow the material  here.)
usage: now you are ready to debug.
suppose we then want to use one of those components as numerical input into another operation.
[20] 97 60 80 70 50 60 24 60 75 77 71 25 93 80 92 75 26 27 55
in our  example above, we would call it this way: > fit1  ls.print(fit1) to regress exam3 against exam1 and exam2, we would type: > fit12   lsfit(cbind(testscores$exam1,testscores$exam2),testscores$exam3)
r faq, mainly aimed at programmers reference manual, by several prominent people in the r/s community a nice tutorial on debugging in r, with more detailed examples than i  have here on graphics: a slide-show tutorial on r graphics, very nice, easy to follow, lots of  color; by m. nelson of esperion therapeutics an extensive r graphics tutorial, by vince carey of the harvard  biostatistics dept. an extensive r graphics tutorial, by the r core development team the r graphics gallery, a collection of graphics examples with source code web page for the book, r graphics, by paul murrell; chapters 1, 4  and 5 are available there, plus all the figures from the book and the r code  which generated them searching r issues: various r search engines are listed in the the r home page; click on  search.
if you want to know how to do principal components analysis in r,  you'll need to try one of the other tutorials that i link to below.
[1] 1 3 0 2 the form is ifelse(some_vector_filtering_expression,b,c) where some_vector_filtering_expression is of the form in section titled"filtering" above, and b and c are constants.
(see "for further information" below for an explanation of how you might find that this is the function we want.)
[y/n/c]: n that last question asked whether we want to save our variables, etc., so  that we can resume work later on.
for instance, if you have a long vectorx and wish to display it one screen at a time, then instead of typing > x type > page(x) set the hit q to quit the pager, type "/abc" to search for the string "abc" in the pager output, etc.
r is capable of reading.csv files.
other information on startup files, e.g. the file .rdata which records your workspace if you request it to be saved when you exit r, is  available by typing help(.rprofile)
to do this, type > set.seed(8888) # or your favorite number as an argument startup files:
[1] 2.333333 these of course are especially useful when writing programs (see our the  section titled "r programming below), but they are useful for interactive  use too, since r does record your commands (see"session data" below).
say for instance  the functionf() returns a matrix m and a  vectorv.
[1] 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.0 though it may seem innocuous, the seq() function provides  foundation for many r operations.
if single-stepping is too tedious, an alternative is to place breakpoints, by simply inserting the call browser() at the points at which you wish execution to pause.
(the function abline() can take on various forms of  arguments.
[1] 3 > oddcount(c(1,2,3,7,9))
if you try > y[1]  y[2]  y  y[1]  y[2]  y  c(1,2,4) + c(6,0,9,20,22)
consider the filez.r: pdf("xh.pdf") # set graphical output file hist(rnorm(100)) # generate 100 n(0,1) variates and plot their histogram dev.off() # close the file we could run it automatically by simply typing r cmd batch --vanilla
say our data is in a matrixx, whose first column  consists of 0s and 1s and forms the response variable.
help on the web: for more information on graphics, the command ?
[,1] [,2] [1,] 1 4 [2,] 2 5
there are precompiled binaries for windows, linux and macos x at the r home page.
our  variable names didn't have any embedded spaces in this case, but if they had,  we'd need to quote any such name.
by the way, you don't need the return().
the comments then help you remember what you were doing when you read the  record.
then you can invoke various debugging operations, such as: to turn off debugging for that function, type > undebug(f) note that if you simultaneously have a separate window open in which you are editing your source code, each time you reload it usingsource() , the debugging status is lost.
just plotting a cloud of points, whether connected or not, may turn out to be just an uninformative mess.
loops: the line + for (n in x) { will again instantly be recognized by python programmers.
the function is supposed to count the number of odd numbers in its  argument vector.
consider the filez.r: pdf("xh.pdf") # set graphical output file hist(rnorm(100))
(i'm assuming that your program  itself consists of a function.)
the bootstrap is a resampling method for performing statistical inference in analytically intractable situations.
say the second column is the sole predictor variable.
[1] 5.2 7.9 4.4 you can also do "slicing" of arrays, picking out elements with specific indices, e.g. > y[c(1,3)]
for example: > a  b  solve(a,b)
that was our data in linear form, and then we specified the number of rows and columns.
for instance,  you can change the number of bins by specifying thebreaks variable;hist(z,breaks=12) would draw a histogram of the data z with 12 bins.
also, if you  prefer the more sophisticated kernel method for estimating a density, r offers  thedensity() function, an example of which is in our section  below titled"plotting multiple curves, using the lines() function ".
the expression x[-1] gave us the vector (15,8,11,24) and x[-length(x)] gave us (12,15,8,11).
recall  too that these boolean constants in r can be abbreviated t and f. performing checks after a crash with the traceback() and debugger()  function: say your r code crashes when you are not running the debugger.
the functionmvrnorm() in the packagemass does this.
the point is that the round() function was applied  individually to each element in the vectory.
this displays material one screen at a time.
just write a function whose name begins  and ends with %.
say for instance we perform a linear regression analysis by callinglm(), assigning the result to lmout.
the expression w[,2] > 4 gave us the vector c(f,t,t).
here is a slightly more complicated example, using a classical problem from elementary probability courses.
to read your dataset into your r space, issue the command d  help.start() r will then invoke a default web browser.
[1] 0.028 0.000 0.027 0.000 0.000 >  system.time(sim2(1000))
the first time we did this, the result of that call was the vector (3,1).
the comments then help you remember what you were doing when you read the record.
[1] 0.832 but as noted in the section titled "writing efficient r code", you should try to use r's built-in features for greater speed.
[3,] 31 32 > x[sample(c(1,2,3),2), ]
the latter reads an ascii data file, and the former  writes one.
this function is sometimes more convenient to use when writing r programs.
we can also create a data frame directly, using the  functiondata.frame().
however, you can change them, e.g. > z x1 x2 1 1 3 2 2 4 > names(z)  z col 1 col 2 1 1 3 2 2 4 consider the data matrix 1 1 1 2 2 2 3 1 2 2 where in the usual statistical fashion each row represents one subject under study.
[1] 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.0 though it may seem innocuous, the seq() function provides foundation for many r operations.
but you can learn a lot from tutorials on the web.
[1] 3.841459 there are also functions for the normal distribution, the t, the binomial.
example: > one [1] 1 1 1 1 > z
in our example above, we would call it this way: > fit1  ls.print(fit1) to regress exam3 against exam1 and exam2, we would type: > fit12  lsfit(cbind(testscores$exam1,testscores$exam2),testscores$exam3)
[1] 0.832 > count/1000.0
par will give you documentation on the various graphics parameters, but it is rather overwhelming.
[1] 4  1 3 the point is that x didn't change.
in the case above, i could changef1() by typing > f1  x1  x2  y  lm(y ~ x1+x2) call: lm(formula =
if you want to install to a nonstandard directory, say /a/b/c, run configure as configure --prefix=/a/b/c there is a very popular package which allows one to run r (and some other statistical packages) from within emacs,ess.
this quantity is easy to find analytically, but we'll use simulation.
[1] 5.2 7.9 4.4 vector slicing: you can also do "slicing" of arrays, picking out elements with  specific indices, e.g. > y[c(1,3)]
to do this, type > set.seed(8888) # or your favorite number as an argument
further details are described in  an article by the author of boot() in  the december 2002 issue ofr news.
[1] 5 6 7 8 > seq(12,30,3)
[1] 5 1 if-else: the syntax for if-else is like this: > if (r == 4) { + x  u
footnotes: note library:
a more functional debugging package available for r, of course called debug.
you then pick and choose which parts of that object to extract, as you wish.
the file contents in that directory gives brief descriptions of each entity.
though the terms object-oriened and functional programming may pique the interests of computer scientists, they are actually quite  relevant to anyone who uses r.
yet at the same time we can  work them as numbers; r will be smart enough to leave the names out of things  then.
to "browse," go to the place in your r directory tree where the  base is stored.
suppose i wish to create five files, q1.pdf through q5.pdf, consisting of histograms of 100 random n(0,i2) variates.
it's also useful if you are not  quite sure what an r library function does; by looking at the code you may  understand it better.
the help is piped through the pager.
(unix users will recognize the similarity to  unix shell pipe commands.)
note that we asked r to have blank labels for the figure as a whole and for the x axis; otherwise, r would have gotten such labels fromd2 , which would have been specific to exam 2.
we could get a number of plots related to this fit by typing plot(fit1)
we can perform various operations on matrices, e.g. matrix multiplication, matrix scalar multiplication and matrix addition: > y %*%
my tutorial is concerned mainly with general r operations, rather than  the details of the specific statistical procedures.
the default device is the  screen.
you can also use this to selectively change elements of a vector, e.g. > x  x[x > 3]  x
this is nice, since it means that you, as a user, have fewer commands to remember!
the above code would be better written > x  length(x[x  system.time(sim1(1000))
just write a function whose name begins and ends with %.
for instance,[,2] means column 2, as can be seen in this check: > y[,2] [1] 3 4 as you can see, a matrix is really a vector, with extra atributes, the number of rows and columns.
at the end of the function, and then have the caller access these items like this: l  print("abc")
in its simpler form, arguments  are the matrix to be applied to, the dimension--1 for rows, 2 for columns--and  the function to be applied.
we used r's vector filtering to avoid a loop, and even though r internally will loop through the array, it will do so much faster than we would with an explicit loop in our r code.
of course, we could get both the cloud and the smoothed curve: plot(x,y) lines(lowess(x,y))
there is still a debugging tool available to you after the fact: you can do a "post mortem" by simply callingtraceback().
(see "for further  information" below for an explanation of how you might find that this is  the function we want.)
if a name contains a blank, the name must be quoted.
here we will do some multivariate analysis, and also introduce data frames, which allow a richer structure than simply using individual vectors.
recall that for instance in ourour section titled "a second r session" above, we first created a scatter plot and then later superimposed the fitted regression line onto the same graph.
the plot() function works in stages, i.e. you can build up a graph in stages by giving more and more commands.
e.g.: > f1  f2  f  f(3,2)
[,1] [,2] [1,] 31 32 [2,] 11 12 > x[sample(c(1,2,3),2), ]
you do have to tell r where to find that package, though, which you can do  via the.libpaths() function: > .libpaths("/a/b/c/")
would assign all of your objects to list, thus removing  everything.
how to obtain/install r:
for example, the reason why  elementwise addition of 4 works here, > y+4 [1] 5.2 7.9 4.4 is that the + is actually considered a function!
thus the overall expression was w[c(f,t,t),], meaning to choose the second and third rows of w. without that final comman, indicating rows, r would have given us an error message.
they can be abbreviated tot and f, but must  be capitalized.
we draw a marble at random from urn 1 and transfer it to urn 2, and then draw a marble at random from urn 2.
say for example we suspect that our bug is in the functionf().
" its virtues: it's a public-domain implementation of the widely-regarded s statistical  language; r/s is thede facto standard among professional statisticians open-software nature means it's easy to get help from the user community,  and lots of new functions get contributed by users, many of which are prominent  statisticians comparable, and often superior, in power to commercial products in most  senses available for windows, macs, unix/linux in addition to enabling statistical operations, it's a general  programming language, so that you canprogram your more complex tasks object-oriented and functional programming structure your data sets are saved between sessions, so you don't have to reload  each time i should warn you that one submits commands to r via text, rather than  mouse clicks in a graphical user interface (gui).
for instance, in oursecond  5-minute example above: points(testscores$exam1,testscores$exam3,pch="+") would superimpose onto the current graph the points of the exam scores  from that example, using "+" signs to mark them.
for a regression object, these will be "coefficients", "residuals" and so on.
the call tolines() then adds the second curve.
there are entire books on r/s+ graphics.
y test for  equality x =
you thus do not have to recreate the objects again from scratch if you wish to continue work from before.
for instance, if x and y are the vectors (1.5,2.5) and (3,), then the call > lines(c(1.5,2.5),c(3,3)) would add a line from (1.5,3) to (2.5,3) to the present graph.
note that as described here, the breakpoints are hard-coded into the  function's source code.
our pdf file is device number 3.
[,1] [,2] [,3] [1,] 1 4 7
[1] 2 8 9 try to avoid writing large loops, instead of having r's rich functionality do the work for you.
this would have the same effect as placing the command browser() in our source code for gy(), but would be quicker and more convenient than inserting such a line, saving the file and rerunning source() to load in the new version of the file.
logistic regression: logistic regression is handled as a special case of the generalized linear  model.
i will discuss this below.
for instance, say we wish to set a breakpoint at the beginning of the functiongy().
example--creating a histogram: as the last action in this quick introduction to r, let's have r draw a  histogram of the data: > hist(x) a window pops up with the histogram in it.
once you are in f(), for instance, to set a  breakpoint at line 12 in that function type d(1)> bp(12) to set a conditional breakpoint, say at line 12 with the condition
we first read in the data from the file exams into a data  frame which we'll nametestscores: > testscores  testscores$exam1
we could do  this by the command > trace(gy,browser)
[1] 1 3 0 2 combining elementwise operations and filtering, with the ifelse() function: the form is ifelse(some_vector_filtering_expression,b,c) where some_vector_filtering_expression is of the form in section  titled"filtering" above, and b and c are constants.
since we were still in the body of the function, r reminded us of that by using + as its prompt instead of the usual >.
one of the big advantages of open-source software is that people love to share.
the advantage of this is that if we ever wanted to rerun this sequence of commands, say with a slightly different set of parameters, we need only edit the filetestscores.r to reflect the parameter changes and then run as above.
the first argument to lsfit() is a matrix of the  predictor variable data, with the ith row consisting of observation number i in  our sample.
it would also be quicker and more convenient to undo, by simply running > untrace(gy) you can turn tracing on or off globally by calling tracingstate() , with the argument true to turn it on, false to turn it off.
we may just want to find the positions within z at which  the condition occurs.
running r in batch mode: sometimes it's preferable to automate the process of running r. for  example, we may wish to run an r script that generates a graph output file, and  not have to bother with manually running r.
it is automatically invoked by some r commends, such ashelp(), and you can invoke it yourself on lengthy output.
[1] "abc1.5def" handy miscellaneous features: during a session, you can scroll back and forth in your command history by  typing ctrl-p and ctrl-n. you can also use thehistory() command to list your more recent commands (which will be run through thepager).
there are a number of r tutorials and manuals which have been written,  many of which are linked to on the r web page (click on manuals | contributed  documentation).
recall that when one does almost any complex operation in r, the results are returned packaged as an object.
as described in ther faq, ess offers r users: r support contains code for editing r source code (syntactic  indentation and highlighting of source code, partial evaluations of code,  loading and error-checking of code, and source code revision maintenance) and  documentation (syntactic indentation and highlighting of source code, sending  examples to running ess process, and previewing), interacting with an inferior  r process from within emacs (command-line editing, searchable command history,  command-line completion of r object and file names, quick access to object and  search lists, transcript recording, and an interface to the help system), and  transcript manipulation (recording and saving transcript files, manipulating  and editing saved transcripts, and re-evaluating commands from transcript  files).
on one machine, i encountered a tcl/tk problem when i tried to loaddebug.
z[, 1] ~ z[, c(2, 3)]) coefficients: (intercept) z[, c(2, 3)]1 z[, c(2, 3)]2 -1.6779 2.4899 -0.3221
further details are described in an article by the author of boot() in the december 2002 issue ofr news.