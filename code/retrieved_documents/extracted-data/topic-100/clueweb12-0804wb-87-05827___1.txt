along the way, i will highlight r’s functional programming features, its compact syntax for statistical modeling, and its ease of connectivity with persistent data stores.
he also founded and until 2008 served on the board of customink.com, an  inc. 500 e-commerce firm.
in particular, i will present the following two case studies applying r to large, freely available data sets: - an analysis of nasa’s landsat imagery of brazil’s center-west agricultural regions to detect correlates for soybean harvest yields, and a derived predictor of the brazilian soybean market based in part on these correlates.
innovative technologies have emerged to cope with the storage and retrieval  of big data, yet analysis tools have been less emphasized.
comments on this page are now closed.
most importantly, closed-source tools  cannot keep pace with the leading edge of innovation in statistical and  machine-learning algorithms.
innovative technologies have emerged to cope with the storage and retrieval of big data, yet analysis tools have been less emphasized.
he has eight years of experience developing  large-scale databases and inference algorithms across academia and industry  with applications ranging from metal-breathing microbes to municipal real  estate.
enter the open source programming language r. r has been dubbed the lingua franca for statistical computing and graphical analysis, with a pedigree tracing back several decades at bell labs.
michael has a ph.d. in bioinformatics and systems biology from boston
in addition, r’s extensibility via user-contributed packages has spawned an active developer community.
there was also little or no practical information on the tools that have been built around the language to make it do the cool things that michael talked about.
many emerging data  sets do not fit within existing software paradigms: either their size  overwhelms traditional desktop tools such as excel, or their range of data  types (geocodes, for example) prevent them from being pipelined into more  powerful, but narrowly designed tools.
- a validation of bill james’ sabermetrics approach to batting performance using 30 years of major league baseball statistics, and a derived predictor for batters’ salaries.
what every developer should know about database scalability michael driscoll metamarkets michael e. driscoll is a principal at dataspora, inc. a business analytics  consultancy in san francisco.
he also founded and until 2008 served on the board of customink.com, an inc. 500 e-commerce firm.
this session seeks to give developers the  courage to learn r, the confidence to include it in theiross arsenal, and the  wisdom to recognize opportunities for its use.
though its million-plus users are concentrated within academia, r is gaining currency within several high-profile quantitative analysis groups, including google’s customer insights team and barclays global investors.
- a validation of bill james’ sabermetrics approach to batting  performance using 30 years of major league baseball statistics, and a derived  predictor for batters’ salaries.
he is the co-chair of the bay area r users group, and has used r  extensively for the visualization and analysis of genome data,gis data, and  macroeconomic data sets.
he has eight years of experience developing large-scale databases and inference algorithms across academia and industry with applications ranging from metal-breathing microbes to municipal real estate.
many emerging data sets do not fit within existing software paradigms: either their size overwhelms traditional desktop tools such as excel, or their range of data types (geocodes, for example) prevent them from being pipelined into more powerful, but narrowly designed tools.
this session seeks to give developers the courage to learn r, the confidence to include it in theiross arsenal, and the wisdom to recognize opportunities for its use.
in this session, i will focus on applying r’s powerful visualization and analysis capabilities to the kinds of large, multidimensional data sets that increasingly confront developers.
while  source code for these examples will be provided, this talk will emphasize  techniques and approach over detail.
he is the co-chair of the bay area r users group, and has used r extensively for the visualization and analysis of genome data,gis data, and macroeconomic data sets.
in particular, i will present the following two case studies applying r to  large, freely available data sets: - an analysis of nasa’s landsat imagery of brazil’s center-west  agricultural regions to detect correlates for soybean harvest yields, and a  derived predictor of the brazilian soybean market based in part on these  correlates.
people planning to attend this session also want to see: using hadoop for big data analysis even faster websites gearman: bringing the power of map/reduce to everyday applications
most importantly, closed-source tools cannot keep pace with the leading edge of innovation in statistical and machine-learning algorithms.
for information on exhibition and sponsorship opportunities at the conference, contact sharon cordesse atscordesse@oreilly.com download the oscon sponsor/exhibitor prospectus download the media & promotional partner brochure (pdf) for information on trade opportunities with o'reilly conferences or contactmediapartners@ oreilly.com for media-related inquiries, contact maureen jennings at maureen@oreilly.com to stay abreast of conference news and to receive email notification when registration opens, please sign up for theoscon newsletter (login required) view a complete list of oscon contacts o'reilly home | privacy policy | contact us | sitemap | conf-webmaster@oreilly.com event software powered byexpectnation © 2009, o'reilly media, inc. | (707) 827-7000 / (800) 998-9938
michael e. driscoll is a principal at dataspora, inc. a business analytics consultancy in san francisco.
though its million-plus users are  concentrated within academia, r is gaining currency within several high-profile  quantitative analysis groups, including google’s customer insights team  and barclays global investors.
in this session, i will focus on applying r’s powerful visualization  and analysis capabilities to the kinds of large, multidimensional data sets  that increasingly confront developers.
there was more time/effort devoted to “how to do good visualization” which could have been summarized to a few book recommendations, and too little “here is how to get started munging, modeling and visualizing data using the r toolkit”.
the economics of data aggregation and analysis are being disrupted by falling costs for storage andcpu power, the continuing shift of business processes online, and the deluge of data that is being generated as a consequence.
while source code for these examples will be provided, this talk will emphasize techniques and approach over detail.
along the way, i will highlight  r’s functional programming features, its compact syntax for statistical  modeling, and its ease of connectivity with persistent data stores.
location: exhibit hall 3 presentation file: open source analytics_ visualization and predictive  modeling of big data with the r programming language presentation 1 [ppt] the economics of data aggregation and analysis are being disrupted by  falling costs for storage andcpu power, the continuing shift of business  processes online, and the deluge of data that is being generated as a  consequence.
michael has a ph.d. in bioinformatics and systems biology from boston university, where he was adoe computational science graduate fellow, and an a.b. from harvard college.
there was a bit too much pr fluff plus tufte advocacy and too little focus on what r is and what it can do.
for all of its strengths, r has an admittedly steep learning curve.
in addition, r’s extensibility via  user-contributed packages has spawned an active developer community.
university, where he was adoe computational science graduate fellow, and an  a.b. from harvard college.
enter the open source programming language r. r has been dubbed the lingua  franca for statistical computing and graphical analysis, with a pedigree  tracing back several decades at bell labs.