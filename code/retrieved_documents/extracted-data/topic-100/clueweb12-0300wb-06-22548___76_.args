a general mathematical data model that can be adapted to virtually any numerical data, that supports data sharing among different users, different data sources and different scientific disciplines, and that provides transparent access to data independent of storage format and location (i.e., memory, disk or remote).multi-sheet workbooks, publication-quality graphics, and standardized analysis tools provide a tightly integrated workspace for you to import data, create and annotate graphs, explore and analyze data, and publish your work.it provides the necessary tools to diagnose, validate, and intercompare large observational and global climate model data sets.this highly flexible system allows scientific investigators to interactively superimpose and highlight diverse data sets; thus aiding data interpretation.this allows a user to rapidly and automatically create and store a session, either for his own use, or for use by a collaborator on another machine; a data provider to automatically create a specialized analysis environment which can be downloaded (as a small script file) along with a dataset from a website; and realtime collaboration or sharing of sessions over (even low-bandwidth) networks, including the internet.the software has a gradual learning curve, allowing the novice user to quickly obtain useful results.tutorials which range from very simple visualizations to complex combinations of data sets provide the user with a quick learning tool.the climate data analysis tool (cdat), developed by the program for climate model diagnosis and intercomparison (pcmdi) at lawrence livermore national laboratory, provides the capabilities needed to analyze model data, perform complex mathematical calculations, and graphically display the results.this greatly simplifies the retrieval of metadata and data from files in supported formats.data handling capabilities permit external analysis programs to be easily linked with display and data storage processes.to ensure that origin meets your data analysis requirements, intuitive tools for advanced statistics, regression, nonlinear curve fitting, signal processing, image processing and peak analysis are built-in.3d graphics are built from the underlying data in real-time, and the user has interactive control of graphics, navigation, animation, and more.data analysis and computation integrated with visualization to support computational steering and other complex interaction modes.a group of researchers at northwestern university and argonne national laboratory (jianwei li, wei-keng liao, alok choudhary, robert ross, rajeev thakur, william gropp, and rob latham) have designed and implemented a new parallel interface for writing and reading netcdf data, tailored for use on high performance platforms with parallel i/o. the implementation builds on the mpi-io interface, providing portability to most platforms in use and allowing users to leverage the many optimizations built into mpi-io implementations.the main advantages of using ezget instead of the lower level cdunif library include: substantial error trapping capabilities and detailed error messages versatile capability of conveniently selecting data from specified regions (e.g., oceans, north america, all land areas north of 45 degrees latitude, etc.)