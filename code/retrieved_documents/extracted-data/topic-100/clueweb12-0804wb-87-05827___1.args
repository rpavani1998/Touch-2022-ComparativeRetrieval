along the way, i will highlight r’s functional programming features, its compact syntax for statistical modeling, and its ease of connectivity with persistent data stores.
in particular, i will present the following two case studies applying r to large, freely available data sets: - an analysis of nasa’s landsat imagery of brazil’s center-west agricultural regions to detect correlates for soybean harvest yields, and a derived predictor of the brazilian soybean market based in part on these correlates.
most importantly, closed-source tools cannot keep pace with the leading edge of innovation in statistical and machine-learning algorithms.
there was also little or no practical information on the tools that have been built around the language to make it do the cool things that michael talked about.
many emerging data sets do not fit within existing software paradigms: either their size overwhelms traditional desktop tools such as excel, or their range of data types (geocodes, for example) prevent them from being pipelined into more powerful, but narrowly designed tools.
- a validation of bill james’ sabermetrics approach to batting performance using 30 years of major league baseball statistics, and a derived predictor for batters’ salaries.
this session seeks to give developers the courage to learn r, the confidence to include it in theiross arsenal, and the wisdom to recognize opportunities for its use.
- a validation of bill james’ sabermetrics approach to batting performance using 30 years of major league baseball statistics, and a derived predictor for batters’ salaries.
many emerging data sets do not fit within existing software paradigms: either their size overwhelms traditional desktop tools such as excel, or their range of data types (geocodes, for example) prevent them from being pipelined into more powerful, but narrowly designed tools.
this session seeks to give developers the courage to learn r, the confidence to include it in theiross arsenal, and the wisdom to recognize opportunities for its use.
in this session, i will focus on applying r’s powerful visualization and analysis capabilities to the kinds of large, multidimensional data sets that increasingly confront developers.
in particular, i will present the following two case studies applying r to large, freely available data sets: - an analysis of nasa’s landsat imagery of brazil’s center-west agricultural regions to detect correlates for soybean harvest yields, and a derived predictor of the brazilian soybean market based in part on these correlates.
people planning to attend this session also want to see: using hadoop for big data analysis even faster websites gearman: bringing the power of map/reduce to everyday applications
most importantly, closed-source tools cannot keep pace with the leading edge of innovation in statistical and machine-learning algorithms.
in this session, i will focus on applying r’s powerful visualization and analysis capabilities to the kinds of large, multidimensional data sets that increasingly confront developers.
there was more time/effort devoted to “how to do good visualization” which could have been summarized to a few book recommendations, and too little “here is how to get started munging, modeling and visualizing data using the r toolkit”.
the economics of data aggregation and analysis are being disrupted by falling costs for storage andcpu power, the continuing shift of business processes online, and the deluge of data that is being generated as a consequence.
along the way, i will highlight r’s functional programming features, its compact syntax for statistical modeling, and its ease of connectivity with persistent data stores.
location: exhibit hall 3 presentation file: open source analytics_ visualization and predictive modeling of big data with the r programming language presentation 1 [ppt] the economics of data aggregation and analysis are being disrupted by falling costs for storage andcpu power, the continuing shift of business processes online, and the deluge of data that is being generated as a consequence.
there was a bit too much pr fluff plus tufte advocacy and too little focus on what r is and what it can do.
