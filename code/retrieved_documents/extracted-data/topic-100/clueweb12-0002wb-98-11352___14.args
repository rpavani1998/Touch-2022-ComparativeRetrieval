the s language is often the vehicle of choice for research in statistical methodology, and r provides an open source route to participation in that activity.
- getty thesaurus of geographic names (getty research institute) learn about the purpose, scope and structure of the tgn.
it takes care of many of the fiddly details that make plotting a hassle (like drawing legends) as well as providing a powerful model of graphics that makes it easy to produce complex multi-layered graphics.
the most important of these exceptions are, that there are no “time bombs”; your copy of pspp will not “expire” or deliberately stop working in the future.
in addition to the classic “web of documents” w3c is helping to build a technology stack to support a “web of data,” the sort of data you find in databases.
creately online diagramming and design.
from next issue iassist will be saving trees and only publish the iq on the web.
- library of congress authorities (search for name, subject, title and name/title) using library of congress authorities, you can browse and view authority headings for subject, name, title and name/title combinations; and download authority records in marc format for use in a local library system.
the s language is often the vehicle of choice for research in statistical methodology, and r provides an open source route to participation in that activity.
of course, without detailed documentation, data reuse may indeed result in inaccurate interpretations.
google chart tools - google chart tools provide a perfect way to visualize data on your website.
anyone can write a screen scraper using the online editor.
- fathom fathom information design helps clients understand and express complex data through information graphics, interactive tools, and software for installations, the web, and mobile devices.
you can use pspp with its graphical interface or the more traditional syntax commands.
these applications place very different demands on bigtable, both in terms of data size (fromurls to web pages to satellite imagery) and latency requirements (from backend bulk processing to real-time data serving).
the project will gain experience in the complex balance between confidentiality and analysis, and the differences between national laws.
we should also give a special thanks to the editors of the issue.
- matlab - the language of technical computing matlab® is a high-level language and interactive environment that enables you to perform computationally intensive tasks faster than with traditional programming languages such as c, c++, and fortran.
revolution analytics - commercial software & support for the r statistics language revolution analytics delivers advanced analytics software at half the cost of existing solutions.
the community consists of members within and outside academia, as local history groups and genealogists are using the software to enhance and combine data from historical scottish post office directories with large-scale historical maps.
what we can strive for as data and information managers is to work together as fellow researchers and to be ever curious about how these partnerships and the sharing of information back and forth can be enhanced by thoughtful information and technology design.
similarly, research data & environmental sciences librarian, gail steinhart, writes about the development of datastar, a data staging repository hosted by cornell university’s albert r. mann library.
the onlinerda toolkit subscription is the most effective way to interact with the new standard.
weka contains tools for data pre-processing, classification, regression, clustering, association rules, and visualization.
instead of juggling versions and overwriting files, use buzzdata and enjoy a social network designed for data.
the hope is that these articles will carry involvement to the iassist community, so that the gained knowledge can be shared and practised widely.
22 free tools for data visualization and analysis the r journal - the r journal is the refereed journal of the r project for statistical computing.
- ggplot2 ggplot2 is a plotting system for r, based on the grammar of graphics, which tries to take the good parts of base and lattice graphics and none of the bad parts.
in the free version, the code and data are shared with the world.
its backend is designed to perform its analyses as fast as possible, regardless of the size of the input data.
the project developed as a “managed workspace” where researchers contribute datasets they are still actively using in direct response to questions that have to do with sharing in the active research environment, rather than an archival one.
i hope most of you have made it safely back home by now - and are ready to refresh the memories by watching the conference webcasts and viewing presentations.
advanced search allows you to perform more specific queries.
in its own way, each project described here moves data managers upstream, pre-publication, into the place where research is actively happening.
data tools google refine - a power tool for working with messy data (formerly freebase gridworks) the overview project - overview is an open-source tool to help journalists find stories in large amounts of data, by cleaning, visualizing and interactively exploring large document and data sets.
unlike commercial catalogues, it is run by a loose confederation of volunteers, who compile pages of key links for particular areas in which they are expert; even though it isn't the biggest index of the web, the vl pages are widely recognised as being amongst the highest-quality guides to particular sections of the web.
opengl - the industry standard for high performance graphics opengl.org is a vendor-independent and organization-independent web site that acts as one-stop hub for developers and consumers for all opengl news and development resources.
data curation profiles - this website is an environment where academic librarians of all kinds, special librarians at research facilities, archivists involved in the preservation of digital data, and those who support digital repositories can find help, support and camaraderie in exploring avenues to learn more about working with research data and the use of the data curation profiles tool.
the background and technical issues are presented in the paper, which also looks into issues and perspectives of user generated content.
- google research publication: bigtable - bigtable is a distributed storage system for managing structured data that is designed to scale to a very large size: petabytes of data across thousands of commodity servers.
the chart is rendered within the browser using flash.
an interactive time series line chart with optional annotations.
- art & architecture thesaurus (getty research institute) learn about the purpose, scope and structure of the aat.
it uses javascript andsvg for web-native visualizations; no plugin required (though you will need a modern web browser)!
create, share, explore google fusion tables - google fusion tables is a modern data management and publishing web application that makes it easy to host, manage, collaborate on, visualize, and publish data tables online.
the paper highlights the development of e-learning materials that can raise awareness and ease access to international data.
from simple line charts to complex hierarchical tree maps, the chart galley provides a large number of well-designed chart types.
articles for the iq are always very welcome.
on the other hand, the professors saw many benefits in open access to research data.
covering useful tools, tutorials, tips and inspirational photos.
linked data are empowered by technologies such as rdf, sparql, owl, and skos.
you don't have to be a data expert to navigate between different views, make your own comparisons, and share your findings.
- infoplease: encyclopedia, almanac, atlas, biographies, dictionary, thesaurus.
there are visualization tools for search, music, networks, online communities, and almost anything else you can think of.
response date: january 2, 2012...." http://goo.gl/vtp18 - swright's blog - login to post comments 86 helpful tools for the data professional plus 45 bonus tools submitted by jkitlas on sat, 2011-10-29 16:04 topic: - data-related advocacy - data access & open data - tools, apps, technology - metadata & standards i have been working on this (mostly) annotated collection of tools and articles that i believe would be of help to both the data dabbler and professional.
we see plainly that as one moves up the continuum, more and more human effort and intervention is required to craft the discovery, access, analytic and preservation environment.
it is demonstrated how even international data produced by intergovernmental organizations like the international monetary fund, the international energy agency, oecd, the united nations and the world bank are often only available with an expensive subscription, presented in complex incomprehensible tables, through special interfaces; such barriers are making the international use of the data difficult.
also the iassist jobs repository for an archive of data-related position descriptions.
great care has been taken over the defaults for the minor design choices in graphics, but the user retains full control.
among the users are well-known companies as ford, honda, nokia, miele, philips, ibm, hp, cisco, merrill lynch, bnp paribas, bank of america, mobilkom austria, akzo nobel, aureus pharma, pharmadm, cyprotex, celera, revere, lexisnexis, mitre and many medium-sized businesses benefitting from the open-source business model of rapid-i. r project - r is a language and environment for statistical computing and graphics.
although programming experience is helpful, protovis is mostly declarative and designed to be learnedby example.
rice provides visual evidence in a compelling diagram of the data sharing continuum based on storage, discovery, and preservation conditions of the digital research materials at each level along the scale -- from the lowly thumb drive to the officious national archive.
this is a rich reuse experience, creating a real digital “laboratory.”
you don't have to be a data expert to navigate between different views, make your own comparisons, and share your findings.
there are also some invisible web resources (if you're looking for something data-related on google and not finding it) and metadata resources so you can appropriately curate your data.
attributes are not in a mandated sequence and not repeatable (per xml rules).
chairing a conference session with the purpose of aggregating and integrating papers for a special issue iq is much appreciated as the information in the form of an iq issue reaches many more people than the session participants and will be readily available on the iassist website at http://www.iassistdata.org.
- google chart tools - google chart tools provide a perfect way to visualize data on your website.
google research publication: bigtable - bigtable is a distributed storage system for managing structured data that is designed to scale to a very large size: petabytes of data across thousands of commodity servers.
i included a list of tools, such as programming languages and web-based utilities,data mining resources, some prominent organizations in the field, repositories where you can play with data, events you may want to attend and important articles you should take a look at.
- pixlr editor a powerful online photo editor.
in order to preserve the confidentiality of single entities, access to complete datasets is often restricted to monitored on-site analysis.
clearly these topics are international (e.g. the weather or air pollution does not stop at national borders), but the article discusses how existing barriers prevent global data sharing.
- ionz ionz will help you craft an infographic about yourself.
the algorithms can either be applied directly to a dataset or called from your own java code.
mondrian: pentaho analysis - pentaho open source analysis olap server written in java.
subelements are optional, although in some cases you may not have empty containers.
- protovis protovis composes custom views of data with simple marks such as bars and dots.
from simple line charts to complex hierarchical tree maps, the chart galley provides a large number of well-designed chart types.
- opengl - the industry standard for high performance graphics opengl.org is a vendor-independent and organization-independent web site that acts as one-stop hub for developers and consumers for all opengl news and development resources.
authors are very welcome to take a look at the instructions and layout: http://iassistdata.org/iq/instructions-authors authors can also contact me via e-mail: kbr@sam.sdu.dk.
among the users are well-known companies as ford, honda, nokia, miele, philips, ibm, hp, cisco, merrill lynch, bnp paribas, bank of america, mobilkom austria, akzo nobel, aureus pharma, pharmadm, cyprotex, celera, revere, lexisnexis, mitre and many medium-sized businesses benefitting from the open-source business model of rapid-i. - r project - r is a language and environment for statistical computing and graphics.
weka contains tools for data pre-processing, classification, regression, clustering, association rules, and visualization.
- chart builder powerful tools for creating a variety of charts for online display.
pixlr editor a powerful online photo editor.
the report concludes that from the viewpoint of long-term preservation and reuse, it is definitely less recommendable to leave the responsibility for the preservation and dissemination of data to individual researchers.
dbpedia allows you to ask sophisticated queries against wikipedia, and to link other data sets on the web to wikipedia data.
more... - community find out what iassisters are doing in the field and explore other avenues of presentation, communication and discussion via social networking and related online social spaces.more...
refine, reuse and request data | scraperwiki - scraperwiki is an online tool to make acquiring useful data simpler and more collaborative.
the answer may be that benefit is more than finding or accessing a particular resource (yep, i have downloaded the whole thing and all the bits are there), but instead being able to examine this resource in many ways (okay, lets run frequencies, now i want to see it on a map, and let’s include some other variables).
the comprehensive r archive network - r is `gnu s', a freely available language and environment for statistical computing and graphics which provides a wide variety of statistical and graphical techniques: linear and nonlinear modelling, statistical tests, time series analysis, classification, clustering, etc.
r can be considered as a different implementation of s. there are some important differences, but much code written for s runs unaltered under r. r provides a wide variety of statistical (linear and nonlinear modelling, classical statistical tests, time-series analysis, classification, clustering, ...) and graphical techniques, and is highly extensible.
deeppeep helps you discover the entry points to content in deep web (aka hidden web) sites, including online databases and web services.
in other words, data curators matter.
22 useful online chart & graph generators the best tools for visualization visualization is a technique to graphically represent sets of data.
an interactive time series line chart with optional annotations.
- tableau software - fast analytics and rapid-fire business intelligence from tableau software.
google correlate google correlate finds search patterns which correspond with real-world trends.
resource description and access is the new, unified cataloging standard.
professors were concerned about inadvertent misuse of data and consequent mistakes.
it is available as a stand-alone application for data analysis and as a data mining engine which can be integrated into own products.
the most important of these exceptions are, that there are no “time bombs”; your copy of pspp will not “expire” or deliberately stop working in the future.
(1) "[t]his request for information (rfi) offers the opportunity for interested individuals and organizations to provide recommendations on approaches for ensuring long-term stewardship and encouraging broad public access to unclassified digital data that result from federally funded scientific research....
the home page for the american memory historical collections from the library of congress.
if you are a data scientist, data analyst or data dummy, chances are there is something in here for you.
the discovery and leverage of unused business intelligence from existing data enables better informed decisions and allows for process optimization.
- photostats create gorgeous infographics about your iphone photos, with photostats.
vue provides a flexible visual environment for structuring, presenting, and sharing digital information.
- buzzdata buzzdata lets you share your data in a smarter, easier way.
when data is large or abstract, visualization can help make the data easier to read or understand.
metadata - description schema: mods (library of congress) and outline of elements and attributes in mods version 3.4: metadataobject this document contains a listing of elements and their related attributes in mods version 3.4 with values or value sources where applicable.
create, share, explore - google fusion tables - google fusion tables is a modern data management and publishing web application that makes it easy to host, manage, collaborate on, visualize, and publish data tables online.
semantic web technologies enable people to create data stores on the web, build vocabularies, and write rules for handling data.
great care has been taken over the defaults for the minor design choices in graphics, but the user retains full control.
the survey also charted barriers to open access.
most common practise seems to be that the data remains in the hand of the original researcher(s).
it allows you to analyze your data through interactive data visualizations and create stunning dashboards from the web.
more... - robin's blog - login to post comments open access and reuse of research data in finland submitted by marik on fri, 2008-10-10 13:12 topic: - reports & studies - archiving, preservation, curation - data access & open data
because it's a wiki, other programmers can contribute to and improve the code.
it is available as a stand-alone application for data analysis and as a data mining engine which can be integrated into own products.
data science toolkit a collection of data tools and open apis curated by our own pete warden.
it takes care of many of the fiddly details that make plotting a hassle (like drawing legends) as well as providing a powerful model of graphics that makes it easy to produce complex multi-layered graphics.
you can use it to extract text from a document, learn the political leanings of a particular neighborhood, find all the names of people mentioned in a text and more.
should you be interested in compiling a special issue for the iq as guest editor(s) i will also be delighted to hear from you.
enabling interactive analysis of very large datasets stored in sql databases without writing sql.
natural language toolkit - open source python modules, linguistic data and documentation for research and development in natural language processing and text analytics, with distributions for windows,mac osx and linux.
all in all, the benefits were estimated to be more significant than the barriers.
scholarly internet resource collections infomine is a virtual library of internet resources relevant to faculty, students, and research staff at the university level.
the discovery and leverage of unused business intelligence from existing data enables better informed decisions and allows for process optimization.
response date: january 2, 2012...." http://goo.gl/vtp18 86 helpful tools for the data professional plus 45 bonus tools submitted by jkitlas on sat, 2011-10-29 16:04 topic: data-related advocacy tools, apps, technology metadata & standards i have been working on this (mostly) annotated collection of tools and articles that i believe would be of help to both the data dabbler and professional.
buzzdata buzzdata lets you share your data in a smarter, easier way.
- natural language toolkit - open source python modules, linguistic data and documentation for research and development in natural language processing and text analytics, with distributions for windows,mac osx and linux.
the chart is rendered within the browser using flash.
the “crowdsourcing” tool did successfully generate engagement and there are plans for further development, such as upload and attachment of photos of people, buildings, and landmarks to enrich the collection.
photostats create gorgeous infographics about your iphone photos, with photostats.
- scirus - for scientific information the most comprehensive scientific research tool on the web.
find out more about the tgn's contributors.
there are visualization tools for search, music, networks, online communities, and almost anything else you can think of.
- 22 useful online chart & graph generators - the best tools for visualization visualization is a technique to graphically represent sets of data.
protovis protovis composes custom views of data with simple marks such as bars and dots.
with over 410 million scientific items indexed at last count, it allows researchers to search for not only journal content but also scientists' homepages, courseware, pre-print server material, patents and institutional repository and website information.
it uses javascript andsvg for web-native visualizations; no plugin required (though you will need a modern web browser)!
american memory offers primary source materials that chronicle historical events, people, places, and ideas that continue to shape america.
study participants reflected on and, as a result, fine-tuned how they work with data, why they create these materials in the first place and were able to articulate reasons for managing these resources the way they do.
brightplanet initially developed the completeplanet compilation to identify and tap into many hundreds and thousands of search sources simultaneously to automatically deliver high-quality content to its corporate and enterprise customers.
while the study results reveal researchers’ needs and workflows.
pspp can perform descriptive statistics, t-tests, linear regression and non-parametric tests.
luis martinez-uribe introduces the university of oxford’s scoping digital repository services for research data management project and the findings of a requirement gathering exercise.
ionz ionz will help you craft an infographic about yourself.
his talk will locate the social sciences in the broader e-science picture and give us a glimpse of the future.
- techxtra: engineering, mathematics, and computing techxtra is a free service which can help you find articles, books, the best websites, the latest industry news, job announcements, technical reports, technical data, full text eprints, the latest research, thesis & dissertations, teaching and learning resources and more, in engineering, mathematics and computing.
whether from government transparency initiatives, leaks or freedom of information requests, journalists are drowning in more documents than they can ever hope to read.
- machine learning demos - visual.ly - infographics & visualizations.
tuomas j. alaterä information network specialist tuomas.alatera@uta.fi finnish social science data archive (fsd) http://www.fsd.uta.fi fi-33014 university of tampere - robin's blog - login to post comments special iq:
populating your data is easy using the provided client- and server-side tools.
one of r's strengths is the ease with which well-designed publication-quality plots can be produced, including mathematical symbols and formulae where needed.
- refine, reuse and request data | scraperwiki - scraperwiki is an online tool to make acquiring useful data simpler and more collaborative.
there are also some invisible web resources (if you're looking for something data-related on google and not finding it) and metadata resources so you can appropriately curate your data.
smashing magazine - how to create animated gifs using photoshop cs3 - wikihow - ian symbol libraries (free vector symbols and icons) - integration and application network - usability.gov - best icons - iconspedia - iconfinder - iconseeker invisible web - 10 search engines to explore the invisible web like the header says...
martinez-uribe asserts that the study process itself made an impact on the participants.
the virtual training suite can also help you develop your internet research skills through tutorials written by lecturers and librarians from universities across the uk.
the open-source data mining specialist rapid-i enables other companies to use leading-edge technologies for data mining and business intelligence.
chart builder powerful tools for creating a variety of charts for online display.
you can use pspp with its graphical interface or the more traditional syntax commands.
even if the data are stored in the department or research insitute, no further processing nor documentation takes place.
by building on open source r—the world’s most powerful statistics software—with innovations in big data analysis, integration and user experience, revolution analytics meets the demands and requirements of modern data-driven businesses.
the chart is rendered within the browser using flash.
many projects at google store data in bigtable, including web indexing, google earth, and google finance.
plenary iii date: friday, june 03 video the quicktime .mov files are available in a variety of viewing formats: via desktops, iphone, ipod, ipad, smartphones.
in 2006, motivated by the oecd open access guidelines, the finnish social science data archive (fsd) carried out an online survey targeting professors of human sciences, social sciences and behavioural sciences in finnish universities.
besides specifying keywords, you can also search for specific form element labels, i.e., the description of the form attributes.
the survey data is naturally available, too:fsd2268 open access to and reuse of research data 2006 mari kleemola finnish social science data archive iassist european regional secretary - marik's blog - login to post comments - home - topic - other-topics - data access & open data - iassist quarterly sharing data and building information with this issue (volume 35-3, 2011) of the iassist quarterly (iq) we return to the regular format of a collection of articles not within the same specialist subject area as we have seen in recent special issues of iq.
- google correlate google correlate finds search patterns which correspond with real-world trends.
the company concentrates on automatic intelligent analyses on a large-scale base, i.e. for large amounts of structured data like database systems and unstructured data like texts.
when data is large or abstract, visualization can help make the data easier to read or understand.
the google public data explorer makes large datasets easy to explore, visualize and communicate.
data tools data mining - google refine - a power tool for working with messy data (formerly freebase gridworks) - the overview project - overview is an open-source tool to help journalists find stories in large amounts of data, by cleaning, visualizing and interactively exploring large document and data sets.
american memory provides free access to historical images, maps, sound recordings, and motion pictures that document the american experience.
though all of the articles focus on technological choices and architectures to support research data curation, it is striking to realize that each of these choices emerge from old-fashioned personal, social, and organizational relationships.
pspp can perform descriptive statistics, t-tests, linear regression and non-parametric tests.
- data curation profiles - this website is an environment where academic librarians of all kinds, special librarians at research facilities, archivists involved in the preservation of digital data, and those who support digital repositories can find help, support and camaraderie in exploring avenues to learn more about working with research data and the use of the data curation profiles tool.
visualization: motion chart - google chart tools - google code a dynamic chart to explore several indicators over time.
we didn't have cameras available during the wednesday sessions, so no videos of these presentations, sorry!
these applications place very different demands on bigtable, both in terms of data size (fromurls to web pages to satellite imagery) and latency requirements (from backend bulk processing to real-time data serving).
- incywincy: the invisible web search engine incywincy is a showcase of net research server (nrs) 5.0, a software product that provides a complete search portal solution, developed byloopip llc.
a space for iassist members to share professional resources useful to them in their daily work.
the second segment (bonus!) of the list includes a number of art and design resources the infographic designers might like including color palette generators and image searches.
"authority" attributes are either followed by codes for authority lists (e.g., iso639-2b) or "see" references that link to documents that contain codes for identifying authority lists.
in this case the example is e-learning for the “united nations millennium development goals”.
the company concentrates on automatic intelligent analyses on a large-scale base, i.e. for large amounts of structured data like database systems and unstructured data like texts.
- search tools and databases (getty research institute) use these search tools to access library materials, specialized databases, and other digital resources.
fathom fathom information design helps clients understand and express complex data through information graphics, interactive tools, and software for installations, the web, and mobile devices.
the open-source data mining specialist rapid-i enables other companies to use leading-edge technologies for data mining and business intelligence.
"[t]his request for information (rfi) offers the opportunity for interested individuals and organizations to provide recommendations on approaches for ensuring long-term stewardship and broad public access to the peer-reviewed scholarly publications that result from federally funded scientific research....
despite these varied demands, bigtable has successfully provided a flexible, high-performance solution for all of these google products.
vue provides a flexible visual environment for structuring, presenting, and sharing digital information.
find out more about the aat's contributors.
"[t]his request for information (rfi) offers the opportunity for interested individuals and organizations to provide recommendations on approaches for ensuring long-term stewardship and broad public access to the peer-reviewed scholarly publications that result from federally funded scientific research....
kevin ashley, director of the digital curation centre (dcc), was the third.more... - chuck's blog - login to post comments us and uk governments embrace 'open data' submitted by robin on wed, 2009-12-23 12:17 topic: - data access & open data - news and announcements - other topics the us open government directive, released on december 8, 2009, instructs all federal agencies to provide high-value information to the public online in open, accessible, machine-readable formats.more... - robin's blog - login to post comments conference webcasts and presentations online!
enabling interactive analysis of very large datasets stored in sql databases without writing sql.
- visualization: motion chart - google chart tools - google code a dynamic chart to explore several indicators over time.
unlike low-level graphics libraries that quickly become tedious for visualization, protovis defines marks through dynamic properties that encode data, allowinginheritance, scales and layoutsto simplify construction.
lack of agreements regarding data ownership and ip rights were also mentioned as barriers, as well as loss of competitive advantage, it problems, and confidentiality issues.
cco also covers many other types of cultural works, including archaeological sites, artifacts, and functional objects from the realm of material culture.
matlab - the language of technical computing matlab® is a high-level language and interactive environment that enables you to perform computationally intensive tasks faster than with traditional programming languages such as c, c++, and fortran.
- data science toolkit a collection of data tools and open apis curated by our own pete warden.
it allows you to analyze your data through interactive data visualizations and create stunning dashboards from the web.
because it's a wiki, other programmers can contribute to and improve the code.
by tracing through completeplanet's subject structure or searching deep web sites, you can go to various topic areas, such as energy or agriculture or food or medicine, and find rich content sites not accessible using conventional search engines.
unlike low-level graphics libraries that quickly become tedious for visualization, protovis defines marks through dynamic properties that encode data, allowinginheritance, scales and layoutsto simplify construction.
they can be papers from iassist conferences or other conferences and workshops, from local presentations or papers especially written for the iq.
the survey also charted what actually happens to research data and what are the barriers to and benefits of open access to research data.
the second paper is also related to the sharing of data with an introduction to the international level.
although programming experience is helpful, protovis is mostly declarative and designed to be learnedby example.
its backend is designed to perform its analyses as fast as possible, regardless of the size of the input data.
you can use it to extract text from a document, learn the political leanings of a particular neighborhood, find all the names of people mentioned in a text and more.
- the comprehensive r archive network - r is `gnu s', a freely available language and environment for statistical computing and graphics which provides a wide variety of statistical and graphical techniques: linear and nonlinear modelling, statistical tests, time series analysis, classification, clustering, etc.
the google public data explorer makes large datasets easy to explore, visualize and communicate.
anyone can write a screen scraper using the online editor.
whether from government transparency initiatives, leaks or freedom of information requests, journalists are drowning in more documents than they can ever hope to read.
it contains useful internet resources such as databases, electronic journals, electronic books, bulletin boards, mailing lists, online library card catalogs, articles, directories of researchers, and many other types of information.
by building on open source r—the world’s most powerful statistics software—with innovations in big data analysis, integration and user experience, revolution analytics meets the demands and requirements of modern data-driven businesses.
we hope this will make it easier for the amazing amount of information in wikipedia to be used in new and interesting ways, and that it might inspire new mechanisms for navigating, linking and improving the encyclopaedia itself.
the ultimate goal of the web of data is to enable computers to do more useful work and to develop systems that can support trusted interactions over the network.
in the free version, the code and data are shared with the world.
the algorithms can either be applied directly to a dataset or called from your own java code.
completeplanet is the front door to these deep web databases on the web and to the thousands of regular search engines — it is the first step in trying to find highly topical information.
the second segment (bonus!) of the list includes a number of art and design resources the infographic designers might like including color palette generators and image searches.
the main product of rapid-i, the data analysis solution rapidminer is the world-leading open-source system for knowledge discovery and data mining.
the main product of rapid-i, the data analysis solution rapidminer is the world-leading open-source system for knowledge discovery and data mining.
one of r's strengths is the ease with which well-designed publication-quality plots can be produced, including mathematical symbols and formulae where needed.
these are large video files (each over an hour in length), so patience is required.
fsd's influence could be seen in social sciences, making archiving at a data archive a bit more frequent than in other sciences.
professors were asked, for example, whether their department had any guidelines on the preservation of digital research data.
i included a list of tools, such as programming languages and web-based utilities,data mining resources, some prominent organizations in the field, repositories where you can play with data, events you may want to attend and important articles you should take a look at.
ggplot2 ggplot2 is a plotting system for r, based on the grammar of graphics, which tries to take the good parts of base and lattice graphics and none of the bad parts.
loopip licenses the nrs engine and provides consulting expertise in building search solutions.
the most significant was enhancing the diversity of research designs with the use of archived data.
despite these varied demands, bigtable has successfully provided a flexible, high-performance solution for all of these google products.
machine learning demos visual.ly - infographics & visualizations.
(1) "[t]his request for information (rfi) offers the opportunity for interested individuals and organizations to provide recommendations on approaches for ensuring long-term stewardship and encouraging broad public access to unclassified digital data that result from federally funded scientific research....
this double issue is the work of the authors and their articles are introduced below.
r can be considered as a different implementation of s. there are some important differences, but much code written for s runs unaltered under r. r provides a wide variety of statistical (linear and nonlinear modelling, classical statistical tests, time-series analysis, classification, clustering, ...) and graphical techniques, and is highly extensible.
- revolution analytics - commercial software & support for the r statistics language revolution analytics delivers advanced analytics software at half the cost of existing solutions.
the survey also showed - not surprisingly - that it is usual to a researcher to have a positive attitude towards open access in general but a less-than-enthusiastic one to open access to his/her own data.
- completeplanet - discover over 70,000+ databases and specially search engines there are hundreds of thousands of databases that contain deep web content.
tableau software - fast analytics and rapid-fire business intelligence from tableau software.
many projects at google store data in bigtable, including web indexing, google earth, and google finance.
the primary focus of cco is art and architecture, including but not limited to paintings, sculpture, prints, manuscripts, photographs, built works, installations, and other visual media.
finally, each contributor notes the expanding role of data manager.
healthymagination | ge data visualization visualizations that advance the conversation about issues that shape our lives, and so we encourage visitors to download, post and share these visualizations.
if you are a data scientist, data analyst or data dummy, chances are there is something in here for you.
art design - periodic table of typefaces - color scheme designer 3 - color palette generator generate a color palette for any image - colourlovers - colorbrewer: color advice for maps image searches - american memory from the library of congress
because of missing metadata standards it is difficult to evaluate the quality of the dataset and to search for and locate the data resources required.
- walter's blog - login to post comments sparc digital repositories meeting includes session on open data submitted by chuck on wed, 2010-11-10 05:41 topic: - asia/pacific - data-related advocacy - external events - canada - europe - united states - data access & open data kathleen shearer of the canadian association of research libraries organized and chaired a panel on open data was held at the sparc digital repositories meeting on november 8, 2010.
populating your data is easy using the provided client- and server-side tools.