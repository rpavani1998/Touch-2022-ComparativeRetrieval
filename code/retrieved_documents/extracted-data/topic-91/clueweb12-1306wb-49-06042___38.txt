while  most of the previous studies extracted features which are based onbyte  n-grams[12,13], in this study, we use opcode n-gram patterns,  generated by disassembling the inspected executable files, to represent the  files.
secondly, it is not  clear what is the required period of time needed to observe the appearance of  the malicious activity for each malware.
thus, we ran all the product combinations of five training sets and  five test-sets for a total of 25 runs for each classifier.
statistics department, university of california at berkeley; 2004.
the comparisons show that for all classifiers, excluding the nb and bnb, the best averaged setting yields similar performance.
this was done for a variety of classifiers such as artificial neural networks[28], random forests [ 29], and svm [30].
the ann performance was generally low and dropped significantly for 5%, 15% and 50% mfp in the training set.
this is, however, different from our goal in which we attempt to classify unknown suspicious files as malicious or benign in order to detect new malware.
in annual computer security applications conference.
san francisco,  ca, usa: morgan kaufmann publishers, inc; 1993.
witten ih, frank e: data mining: practical machine learning tools and techniques.
in such cases the classifier tends to misclassify the instances of the less represented classes.
10% malware percentage in the test-set we consider the 10% mfp level in the test-set to be a reasonable real-life  scenario, as mentioned in the introduction.
anti-virus vendors are facing huge quantities (thousands) of suspicious files every day[2].
in technical report 666.
background 2.1 detecting unknown malware using byte n-grams patterns over the past decade, several studies have focused on the detection of  unknown malware based on its binary code content.
we rigorously evaluate the framework that is suggested in this paper, using a test collection containing more than 30,000 files, in order to determine the optimal settings of the framework.
thus, having a relatively high false-positive is reasonable in order to decrease the probability of missing an unknown malicious file.
this problem is even more relevant in fields where the natural datasets are highly imbalanced in the first place[25 ], as in the problem we describe.
a total of 67 malware executables were compared with the aggregate statistics of 20 non-malicious samples.
publisher full text moskovitch r, elovici y, rokach l: detection of unknown computer  worms based on behavioral classification of the host.
in the second experiment, we investigated the relationship between the  malicious file percentage (mfp) in the test-set, which represents real-life  scenario, and in the training set, which is used for training the classifier.
based on the reported experiments and results, we suggest that when setting  up a classifier for real-life purposes, one should first use the opcode  representation and, if the disassemble of the file is not feasible, use the  byte representation[12], which appears to be less accurate.
3.2 dataset creation we created a dataset of malicious and benign executables for the windows  operating system, the system most commonly used and attacked today.
publisher full text siddiqui m, wang mc, lee j: data mining methods for malware detection using instruction sequences.
over the years, the ml community has addressed the issue of class imbalance following two general strategies.
we begin in section 2 with a survey of previous relevant studies.
we designed a wide and comprehensive set of evaluation runs, including all the combinations of the optional settings for each of the aspects, amounting to 1,152 runs in a 5-fold cross validation format for all eight classifiers.
by processing these vectors, the learning algorithm trains a classifier.
- top 1,800 over all n-gram sizes tf representation, 300 features selected by the gr measure - denoted by  [top1800all;tf;top300;gr].
in this set, all opcode n-grams, of all sizes, were sorted according to their df value.
we created five  levels of malicious files percentage (mfp) in the training set (5, 10, 15, 30,  and 50%).
[17] also used byte n-grams representation,  however the vector ofn-gram features was binary, presenting the  presence or absence of a feature in the file and ignoring the frequency of  feature appearances (in the file).
it is shown that all classifiers, excluding ann, had a similar trend and perform better when using mfp of 15% - 30% in the training set, while random forest and boosted decision tree outperformed all other classifiers exceeding 94.5% accuracy and 87.1% tpr, while keeping the fpr bellow 4%.
we created five levels of malicious files percentage (mfp) in the training set (5, 10, 15, 30, and 50%).
this process is  presented in figure1.
international symposium on engineering secure software and  systems 2010, 35-42.
for example, when referring to 15%, we assert that 15% of the files  in the training set were malicious and 85% were benign.
recently, classification algorithms were employed to automate and extend the idea ofheuristic-based methods.
chawla nv, japkowicz n, kotcz a: editorial: special issue on learning from imbalanced datasets.
ieee computer  society; 2006:289-300.
the mean accuracy,  tpr and g-mean of the 2-gram outperforms all the othern-grams with the  lowest mean fpr for all classifiers.
when searching for such common engines among known malware, one must be aware that malware designers will attempt to hide such engines using a broad range of techniques.
this is an open access article distributed under the terms of the creative commons attribution license (http://creativecommons.org/licenses/by/2.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.
[19] conducted several experiments in which they evaluated the  combinations of seven feature selection methods, three classifiers, and byte n-gram size.
seeing as we assume that in most real-life scenarios low proportions of  malicious files are present, training sets should be designed accordingly.
proc of the 28th annual international computer software and  applications conference, ieee computer society 2004, 41-42.
the results show that malicious software opcode distributions differ significantly from non-malicious software and suggests that the method can be used to detect malicious code.
[12] published the results of a study which used a test collection containing more than 30,000 files, in which the files were represented by byten-grams.
heidelberg:  springer; 2008:204-215.
in the second experiment, we investigated the relationship between the malicious file percentage (mfp) in the test-set, which represents real-life scenario, and in the training set, which is used for training the classifier.
the performance of both the naïve bayes and the boosted naïve bayes  was the worst for all then-gram sizes, having the lowest mean tpr,  accuracy and g-mean, and highest mean fpr.
thus, we first extracted the 1,000 features (i.e., opcoden -grams patterns) with the highestdocument frequency values and on which three feature selection methods were later applied.
heidelberg: springer; 2008:204-215.
fs performed very well, especially when fewer features were used (top 50 and top 100).
recent studies, which we survey in the next section, have shown that by using byten-grams to represent the binary file features, classifiers with very accurate classification results can be trained, yet there still remains room for improvement.
we designed  a wide and comprehensive set of evaluation runs, including all the combinations  of the optional settings for each of the aspects, amounting to 1,152 runs in a  5-fold cross validation format for all eight classifiers.
we used thedocument frequency measuredf (the amount of files in which the term appeared), gain  ratio(gr) [40] and fisher score (fs)
distribution of n-gram sizes, chosen by  each feature selection method, for the twon-grams sets that consist of  varyingn-grams sizes.
the process of streamlining an executable starts with disassembling it.
in addition, one should consider the expected proportion of malicious files in the stream of data.
publisher full text abou-assaleh t, keselj v, sweidan r: n-gram based detection of new malicious code.
in this set, all opcode n-grams, of all sizes,  were sorted according to their df value.
5.1.4 varying opcode n-grams sizes
computational statistics and data analysis 2008, 52 (9):4544-4566.
several solutions to the challenge of packed code were suggested (e.g., ether[36], mcboost [37], polyunpack [38]).
mcafee study finds 4% of search results malicious [ http://www.newsfactor.com/story.xhtml?story_id = 010000ceueqo] webcite frederick lane 2007.
this can be explained by the fact that for training sets with higher mfp most  of the test sets are have a lower mfp, which in turn results in higher fpr.
we believe that the application of cost-sensitive  classification depends on the goals to be achieved, and accordingly the cost of  having a misclassification of each type.
over the years, the ml community has addressed the issue of class imbalance  following two general strategies.
in static analysis, information about the program or its expected behavior consists of explicit and implicit observations in its binary/source code.
the operations of an opcode may include  arithmetic, data manipulation, logical operations, and program control.
thus, we ran all the product combinations of five training sets and five test-sets for a total of 25 runs for each classifier.
in the first experiment, we found that the tfidf representation has no added value over the tf representation, which is not the case in many information retrieval applications.
we believe that the application of cost-sensitive classification depends on the goals to be achieved, and accordingly the cost of having a misclassification of each type.
which opcode n-gram size is the best: 1, 2, 3, 4 , 5 or 6? or a combination of opcode n-gram sizes? 3.
machine learning 1997, 29: 103-130.publisher full text freund y, schapire re: a brief introduction to boosting.
the mean tpr, fpr, accuracy and g-mean  for each term representation (tf and tfidf) as a function of the opcoden -gram size.
publisher full text shabtai a, potashnik d, fledel y, moskovitch r, elovici e: monitoring, analysis and filtering system for purifying network traffic of known and unknown malicious content.
indynamic analysis(also known as behavioral analysis) the detection of malware consists of information that is collected from the operating system at runtime (i.e., during the execution of the program) such as system calls, network access and files and memory modifications[3-7].
the first example pertains to for anti-virus companies that need to analyze dozens of thousands of maliciously suspected (or unknown) files, including benign files, every day.
each time the training set was chosen from one part and  the test set was chosen from the other part, thus forming a 2-fold cross  validation-like evaluation to render the results more significant.
domingos p, pazzani m:
a complete machine language instruction contains an opcode and, optionally, the specification of one or more operands.
moreover, the df and fs performance was more stable for varying numbers of top feature in terms accuracy and g-mean.
we rigorously evaluate the framework that is suggested in this paper, using  a test collection containing more than 30,000 files, in order to determine the  optimal settings of the framework.
[ 45], decision trees (dt)
as  a case in point, a recent mcafee survey[14] indicates that about 4% of search  results from the major search engines on the web contain malicious code.
the remaining the classifiers  performed very well, having the random forest, boosted decision trees and  decision trees outperforming.
relations among mfps in training and test-sets further to our results from the training-set point of view (figures 7 and 8 ), we present a detailed description of the accuracy, tpr and fpr for the mfp  levels in the two sets in a 3-dimensional presentation for each classifier (the  graphs of the two best classifiers, rf and bdt, are presented in figure9; the  graphs of the rest of the classifiers are provided in additional file1).
detailed description of the  accuracy, tpr and fpr for the malicious file percentage levels in the two sets  in a 3-dimensional presentation for each classifier.
in particular, these approaches search for methods for incorporating misclassification costs into the classification process and assigning higher misclassification costs to the minority class so as to compensate for its small size.
in this analysis we set out to answer the second part of research question 2 and to understand whether a combination of different sizes of opcoden -grams, as features in the classification task, may result in better detection performance.
their work considers the case of decision  trees induction on 26 different data-sets.
these results are quite similar in their magnitude to the results in figure7, although here the performance level was higher.
international journal electronic security and digital forensics 2007,1(2):156-168.
the 2-gram opcodes outperformed the others and the df was  the best feature selection method.
chawla nv, japkowicz n, kotcz a: editorial: special issue on  learning from imbalanced datasets.
mean accuracy, fpr, trp and g-mean (over all the mfp levels in the test-sets) for each mfp in the training set.
previous studies presented evaluations based on test collections having similar proportions of malicious and benign files in the test collections.
in these methods the binary code of a file is represented, for example, using byte sequence (i.e., byten-grams), and classifiers are used to learn patterns in the code in order to classify new (unknown) files as malicious or benign[1,10].
another important aspect when using binary classifiers for the detection of unknown malicious code is the imbalance problem.
information security technical report 2009, 14(1) :1-34.
kolter j, maloof m: learning to detect and classify malicious executables in the wild.
then, the first 1,800n-grams with the top df score were selected.
we consider the 10% mfp level in the test-set to be a reasonable real-life scenario, as mentioned in the introduction.
unlike byte sequence, opcode expressions, extracted from the executable  file, are expected to provide a more meaningful representation of the code.
which top-selection (number of features) is the best: 50 , 100, 200 or 300 and which features  selectionmethod: df, fs and gr is superior? 4.
finally, for all classifiers, when testing on 2007 examples, a  significant decrease in the accuracy was observed; a fact that might indicate  that new types of malware were released during 2007.
the results show that using various sizes of opcode n-grams patterns does not improve the detection performance and in fact for most classifiers, the performance accuracy was deteriorated.
while most of the previous studies extracted features which are based onbyte n-grams[12,13], in this study, we use opcode n-gram patterns, generated by disassembling the inspected executable files, to represent the files.
we performed an extensive evaluation using a test collection comprising more than 30,000 files.
figure10  presents the results with a 50% mfp in the training set and10% mfp in the  testing set for the two best classifiers bdt and rf (the graphs for the rest of  the classifiers are provided in additional file2).
shabtai a, moskovitch r, elovici y, glezer c: detection of malicious code by applying machine learning classifiers on static features: a state-of-the-art survey.
kolter jz, maloof ma: learning to detect malicious executables in the wild.
while being very precise, signature-based methods are useless against unknown malicious code[9].
the  kaspersky anti-virus program was used to verify that these files did not  contain any malicious code.
the  chronological evaluation showed a clear trend in which the performance improves  as the training set is more updated.
this was done for a  variety of classifiers such as artificial neural networks[28], random forests
in the trainingphase, a training-set of benign and malicious files is provided to  the system.
we  believe that disregarding the parameters would provide a more general  representation of the files, which is expected to be more effective for  purposes of classification into benign and malicious files.
journal of artificial intelligence research (jair) 2002, 16 :321-357.
quinlan jr: c4.5: programs for machine learning.
in this paper we chose to  decompose accuracy into basic components in addition to the use of the g-mean.
the representative vectors of the files in the training set and their real (known) classification are the input for a learning algorithm (such as a decision tree or artificial neural network algorithms).
moreover, these malicious files are written in varying frameworks which result in differing patterns.
for this we used three opcoden-grams sets on which the  three feature selection methods were applied with four top-selections (50, 100,  200 or 300): - constant n-gram size this option refers to the 6 opcode n-grams sets that were used in  the previous experiments, in which then-grams in each set are of the  same size (1, 2, 3, 4, 5 and 6).
in european conference on intelligence and security informatics.
thus, we divided the test collection into years and  evaluated training sets of selected years on the next years.
publisher full text siddiqui m, wang mc, lee j: data mining methods for malware  detection using instruction sequences.
lawrence s, burns i, back ad, tsoi ac, giles cl:
generally, df outperformed on all sizes of top features, while fs performed very well, especially when fewer top features were used (top 50 and top 100).
machine learning 1997, 29: 103-130.publisher full text freund y, schapire re: a brief introduction to boosting.
for each malicious and benign class a representative profile was constructed.
df was accurate for all sizes of top features.
in our  domain, eachn-gram is analogous to a word (or a term) in a text  document.
these  proportions do not reflect real-life situations in which malicious code is  significantly lower than 50% and therefore might report optimistic results.
journal of artificial intelligence research 2003, 19 :315-354.
in accordance to these questions, we wanted to identify the best settings of the classification framework which is determined by a combination of: (1) the term-representation (tf or tfidf); (2) the opcoden-gram size (1, 2, 3, 4, 5 or 6); (3) the top-selection of features (50, 100, 200 or 300); (4) the feature selection method (df, fs or gr); and (5) the classifier (svm, lr, rf, ann, dt, bdt, nb or bnb).
discussion and conclusions
using 10% malicious files in  the training set showed a clear trend in which the performance improves when  the training set is updated on a yearly basis.
these files could not be disassembled by disassembler software and therefore, after converting the files into opcode representation we ended up with 5,677 malicious and 20,416 benign files (total of 26,093 files).
which opcode n-gram size is the best: 1, 2, 3, 4 , 5 or 6? or a combination of opcode n-gram  sizes? 3.
mean accuracy, fpr, trp and g-mean (over  all the mfp levels in the test-sets) for each mfp in the training set.
in this analysis we set out to answer the second part of research question  2 and to understand whether a combination of different sizes of opcoden -grams, as features in the classification task, may result in better detection  performance.
figure 7 presents the mean accuracy, fpr, tpr, and g-mean (i.e., averaged over all the mfp levels in the test-sets) of each classifier and for each training mfp level.
these  results are quite similar in their magnitude to the results in figure7,  although here the performance level was higher.
cai dm, gokhale m, theiler j: comparison of feature selection and  classification algorithms in identifying malicious executables.
we had two representations, the known one, often called byte n-grams, which consists of byte sequences of characters extracted from the binary code[12], and the second opcode n-grams represented by sequences of opcodes.
in such cases, where many of the vectors are sparse, the detection accuracy will be decreased.
after determining the optimal settings when using the opcode representation, we compared the achieved accuracy to the byten -gram representation used in [12].
in figure 6 we present the mean tpr, fpr, accuracy and g-mean of each classifier when using the best mean settings obtained for each of the three opcoden-grams patterns sets: figure 6.
based on each feature  selection measure we selected the top 50, 100, 200 and 300 features.
using the selected features, we evaluated eight commonly used  classification algorithms: support vector machine (svm)[42], logistic  regression (lr)[43], random forest (rf)
following this observation we opted to use the tf representation for the rest of our experiments.
salton g, wong a, yang cs: a vector space model for automatic indexing.
the next and final step in streamlining the executable is achieved by extracting the sequence of opcodes generated during the disassembly process.
acm press; 2003:290-299.
machine learning 2001, 42(3): 203-231.publisher full text kubat m, matwin s: machine learning for the detection of oil  spills in satellite radar images.
ida-pro implements sophisticated techniques which enabled us to disassemble most of our malware collection successfully (approximately 74% of the malware files).
kubat m, matwin s: addressing the curse of imbalanced data sets: one-sided sampling.
then, the first 1,800n-grams  with the top df score were selected.
the test-set represents  the real-life situation while the training set represents the set-up of the  classifier, which is controlled.
full text joachims t: making large-scale support vector machine learning practical.
machine learning 1998, 30: 195-215.publisher full text heavens vx[http://vx.netlux.org] webcite linn c, debray s: obfuscation of executable code to improve  resistance to static disassembly.
the authors of[16] were the  first to introduce the idea of applyingmachine learning ( ml) methods for the detection of different malwares based on their  respective binary codes.
evaluation results indicate that  the evaluated methodology achieves a level of accuracy higher than 96% (with  tpr above 0.95 and fpr approximately 0.1), which slightly improves the results  in previous studies that use byten-gram representation.
based on the reported experiments and results, we suggest that when setting up a classifier for real-life purposes, one should first use the opcode representation and, if the disassemble of the file is not feasible, use the byte representation[12], which appears to be less accurate.
chronological evaluation:  accuracy, tpr and fpr with a 50% mfp in the training set and 10% mfp in the  testing set for all classifiers.
we investigated the imbalance problem, referring to several real-life scenarios in which malicious files are expected to be about 10% of the total inspected files.
this can be explained by the fact that for eachn-gram size, the top 1,000 opcode n-grams, having the highest document frequency (df) value, were selected.
additionally, it is shown that the fpr  grows for all classifiers with the increasing of the mfp in the training set.
san francisco, ca, usa: morgan kaufmann publishers, inc; 1993.
in  the analogy to text categorization, using letters or sequences of letters as  features is analogous to using byte sequences, while using words or sequences  of words is analogous to the opcode sequences.
each file in the  test-set is first parsed and the representative vector is extracted using the  same vocabulary as in the training phase.
publisher full text japkowicz n, stephen s: the class imbalance problem: a systematic study.
this approach has several disadvantages.
5.1.3 classifiers figure 4 depicts the mean tpr, fpr, accuracy and g-mean for each classifier  as a function of the opcoden-gram size using the tf representation.
finally, in the third experiment, we performed a chronological evaluation to determine how well a classifier, which was trained on past examples, can detect new malicious file and to investigate the importance and need in updating the training set frequently.
karim et  al.[20] addressed the tracking of malware evolution based on opcode sequences  and permutations.
when searching for such common engines among known  malware, one must be aware that malware designers will attempt to hide such  engines using a broad range of techniques.
[top300each;tf;top300;gr].
5.1.2 feature selections and top selections to identify the best feature selection method and the top number of  features, we calculated the mean tpr, fpr, accuracy and g-mean of each method,  as shown in figure3.
morgan kaufmann publishers inc; 1999:1401-1406.
this approach is conceptually simpler than using roc analysis and sheds sufficient light on our results.
anti-virus vendors are facing huge quantities (thousands) of suspicious  files every day[2].
in addition, we can see that in most cases, fs and gr tend to selectn-grams of size 2, 3 and 4 which we conclude to be more informative and with a tendency to discriminate better between the malicious and benign classes in the classification task.
in order to answer these questions we divided the entire test collection into years from 2000 to 2007, in which the files were created.
based on our experiments, using opcode sequences improves the detection performance significantly.
journal of machine learning research 2006, 7 :2721-2744.
annual computer security applications conference, ieee computer society 2008, 301-310.
for the imbalance  analysis, where the accuracy measure can sometimes be misleading, we also  computed the g-means measure.
the main advantage of static analysis is that it is able to detect a file without actually executing it and thereby providing rapid classification[8].
each training set k was evaluated separately on each following year from 200[k+1] till 2007.
computational statistics and data analysis 2007, 51 :3156-3172.
publisher full text karim e, walenstein a, lakhotia a, parida l: malware phylogeny generation using permutations of code.
a total of 67 malware executables were  compared with the aggregate statistics of 20 non-malicious samples.
several analysis techniques for detecting malware, which commonly  distinguished between dynamic and static, have been proposed.
each file is then parsed and a vector representing each file is  extracted based on a pre-determined vocabulary (which can be an outcome of setup feature selection process).
the large amount of files makes efficient  and effective inspection of files particularly challenging.
this approach has several  disadvantages.
cai dm, gokhale m, theiler j: comparison of feature selection and classification algorithms in identifying malicious executables.
however, it  is not clear to what extent it is essential to retrain the classifier with the  new files.
in particular, researchers have experimented with random (e.g.,[26]), directed (e.g., [24,26 ]), and artificial sampling[27].
several proposals have been made to address this issue including the decomposition of accuracy into its basic components[25 ], the use of roc analysis[32] or the g-mean [33].
this can be  explained by the fact that for eachn-gram size, the top 1,000 opcode n-grams, having the highest document frequency (df) value, were  selected.
another relevant issue to the research which emanates from the class imbalance problem concerns the choice of an evaluation metric.
feature selection was applied on the collection of 1,800 n-grams patterns.
additionally, we investigate the imbalance problem and evaluate through various malicious-benign proportions, the best settings for a training set given a test set.
converting byte representation into opcoden-grams patterns.
rf and bdt out-performed across the varying mfps.
by processing these vectors, the learning algorithm trains a  classifier.
combining statistical learning with a knowledge-based approach - a case study in intensive care monitoring.
three different feature extraction (fe) approaches were employed: features extracted from theportable executable (pe ) section, meaningful plain-text strings that are encoded in programs files, andbyte sequence features.
in the third experiment, we addressed our 6th research question in order to understand the need in updating the training set.
this measure, which is often used in imbalance  dataset evaluation studies, is a metric that combines both the sensitivity and  specificity by calculating their geometric mean.
this signifies that the sequence of two  opcodes is more representative than single opcodes, however, longer grams  decreased the accuracy.
in this paper, which is an extended version of [11], we use a methodology for malware categorization by implementing concepts from the text categorization domain, as was presented by part of the authors in[12].
another aspect in the maintenance of such a framework is the importance of  updating the training set with new known malicious files.
the mean accuracy, tpr and fpr for  different mfp levels in the training and test sets for the two best classifiers  bdt and rf (the graphs for the rest of the classifiers are provided in  additional file1).
publisher full text griffin k, schneider s, hu x, chiueh t: automatic generation of string signatures for malware detection.
consequently, the selected opcoden -grams appear in both sets and therefore eliminate the idf factor in the tf-idf measure.
thus, it is necessary to know the real class  of the files in the test-set in order to compare their real class with the  class that was derived by the classifier.
the result of this experiment showed no improvement when using opcoden-grams of different sizes.
combining statistical  learning with a knowledge-based approach - a case study in intensive care  monitoring.
weiss gm, provost f: learning when training data are costly: the  effect of class distribution on tree induction.
these files are collected from various sources including  dedicated honeypots, third party providers and files reported by customers  either automatically or explicitly.
similarly to the work of[31], in our research we also  consider the question of what is the appropriate proportion of examples of each  class (benign and malicious) for learning if only a limited number of training  instances can be used altogether.
the 2-gram opcodes outperformed the others and the df was the best feature selection method.
the mean accuracy, fpr, tpr and g-mean for 10% mfp in the test-set, for each mfp in the training set.
a complete  machine language instruction contains an opcode and, optionally, the  specification of one or more operands.
asaf shabtai1,2*, robert moskovitch1,2, clint feher1,2, shlomi dolev3,1 and yuval elovici1,2 *
in attempts to estimate their  ability to detect malicious codes based on their issue dates, these techniques  were trained on files issued before july 2003, and then tested on files issued  from that point in time through august 2004.
we acquired  7,688 malicious files from the vx heaven website[34].
proc of the 10th acm sigkdd international conference on knowledge  discovery and data mining, acm press 2006, 470-478.
[13] introduced a framework that uses the common n-gram  (cng) method and thek-nearest neighbor (knn) classifier for the  detection of malware.
however, in the textual domain, it was shown that thetfidf is a richer and more successful representation for the retrieval and categorization purposes[39] and thus we expected that using the tfidf weighting would lead to better performance than thetf.
chawla nv, bowyer kw, kegelmeyer wp: smote: synthetic minority over-sampling technique.
the results  show that malicious software opcode distributions differ significantly from  non-malicious software and suggests that the method can be used to detect  malicious code.
lee w, stolfo sj: a framework for constructing features and models for intrusion detection systems.
for example, these common engines may be located in varying locations inside the executables, and thus may be mapped to different addresses in memory or even perturbed slightly.
in this set, for each opcode n-gram size (1- to 6-gram), the first 300n-grams with the top df score were selected (i.e., total of 1,800 n-grams).
in figure 6 we present the mean tpr, fpr, accuracy and g-mean of each  classifier when using the best mean settings obtained for each of the three  opcoden-grams patterns sets: figure 6.
later, thenormalized term frequency (tf) and tfinverse document frequency (tfidf) representations were calculated for each opcoden-grams patterns in each file.
in artificial intelligence and applications.
thus, we divided the test collection into years and evaluated training sets of selected years on the next years.
the dataset was  divided into two parts.
additionally, it is important to identify the terms  that appear in most of the files in order to avoid vectors that contain many  zeros.
acm conference on computer and communications security, acm press 2008, 51-62.
provost f, fawcett t: robust classification systems for imprecise environments.
[19] conducted several experiments in which they evaluated the combinations of seven feature selection methods, three classifiers, and byte n-gram size.
the graphs show that the random forest and  boosted decision tree yielded the highest accuracy and lowest fpr.
in our second experiment, we addressed our 5th research question in order to find the best malicious file percentage (mfp) among the training-set files for varying mfp in the test-set files, and more specifically, for low mfp in the test-set (10-15%), which resembles a real-life scenario.
5.2 experiment 2 - the imbalance problem in our second experiment, we addressed our 5th research question in order  to find the best malicious file percentage (mfp) among the training-set files  for varying mfp in the test-set files, and more specifically, for low mfp in  the test-set (10-15%), which resembles a real-life scenario.
publisher full text jacob g, debar h, filiol e: behavioral detection of malware: from  a survey towards an established taxonomy.
the df is a simple feature selection method which favors features which appear in most of the files.
methods the goal of our work was to explore methods of using data mining techniques  in order to create accurate detectors for new (unseen) binaries.
publisher full text shabtai a, potashnik d, fledel y, moskovitch r, elovici e: monitoring, analysis and filtering system for purifying network traffic of  known and unknown malicious content.
several solutions to the challenge of packed code were suggested (e.g.,  ether[36], mcboost [37], polyunpack [38]).
in the first experiment we aimed to answer the first four research  questions presented in section 4.1.
the disassembly process consists of translating the machine code instructions stored in the executable to a more human-readable language, namely, assembly language.
communications of the acm 1975, 18: 613-620.
finally, in the third experiment, we performed a chronological evaluation to  determine how well a classifier, which was trained on past examples, can detect  new malicious file and to investigate the importance and need in updating the  training set frequently.
having experience in using this approach in real life setting, we can give two general examples of such applications.
in our study, the reduction of the number of features is crucial and must be performed while maintaining a high level of accuracy.
the kaspersky anti-virus program was used to verify that these files did not contain any malicious code.
additionally, an investigation of the  imbalance problem, on which we elaborate later, was demonstrated.
we had the same mfp levels for the test-sets  as well.
for the imbalance analysis, where the accuracy measure can sometimes be misleading, we also computed the g-means measure.
in this study we used opcode n-gram patterns generated by  disassembling the inspected executable files to extract features from the  inspected files.
in static analysis, information about the program or its expected  behavior consists of explicit and implicit observations in its binary/source  code.
in such  cases, static analysis methods might fail to correctly classify a packed malware
the imbalance problem refers to scenarios in which the proportions of the classes are not equal.
publisher full text santos i, brezo f, nieves j, penya yk, sanz b, laorden c, bringas pg: idea: opcode-sequence-based malware detection.
we investigated the imbalance problem, referring to several real-life scenarios  in which malicious files are expected to be about 10% of the total inspected  files.
evaluation performed in these studies showed that unpacking files before being classified increase the classification accuracy[37,38].
improving malware  detection by applying multi-inducer ensemble.
in other methods, the lack of appearances in many files might create zeroed vectors and might consequently lead to a lower accuracy level.
we, on the other hand, focus on the single problem of interest here--malware detection--but consider eight different classifiers.
next, during the testing phase, a test-set collection of new benign  and malicious files which did not appear in the training-set are classified by  the classifier that was generated in the training phase.
acta press; 2008:358-363.
in this experiment, we found that there are classifiers which are relatively non-reactive to changes in the mfp level of the test-set.
publisher full text moskovitch r, elovici y, rokach l: detection of unknown computer worms based on behavioral classification of the host.
security and communication networks 2010.
the evaluation showed a high accuracy level of 98.4%.
first, it is difficult to simulate the appropriate conditions in  which the malicious functions of the program, such as the vulnerable  application that the malware exploits, will be activated.
abstract in previous studies classification algorithms were employed successfully  for the detection of unknown malicious code.
chen c, liaw a, breiman l: using random forest to learn  unbalanced data.
benign files, including executable and dll  (dynamic linked library) files, were gathered from machines running the windows  xp operating system on our campus.
this is intuitively  important, because the purpose of malicious files changes over time and  accordingly the patterns within the code.
in this case we would like to decrease the probability of false-negative, which will result in quarantining, deleting, or blocking of a legitimate file.
another application is as an anti-virus.
sigkdd explorations newsletter 2004, 6(1): 1-6.
introduction modern computer and communication infrastructures are highly susceptible to  various types of attacks.
kubat m, matwin s: addressing the curse of imbalanced data sets:  one-sided sampling.
out of the ann classifier, all other classifiers observed similar behavior in which higher tpr and lower fpr were achieved when training on newer files.
the benign set contained 22,735 files.
after determining the optimal settings when using  the opcode representation, we compared the achieved accuracy to the byten -gram representation used in [12].
the overall  process of classifying unknown files as either benign or malicious using ml  methods is divided into two subsequent phases: training and testing.
this is very important since using the tfidf representation introduces additional computational challenges in the maintenance of the collection when it is updated.
using a disassembler software, we extracted a sequence of  opcodes from each file representing execution flow of machine operations.
what is the best malicious file percentage (mfp) in the training set for varying mfp in the test set? 6.
san francisco, ca, usa: morgan kaufmann  publishers, inc; 2005.
a new executable file was compared with the profiles of malicious and benign classes, and was assigned to the most similar.
however, in the textual domain, it was shown that thetfidf is a richer and more successful representation for the retrieval and  categorization purposes[39] and thus we expected that using the tfidf weighting would lead to better performance than thetf.
which term-representation is better: tf or tfidf ?
in fact, in all of the cases,  the tpr was above 0.95 and fpr approximately 0.1 when training the models on a  yearly basis.
doi: 10.1002/sec.229 moser a, kruegel c, kirda e: limits of static analysis for  malware detection.
thus, generalization of the detection methods is crucial in order to be able to detect unknown malware before its execution.
another relevant issue to the research which emanates from the class  imbalance problem concerns the choice of an evaluation metric.
in a filters approach method, a measure is used to quantify the correlation of each feature to the class (malicious or benign) and estimate its expected contribution to the classification task.
in tricks of the trade, lecture notes in computer science state-of-the-art surveys.
an opcode (short for operational code) is the portion of a machine language instruction that specifies the operation to be performed.
benign files, including executable and dll (dynamic linked library) files, were gathered from machines running the windows xp operating system on our campus.
fs performed very  well, especially when fewer features were used (top 50 and top 100).
distribution of n-gram sizes, chosen by each feature selection method, for the twon-grams sets that consist of varyingn-grams sizes.
the authors declare that they have no competing interests.
we, on the other hand, focus on the  single problem of interest here--malware detection--but consider eight  different classifiers.
this was done in order to avoid problems related to sparse data  (i.e., vectors that contain many zeros).
menahem e, shabtai a, rokach l, elovici y:
heidelberg: springer; 2008:108-125.
acm press;  2003:290-299.
a common method of launching these attacks is by  means ofmalicious software (malware) such as worms, viruses, and  trojan horses, which, when spread, can cause severe damage to private users,  commercial companies and governments.
the imbalance problem the class imbalance problem was first introduced to the ml research  community a little
additionally, we investigate the imbalance  problem and evaluate through various malicious-benign proportions, the best  settings for a training set given a test set.
the files in the  test-set were not in the training set, presenting unknown files to the  classifier.
to identify the files, we  used the kaspersky anti-virus.
although such a process seems trivial, malware writers often try to prevent  the successful application of the disassembly process to prevent experts from  analyzing their malwares.
we had the same mfp levels for the test-sets as well.
cf carried out the data collection and experiments.
in the first experiment, we found that the tfidf representation has no  added value over the tf representation, which is not the case in many  information retrieval applications.
ye and sd participated in the design of the study and its coordination.
for the rf and bdt, the highest  performance level was in 10% and 15% of mfp in the training set, which is more  similar to the mfp in the test-set.
[12] published the results of a study which  used a test collection containing more than 30,000 files, in which the files  were represented by byten-grams.
figure2 presents the mean tpr, fpr, accuracy and g-mean of the combinations of the term representation andn-grams size.
this is due to the fact that the vocabulary size may exceed millions of features; far more than can be processed by any feature selection tool within a reasonable period of time.
proc of the 10th acm sigkdd international conference on knowledge discovery and data mining, acm press 2006, 470-478.
using 10% malicious files in the training set showed a clear trend in which the performance improves when the training set is updated on a yearly basis.
each file in the test-set is first parsed and the representative vector is extracted using the same vocabulary as in the training phase.
the files in the test-set were not in the training set, presenting unknown files to the classifier.
the mean tprs, fprs, accuracies and g-means of the tf and the tfidf were quite identical, which is good because maintaining the tfidf requires additional computational efforts each time a malcode or benign files are added to the collection.
- constant n-gram size 2-gram, tf representation, 300 features selected by the df measure (as  presented in section 5.1.3) - denoted by [2gram;tf;top300;df].
in  addition, we would like to point out that classifying benign files is also  useful and can reduce the load of inspecting suspicious (or unknown) files.
machine learning 2001, 42(3): 203-231.publisher full text kubat m, matwin s: machine learning for the detection of oil spills in satellite radar images.
which top-selection (number of features) is the best: 50 , 100, 200 or 300 and which features selectionmethod: df, fs and gr is superior? 4.
over the past decade, several studies have focused on the detection of unknown malware based on its binary code content.
the feature measure that is used by the feature selection method is independent of any classification algorithm, thus allowing us to compare the performances of the different classification algorithms.
bailey m, oberheide j, andersen j, mao zm, jahanian f, nazario j: automated classification and analysis of internet malware.
the mean accuracy, tpr and g-mean of the 2-gram outperforms all the othern-grams with the lowest mean fpr for all classifiers, but not significantly.
moskovitch r, stopel d, feher c, nissim n, japkowicz n, elovici y: unknown malcode detection and the imbalance problem.
salton g, wong a, yang cs: a vector space model for automatic  indexing.
while the mean tprs, fprs, accuracies and g-means of  the tf and tfidf were quite identical, the mean accuracy and g-mean of the  2-gram outperforms all the othern-grams with the lowest fpr.
typically, the class imbalance  problem occurs when there are significantly more instances from one class  relative to other classes.
in particular, the dt and bdt classifiers behaved  optimally when the mfp levels in the training-set and test-set were similar.
the distribution of n-grams sizes for the two n-grams sets that consist of varying n-gram sizes is presented in table3.
further to our results from the training-set point of view (figures 7 and 8 ), we present a detailed description of the accuracy, tpr and fpr for the mfp levels in the two sets in a 3-dimensional presentation for each classifier (the graphs of the two best classifiers, rf and bdt, are presented in figure9; the graphs of the rest of the classifiers are provided in additional file1).
when designing these experiments our objective was to investigate the usage of opcode for unknown malcode detection while considering various strategies and settings of the framework.
in such an application the goal is to perform an initial filtering to reduce the amount of files to investigate manually.
most of these studies extracted  features based onbyte n-gram patterns in order to represent the  inspected files.
to overcome such practices, we suggest disregarding any parameters of the opcodes.
to answer the above questions we first performed a wide set of experiments to identify the best term representation,n-gram size, top-selection and feature selection method.
the large amount of files makes efficient and effective inspection of files particularly challenging.
lastly, section 6 discusses the results and future work.
in an extension of their previous study,  kolter and maloof[18] classified malware into families (multiple classes) based  on the functions in their respective payloads.
a typical problem of this domain is the imbalance problem in which the distribution of the classes in real life varies.
to identify the best feature selection method and the top number of features, we calculated the mean tpr, fpr, accuracy and g-mean of each method, as shown in figure3.
format: pdf size: 1.5mb download file this file can be viewed with: adobe acrobat reader when comparing these results with the results of the byte n-grams patterns experiments in[12] we notice that in terms of accuracy, the byte n -grams classifiers are more sensitive to varying mfp levels in the training and test-sets.
format: pdf size: 307kb download file this file can be viewed with: adobe acrobat reader
feature selection was applied on the  collection of 1,800n-grams patterns.
first, it is difficult to simulate the appropriate conditions in which the malicious functions of the program, such as the vulnerable application that the malware exploits, will be activated.
in general, this indicates that in order to achieve a desired tpr and fpr, only the training set can be considered and selecting the proper mfp in the training set will ensure the desired tpr and fpr for any mfp in the test set.
packing and compressing files can be achieved by using off-the-shelf packers such as armadillo, upx and themida.
in our study, the reduction of the number of features is  crucial and must be performed while maintaining a high level of accuracy.
similarly to the work of[31], in our research we also consider the question of what is the appropriate proportion of examples of each class (benign and malicious) for learning if only a limited number of training instances can be used altogether.
in this study we represent the inspected files usingopcode  n-grampatterns which are extracted from the files after disassembly.
from the results we conclude that for this problem domain, complex classifiers, such as the ensemble random forest algorithm[44] which induces many decision trees and then combines the results of all trees, and the boosted decision tree[48] generate a more accurate classifier.
finally, for all classifiers, when testing on 2007 examples, a significant decrease in the accuracy was observed; a fact that might indicate that new types of malware were released during 2007.
morik k, brockhausen p, joachims t:
code obfuscation is a prominent technique used by hackers in order to avoid detection by security mechanisms (e.g., anti-viruses and intrusion detection systems)[35].
in this experiment, themalicious file percentage (mfp) in the training and test sets was set according to the natural proportions in the file-set at approximately 22%.
on the optimality of simple bayesian classifier under zero-one loss.
section 3 describes the methods we used, including concepts from text categorization, data preparation, and classifiers.
all authors read and approved the final manuscript.
publisher full text griffin k, schneider s, hu x, chiueh t: automatic generation of  string signatures for malware detection.
in a filters approach method, a measure is used to  quantify the correlation of each feature to the class (malicious or benign) and  estimate its expected contribution to the classification task.
this observation may indicate an advantage of the opcoden-grams  representation as being less sensitive to the levels of mfp in the two sets, or  more specifically in the test sets which represent the changes of proportions  in real life conditions.
we begin in section 2 with a  survey of previous relevant studies.
heidelberg: springer; 2007:178-197.
evaluation results show that an update in the training set is needed.
the first strategy, which is classifier-independent, consists of balancing the original data-set by using different kinds of undersampling or oversampling approaches.
in conference on detection of intrusions and malware & vulnerability assessment.
in an extension of their previous study, kolter and maloof[18] classified malware into families (multiple classes) based on the functions in their respective payloads.
[44], artificial neural networks (ann) [ 45], decision trees (dt)
in 12th international  symposium on recent advances in intrusion detection.
we believe that disregarding the parameters would provide a more general representation of the files, which is expected to be more effective for purposes of classification into benign and malicious files.
this in fact emphasizes the imbalance problem.
edited by scholkopf b, burges c, smola aj.
the approach in[22] presents a single case in our methodology; in this paper we test several opcoden-gram sizes while bilar [22] used only 1-gram.
the tf representation is actually the representation which was used in  previous papers in the domain of malicious code classification[13,16,17], where  counting words was replaced by byten-grams extracted from the  executable files.
in addition, we would like to point out that classifying benign files is also useful and can reduce the load of inspecting suspicious (or unknown) files.
we also evaluated the performance of classifiers when using a constant size of opcoden-grams versus using varying sizes ofn-grams.
this  is due to the fact that the vocabulary size may exceed millions of features;  far more than can be processed by any feature selection tool within a  reasonable period of time.
in this experiment, themalicious file percentage (mfp) in  the training and test sets was set according to the natural proportions in the  file-set at approximately 22%.
based on our experiments, using opcode sequences improves the  detection performance significantly.
the opcodes, being the building blocks of machine language, have been used for statically analyzing application behavior and detecting malware.
in the third experiment we wanted to determine the importance of updating the training set over time.
detailed description of the accuracy, tpr and fpr for the malicious file percentage levels in the two sets in a 3-dimensional presentation for each classifier.
we  performed an extensive evaluation using a test collection comprising more than  30,000 files.
the operations of an opcode may include arithmetic, data manipulation, logical operations, and program control.
in the testing phase the performance of the generated classifier is evaluated by extracting standard accuracy measures for classifiers.
packing and compressing files can be achieved  by using off-the-shelf packers such as armadillo, upx and themida.
which classifier is the best: svm, lr, rf, ann, dt, bdt, nb or  bnb?
for this we used three opcoden-grams sets on which the three feature selection methods were applied with four top-selections (50, 100, 200 or 300): this option refers to the 6 opcode n-grams sets that were used in the previous experiments, in which then-grams in each set are of the same size (1, 2, 3, 4, 5 and 6).
journal in computer virology 2008, 4: 251-266.
publisher full text karim e, walenstein a, lakhotia a, parida l: malware phylogeny  generation using permutations of code.
the mean accuracy, tpr and fpr for different mfp levels in the training and test sets for the two best classifiers bdt and rf (the graphs for the rest of the classifiers are provided in additional file1).
in this case we would like to decrease the  probability of false-negative, which will result in quarantining, deleting, or  blocking of a legitimate file.
what is the best malicious file percentage (mfp) in  the training set for varying mfp in the test set? 6.
publisher full text mitchell t: machine learning.
additionally, in order to compare the classifiers' performance, we selected the settings which had the highest mean accuracy level over all the classifiers.
the  opcoden-gram patterns are used as features for the classification  process.
the mean tprs, fprs,  accuracies and g-means of the tf and the tfidf were quite identical, which is  good because maintaining the tfidf requires additional computational efforts  each time a malcode or benign files are added to the collection.
we first wanted to find the best terms representation (i.e., tf or tfidf).
security informatics 2012, 1:1  doi:10.1186/2190-8532-1-1 the electronic version of this article is the complete one and can be found  online at:http://www.security-informatics.com/content/1/1/1 received:
the df is a simple  feature selection method which favors features which appear in most of the  files.
dinaburg a, royal p, sharif mi, lee w: ether: malware analysis  via hardware virtualization extensions.
for that, we investigate the approach of representing malicious files by opcode expressions as features in the classification task.
science 1999, 286:531-537.
classifiers differ in performance within different domains and the best fitted classifier can often be identified by experimentation.
while being very precise, signature-based methods are  useless against unknown malicious code[9].
tpr, fpr, accuracy and g-mean of each  classifier when comparing the best averaged settings (i.e., 2-gram, tf  representation, 300 features selected by the df measure) and the classifier's  optimal settings.
a rigorous evaluation was performed using a test  collection comprising of more than 30,000 files, in which various settings of  opcoden-gram patterns of various size representations and eight types  of classifiers were evaluated.
lastly, we present a chronological evaluation in which the frequent need for updating the training set was evaluated.
however, it is not clear to what extent it is essential to retrain the classifier with the new files.
lastly, we present a chronological evaluation in which the frequent need  for updating the training set was evaluated.
based on this vector, the classifier  will classify the file as either benign or malicious.
ye and sd  participated in the design of the study and its coordination.
thenormalized tf is calculated by dividing the frequency of the term in the document by the frequency of the most frequent term in a document.
another  application is as an anti-virus.
lee w, stolfo sj: a framework for constructing features and  models for intrusion detection systems.
in the first experiment we aimed to answer the first four research questions presented in section 4.1.
these proportions do not reflect real-life situations in which malicious code is significantly lower than 50% and therefore might report optimistic results.
in such cases, where many of the vectors are sparse, the detection  accuracy will be decreased.
in such cases the classifier tends to misclassify  the instances of the less represented classes.
the tf and tfidf are  well known measures in thetext categorization field [39].
code obfuscation is a prominent technique used by hackers in order to avoid  detection by security mechanisms (e.g., anti-viruses and intrusion detection  systems)[35].
the mean tpr, fpr, accuracy and g-mean  of the evaluated feature selection methods (document frequency, fisher score,  gain ratio) as a function of the number of top features (50, 100, 200 and 300) .
their work considers the case of decision trees induction on 26 different data-sets.
static analysis solutions are primarily implemented using the signature-basedmethod which relies on the identification of unique strings  in the binary code[2].
chawla nv, bowyer kw, kegelmeyer wp: smote: synthetic minority  over-sampling technique.
another aspect in the maintenance of such a framework is the importance of updating the training set with new known malicious files.
corresponding author: asaf shabtai shabtaia@bgu.ac.il author affiliations 1 deutsche telekom laboratories, ben-gurion university, be'er sheva,  84105, israel 2 department of information systems engineering, ben-gurion university,  be'er sheva, 84105, israel 3 department of computer science, ben-gurion university, be'er sheva,  84105, israel for all author emails, please log on.
this observation, which emphasizes the imbalance problem, signifies  that in order to achieve a desired tpr and fpr, only the training set can be  considered and selecting the proper mfp in the training set will ensure the  desired tpr and fpr for any mfp in the test set.
each file is then parsed and a vector representing each file is extracted based on a pre-determined vocabulary (which can be an outcome of setup feature selection process).
evaluation results  show that an update in the training set is needed.
in the following two experiments we used the best six classifiers (rf, dt,  bdt, lr, ann, svm) when trained on the best averaged settings (2-gram, tf  representation, 300 top features selected by the df measure).
for the rf and bdt, the highest performance level was in 10% and 15% of mfp in the training set, which is more similar to the mfp in the test-set.
the performance of both the naïve bayes and the  boosted naïve bayes was worst for alln-gram sizes having the  lowest mean tpr, accuracy and g-mean and highest mean fpr.
from the results  we conclude that for this problem domain, complex classifiers, such as the  ensemble random forest algorithm[44] which induces many decision trees and then  combines the results of all trees, and the boosted decision tree[48] generate a  more accurate classifier.
table1 depicts  the top five settings with the highest mean accuracy level (averaged over all  the classifiers).the outperforming setting was the: 2-gram, tf, using 300  features selected by the df measure.
proc of the 3rd international conference on document analysis and  recognition 1995, 278-282.
in future work we plan to experiment with cost-sensitive classification in which the costs of the two types of errors (i.e., missing a malicious file and false alarm) are not equal.
© 2012 shabtai et al; licensee springer.
in the following two experiments we used the best six classifiers (rf, dt, bdt, lr, ann, svm) when trained on the best averaged settings (2-gram, tf representation, 300 top features selected by the df measure).
in 12th international symposium on recent advances in intrusion detection.
the goal of our work was to explore methods of using data mining techniques in order to create accurate detectors for new (unseen) binaries.
generally, df outperformed on all sizes of top features,  while fs performed very well, especially when fewer top features were used (top  50 and top 100).
in addition, the optimal  setting of each classifier is presented, as well as the resulted accuracy for  the optimal setting, and the difference compared to the accuracy achieved with  the best averaged setting.
all authors read  and approved the final manuscript.
4 evaluation 4.1 research questions we set out to evaluate the use of opcodes patterns for the purpose of  unknown malicious code detection through three main experiments.
most of these studies extracted features based onbyte n-gram patterns in order to represent the inspected files.
when designing  these experiments our objective was to investigate the usage of opcode for  unknown malcode detection while considering various strategies and settings of  the framework.
rieck k, holz t, düssel p, laskov p: learning and classification of malware behavior.
moreover, these malicious files are  written in varying frameworks which result in differing patterns.
the results of each classifier when using the best mean settings (i.e., -gram, tf, using 300 features selected by the df measure), including the accuracy, tpr, fpr and g-mean are presented in table2.
shin s, jung j, balakrishnan h: malware prevalence in the kazaa file-sharing network.
we also evaluated the performance of  classifiers when using a constant size of opcoden-grams versus using  varying sizes ofn-grams.
[17] also used byte n-grams representation, however the vector ofn-gram features was binary, presenting the presence or absence of a feature in the file and ignoring the frequency of feature appearances (in the file).
as a case in point, we extracted 443,730 3-grams and 1,769,641  4-grams.
the extracting of sequences is in the same logical order in which the opcodes appear in the executable, disregarding the extra information available (e.g., memory location, registers, etc.)
moreover, there are malware generation utilities which use a common engine to  create new malware instances; this engine may even be used to polymorph the  threat as it propagates.
the ann performance was generally low and dropped significantly for  5%, 15% and 50% mfp in the training set.
statistics  department, university of california at berkeley; 2004.
for evaluation purposes, we used the true positive rate (tpr) measure, which is the number ofpositive instances classified correctly, false positive rate (fpr), which is the number of negative instances misclassified, and thetotal accuracy, which measures the  number of absolutely correctly classified instances, either positive or  negative, divided by the entire number of instances.
recent studies, which we survey in the next section, have shown  that by using byten-grams to represent the binary file features,  classifiers with very accurate classification results can be trained, yet there  still remains room for improvement.
we had 7 training sets, in which  training setk included samples from the year 2000 till year 200[k ] (where k = 0,1,2
this  malicious and benign file collection was previously used in[12].
while the mean tprs, fprs, accuracies and g-means of the tf and tfidf were quite identical, the mean accuracy and g-mean of the 2-gram outperforms all the othern-grams with the lowest fpr.
the mean accuracy, tpr and g-mean of the 2-gram  outperforms all the othern-grams with the lowest mean fpr for all  classifiers, but not significantly.
the mean tpr, fpr, accuracy and g-mean  for each classifier (using tf representation) as a function of the opcoden -gram size.
the performance of both the naïve bayes and the boosted naïve bayes was worst for alln-gram sizes having the lowest mean tpr, accuracy and g-mean and highest mean fpr.
opcoden-grams are used as features during the classification process with the aim of identifying unknown malicious code.
we set out to evaluate the use of opcodes patterns for the purpose of unknown malicious code detection through three main experiments.
doi: 10.1002/sec.229 moser a, kruegel c, kirda e: limits of static analysis for malware detection.
in our domain, eachn-gram is analogous to a word (or a term) in a text document.
dinaburg a, royal p, sharif mi, lee w: ether: malware analysis via hardware virtualization extensions.
royal p, halpin m, dagon d, edmonds r, lee w: polyunpack: automating the hidden-code extraction of unpack-executing malware.
to overcome  such practices, we suggest disregarding any parameters of the opcodes.
proc of the 14th international conference on machine learning 1997, 179-186.
thus, we first extracted the 1,000 features (i.e., opcoden -grams patterns) with the highestdocument frequency values and on  which three feature selection methods were later applied.
heidelberg: springer;  2009:101-120.
the distribution of n-grams sizes for the two n-grams  sets that consist of varying n-gram sizes is presented in table3.
bishop c: neural networks for pattern recognition.
the results of each classifier when using the best mean settings (i.e.,  -gram, tf, using 300 features selected by the df measure), including the  accuracy, tpr, fpr and g-mean are presented in table2.
in accordance to these questions, we wanted  to identify the best settings of the classification framework which is  determined by a combination of: (1) the term-representation (tf or tfidf); (2)  the opcoden-gram size (1, 2, 3, 4, 5 or 6); (3) the top-selection of  features (50, 100, 200 or 300); (4) the feature selection method (df, fs or  gr); and (5) the classifier (svm, lr, rf, ann, dt, bdt, nb or bnb).
additionally, in order to compare the classifiers' performance, we selected  the settings which had the highest mean accuracy level over all the  classifiers.
relations among mfps in  training and test-sets: accuracy, tpr and fpr for the mfp levels in the two  sets in a 3-dimensional presentation.
secondly, it is not clear what is the required period of time needed to observe the appearance of the malicious activity for each malware.
the classification process main goal is to detect unknown malware  within a set of suspected files which will later be included in antivirus  software as signatures.
next, during the testing phase, a test-set collection of new benign and malicious files which did not appear in the training-set are classified by the classifier that was generated in the training phase.
improving malware detection by applying multi-inducer ensemble.
the mean accuracy, tpr and g-mean of the 2-gram outperforms all the othern-grams with the lowest mean fpr for all classifiers.
5.1.1 feature representation vs. n-grams
thenormalized tf is calculated by dividing the frequency of  the term in the document by the frequency of the most frequent term in a  document.
also, the large number of malware files in our dataset that could be dissembled indicates that in order to appear benign and to pass security mechanisms (that are configured to block content that is encrypted\obfuscated and cannot be inspected), these techniques are not always used by hackers.
additionally, shin et al.[15] found that above 15% of the files in the kazaa network contained malicious code.
heidelberg: springer; 2009:101-120.
each training set k was  evaluated separately on each following year from 200[k+1] till 2007.
we summarize the research goals in six questions: 1.
the opcoden-gram patterns are used as features for the classification process.
in attempts to estimate their ability to detect malicious codes based on their issue dates, these techniques were trained on files issued before july 2003, and then tested on files issued from that point in time through august 2004.
in the testing phase the  performance of the generated classifier is evaluated by extracting standard  accuracy measures for classifiers.
our main goal in this study is to be able to filter out unknown malicious files from the files arriving to an anti-virus vendor every day.
interestingly, a stable state is observed in the accuracy measure for any mfp level.
annual computer security applications conference, ieee computer society 2007, 421-430.
in order to find the best settings for all the classifiers, we  calculated the mean fpr, tpr, accuracy and g-mean for each setting that is  defined by the: (1)n-gram size; (2) feature representation; (3)  feature selection method; and (4) the number of top features.
the term's (normalized) tf value is multiplied by the idf = log (n/df), where n is the number of documents in  the entire file collection anddf is the number of files in which it  appears.
authors' contributions rm and as conceived of the study, studied the research domain, participated  in the design of the study, performed the analysis of the results, and drafted  the manuscript.
mcafee study finds 4% of
the results show that using various sizes of opcode n-grams  patterns does not improve the detection performance and in fact for most  classifiers, the performance accuracy was deteriorated.
proc of the 3rd international conference on document analysis and recognition 1995, 278-282.
the mean accuracy, fpr, tpr and g-mean  for 10% mfp in the test-set, for each mfp in the training set.
intelligent data analysis journal 2002, 6(5) :429-450.
oxford: clarendon press; 1995.
computational statistics and data analysis 2008, 53 (4):1483-1494.
from the  table we can see, as expected, that the df feature selection method favors short n-grams which appear in a larger number of files.
in this study we used ida-pro, the most advanced commercial disassembly program available today.
pubmed abstract | publisher
how often should a classifier be trained with recent malicious files in order to improve the detection accuracy of new malicious files?
this malicious and benign file collection was previously used in[12].
we acquired 7,688 malicious files from the vx heaven website[34].
in 12th  international symposium on recent advances in intrusion detection.
for that, we investigate the  approach of representing malicious files by opcode expressions as features in  the classification task.
we therefore use the  constantn-gram size sets for the next experiments.
edited by scholkopf  b, burges c, smola aj.
tf representation, 300 features selected by the gr measure - denoted by [top300each; tf;top300;gr].
oxford:  clarendon press; 1995.
table1 depicts the top five settings with the highest mean accuracy level (averaged over all the classifiers).the outperforming setting was the: 2-gram, tf, using 300 features selected by the df measure.
the three feature selection methods operate according to the filters approach [40].
mean tpr, fpr, accuracy and g-mean of  each classifier when using the best mean settings obtained for each of the three n-grams sets: [2gram;tf;top300;df], [top1800all;tf;top300;gr] and  [top300each;tf;top300;gr].
the feature  measure that is used by the feature selection method is independent of any  classification algorithm, thus allowing us to compare the performances of the  different classification algorithms.
the tf and tfidf are well known measures in thetext categorization field [39].
this observation may indicate an advantage of the opcoden-grams representation as being less sensitive to the levels of mfp in the two sets, or more specifically in the test sets which represent the changes of proportions in real life conditions.
format: pdf size: 307kb download file this file can be viewed with: adobe acrobat reader 6.
icml, morgan kaufmann publishers inc 1999, 268-277.
the opcodes, being the building blocks of machine language, have been used  for statically analyzing application behavior and detecting malware.
rm and as conceived of the study, studied the research domain, participated in the design of the study, performed the analysis of the results, and drafted the manuscript.
in the third experiment, we addressed our 6th research question in order to  understand the need in updating the training set.
modern computer and communication infrastructures are highly susceptible to various types of attacks.
in order to reduce the number of opcoden-gram features, which ranges from thousands to millions, we used the df measure to select the top 1,000 features and tested three feature selection methods.
this is intuitively important, because the purpose of malicious files changes over time and accordingly the patterns within the code.
the tfidf combines the frequency of a term in the document (tf) and its frequency in the whole document collection, denoted bydocument frequency (df).
security informatics 2012, 1:1 doi:10.1186/2190-8532-1-1 the electronic version of this article is the complete one and can be found online at:http://www.security-informatics.com/content/1/1/1
interestingly, the best n-gram size of opcodes was the 2-gram with  the highest accuracy and g-mean values and the lowest fpr (and with tpr similar  but slightly lower from the 3-gram).
the result of this experiment showed no  improvement when using opcoden-grams of different sizes.
for both scenarios it is difficult to assign the costs for the two errors (note that each type of malware can be assigned with a different cost level based on the damage it causes) and therefore in this paper we focus on exploring and identifying the settings and classifiers that can classify the files as accurately as possible, leaving the cost-sensitive analysis for future work.
schultz m, eskin e, zadok e, stolfo s: data mining methods for detection of new malicious executables.
later, thenormalized term frequency (tf) and  tfinverse document frequency (tfidf) representations were calculated  for each opcoden-grams patterns in each file.
bilar[22]  examines the difference of statistical opcode frequency distribution in  malicious and non-malicious code.
the extracting of sequences is in the same logical  order in which the opcodes appear in the executable, disregarding the extra  information available (e.g., memory location, registers, etc.)
the size of vocabularies (number of distinct n-grams) extracted  for the opcoden-grams representation were of 515, 39,011, 443,730,  1,769,641, 5,033,722 and 11,948,491, for 1-gram, 2-gram, 3-gram, 4-gram, 5-gram  and 6-gram, respectively.
the comparisons show that for all classifiers,  excluding the nb and bnb, the best averaged setting yields similar performance.
to classify the files we had to convert them into a vectorial representation.
the mean tpr, fpr, accuracy and g-mean for each term representation (tf and tfidf) as a function of the opcoden -gram size.
[47], and their boosted  versions, bdt and bnb[48].
keywords: malicious code detection; opcode; data mining;  classification 1.
in addition, we can see that for a given mfp in thetraining set , the tpr and the fpr of the classifiers are stable for any mfp level in the  test set.
the results (accuracy, tpr and fpr) for  with a 50% mfp on the training set and 10% mfp on the test set for the two best  classifiers bdt and rf (the rest of the classifiers are presented in additional  file2).
we created a dataset of malicious and benign executables for the windows operating system, the system most commonly used and attacked today.
in addition, one  should consider the expected proportion of malicious files in the stream of  data.
chronological evaluation: accuracy, tpr and fpr with a 50% mfp in the training set and 10% mfp in the testing set for all classifiers.
moreover, there are malware generation utilities which use a common engine to create new malware instances; this engine may even be used to polymorph the threat as it propagates.
this process is presented in figure1.
the remaining the classifiers performed very well, having the random forest, boosted decision trees and decision trees outperforming.
5.3 experiment 3 - chronological evaluation
heidelberg:  springer; 2008:108-125.
- top 300 for each n-gram size in this set, for each opcode n-gram size (1- to 6-gram), the first  300n-grams with the top df score were selected (i.e., total of 1,800 n-grams).
in the trainingphase, a training-set of benign and malicious files is provided to the system.
additionally, it is important to identify the terms that appear in most of the files in order to avoid vectors that contain many zeros.
proc of the ieee symposium on security and privacy, ieee computer society 2001, 38.
as a case in point, a recent mcafee survey[14] indicates that about 4% of search results from the major search engines on the web contain malicious code.
thus, it is necessary to know the real class of the files in the test-set in order to compare their real class with the class that was derived by the classifier.
mean tpr, fpr, accuracy and g-mean of each classifier when using the best mean settings obtained for each of the three n-grams sets: [2gram;tf;top300;df], [top1800all;tf;top300;gr] and
detailed description of the accuracy,  tpr and fpr with a 50% mfp in the training set and 10% mfp in the testing set  for all classifiers.
more and more researchers  realized that the performance of their classifiers may be sub-optimal due to  the fact that the datasets are not balanced.
the top five settings with the highest mean accuracy over all the classifiers.
witten ih, frank e: data mining: practical machine learning tools and  techniques.
in sections 4 and 5 we present the evaluation and the evaluation results.
to answer the above questions we first performed a wide set of experiments  to identify the best term representation,n-gram size, top-selection  and feature selection method.
this is very important since using the  tfidf representation introduces additional computational challenges in the  maintenance of the collection when it is updated.
competing interests the authors declare that they have no competing interests.
the class imbalance problem was first introduced to the ml research community a little
ida-pro implements  sophisticated techniques which enabled us to disassemble most of our malware  collection successfully (approximately 74% of the malware files)
part of springer science+business media.
publisher full text santos i, brezo f, nieves j, penya yk, sanz b, laorden c, bringas pg: idea: opcode-sequence-based malware detection.
the term's (normalized) tf value is multiplied by the idf = log (n/df), where n is the number of documents in the entire file collection anddf is the number of files in which it appears.
in proc of the 10th acm  conference on computer and communications security.
the mean tpr, fpr, accuracy and g-mean for each classifier (using tf representation) as a function of the opcoden -gram size.
the results (accuracy, tpr and fpr) for with a 50% mfp on the training set and 10% mfp on the test set for the two best classifiers bdt and rf (the rest of the classifiers are presented in additional file2).
thus, generalization of the  detection methods is crucial in order to be able to detect unknown malware  before its execution.
neural network classification and unequal prior class probabilities.
royal p, halpin m, dagon d, edmonds r, lee w: polyunpack:  automating the hidden-code extraction of unpack-executing malware.
journal in computer virology 2005, 1(1-2): 13-23.
for example, when referring to 15%, we assert that 15% of the files in the training set were malicious and 85% were benign.
- top 300 for each n-gram size tf representation, 300 features selected by the gr measure - denoted by  [top300each; tf;top300;gr].
in order to reduce the number  of opcoden-gram features, which ranges from thousands to millions, we  used the df measure to select the top 1,000 features and tested three feature  selection methods.
interestingly, the best n-gram size of opcodes was the 2-gram with the highest accuracy and g-mean values and the lowest fpr (and with tpr similar but slightly lower from the 3-gram).
in such cases, static analysis methods might fail to correctly classify a packed malware [36].
the question asks how important it is to update the repository of malicious and benign files and whether, for specific years, the files were more contributive to the accuracy when introduced in the training set or in the test set.
typically, the class imbalance problem occurs when there are significantly more instances from one class relative to other classes.
3.3 data preparation and feature selection to classify the files we had to convert them into a vectorial  representation.
subsequently, several opcoden-gram lengths were considered where each n-gram was composed of n sequential opcodes.
provost f, fawcett t: robust classification systems for imprecise  environments.
these methods were proposed for automatic unpacking of packed files by applying either static or dynamic analysis.
[44], artificial neural networks (ann)
in particular, the dt and bdt classifiers behaved optimally when the mfp levels in the training-set and test-set were similar.
ieee computer society; 2006:289-300.
in proc of the 10th acm conference on computer and communications security.
in particular,  researchers have experimented with random (e.g.,[26]), directed (e.g., [24,26 ]), and artificial sampling[27].
publisher full text jacob g, debar h, filiol e: behavioral detection of malware: from a survey towards an established taxonomy.
we had two representations, the known one, often called byte n-grams, which consists of byte sequences of characters extracted from the  binary code[12], and the second opcode n-grams represented by  sequences of opcodes.
in artificial intelligence  and applications.
perdisci r, lanzi a, lee w: mcboost: boosting scalability in malware collection and analysis using statistical classification of executables.
cambridge, ma: mit press; 1999:169-184.
in other methods, the lack of appearances in many files might create  zeroed vectors and might consequently lead to a lower accuracy level.
rieck k, holz t, düssel p, laskov p: learning and  classification of malware behavior.
indynamic  analysis(also known as behavioral analysis) the detection of malware  consists of information that is collected from the operating system at runtime  (i.e., during the execution of the program) such as system calls, network  access and files and memory modifications[3-7].
in conference on detection of  intrusions and malware & vulnerability assessment.
bilar d: opcodes as predictor for malware.
golub t, slonim dk, tamayo p, huard c, gaasenbeek m, mesirov jp, coller h, loh ml, downing jr, caligiuri ma, bloomfield cd, lander es:
the representative vectors of the  files in the training set and their real (known) classification are the input  for a learning algorithm (such as a decision tree or artificial neural network  algorithms).
in ml applications, the large number of features (many of which do not  contribute to the accuracy and may even decrease it) in many domains presents a  significant problem.
in this experiment, we found that there are classifiers which are relatively  non-reactive to changes in the mfp level of the test-set.
golub t, slonim dk, tamayo p, huard c, gaasenbeek m, mesirov jp, coller h,  loh ml, downing jr, caligiuri ma, bloomfield cd, lander es:
in addition, we can see that for a given mfp in thetraining set , the tpr and the fpr of the classifiers are stable for any mfp level in the test set.
based on this vector, the classifier will classify the file as either benign or malicious.
the first strategy, which is  classifier-independent, consists of balancing the original data-set by using  different kinds of undersampling or oversampling approaches.
our main goal in  this study is to be able to filter out unknown malicious files from the files  arriving to an anti-virus vendor every day.
from the table we can see, as expected, that the df feature selection method favors short n-grams which appear in a larger number of files.
schultz m, eskin e, zadok e, stolfo s: data mining methods for  detection of new malicious executables.
moreover, the df and fs performance was more stable for  varying numbers of top feature in terms accuracy and g-mean.
the mean tpr, fpr, accuracy and g-mean of the evaluated feature selection methods (document frequency, fisher score, gain ratio) as a function of the number of top features (50, 100, 200 and 300) .
in these  methods the binary code of a file is represented, for example, using byte  sequence (i.e., byten-grams), and classifiers are used to learn  patterns in the code in order to classify new (unknown) files as malicious or  benign[1,10].
weiss gm, provost f: learning when training data are costly: the effect of class distribution on tree induction.
a typical problem of this domain is the  imbalance problem in which the distribution of the classes in real life varies.
for evaluation purposes, we used the true positive rate (tpr) measure, which is the number ofpositive instances classified correctly, false positive rate (fpr), which is the number of negative instances misclassified, and thetotal accuracy, which measures the number of absolutely correctly classified instances, either positive or negative, divided by the entire number of instances.
it is shown that all classifiers, excluding ann, had a  similar trend and perform better when using mfp of 15% - 30% in the training  set, while random forest and boosted decision tree outperformed all other  classifiers exceeding 94.5% accuracy and 87.1% tpr, while keeping the fpr  bellow 4%.
2.2 representing executables using opcodes an opcode (short for operational code) is the portion of a machine  language instruction that specifies the operation to be performed.
in the analogy to text categorization, using letters or sequences of letters as features is analogous to using byte sequences, while using words or sequences of words is analogous to the opcode sequences.
the accuracy, fpr, tpr and g-mean of each classifier when using the best mean settings (i the graphs in figure 5 depict the tpr, fpr, accuracy and g-mean of each classifier when comparing the best averaged settings (2-gram, tf representation, using 300 features selected by the df measure) with the classifier's optimal settings.
detailed description of the accuracy, tpr and fpr with a 50% mfp in the training set and 10% mfp in the testing set for all classifiers.
kolter jz, maloof ma: learning to detect malicious executables in  the wild.
this observation can be explained by the fact that  longer opcoden-grams indicates larger vocabulary (since there are more  combinations of then-grams), yet on the other hand, a large number of n-grams results in fewer appearances in many files, thus creating  sparse vectors.
karim et al.[20] addressed the tracking of malware evolution based on opcode sequences and permutations.
we used the weka implementation of these methods [49 ].
out of the ann classifier,  all other classifiers observed similar behavior in which higher tpr and lower  fpr were achieved when training on newer files.
this can be explained by its criterion, which has an advantage for fewer  features.
these  files could not be disassembled by disassembler software and therefore, after  converting the files into opcode representation we ended up with 5,677  malicious and 20,416 benign files (total of 26,093 files).
ininternational joint conference on artificial intelligence.
when faced with unequal class sizes, classification accuracy is often an inappropriate measure of performance.
opcoden-grams are used as features during the  classification process with the aim of identifying unknown malicious code.
neter j, kutner mh, nachtsheim cj, wasserman w: applied linear statistical models.
in this paper we present the results of an alternative representation of the executable files using opcoden-gram patterns instead of using byte n-gram patterns.
in previous studies classification algorithms were employed successfully for the detection of unknown malicious code.
morgan  kaufmann publishers inc; 1999:1401-1406.
figure8 presents the mean accuracy,  fpr, tpr and g-mean for a 2-fold cross validation experiment for each mfp in  the training set and with a fixed level of 10% mfp in the test-set.
we had 7 training sets, in which training setk included samples from the year 2000 till year 200[k ] (where k = 0,1,2
in fact, in all of the cases, the tpr was above 0.95 and fpr approximately 0.1 when training the models on a yearly basis.
interestingly, a stable state is observed in the accuracy measure for any mfp  level.
kolter j, maloof m: learning to detect and classify malicious  executables in the wild.
we therefore use the constantn-gram size sets for the next experiments.
kam ht: random decision forest.
in particular, these  approaches search for methods for incorporating misclassification costs into  the classification process and assigning higher misclassification costs to the  minority class so as to compensate for its small size.
data mining methods (logistic regression, artificial neural networks and decision trees) are used in[21] to automatically identify critical instruction sequences that can distinguish between malicious and benign programs.
in the second experiment we  investigated the imbalance problem to determine the optimal settings of the  training set for each classifier in varying "real-life" conditions.
a common method of launching these attacks is by means ofmalicious software (malware) such as worms, viruses, and trojan horses, which, when spread, can cause severe damage to private users, commercial companies and governments.
indeed, in such circumstances, a trivial classifier that  predicts every case as the majority class could achieve very high accuracy  levels in extremely skewed domains.
section 3 describes the methods we used,  including concepts from text categorization, data preparation, and classifiers.
in addition, the optimal setting of each classifier is presented, as well as the resulted accuracy for the optimal setting, and the difference compared to the accuracy achieved with the best averaged setting.
this signifies that the sequence of two opcodes is more representative than single opcodes, however, longer grams decreased the accuracy.
unlike byte sequence, opcode expressions, extracted from the executable file, are expected to provide a more meaningful representation of the code.
training-set malware percentage figure 7 presents the mean accuracy, fpr, tpr, and g-mean (i.e., averaged  over all the mfp levels in the test-sets) of each classifier and for each  training mfp level.
the classification process main goal is to detect unknown malware within a set of suspected files which will later be included in antivirus software as signatures.
having experience in using this  approach in real life setting, we can give two general examples of such  applications.
the recent growth in high-speed internet connections enable malware to propagate and infect hosts very quickly, therefore it is essential to detect and eliminate new (unknown) malware in a prompt manner[1].
some of the files in our collection were either compressed or packed.
the first example pertains to for anti-virus companies that need  to analyze dozens of thousands of maliciously suspected (or unknown) files,  including benign files, every day.
© 2012 springer unless otherwise stated.
in this paper  we present the results of an alternative representation of the executable files  using opcoden-gram patterns instead of using byte n-gram  patterns.
the overall process of classifying unknown files as either benign or malicious using ml methods is divided into two subsequent phases: training and testing.
the recent growth in high-speed internet  connections enable malware to propagate and infect hosts very quickly,  therefore it is essential to detect and eliminate new (unknown) malware in a  prompt manner[1].
data mining methods (logistic regression, artificial neural  networks and decision trees) are used in[21] to automatically identify critical  instruction sequences that can distinguish between malicious and benign  programs.
several analysis techniques for detecting malware, which commonly distinguished between dynamic and static, have been proposed.
we used thedocument frequency measuredf (the amount of files in which the term appeared), gain ratio(gr) [40] and fisher score (fs)
12 july 2011 published: 27 february 2012 © 2012 shabtai et al; licensee springer.
perdisci r, lanzi a, lee w: mcboost: boosting scalability in  malware collection and analysis using statistical classification of executables.
another important aspect when using binary classifiers for the detection of  unknown malicious code is the imbalance problem.
machine learning 1998, 30: 195-215.publisher full text heavens vx[http://vx.netlux.org] webcite linn c, debray s: obfuscation of executable code to improve resistance to static disassembly.
the performance of both the naïve bayes and the boosted naïve bayes was the worst for all then-gram sizes, having the lowest mean tpr, accuracy and g-mean, and highest mean fpr.
tpr, fpr, accuracy and g-mean of each classifier when comparing the best averaged settings (i.e., 2-gram, tf representation, 300 features selected by the df measure) and the classifier's optimal settings.
edited by orr g, muller k-r, cruana r. springer verlag; 1998:299-314.
this was done in order to avoid problems related to sparse data (i.e., vectors that contain many zeros).
in this paper we chose to decompose accuracy into basic components in addition to the use of the g-mean.
tf representation, 300 features selected by the gr measure - denoted by [top1800all;tf;top300;gr].
a rigorous evaluation was performed using a test collection comprising of more than 30,000 files, in which various settings of opcoden-gram patterns of various size representations and eight types of classifiers were evaluated.
proc of the 28th annual international computer software and applications conference, ieee computer society 2004, 41-42.
proc of the ieee symposium on security and privacy, ieee computer  society 2001, 38.
static analysis solutions are primarily implemented using the signature-basedmethod which relies on the identification of unique strings in the binary code[2].
more and more researchers realized that the performance of their classifiers may be sub-optimal due to the fact that the datasets are not balanced.
based on each feature selection measure we selected the top 50, 100, 200 and 300 features.
pubmed abstract | publisher full text joachims t: making large-scale support vector machine learning  practical.
recently, moskovitch et al.
in the second experiment we investigated the imbalance problem to determine the optimal settings of the training set for each classifier in varying "real-life" conditions.
chen c, liaw a, breiman l: using random forest to learn unbalanced data.
in future work we plan to experiment with cost-sensitive classification in  which the costs of the two types of errors (i.e., missing a malicious file and  false alarm) are not equal.
the main advantage of static analysis is that it is able to detect a file  without actually executing it and thereby providing rapid classification[8].
these files are collected from various sources including dedicated honeypots, third party providers and files reported by customers either automatically or explicitly.
in this study we used ida-pro, the most advanced  commercial disassembly program available today.
our approach also stems from the idea that there are families of malware  such that two members of the same family share a common "engine."
in tricks of  the trade, lecture notes in computer science state-of-the-art surveys.
also, the large number of malware files in our dataset that could be dissembled  indicates that in order to appear benign and to pass security mechanisms (that  are configured to block content that is encrypted\obfuscated and cannot be  inspected), these techniques are not always used by hackers.
the authors of[16] were the first to introduce the idea of applyingmachine learning ( ml) methods for the detection of different malwares based on their respective binary codes.
the rest of the paper is organized as follows.
although such a process seems trivial, malware writers often try to prevent the successful application of the disassembly process to prevent experts from analyzing their malwares.
additionally, an investigation of the imbalance problem, on which we elaborate later, was demonstrated.
the second strategy involves modifying the classifiers in order to adapt them to the data-sets.
which classifier is the best: svm, lr, rf, ann, dt, bdt, nb or bnb?
to identify the files, we used the kaspersky anti-virus.
consequently, the selected opcoden -grams appear in both sets and therefore eliminate the idf factor in the  tf-idf measure.
the details of the evaluation measures we used will be given in section 5.1.
how often should a classifier be trained with recent malicious files in  order to improve the detection accuracy of new malicious files?
(of size n=1,2) representation to ascribe malware  instances to their families by measuring the similarity between files.
relations among mfps in training and test-sets: accuracy, tpr and fpr for the mfp levels in the two sets in a 3-dimensional presentation.
the size of vocabularies (number of distinct n-grams) extracted for the opcoden-grams representation were of 515, 39,011, 443,730, 1,769,641, 5,033,722 and 11,948,491, for 1-gram, 2-gram, 3-gram, 4-gram, 5-gram and 6-gram, respectively.
figure2 presents the mean tpr, fpr, accuracy and g-mean of the combinations of  the term representation andn-grams size.
these techniques are also applied on benign software for copyrights protection purposes.
the chronological evaluation showed a clear trend in which the performance improves as the training set is more updated.
in our case, the data is imbalanced in real-life conditions and reflected by the test-set in our experiments, therefore, we would like to understand the optimal construction of a training-set for achieving the best performance in real-life conditions.
the next and final step in streamlining the  executable is achieved by extracting the sequence of opcodes generated during  the disassembly process.
the question asks how  important it is to update the repository of malicious and benign files and  whether, for specific years, the files were more contributive to the accuracy  when introduced in the training set or in the test set.
for example, these common engines  may be located in varying locations inside the executables, and thus may be  mapped to different addresses in memory or even perturbed slightly.
figure10 presents the results with a 50% mfp in the training set and10% mfp in the testing set for the two best classifiers bdt and rf (the graphs for the rest of the classifiers are provided in additional file2).
recently, classification algorithms were employed to  automate and extend the idea ofheuristic-based methods.
for this purpose we designed a chronological experiment, based on a  dataset including files from the years 2000 to 2007, trained each time on files  untill yeark and tested on the following years.
this problem is even more relevant  in fields where the natural datasets are highly imbalanced in the first place[25 ], as in the problem we describe.
thus, having a relatively high false-positive is reasonable in order  to decrease the probability of missing an unknown malicious file.
for both scenarios it is difficult to assign the  costs for the two errors (note that each type of malware can be assigned with a  different cost level based on the damage it causes) and therefore in this paper  we focus on exploring and identifying the settings and classifiers that can  classify the files as accurately as possible, leaving the cost-sensitive  analysis for future work.
additionally, it is shown that the fpr grows for all classifiers with the increasing of the mfp in the training set.
naïve  bayes and boosted naïve bayes performed poorly and thus we omitted them  from the following experiments.
in ml applications, the large number of features (many of which do not contribute to the accuracy and may even decrease it) in many domains presents a significant problem.
figure8 presents the mean accuracy, fpr, tpr and g-mean for a 2-fold cross validation experiment for each mfp in the training set and with a fixed level of 10% mfp in the test-set.
references shabtai a, moskovitch r, elovici y, glezer c: detection of  malicious code by applying machine learning classifiers on static features: a  state-of-the-art survey.
the top five settings with the highest mean  accuracy over all the classifiers.
5 experiments and results 5.1 experiment 1 - evaluate opcode n-gram representations settings
over a decade ago[24].
[47], and their boosted versions, bdt and bnb[48].
this is an open access article distributed under the terms of the creative  commons attribution license (http://creativecommons.org/licenses/by/2.0), which  permits unrestricted use, distribution, and reproduction in any medium,  provided the original work is properly cited.
internet measurement conference(imc), acm press 2006, 333-338.
in order to answer  these questions we divided the entire test collection into years from 2000 to  2007, in which the files were created.
evaluation performed in these studies showed that unpacking files  before being classified increase the classification accuracy[37,38].
[46], naïve bayes (nb)
for each malicious and benign class a representative  profile was constructed.
converting byte representation into  opcoden-grams patterns.
moskovitch r, feher c, tzachar n, berger e, gitelman m, dolev s, elovici y: unknown malcode detection using opcode representation.
journal in computer virology 2009, 5(4): 295-308.
using the selected features, we evaluated eight commonly used classification algorithms: support vector machine (svm)[42], logistic regression (lr)[43], random forest (rf)
following this observation we opted to use the tf representation for the  rest of our experiments.
in our case, the data is imbalanced in real-life conditions and reflected  by the test-set in our experiments, therefore, we would like to understand the  optimal construction of a training-set for achieving the best performance in  real-life conditions.
in the third experiment we wanted to determine the importance of updating  the training set over time.
2-gram, tf representation, 300 features selected by the df measure (as presented in section 5.1.3) - denoted by [2gram;tf;top300;df].
the test-set represents the real-life situation while the training set represents the set-up of the classifier, which is controlled.
molecular  classification of cancer: class discovery and class prediction by gene  expression monitoring.
our proposed method can use such an approach in order to overcome packed files.
search results malicious [ http://www.newsfactor.com/story.xhtml?story_id = 010000ceueqo] webcite frederick lane 2007.
in this study we used opcode n-gram patterns generated by disassembling the inspected executable files to extract features from the inspected files.
naïve bayes and boosted naïve bayes performed poorly and thus we omitted them from the following experiments.
feature selection was applied on the collection of 1,800n-grams patterns.
format: pdf size: 1.5mb download file this file can be viewed with: adobe acrobat reader when comparing these results with the results of the byte n-grams  patterns experiments in[12] we notice that in terms of accuracy, the byte n -grams classifiers are more sensitive to varying mfp levels in the  training and test-sets.
the evaluation consisted of three experiments.
publisher full text japkowicz n, stephen s: the class imbalance problem: a systematic  study.
indeed, in such circumstances, a trivial classifier that predicts every case as the majority class could achieve very high accuracy levels in extremely skewed domains.
our approach also stems from the idea that there are families of malware such that two members of the same family share a common "engine."
neural network  classification and unequal prior class probabilities.
using a disassembler software, we extracted a sequence of opcodes from each file representing execution flow of machine operations.
a new executable file was compared with the profiles  of malicious and benign classes, and was assigned to the most similar.
the disassembly process consists of translating the machine code  instructions stored in the executable to a more human-readable language, namely, assembly language.
this approach is conceptually simpler than using roc analysis and sheds  sufficient light on our results.
shin s, jung j, balakrishnan h: malware prevalence in the kazaa  file-sharing network.
figure 4 depicts the mean tpr, fpr, accuracy and g-mean for each classifier as a function of the opcoden-gram size using the tf representation.
(of size n=1,2) representation to ascribe malware instances to their families by measuring the similarity between files.
the tfidf combines the frequency of a term in the document (tf) and  its frequency in the whole document collection, denoted bydocument frequency (df).
- top 1,800 over all n-gram sizes
international symposium on engineering secure software and systems 2010, 35-42.
neter j, kutner mh, nachtsheim cj, wasserman w: applied linear  statistical models.
this can be explained by its criterion, which has an advantage for fewer features.
molecular classification of cancer: class discovery and class prediction by gene expression monitoring.
in addition, we can  see that in most cases, fs and gr tend to selectn-grams of size 2, 3  and 4 which we conclude to be more informative and with a tendency to  discriminate better between the malicious and benign classes in the  classification task.
clearly, the files in the test were not present in the training set.
previous  studies presented evaluations based on test collections having similar  proportions of malicious and benign files in the test collections.
detecting unknown malicious code by applying classification techniques on  opcode patterns asaf shabtai1,2*, robert moskovitch1,2, clint feher1,2, shlomi dolev3,1 and yuval elovici1,2 *
this observation can be explained by the fact that longer opcoden-grams indicates larger vocabulary (since there are more combinations of then-grams), yet on the other hand, a large number of n-grams results in fewer appearances in many files, thus creating sparse vectors.
when faced with  unequal class sizes, classification accuracy is often an inappropriate measure  of performance.
our  proposed method can use such an approach in order to overcome packed files.
each time the training set was chosen from one part and the test set was chosen from the other part, thus forming a 2-fold cross validation-like evaluation to render the results more significant.
santos et al.[23] used the opcode n -grams
in this paper, which is an extended version of [11], we use a methodology  for malware categorization by implementing concepts from the text  categorization domain, as was presented by part of the authors in[12].
in advances in kernel methods.
the second strategy involves modifying the  classifiers in order to adapt them to the data-sets.
in general, this  indicates that in order to achieve a desired tpr and fpr, only the training set  can be considered and selecting the proper mfp in the training set will ensure  the desired tpr and fpr for any mfp in the test set.
in order to find the best settings for all the classifiers, we calculated the mean fpr, tpr, accuracy and g-mean for each setting that is defined by the: (1)n-gram size; (2) feature representation; (3) feature selection method; and (4) the number of top features.
acm transactions on information and system security 2000, 3 (4):227-261.
the tf representation is actually the representation which was used in previous papers in the domain of malicious code classification[13,16,17], where counting words was replaced by byten-grams extracted from the executable files.
seeing as we assume that in most real-life scenarios low proportions of malicious files are present, training sets should be designed accordingly.
classifiers differ in performance within different domains and the best  fitted classifier can often be identified by experimentation.
the graphs show that the random forest and boosted decision tree yielded the highest accuracy and lowest fpr.
the details of the evaluation measures we used  will be given in section 5.1.
on the optimality of simple bayesian  classifier under zero-one loss.
additionally, shin et al.[15] found that above 15% of the files in the kazaa  network contained malicious code.
corresponding author: asaf shabtai shabtaia@bgu.ac.il author affiliations 1 deutsche telekom laboratories, ben-gurion university, be'er sheva, 84105, israel 2 department of information systems engineering, ben-gurion university, be'er sheva, 84105, israel 3 department of computer science, ben-gurion university, be'er sheva, 84105, israel for all author emails, please log on.
three different feature extraction (fe) approaches  were employed: features extracted from theportable executable (pe ) section, meaningful plain-text strings that are  encoded in programs files, andbyte sequence features.
several proposals have been made to address  this issue including the decomposition of accuracy into its basic components[25 ], the use of roc analysis[32] or the g-mean [33].
san francisco, ca, usa: morgan kaufmann publishers, inc; 2005.
in this study we represent the inspected files usingopcode n-grampatterns which are extracted from the files after disassembly.
bilar[22] examines the difference of statistical opcode frequency distribution in malicious and non-malicious code.
this is,  however, different from our goal in which we attempt to classify unknown  suspicious files as malicious or benign in order to detect new malware.
the approach in[22] presents a single case in our methodology;  in this paper we test several opcoden-gram sizes while bilar [22] used  only 1-gram.
as a case in point, we extracted 443,730 3-grams and 1,769,641 4-grams.
the accuracy, fpr, tpr and g-mean of each  classifier when using the best mean settings (i the graphs in figure 5 depict the tpr, fpr, accuracy and g-mean of each  classifier when comparing the best averaged settings (2-gram, tf  representation, using 300 features selected by the df measure) with the  classifier's optimal settings.
in such an application the goal is to  perform an initial filtering to reduce the amount of files to investigate  manually.
[13] introduced a framework that uses the common n-gram (cng) method and thek-nearest neighbor (knn) classifier for the detection of malware.
for this purpose we designed a chronological experiment, based on a dataset including files from the years 2000 to 2007, trained each time on files untill yeark and tested on the following years.
these methods were proposed for  automatic unpacking of packed files by applying either static or dynamic  analysis.
publisher full text abou-assaleh t, keselj v, sweidan r: n-gram based detection of  new malicious code.
the imbalance problem refers  to scenarios in which the proportions of the classes are not equal.
this can be explained by the fact that for training sets with higher mfp most of the test sets are have a lower mfp, which in turn results in higher fpr.
publisher full text mitchell t: machine learning.
this measure, which is often used in imbalance dataset evaluation studies, is a metric that combines both the sensitivity and specificity by calculating their geometric mean.
the dataset was divided into two parts.
this observation, which emphasizes the imbalance problem, signifies that in order to achieve a desired tpr and fpr, only the training set can be considered and selecting the proper mfp in the training set will ensure the desired tpr and fpr for any mfp in the test set.
these techniques are also applied on benign software for  copyrights protection purposes.
evaluation results indicate that the evaluated methodology achieves a level of accuracy higher than 96% (with tpr above 0.95 and fpr approximately 0.1), which slightly improves the results in previous studies that use byten-gram representation.