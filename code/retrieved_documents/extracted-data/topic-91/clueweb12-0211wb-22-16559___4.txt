this application has seven classes (possible types of  forest cover), and the cases are described in terms of 12 numeric and two  multi-valued discrete attributes.
this  definition proved unsatisfactory because it depended on the order in which rule  conditions were checked, and also because many attributes ended up having usage  figures around 100%.
you might like to inspect this file from time to time during long runs.
the xval script is still used for multiple cross-validations.
- cross-validations with misclassification costs - for applications with a .costs file, the unix cross-validation script now reports average misclassification costs.
false positive/false negative breakdown see5/c5.0 currently shows a confusion matrix only when the number of  classes does not exceed twenty.
for linux uses who have installed a recent version of wine, the new  release includes an optional gui with many features of the see5 user interface.
minor tweak boosting has been improved somewhat for large data files (more than four  thousand records).
- changes to .tree and .rules files - up to release 1.11 decision tree and ruleset models have been stored as binary files.
this shows, for each attribute, the percentage of training cases for which the value of that attribute is both known and also used in classifying the case.
release 1.09 confidence values for decision trees
- fuzzy thresholds - a test on a numeric attribute a in a decision tree has two branches associated with it, one for each ofa  t for some thresholdt.
discontinuation of solaris support solaris on sparc architectures will no longer be supported.
earlier releases names file the format of the names file has been extended to allow you to select any  discrete-valued attribute as the class.
finally, large rulesets can be interpreted more quickly -- an advantage  when using the public c code to deploy applications.
release 1.11 - new data types - dates are input and output in the form yyyy/mm/dd and can be used with implicitly defined attributes to determine, for instance, the number of days between two dates or the day of the week on which a date falls.
release 1.20/1.20a the changes in release 1.20 were as follows: differential misclassification costs with rulesets, boosting
every case in this monitoring application is described by 6 numeric-valued attributes and belongs to one of six classes.
if there are more than twenty classes, when a  confusion matrix would be too large, release 2.04 records the number of false  positives and false negatives for each class.
with fuzzy  thresholds, both branches of the tree are explored if the value ofa is  close tot; the results are then combined to give a classification that  changes more slowly with the value ofa. previous releases of see5/c5.0 had a fuzzy thresholds option, but these  soft thresholds were used only in interactive classification.
a label attribute does  not affect classification in any way, but its value is displayed where possible  with information about the case such as error messages, cross-referencing  results etc.
this  enables a fixed percentage of the cases in adata file to be used for  training.
the methods for finding the bounds within which this combination is invoked have been re-designed to make them both faster and more effective.
enhancement of public source code
with values `yes' and `no', and `ticket cost' with numeric values.
release 2.02 - faster rule utility ordering - this option could be quite slow when large numbers of rules are involved.
new class type: thresholded continuous attribute this convenience feature now allows classes to be defined as subranges of  a continuous attribute.
- faster classification with rulesets -
the source code for reading and interpreting classifiers constructed by  see5/c5.0 has been extensively revised.
rule selection the algorithm for refining an initial collection of rules has been  altered, with the result that release 1.20 sometimes produces smaller rulesets.
improvements to the see5 gui
furthermore, rules can be grouped into a number of bands, so that it is possible to see how the most important x% of rules perform on training and test data.
one noticeable consequence is that decision trees tend to be both smaller and more accurate when there are discrete attributes with many values.
- winnowing improved - winnowing (pre-filtering the attributes) is now faster and somewhat more conservative.
- bug fix: attribute winnowing -
usage figures for trees and rulesets are now more similar.
- more efficient memory use for high-dimensional applications - memory allocation has been improved for applications with thousands of attributes.
to ease the changeover, see5/c5.0 and the new public code will still read  model files (.tree and .rules) generated by release 1.11.
more efficient memory use for high-dimensional applications memory allocation has been improved for applications with thousands of  attributes.
the pruning algorithms have been altered slightly to correct a potential problem.
release 1.05 rulesets the method for generating and selecting rules has been `tweaked' slightly  to improve performance on some datasets.
the first line of the names file can now contain the name of another attribute instead of the list of classes separated by commas.
faster classification with rulesets the process for finding all the rules that are satisfied by a case has  been enhanced.
most of these changes will be invisible to the user, but some (such as the method for selecting subsets of discrete values) may cause classifiers to differ from those produced by release 1.10.
the first line of the names file can  now contain the name of another attribute instead of the list of classes  separated by commas.
- bug fixes - several relatively minor bugs have been fixed.
the 32-bit release of see5 will run under either 32-bit or 64-bit windows, so there is no need to change unless your tasks may use more than 2gb of memory.
as an added convenience, classifiers constructed using the sampling option are now automatically evaluated on a disjoint set of test cases.
options for see5x are set by command-line parameters in exactly the same way as for the unix version c5.0.(not included with the free demonstration download.)
muti-class applications that specify a costs file should now observe lower average misclassification costs for unseen cases, especially when rulesets are generated.
in release 2.05, an attribute is "used" to classify a case when it referenced by one or more conditions of anapplicable rule (i.e., a rule whose conditions are all satisfied by a case).
- boosting - a modified method is used to predict when boosting is likely to be harmful.
implicitly defined attributes can be used to compute functions of times, such as the number of seconds between two times.
in this release the algorithms for generating rulesets have been substantially revised.
implicitly defined attributes can be used to compute functions of times, such  as the number of seconds between two times.
release 2.01 multi-threading the core of see5/c5.0 has been rewritten so that it can take advantage of  computers with dual processors or intel pcs with hyper-threading technology.
- result window (windows version) - the system menu for this window has been extended with the option switch to wordpad.
release 1.20 has been modified so that classifiers of these kinds often have lower error rates without a noticeable increase in misclassification costs.
releases 1.17 and 1.18 generate rulesets with similar predictive accuracies, but notice how much faster 1.18 is -- on the largest dataset it isnearly five times as fast as 1.17.
a new winnowing option helps to overcome this problem by investigating the usefulness of all attributes before any classifier is constructed.
right from the very first release, see5/c5.0 has allowed variable costs  to be associated with different types of classification error as describedhere.
predictive  performance are disregarded ("winnowed") and only the remaining  attributes are used to construct decision trees or rulesets.
bug fix: attribute winnowing
- changes to the see5 gui - there have been several improvements in line with suggestions made by users (and please keep them coming!): - a new edit menu brings up the .names or .costs file in wordpad, making it easier to change these files.
this information to test subranges of the values, e.g. [large-xxl].
release 1.19 - rulesets require less memory - the memory required to generate rules from large datasets has been significantly reduced.
earlier releases - names file - the format of the names file has been extended to allow you to select any discrete-valued attribute as the class.
this facility can help to identify problems in the training data, and can be very useful for understanding complex classifiers (such as boosted trees or rulesets).
changes to results window (see5 only) viewing large results files should now be much faster; some minor format  changes will also be apparent.
- in the see5 gui, the "use classifier" button for interactive interpretation would not work with ruleset classifiers.
in this release the algorithms for generating rulesets  have been substantially revised.
the goal of this application is to predict whether a person's income is above or below $50,000 using 7 numeric and 33 discrete (nominal) attributes.
the releases perform  similarly for 25,000 training cases, but 1.17's advantage increases with size  -- at around 200,000 cases, 1.17 is almost twice as fast as 1.16.
- progress report file - the unix progress report file is now filestem .tmp, allowing two or more users to process copies of the same application in different directories.
the problem could arise in applications with many attributes and a  large number of missing values.
a new button on the classifier construction dialog box allows any .costs  file to be ignored.
the linux gui calls the native linux  c5.0, so there is no performance penalty.
(thecross-reference facility in particular provides information that is not available from the command-line version.)
(recall that see5/c5.0 already has data types for times and for dates.)
sleep income forest results for 1.18 are shown in blue.
- new class type: thresholded continuous attribute - this convenience feature now allows classes to be defined as subranges of a continuous attribute.
the information in the cross-referencing window at any point in time can now be saved as a text file.
- batch-mode version of see5 - guis are great, but it's sometimes useful to be able to run see5 non-interactively from a ms-dos command window.
release 1.12 new data values a new value n/a can be used when the value of an attribute is not  applicable to a case.
the on-line help for the windows version has been moved to the more  modern htmlhelp format and now corresponds closely to thetutorial available on  the web.
previous releases often showed low confidence for ruleset predictions even when  those predictions were quite accurate.
when the subsetting option is invoked, the values of discrete attributes are collected into subsets.
for example, the following graphs compare the performance of 1.18 to the previous release (1.17) on three large datasets: - sleep stage scoring data (sleep, 105,908 cases, obtained frommlc++).
- faster rulesets - rulesets are now generated more quickly, especially for large applications.
the dialog box in the windows version has been changed to  accommodate larger values of theminimum cases option.
notes from previous releases release 2.08 - differential misclassification costs - see5/c5.0's handling of misclassification costs has been revised, particularly when the application has more than two classes.
- rules are found more quickly (quite a lot more quickly in some applications).
better rulesets release 1.13 focuses on improvements to all aspects of rulesets.
this  option can lead to noticeably better predictive performance and is now  recommended for applications with many continuous attributes.
there were also problems when the winnowing option was used at the same  time as the minimum cases option was set to 1.
the changes have also been reflected in the public source code for  reading and using classifiers.
the methods for finding the bounds within which this combination is  invoked have been re-designed to make them both faster and more effective.
- improvements to the see5 gui - the output window is now more readable, and can be copied and printed directly (without having to switch to wordpad).
furthermore, the remaining attributes that will be used to build  classifiers are now ranked by importance, with an estimate of how predictive  accuracy or misclassification cost would increase if individual attributes were  removed.
bug fixes two bugs have been fixed: a value of the "minimum cases" option greater than 25 could  occasionally behave as if it was set to 25, and the highest possible threshold of a continuous attribute was sometimes  overlooked.
every case in this monitoring application is described by 6  numeric-valued attributes and belongs to one of six classes.
new unix options options are now provided to ignore any .costs files and to set the random  number seed (so that runs with sampling etc.
the use of costs with rulesets or boosted classifiers, however, can sometimes  produce quite high error rates.
this affects the output from the public code to read and interpret  see5/c5.0 ruleset classifiers, and also impacts results with boosted rulesets.
if a case's  value of the former is `no', the appropriate value for the latter is now `n/a'.
as a result, you may observe changes  in the rulesets generated from your data.
decision trees are pruned more carefully, and the confidence of predictions is now calculated differently.
ordered discrete values are nominal values that have a natural  ordering, such assmall, medium, large, xl, xxl.
right from the very first release, see5/c5.0 has allowed variable costs to be associated with different types of classification error as describedhere.
for  example, a test that separates one class from another in a small subset of the  training cases might be genuinely interesting; on the other hand, if hundreds  of alternatives have been tried, it is more likely that a similar separation  can be found even when none of the tests is helpful for prediction.
the client installation program has been modified to set appropriate registry entries on the client, and also leaves a local copy of the help (see5help.chm) in the see5 folder as a workaround in case new windows updates affect htmlhelp.
on the well-known  census dataset, for example, release 1.17 produces a 159-leaf decision tree  that is slightly more accurate than the 211-leaf tree output by release 1.16.
the main window can be clicked on top of the output window.
- new distribution format for windows - see5 release 2.01 is distributed as a self-contained inno executable.
the 64-bit version of see5 will run only under 64-bit windows xp, windows vista, or windows 7.
release 1.15 faster boosting
the source code that facilitates such deployment has also changed  substantially.
this shows, for each attribute, the percentage of training cases  for which the value of that attribute is both known and also used in  classifying the case.
if there are more than twenty classes, when a confusion matrix would be too large, release 2.04 records the number of false positives and false negatives for each class.
see5/c5.0 now uses a modified test selection strategy when the training  data contains thousands of cases or more.
this mechanism is intended to make classification models more compact without impairing their predictive accuracy.
- new unix options - options are now provided to ignore any .costs files and to set the random number seed (so that runs with sampling etc.
- new unix option - cross-validation has now been incorporated directly into c5.0 rather than being available only through the xval script.
the releases perform similarly for 25,000 training cases, but 1.17's advantage increases with size -- at around 200,000 cases, 1.17 is almost twice as fast as 1.16.
release 1.20a was also tweaked to improve speed.
for example, the time to generate a ruleset for one dataset with  750,000 cases was reduced by more than 10%.
one  noticeable consequence is that decision trees tend to be both smaller and more  accurate when there are discrete attributes with many values.
(recall that see5/c5.0 already has  data types for times and for dates.)
when (single or boosted) ruleset classifiers are used, a new option shows the rules that are applicable to each case.
release 2.01 - multi-threading - the core of see5/c5.0 has been rewritten so that it can take advantage of computers with dual processors or intel pcs with hyper-threading technology.
the source code for reading and interpreting classifiers constructed by  see5/c5.0 has been further revised.
a client pc running 64-bit windows xp/vista/7 can  install and use the 64-bit version, even if the server runs 32-bit windows.
- progress report (unix version) - c5.0 now updates the file /tmp/
a timestamp is rounded to the nearest  minute and implicitly defined attributes can be used to compute functions of  timestamps such as the number of minutes between two of them.
bug fix: rulesets and global pruning this bug affected only ruleset classifiers generated with global pruning  disabled -- the resulting rulesets might have been over-simplified.
progress report file the unix progress report file is now filestem .tmp, allowing two  or more users to process copies of the same application in different  directories.
the classifier construction settings last used with an application are stored and are reset whenever that application is selected again.
in some  situations, for instance when investigating alternative classifier construction  options, it is desirable to be able to `lock in' a particular sample, and an  additional option on the classifier construction dialog box is now provided for  this purpose.
- discontinuation of solaris support - solaris on sparc architectures will no longer be supported.
this enables a fixed percentage of the cases in adata file to be used for training.
this bug could cause  see5/c5.0 to crash, or to give incomplete results with the cross-reference  facility.
better use of cost information
in previous releases, use of the cross-reference facility in the see5  could cause problems when there were errors in thecases file.
warning: the new code will not  work correctly with releases before 1.10, nor will release 1.10 work with the  old source code.
the dialog box in the windows version has been changed to accommodate larger values of theminimum cases option.
this speeds up the generation of decision trees as the following example shows: the graph compares the times required by 1.16 and 1.17 to construct a decision tree for different-sized subsets of a dataset.
when a case is classified by a decision tree, the calculation of the  classification confidence has been changed slightly.
release 2.05 - attribute usage for rules - a summary showing the relevance of attributes to classifying cases was introduced in release 2.04.
release 2.03 introduces an optionalcase weight attribute with  numeric values; the effect is to bias the development of a classifier to  increase accuracy on more important cases.
even without the winnowing option, the  classifiers produced by release 1.16 may differ from those generated by earlier  releases.
bug fixes several relatively minor bugs have been fixed.
release 1.07 sampling option see5 and c5.0 now include an option to sample from large datasets.
the 64-bit version of see5 will run only under 64-bit windows xp,  windows vista, or windows 7.
release 1.10 allows suchimplicitly-defined attributes to be  described by formulas in the .names file.
the method for  finding fuzzy thresholds has been changed in release 1.10 and they are now used  whenever a case is classified by a decision tree.
a new winnowing option helps to overcome this problem by  investigating the usefulness of all attributes before any classifier is  constructed.
cross-validations with misclassification costs
to ease the changeover, see5/c5.0 and the new public code will still read model files (.tree and .rules) generated by release 1.11.
a label attribute does not affect classification in any way, but its value is displayed where possible with information about the case such as error messages, cross-referencing results etc.
the data are divided into a training set of 99,762 cases and a test set of 99,761.
this bug could cause see5/c5.0 to crash, or to give incomplete results with the cross-reference facility.
filestem (where filestem is  the application name) to indicate the stage it is up to, and where it is in  that stage.
- saving cross-referencing results (see5) - see5's cross-referencing facility is a powerful tool for finding the cases covered by particular components of classifiers, and parts of classifiers relevant to particular cases.
can install and use the 64-bit version, even if the server runs 32-bit windows.
release 1.07 - sampling option - see5 and c5.0 now include an option to sample from large datasets.
warning: the new code will not work correctly with releases earlier than 1.10.
improved scalability
the use of data subsets has been discontinued in  release 2.06, at a cost of a small increase in the time required for  applications with many continuous attributes and hundreds of thousands of  training cases.
many-valued discrete attributes see5/c5.0's handling of discrete attributes with numerous values is  faster, and thesubsetting option uses less memory.
any solaris  licensees who might be inconvenienced by this change should contact us to  discuss possible remedies, such as moving their licences to different computers.
this facility can help to identify  problems in the training data, and can be very useful for understanding complex  classifiers (such as boosted trees or rulesets).
usage  figures for trees and rulesets are now more similar.
when an attribute's discrete values are noted as ordered, see5/c5.0 exploits
- revision of source code - the source code for reading and interpreting classifiers constructed by see5/c5.0 has been further revised.
(there's also a new button on the dialog box to reset all of them to their default values.)
- attributes excluded/included - the attributes that may be used in constructing a classifier can now be specified in the .names file.
two small bugs in the windows gui have been rectified.
a client pc running 64-bit windows xp/vista/7
this is particularly useful when discrete attributes have numerous values and is now much faster than in previous releases.
bug fix: case weight attributes and cost files a bug in release 2.04 could cause problems for applications with two  classes that used both a case weight attribute and a .costs file.
(the list of classes is still ok, so you don't have to  change existing names files.)
in a customer retention application, for example, the importance of  a case describing a customer might depend on the size of the customer's  account.
- selecting tests - recent releases used a subset of the training data to eliminate some possible tests from consideration.
- the process for selecting rules to form the final ruleset has been revised, with the result that rulesets are generally a bit smaller without loss of predictive accuracy.
the changes have also been reflected in the public source code for reading and using classifiers.
progress report (unix version) c5.0 now updates the file /tmp/
non-interactively from a ms-dos command window.
changes to test selection one of the fundamental processes in classifier construction is deciding  whether to incorporate another test and, if so, which alternative test to pick.
this invokes a novel method of cross-referencing classifiers and the data from which they were constructed.
these concern the display of implicitly-defined discrete attributes when the value is unknown, and the possible change of classifier settings when the "cross-reference" or "making predictions" windows are invoked immediately after a cross-validation.
bug fix (windows only): interactive interpreter previous releases could sometimes give incorrect results for boosted  classifiers.
release 2.03 - weighting individual cases - the training cases for some applications have different relative importance.
releases 1.17 and 1.18 generate  rulesets with similar predictive accuracies, but notice how much faster 1.18 is  -- on the largest dataset it isnearly five times as fast as 1.17.
new unix option cross-validation has now been incorporated directly into c5.0 rather than  being available only through thexval script.
the new release requires very little time to carry out the ordering and analysis.
- faster subsetting of discrete attributes -
release 1.11 new data types dates are input and output in the form yyyy/mm/dd and can be used with implicitly defined attributes to determine, for  instance, the number of days between two dates or the day of the week on which  a date falls.
attributes excluded/included the attributes that may be used in constructing a classifier can now be  specified in the.names file.
- linux gui - for linux uses who have installed a recent version of wine, the new release includes an optional gui with many features of the see5 user interface.
faster subsetting of discrete attributes when the subsetting option is invoked, the values of discrete attributes  are collected into subsets.
small changes to pruning algorithms
boosting is no longer disabled when this occurs, but a warning message is still printed.
improved error messages problems with application files (.names, .data, .test, .costs etc) can be  corrected more easily because the error message includes the line number of the  file in question.
the formulas need not be simple --  both numeric and logical values can be introduced in this way.
- better use of cost information - while the treatment of costs for two-class problems remains much the same, the handling of cost information for applications with three or more classes has been extensively revised.
- small changes to pruning algorithms -
release 1.20a fixed three bugs in 1.20: in the see5 gui, the "use classifier" button for interactive  interpretation would not work with ruleset classifiers.
the memory required to generate rules from large datasets has been  significantly reduced.
the process for selecting rules to form the final ruleset has been  revised, with the result that rulesets are generally a bit smaller without loss  of predictive accuracy.
the classifier construction settings last used with an application are  stored and are reset whenever that application is selected again.
release 1.20 has been modified so that  classifiers of these kinds often have lower error rates without a noticeable  increase in misclassification costs.
when the value of a is near t, small  changes in the value can produce quite different classifications.
see5 on-line help rewritten
the windows gui has also been improved slightly and  the public code has a new option governing output format.
- bug fix (windows only): interactive interpreter - previous releases could sometimes give incorrect results for boosted classifiers.
release 2.05 attribute usage for rules a summary showing the relevance of attributes to classifying cases was  introduced in release 2.04.
- faster boosting - boosting is speedier for large datasets, especially where the number of boosting trials exceeds 20 or so.
attributes found to be irrelevant or harmful to predictive performance are disregarded ("winnowed") and only the remaining attributes are used to construct decision trees or rulesets.
(note that fuzzy thresholds  have no effect on rulesets.)
- the main window can be clicked on top of the output window.
the attribute winnowing option attempts to identify unhelpful attributes  and exclude them from classifiers.
the most serious bug in  the initial release concerned the use of rulesets together with a costs file --  the system could sometimes associate an incorrect class with a rule, leading to  abnormally high error rates.
release 1.20a was  also tweaked to improve speed.
for most applications this should not affect the final classifier; in  some cases, the tree or ruleset will be larger or smaller, but predictive  accuracy should be similar.
rulesets are  constructed from half the data and tested on the remaining 52,954 cases to  estimate their true error rate.
release 1.08 new attribute type label
release 1.10 allows suchimplicitly-defined attributes to be described by formulas in the .names file.
when the value of a is near t, small changes in the value can produce quite different classifications.
however, the option+d that preserves detailed outputs now  saves one file for each cross-validation rather than one file for each c5.0 run.
the use of costs with rulesets or boosted classifiers, however, can sometimes produce quite high error rates.
- forest cover type data (forest, 581,012 cases, also from uci kdd archive).
release 1.08 - new attribute type label - in some applications, each case has an identifying code or serial number; this information can be recorded in alabel attribute.
for example, consider the attributes `purchased ticket?'
previous releases often showed low confidence for ruleset predictions even when those predictions were quite accurate.
boosting is no longer disabled when this occurs, but a warning message  is still printed.
dates can now be entered as either yyyy/mm/dd or yyyy-mm-dd.
release 1.15 - faster boosting - the proprietary variant of boosting employed in see5/c5.0 has been modified considerably.
these versions allow the use of more than 2gb of memory, as required by some extremely large data mining tasks.
for example, a test that separates one class from another in a small subset of the training cases might be genuinely interesting; on the other hand, if hundreds of alternatives have been tried, it is more likely that a similar separation can be found even when none of the tests is helpful for prediction.
(note that fuzzy thresholds have no effect on rulesets.)
the difference is particularly noticeable when the leaves involved have very little supporting data.
- for thresholded class attributes (see below), a value of "?" for the continuous target attribute in a .cases file caused problems.
the definition of "usage" for rulesets  has been changed in this release so that the information is more consistent  across ruleset and tree classifiers.
- bug fix: case weight attributes and cost files - a bug in release 2.04 could cause problems for applications with two classes that used both a case weight attribute and a .costs file.
when an  attribute's discrete values are noted as ordered, see5/c5.0 exploits this  information to test subranges of the values, e.g.[large-xxl].
in some applications, each case has an identifying code or serial number;  this information can be recorded in alabel attribute.
for example, release 1.19 uses 143mb during processing  of theforest application, less than half the 296mb needed by release 1.18.
smaller trees for applications with multi-valued discrete attributes the algorithms for discrete attributes have been further improved.
this mechanism is intended to make classification models  more compact without impairing their predictive accuracy.
this  tends to produce more compact models with higher predictive accuracy.
as before, half of the data -- 290,506 cases  -- are used for training and the remainder for testing.
the information in the cross-referencing window  at any point in time can now be saved as a text file.
would indicate four discrete  classes: price less than or equal to 100 price greater than 100 but less than or equal to 1000 price greater  than 1000 but less than or equal to 5000 price greater than  5000.
rule numbering has also been changed: the numbers are now sequential, rather than the previous higgledy-piggledy arrangement.
the method for finding fuzzy thresholds has been changed in release 1.10 and they are now used whenever a case is classified by a decision tree.
rule numbering has also been changed:  the numbers are now sequential, rather than the previous higgledy-piggledy  arrangement.
the sampling option introduced in release 1.07 allows random train/test  splits of an application's data to be generated automatically.
bug fix: pruning a minor bug that could affect pruning of decision trees has been  corrected.
- enhanced multi-threading - additional sections of see5/c5.0 have been multi-threaded.
the difference is  particularly noticeable when the leaves involved have very little supporting  data.
the network version of see5 includes both 32-bit and 64-bit versions for  installation on client pcs.
these versions allow the use of more than 2gb of memory, as  required by some extremely large data mining tasks.
a bug that could allow some or all of these  attributes to be retained was corrected on 12 january 2009.
these concern the  display of implicitly-defined discrete attributes when the value is unknown,  and the possible change of classifier settings when the  "cross-reference" or "making predictions" windows are  invoked immediately after a cross-validation.
this can  result in speed improvements when the application has many discrete attributes,  especially with the discrete value subset option.
64-bit linux version c5.0 is now available in a 64-bit linux version for amd pcs with athlon64  and opteron cpus, and intel pcs with extended memory 64 technology.
this option could be quite slow when large numbers of rules are involved.
release 1.19 rulesets require less memory
(thecross-reference facility in particular provides information that is not  available from the command-line version.)
this option, which is commonly used to increase classification accuracy, has been updated to give better results, especially on applications that use differential misclassification costs.
release 1.05 - rulesets - the method for generating and selecting rules has been `tweaked' slightly to improve performance on some datasets.
with fuzzy thresholds, both branches of the tree are explored if the value ofa is close tot; the results are then combined to give a classification that changes more slowly with the value ofa. previous releases of see5/c5.0 had a fuzzy thresholds option, but these soft thresholds were used only in interactive classification.
- smaller trees for applications with multi-valued discrete attributes - the algorithms for discrete attributes have been further improved.
the network version of see5 includes both 32-bit and 64-bit versions for installation on client pcs.
rulesets are constructed from half the data and tested on the remaining 52,954 cases to estimate their true error rate.
this can be either a list of the allowable attributes or, alternatively, a list of the attributes to be excluded.
- 64-bit linux version - c5.0 is now available in a 64-bit linux version for amd pcs with athlon64 and opteron cpus, and intel pcs with extended memory 64 technology.
the goal of this application is to predict whether a  person's income is above or below $50,000 using 7 numeric and 33 discrete  (nominal) attributes.
the output window is now more readable, and can be copied and printed  directly (without having to switch to wordpad).
as before, half of the data -- 290,506 cases -- are used for training and the remainder for testing.
rulesets each rule now provides information on the number of cases that it covers,  and the method of choosing a default class has been altered slightly.
click on a training case to see the parts of the classifiers relevant to that case.
linux c5.0 continues to be available in both 32-bit and 64-bit versions.
release 1.18 major improvements to rulesets release 1.18 complements the changes introduced in 1.17, where the focus  was on decision trees.
the pruning algorithms have been altered slightly to correct a potential  problem.
- bug fix: pruning - a minor bug that could affect pruning of decision trees has been corrected.
- bug fix - in previous releases, use of the cross-reference facility in the see5 could cause problems when there were errors in the cases file.
a new option allows global pruning to be disabled if desired.
this tends to produce more compact models with higher predictive accuracy.
in response to several requests, the free source code for reading and interpreting classifiers has been extended.
the use of data subsets has been discontinued in release 2.06, at a cost of a small increase in the time required for applications with many continuous attributes and hundreds of thousands of training cases.
the process for finding all the rules that are satisfied by a case has been enhanced.
- improved scalability - for larger datasets, release 1.17 uses internal sampling to evaluate alternative splitting tests.
release 1.07 includes an additional programsee5x that can be executed as a console application.
the attribute winnowing option attempts to identify unhelpful attributes and exclude them from classifiers.
- cross-reference facility (windows version) - see5 now has a new button that looks like a large `x'.
boosting is now noticeably faster and more resistant to  noise in the data.
this invokes a  novel method of cross-referencing classifiers and the data from which they were  constructed.
- bug fixes - two bugs have been fixed that (sometimes) cause problems with combinations of options: - use of the discrete value subsetting option together with the rulesets option for applications with ordered discrete attributes; and - use of the attribute winnowing option together with the sampling option and samples greater than 50% (windows only).
- improved error messages - problems with application files (.names, .data, .test, .costs etc) can be corrected more easily because the error message includes the line number of the file in question.
adaptation to microsoft bug-fix (network versions only) to improve security, microsoft windows updates have disabled a feature  that is used by clients to read on-line help, as documentedhere.
rules are found more quickly (quite a lot more quickly in some  applications).
the results summary also incorporates  costs directly.
release 1.13 - new data type - times are read and written in the form hh:mm:ss .
- adaptation to microsoft bug-fix (network versions only) - to improve security, microsoft windows updates have disabled a feature that is used by clients to read on-line help, as documentedhere.
release 2.04 attribute usage a new summary highlights the usage of attributes that appear in a  classifier.
in release 2.05, an attribute is "used" to  classify a case when it referenced by one or more conditions of anapplicable rule (i.e., a rule whose conditions are all satisfied by a case).
changes to .tree and .rules files up to release 1.11 decision tree and ruleset models have been stored as  binary files.
for instance, if attributeprice has  numeric values, the class specifier price: 100, 1000, 5000.
this is particularly useful when discrete  attributes have numerous values and is now much faster than in previous  releases.
the linux gui calls the native linux c5.0, so there is no performance penalty.
the definition of "usage" for rulesets has been changed in this release so that the information is more consistent across ruleset and tree classifiers.
- sample locking (see5) - the sampling option introduced in release 1.07 allows random train/test splits of an application's data to be generated automatically.
faster rulesets rulesets are now generated more quickly, especially for large  applications.
for most applications this should not affect the final classifier; in some cases, the tree or ruleset will be larger or smaller, but predictive accuracy should be similar.
a bug that could allow some or all of these attributes to be retained was corrected on 12 january 2009.
the results summary also incorporates costs directly.
for thresholded class attributes (see below), a value of "?"
batch-mode version of see5 guis are great, but it's sometimes useful to be able to run see5
the data are divided into a training set of 99,762 cases  and a test set of 99,761.
release 1.20/1.20a the changes in release 1.20 were as follows: release 1.20a fixed three bugs in 1.20: - differential misclassification costs with rulesets, boosting -
- bug fixes - two bugs have been fixed: - a value of the "minimum cases" option greater than 25 could occasionally behave as if it was set to 25, and - the highest possible threshold of a continuous attribute was sometimes overlooked.
filestem (where filestem is the application name) to indicate the stage it is up to, and where it is in that stage.
in release 2.04, an attribute was considered to have been "used"  if its value was required to determine which rules applied to a case.
- bug fix: rulesets and global pruning - this bug affected only ruleset classifiers generated with global pruning disabled -- the resulting rulesets might have been over-simplified.
the proprietary variant of boosting employed in see5/c5.0 has been  modified considerably.
you might like to inspect this file from time to time during long  runs.
warning: the new code will not work correctly with releases before 1.10, nor will release 1.10 work with the old source code.
release 1.16 the windows gui has also been improved slightly and the public code has a new option governing output format.
for instance, if attribute price has numeric values, the class specifier would indicate four discrete classes: price less than or equal to 100 price greater than 100 but less than or equal to 1000 price greater than 1000 but less than or equal to 5000 price greater than 5000.
see5/c5.0 uses a  modified form of the original technique that has now been further improved,  especially for large datasets and rule-based classifiers.
- census income data (income, 199,523 cases, obtained from uci kdd archive).
if you downloaded release 2.06 between 22 december 2008 and 12 january 2009, we recommend that you re-install the corrected release.
(this may sound as though 1.18 was rather wasteful with memory.
this can be either a list of the  allowable attributes or, alternatively, a list of the attributes to be excluded.
other changes and bug fixes there have been minor modifications to the way soft thresholds for  decision trees are found.
release 2.03 introduces an optionalcase weight attribute with numeric values; the effect is to bias the development of a classifier to increase accuracy on more important cases.
release 1.14 new data type timestamps are read and written in the form yyyy-mm-dd  hh:mm:ss using a 24-hour clock.
- enhanced multi-threading - release 2.04 will now use up to four processors and so will run faster on the new quad-core cpus and computers with two dual-core processors.
release 1.14 - new data type - timestamps are read and written in the form yyyy-mm-dd hh:mm:ss using a 24-hour clock.
the source code that facilitates such deployment has also changed substantially.
decision trees are  pruned more carefully, and the confidence of predictions is now calculated  differently.
- changes to test selection - one of the fundamental processes in classifier construction is deciding whether to incorporate another test and, if so, which alternative test to pick.
the  reduction is achieved, however, by compressing certain data structures as they  are constructed; when information is required, relevant parts are temporarily  restored.)
fuzzy thresholds a test on a numeric attribute a in a decision tree has two  branches associated with it, one for each ofa  t for some thresholdt.
this decision is made on the basis of heuristic estimates of usefulness and,  although a test can be removed later, the test itself is hardly ever changed.
(this bug only trivially affected the output of see5/c5.0 and had no noticeable impact on the trees' predictive accuracy.)
- revision of source code - the source code for reading and interpreting classifiers constructed by see5/c5.0 has been extensively revised.
- better rulesets - release 1.13 focuses on improvements to all aspects of rulesets.
viewing large results files should now be much faster; some minor format changes will also be apparent.
release 1.16 attribute winnowing when the number of attributes is large (in the hundreds, say) it becomes  harder to distinguish predictive information from chance coincidences.
in release 2.04, an attribute was considered to have been "used" if its value was required to determine which rules applied to a case.
even without the winnowing option, the classifiers produced by release 1.16 may differ from those generated by earlier releases.
a new button on the toolbar allows the previous output to be redisplayed.
in response to several requests, the free source code for reading and  interpreting classifiers has been extended.
furthermore, rules  can be grouped into a number of bands, so that it is possible to see how the  most important x% of rules perform on training and test data.
as a result, you may observe changes in the rulesets generated from your data.
12 january 2009, we recommend that  you re-install the corrected release.
the 32-bit release of see5 will run under either 32-bit or 64-bit windows,  so there is no need to change unless your tasks may use more than 2gb of  memory.
release 2.06 - new algorithm for softening thresholds - see5/c5.0 decision trees have an option to soften threshold tests for continuous attributes; values near the threshold cause both the low and high branches to be evaluated and combined probabilistically.
release 2.08 differential misclassification costs see5/c5.0's handling of misclassification costs has been revised,  particularly when the application has more than two classes.
winnowing improved winnowing (pre-filtering the attributes) is now faster and somewhat more  conservative.
the problem could arise in applications with many attributes and a large number of missing values.
this definition proved unsatisfactory because it depended on the order in which rule conditions were checked, and also because many attributes ended up having usage figures around 100%.
a timestamp is rounded to the nearest minute and implicitly defined attributes can be used to compute functions of timestamps such as the number of minutes between two of them.
bug fixes two bugs have been fixed that (sometimes) cause problems with  combinations of options: use of the discrete value subsetting option together with the rulesets  option for applications with ordered discrete attributes; and use of the attribute winnowing option together with the sampling option  and samples greater than 50% (windows only).
selecting tests recent releases used a subset of the training data to eliminate some  possible tests from consideration.
- bug fix (june 2010) - a bug in the ruleset interpreter was fixed.
cross-reference facility (windows version) see5 now has a new button that looks like a large `x'.
release 1.07 includes an  additional programsee5x that can be executed as a console application.
this option, which is commonly used to increase  classification accuracy, has been updated to give better results, especially on  applications that use differential misclassification costs.
- finally, large rulesets can be interpreted more quickly -- an advantage when using the public c code to deploy applications.
- confidence of ruleset predictions - calculation of the confidence of a ruleset prediction has been altered so that it more accurately reflects the ruleset's performance on unseen data.
the formulas need not be simple -- both numeric and logical values can be introduced in this way.
speed improvements both c5.0 and see5 are now faster, particularly for large datasets.
release 1.12 - new data values - a new value n/a can be used when the value of an attribute is not applicable to a case.
(there's also  a new button on the dialog box to reset all of them to their default values.)
- there were also problems when the winnowing option was used at the same time as the minimum cases option was set to 1.
speed is the most obvious improvement, but the rulesets themselves are sometimes smaller.
- alternative ordering for rulesets - a new option allows rulesets to be ordered by utility, from most important to least important for classification accuracy.
release 1.10 - attributes defined by formulas - it is sometimes convenient to define the value of an attribute as a function of other attribute values rather than by giving the value explicitly in .data files.
alternative ordering for rulesets a new option allows rulesets to be ordered by utility, from most  important to least important for classification accuracy.
release 1.18 - major improvements to rulesets - release 1.18 complements the changes introduced in 1.17, where the focus was on decision trees.
- minor tweaks - several algorithms used in see5/c5.0 have been tuned or otherwise improved.
as an added convenience, classifiers constructed using the sampling  option are now automatically evaluated on a disjoint set of test cases.
- a new button on the classifier construction dialog box allows any .costs file to be ignored.
warning: the new code will not work  correctly with releases earlier than 1.10.
this option can lead to noticeably better predictive performance and is now recommended for applications with many continuous attributes.
speed is the most obvious improvement, but the  rulesets themselves are sometimes smaller.
the cross-reference window itself now indicates whether cases are misclassified.
new distribution format for windows see5
in a customer retention application, for example, the importance of a case describing a customer might depend on the size of the customer's account.
simplified output for rules when the "rules" option is selected, the output now omits  information about decision trees.
result window (windows version) the system menu for this window has been extended with the option switch to wordpad.
muti-class applications that specify a  costs file should now observe lower average misclassification costs for unseen  cases, especially when rulesets are generated.
this option invokes the wordpad editor on the output,  allowing it to be printed, edited etc.
- false positive/false negative breakdown - see5/c5.0 currently shows a confusion matrix only when the number of classes does not exceed twenty.
the -x option invokes cross-validation and specifies the number of folds.
enhanced multi-threading release 2.04 will now use up to four processors and so will run  faster on the new quad-core cpus and computers with two dual-core processors.
- improved boosting - the boosting option generates several classifiers that are then voted to give a final prediction.
these errors are now reported via pop-up messages.
this could (very rarely) lead to different classifiers when the training data were reordered, or when see5/c5.0 was run on computers with multiple cpus.
if a case's value of the former is `no', the appropriate value for the latter is now `n/a'.
the client  installation program has been modified to set appropriate registry entries on  the client, and also leaves a local copy of the help (see5help.chm) in the see5  folder as a workaround in case new windows updates affect htmlhelp.
- changes to results window (see5 only) -
release 2.01 is distributed as a self-contained inno executable.
boosting is now noticeably faster and more resistant to noise in the data.
release 1.10 attributes defined by formulas it is sometimes convenient to define the value of an attribute as a  function of other attribute values rather than by giving the value explicitly  in .data files.
options for see5x are set by command-line parameters in exactly the same way as  for the unix version c5.0.(not included with the free demonstration download.)
faster boosting boosting is speedier for large datasets, especially where the number of  boosting trials exceeds 20 or so.
(this bug only trivially affected the output of  see5/c5.0 and had no noticeable impact on the trees' predictive accuracy.)
when (single or boosted) ruleset  classifiers are used, a new option shows the rules that are applicable to each  case.
for example, the following graphs compare the performance of 1.18 to the  previous release (1.17) on three large datasets: sleep stage scoring data (sleep, 105,908 cases, obtained  frommlc++).
the most serious bug in the initial release concerned the use of rulesets together with a costs file -- the system could sometimes associate an incorrect class with a rule, leading to abnormally high error rates.
in some situations, for instance when investigating alternative classifier construction options, it is desirable to be able to `lock in' a particular sample, and an additional option on the classifier construction dialog box is now provided for this purpose.
- public source code - output from the sample program is easier to read, and cases are identified by their label attribute (if this is defined).
changes to the see5 gui there have been several improvements in line with suggestions made by  users (and please keep them coming!): a new edit menu brings up the .names or .costs file in wordpad,  making it easier to change these files.
ordered discrete values are nominal values that have a natural ordering, such as small, medium, large, xl, xxl.
census income data (income, 199,523 cases, obtained from  uci kdd archive).
the change is intended to reduce the number of unhelpful tests appearing in classifiers so that they are smaller and/or have higher predictive accuracy.
- - see5 on-line help rewritten - the on-line help for the windows version has been moved to the more modern htmlhelp format and now corresponds closely to thetutorial available on the web.
release 1.17 simpler trees a further global decision tree pruning phase has been incorporated  in the new release.
minor tweaks several algorithms used in see5/c5.0 have been tuned or otherwise  improved.
revision of source code
however, the option +d that preserves detailed outputs now saves one file for each cross-validation rather than one file for each c5.0 run.
public source code output from the sample program is easier to read, and cases are  identified by their label attribute (if this is defined).
furthermore, the remaining attributes that will be used to build classifiers are now ranked by importance, with an estimate of how predictive accuracy or misclassification cost would increase if individual attributes were removed.
release 1.06 - cross-reference facility (see5) - this has been extended to allow classifiers to be related to cases in .test and .cases files in addition to the .data file.
release 1.13 new data type times are read and written in the form hh:mm:ss .
for larger datasets, release 1.17 uses internal sampling to evaluate  alternative splitting tests.
for applications with a .costs file, the unix cross-validation script now  reports average misclassification costs.
this option invokes the wordpad editor on the output, allowing it to be printed, edited etc.
boosting a modified method is used to predict when boosting is likely to be  harmful.
- speed improvements - both c5.0 and see5 are now faster, particularly for large datasets.
last updated february 2012 home products download evaluations prices purchase contact us
release 2.02 faster rule utility ordering
- minor tweak - boosting has been improved somewhat for large data files (more than four thousand records).
release 2.07 64-bit windows support
this release includes 64-bit versions of see5 and see5x (the batch  executable).
while the treatment of costs for two-class problems remains much the  same, the handling of cost information for applications with three or more  classes has been extensively revised.
release 2.03 weighting individual cases the training cases for some applications have different relative  importance.
if you downloaded  release 2.06 between 22 december 2008 and
for the continuous target attribute in a .cases file caused problems.
any solaris licensees who might be inconvenienced by this change should contact us to discuss possible remedies, such as moving their licences to different computers.
attributes found to be irrelevant or harmful to
this decision is made on the basis of heuristic estimates of usefulness and, although a test can be removed later, the test itself is hardly ever changed.
for example, release 1.19 uses 143mb during processing of theforest application, less than half the 296mb needed by release 1.18.
- many-valued discrete attributes - see5/c5.0's handling of discrete attributes with numerous values is faster, and thesubsetting option uses less memory.
© rulequest research 2012
sample locking (see5)
- rule selection - the algorithm for refining an initial collection of rules has been altered, with the result that release 1.20 sometimes produces smaller rulesets.
release 1.09 - confidence values for decision trees - when a case is classified by a decision tree, the calculation of the classification confidence has been changed slightly.
- enhancement of public source code -
most of these changes will be invisible to the user, but some (such  as the method for selecting subsets of discrete values) may cause classifiers  to differ from those produced by release 1.10.
on the well-known census dataset, for example, release 1.17 produces a 159-leaf decision tree that is slightly more accurate than the 211-leaf tree output by release 1.16.
- rulesets - each rule now provides information on the number of cases that it covers, and the method of choosing a default class has been altered slightly.
(for the technically minded, the results window  no longer uses the rich edit control.)
the change is intended to reduce the  number of unhelpful tests appearing in classifiers so that they are smaller  and/or have higher predictive accuracy.
improved boosting boosting is a technique originated by yoav freund and rob schapire for  building multiple classifiers to improve predictive accuracy.
- improved boosting - boosting is a technique originated by yoav freund and rob schapire for building multiple classifiers to improve predictive accuracy.
confidence of ruleset predictions calculation of the confidence of a ruleset prediction has been altered so  that it more accurately reflects the ruleset's performance on unseen data.
release 2.07 - 64-bit windows support - this release includes 64-bit versions of see5 and see5x (the batch executable).
- other changes and bug fixes - there have been minor modifications to the way soft thresholds for decision trees are found.
for example, consider the attributes `purchased ticket?' with values `yes' and `no', and `ticket cost' with numeric values.
- simplified output for rules - when the "rules" option is selected, the output now omits information about decision trees.
improved boosting the boosting option generates several classifiers that are then voted to  give a final prediction.
forest cover type data (forest, 581,012 cases, also from  uci kdd archive).
this can noticeably reduce the time taken to process very large datasets.
for example, the time to generate a ruleset for one dataset with 750,000 cases was reduced by more than 10%.
this application has seven classes (possible types of forest cover), and the cases are described in terms of 12 numeric and two multi-valued discrete attributes.
see5/c5.0 now uses a modified test selection strategy when the training data contains thousands of cases or more.
enhanced multi-threading additional sections of see5/c5.0 have been multi-threaded.
release 2.06 new algorithm for softening thresholds see5/c5.0 decision trees have an option to soften threshold tests for  continuous attributes; values near the threshold cause both the low and high  branches to be evaluated and combined probabilistically.
the new release requires very little time to carry out the ordering and  analysis.
conversely, click on a decision tree leaf or a rule to  see the cases that match that leaf or rule.
release 2.04 - attribute usage - a new summary highlights the usage of attributes that appear in a classifier.
the cross-reference window itself now indicates whether cases are  misclassified.
from this release they have been changed to ascii files, so that  models generated on one machine type may be deployed on machines of another  type.
from this release they have been changed to ascii files, so that models generated on one machine type may be deployed on machines of another type.
- attribute winnowing - when the number of attributes is large (in the hundreds, say) it becomes harder to distinguish predictive information from chance coincidences.
(for the technically minded, the results window no longer uses the rich edit control.)
a bug in the ruleset interpreter was fixed.
conversely, click on a decision tree leaf or a rule to see the cases that match that leaf or rule.
see5/c5.0 uses a modified form of the original technique that has now been further improved, especially for large datasets and rule-based classifiers.
saving cross-referencing results (see5) see5's cross-referencing facility is a powerful tool for finding the  cases covered by particular components of classifiers, and parts of classifiers  relevant to particular cases.
click on a training case to see the parts of the classifiers  relevant to that case.
this affects the output from the public code to read and interpret see5/c5.0 ruleset classifiers, and also impacts results with boosted rulesets.
release 1.17 - simpler trees - a further global decision tree pruning phase has been incorporated in the new release.
(the list of classes is still ok, so you don't have to change existing names files.)
this speeds up the generation of decision trees as  the following example shows: the graph compares the times required by 1.16 and 1.17 to construct a  decision tree for different-sized subsets of a dataset.
this can result in speed improvements when the application has many discrete attributes, especially with the discrete value subset option.
this could (very rarely) lead to different  classifiers when the training data were reordered, or when see5/c5.0 was run on  computers with multiple cpus.
the reduction is achieved, however, by compressing certain data structures as they are constructed; when information is required, relevant parts are temporarily restored.)
release 1.06 cross-reference facility (see5) this has been extended to allow classifiers to be related to cases in .test and .cases files in addition to the .data file.