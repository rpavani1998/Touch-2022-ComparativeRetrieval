we show that the resulting ranker, compared to  ei- ther component technique, frequently significantly increases auc.
this paper examines  the various parameters and variants of empirical bias variance decompositions  through an extensive simulation study.
this thesis investigates the use of machine learning  techniques in computer games to create a computer player that adapts to its  opponent's game-play.
this thesis investigates the case where each instance has a weight value determining the level of influence that it has on its s class label.
{combining naive {b}ayes and decision tables}, booktitle = {proc 21st florida artificial intelligence research society conference}, year = 2008, series = {miami, florida}, publisher = {aaai press}, pdf = { http://www.cs.waikato.ac.nz/~ml/publications/2008/hallandfrankflairs08.pdf}, abstract = {
this is also the case  when attribute selection is performed in naive bayes and its semi-naive  variant.} } @inproceedings{mutter08:_propos, author = {stefan mutter and bernhard  pfahringer and geoffrey holmes}, title =
aft was tested on the cedar and gpds benchmark datasets, with classification using either a manual or an automatic variant.
they offer the advantage to provide sound,  probabilistic scores.
for both datasets aft is less complex and requires fewer images features than the existing state of the art methods, while achieving competitive results.}, pages =
this limits the effectiveness of reinforcement learning because a large number of episodes are required before performance becomes sufficient to match the opponent.}, http = { http://hdl.handle.net/10289/2779} } @phdthesis{anderson08:_random_relat_rules, author = {grant anderson}, title = {random relational rules},
the  methods are evaluated in terms of their accuracy and the time taken to find the  neighbours.
the method allows the use of phmms discriminatively in a classification task.
this allows the  classification process to inherently take into account correlations between  labels.
an empirical investigation compares semi-supervised  propositionalization to standard propositionalization using just the labeled  data portion, as well as to a variant that also just uses the labeled data  portion but includes the label information in an attempt to improve the  resulting propositionalization.
for both datasets aft is less complex and requires fewer images features than  the existing state of the art methods, while achieving competitive results.},  pages = {1-6}, year = 2008, series = {christchurch, new zealand}, publisher =
this is one of the main contributions of the paper.
our main finding is that  multi-class and two-class classification becomes preferable to one-class  classification when a sufficiently large number of non-target classes is  available.} } @inproceedings{mutter08:_propos_ai08, author = {stefan mutter and  bernhard pfahringer and geoffrey holmes}, title = {propositionalisation of  profile hidden markov models for biological sequence analysis}, booktitle =  {proc 21st
mi  learning has applications in areas such as drug activity prediction, fruit  disease management and image classification.
an existing approach known as miles is retroactively identified as an algorithm that uses instance weights for mi learning, and is evaluated using a variety of base learners on benchmark problems.
previously, kernel approaches have been proposed to generate a  discriminative description for an hmm, but require the explicit definition of a  similarity measure for hmms.
our main finding is that multi-class and two-class classification becomes preferable to one-class classification when a sufficiently large number of non-target classes is available.} } @inproceedings{mutter08:_propos_ai08, author = {stefan mutter and bernhard pfahringer and geoffrey holmes}, title = {
this thesis presents algorithms for learning from relational data that mitigate, to some extent, the complexity normally associated with such learning.
{rober larkins and michael mayo}, title
only if the learning algorithm is stable, fewer samples, a smaller test set size or lower number of folds may be justified.} } @inproceedings{foulds08:_revis_multip_instan_learn_via, author =
{http://hdl.handle.net/10289/2172} } @inproceedings{zhang08:_patter, author = {edmond zhang and michael  mayo},
there are three basic methods that have been applied in most approaches to the netflix problem so far: stand-alone neighborhood-based methods, latent factor models based on singular-value decomposition, and ensembles consisting of variations of these techniques.
this includes first confirming that machine learning  algorithms can be integrated into a modern computer game without have a  detrimental effect on game performance, then experimenting with different  machine learning techniques to maximize the computer player's performance.
however, if known non-target classes are available at training time, it is also possible to use standard multi-class or two-class classification, exploiting the negative data to infer a description of the target class.
handling numeric attributes in hoeffding trees}, booktitle = {proc 12th pacific-asia conference on knowledge discovery and data mining}, publisher = {springer}, year = 2008, pages = {296-307}, http = { http://dx.doi.org/10.1007/978-3-540-68125-0_27}, series = {osaka, japan}, abstract = {
for conventional machine learning classification algorithms handling numeric attributes is relatively straightforward.
when the number of dimensions is  greater than two there are no known solutions that can guarantee a sublinear  retrieval time.
{combining naive {b}ayes and decision tables},  booktitle = {proc 21st florida artificial intelligence research society  conference}, year = 2008, series = {miami, florida}, publisher = {aaai press},  pdf = { http://www.cs.waikato.ac.nz/~ml/publications/2008/hallandfrankflairs08.pdf},  abstract =
new algorithms for learning  instance weights for mi learning are also proposed and rigorously evaluated on  both artificial and real-world datasets.
the results show that the inclusion  of spatial relationships leads to a measurable increase in performance for two  of the most challenging datasets.}, pages = {1 - 6}, year = 2008, series =  {christchurch, new zealand}, publisher = {ieee}, http = { http://hdl.handle.net/10289/2173} } @mastersthesis{miles08:_machin_learn_adapt_comput_game_oppon, author =
the challenge is  to accurately estimate these weights in order to make predictions at the bag  level.
although miles provides competitive performance when  compared to other mi learners, we identify simpler propositionaliza- tion  methods that require shorter training times while retaining miles' strong  classification performance on the datasets we tested.} } @inproceedings{frank08:_addit_regres_applied_to_large, author =
it is simple and  effective but has a time complexity that is the product of the number of  instances and the number of dimensions.
timation techniques or by adapting a standard classification algorithm to the  problem of carving out a decision boundary that describes the location of the  target data.
the new algorithms are shown to  achieve better root mean squared error rates than existing approaches on  artificial data generated according to the underlying assumptions.
using a benchmark face gender classification dataset recently proposed in the literature, we obtain a state-of-the-art accuracy of 92.5%, thus validating our approach.},
{propositionalisation of multiple  sequence alignments using probabilistic models}, booktitle = {new zealand  computer science research student conference (nzcsrsc 2008)}, year = 2008,  series = {christchurch, new zealand}, month = {april}, pages = {234-237}, pdf =
in this method, the ref- erence distribution is used to generate artificial data that is employed to form a second, artificial class.
the demanding nature of  the netflix data has lead to some interesting and ingenious modifications to  standard learning methods in the name of efficiency and speed.
however, the original authors consider only one single-instance base  learner for the algorithm --- the 1-norm svm.
the basic idea we present in this paper is to use the  structure of a profile hidden markov model for propositionalisation.
the methods are evaluated in terms of their accuracy and the time taken to find the neighbours.
static models show the highest initial performance but are not able to beat a simple opponent.
all algorithms in this thesis are based on the generation of random relational rules.
in conjunction with the target class, this artificial class is the basis for a standard two-class learning problem.
finally, we discuss a range of possible services  such a resource can offer, either used directly or integrated into data mining  tools.} } @inproceedings{larkins08:_adapt, author =
this  indicates a need for algorithms that can operate efficiently on relational data  and exploit the larger body of work produced in the area of single-table  techniques.
the methods are best described as heuristic as they are neither  exact nor approximate.
using a benchmark face gender  classification dataset recently proposed in the literature, we obtain a  state-of-the-art accuracy of 92.5%, thus validating our approach.}, pages =
experimental  results also demonstrate that the new algorithms are competitive with existing  approaches on real-world problems.} }
improving face gender classification by adding deliberately misaligned faces to the training data}, booktitle = {proc 23rd international conference image and vision computing new zealand}, abstract = {a novel method of face gender classifier construction is proposed and evaluated.
2008.bib @comment{{automatically generated - do not modify!}
further  applications of random rules are investigated.
to this end, we extend an  existing approximation approach, based on simple gaussian approximation.
australasian joint conference on artificial intelligence}, year = 2008, series = {auckland, new zealand}, publisher = {springer}, pdf = {
by pruning these sets, ps focuses only on the most important  correlations, which reduces complexity and improves accuracy.
in this paper, we make use of such a database to answer various interesting research questions about learning algorithms and to verify a number of recent studies.
yet, the information contained in these experiments might have  uses beyond their original intent and, if properly stored, could be of great  use to future research.
we draw parallels between how experiments are being curated in other sciences, and consecutively discuss how both the empirical and theoretical details of learning experiments can be expressed, organized and made universally accessible.
university of porto}, abdstract =
the challenge is to accurately estimate these weights in order to make predictions at the bag level.
{many applications require the ability to identify data that is  anomalous with respect to a target group of observations, in the sense of  belonging to a new, previously unseen 'attacker' class.
in the field of machine learning, methods for learning from single-table data have received much more attention than those for learning from multi-table, or relational data, which are generally more computationally complex.
however, the field is still evolving relatively quickly, and new algorithms, preprocessing methods, learning tasks and evaluation procedures continue to emerge in the literature.
this paper examines the various parameters and variants of empirical bias variance decompositions through an extensive simulation study.
the methods are best described as heuristic as they are neither exact nor approximate.
naive bayes and  decision tables can both be trained effi- ciently, and the same holds true for  the combined semi-naive model.
this paper describes and evaluates two ways to make nns efficient for datasets that are arbitrarily large in the number of instances and dimensions.
experimental results also demonstrate that the new algorithms are competitive with existing approaches on real-world problems.} }
one possible approach  to this kind of verification problem is one-class classification, learning a  description of the target class concerned based solely on data from this class.
experimental results show that our methods produce  competitive results.} } @inproceedings{hempstalk08:_discr_again_new_class, author = {kathryn  hempstalk and eibe frank}, title =
we show empirically that using propositionalisation leads to higher accuracies in comparison with phmms on benchmark datasets.} } @inproceedings{wu08:_minin_arbit_large_datas_using, author =
surprisingly, the experimental comparison shows that the most approximate methods produce the most accurate trees by allowing for faster tree growth.} } @mastersthesis{foulds08:_learn_instan_weigh_multi_instan_learn, author =
the much-publicized netflix competition has put the spot- light on the application domain of collaborative filtering and has sparked interest in machine learning algorithms that can be applied to this sort of problem.
{1-6}, year = 2008, series = {christchurch, new zealand}, publisher = {ieee}, http = {ttp://hdl.handle.net/10289/2174} } @inproceedings{mayo08:_improv, author = {michael mayo and edmond zhang}, title = {
{many applications require the ability to identify data that is anomalous with respect to a target group of observations, in the sense of belonging to a new, previously unseen 'attacker' class.
this includes first confirming that machine learning algorithms can be integrated into a modern computer game without have a detrimental effect on game performance, then experimenting with different machine learning techniques to maximize the computer player's performance.
continuous  learning is able to improve the performance achieved with static models but the  rate of improvement drops over time and the computer player is still unable to  beat the opponent.
revisiting multiple-instance learning via  embedded instance selection}, booktitle = {proc 21st
{proc 21set australasian joint conference on artificial intelligence}, year = 2008, series = {auckland, new zealand}, publisher = {springer}, pdf = {
the results from experimental evaluation on a  variety of multi-label datasets show that [e]ps can achieve better performance  and train much faster than other multi-label methods.}, series = {pisa, italy},  publisher = {ieee computer society} } @inproceedings{bouckaert08, author =
the  much-publicized netflix competition has put the spot- light on the application  domain of collaborative filtering and has sparked interest in machine learning  algorithms that can be applied to this sort of problem.
it is commonly tackled using density es-
we investigate a simple semi-naive bayesian ranking method that  combines naive bayes with induction of decision tables.
the basic idea we present in this paper is to use the structure of a profile hidden markov model for propositionalisation.
{bernhard pfahringer and geoffrey holmes and richard kirkby}, title = {
our results show that boosted decision stumps can in some cases provide better classification accuracy than the 1-norm svm as a base learner for miles.
new algorithms for learning instance weights for mi learning are also proposed and rigorously evaluated on both artificial and real-world datasets.
solutions for data streams have been proposed by several authors but as yet none have been compared empirically.
propositionalisation of profile hidden markov models for biological sequence analysis}, booktitle = {proc 21st
most alignment representations are designed to facilitate knowledge extraction  by human experts.
our model is based on the successful `bag of words' approach.
} @inproceedings{vanschoren08:_learn_past_exper_datab, author = {joaquin  vanschoren and bernhard pfahringer and geoffrey holmes}, title =
unsupervised and  supervised solutions exist that either segment the data into pre-defined bins  or sort the data and search for the best split points.
{xing wu  and geoffrey holmes and bernhard pfahringer}, title = {
this paper introduces adaptive feature  thresholding (aft) which is a novel method of person-dependent off-line  signature verification.
{http://hdl.handle.net/10289/2172} } @inproceedings{zhang08:_patter, author = {edmond zhang and michael mayo}, title =
however, unlike the original model, image features (keypoints) are not seen as independent and orderless.
this thesis presents algorithms for learning from relational data  that mitigate, to some extent, the complexity normally associated with such  learning.
however, the field is still evolving relatively quickly, and new  algorithms, preprocessing methods, learning tasks and evaluation procedures  continue to emerge in the literature.
{jonathan david miles}, title = {machine learning for adaptive computer game  opponents}, school = {department of computer science, university of waikato},  year = 2008, abstract = {
australasian joint conference on artificial intelligence}, year =
solutions for data streams have been proposed by several authors but as yet  none have been compared empirically.
{bernhard pfahringer and grant anderson}, title
in this paper we assume that this scenario holds and inves- tigate under what conditions multi-class and two-class naive bayes clas- sifiers are preferable to the corresponding one-class model when the aim is to identify examples from a new 'attacker' class.
however, unlike  the original model, image features (keypoints) are not seen as independent and  orderless.
propositionalisation allows  single-table algorithms for classification and clustering to be applied to the  resulting data, reducing the amount of relational processing required.
in this paper, we propose  a community-based approach for the analysis of learning algorithms, driven by  sharing meta-data from previous experiments in a uniform way.
to this end we first identify a way of performing a fair  comparison between the techniques concerned and present an adaptation of  standard cross-validation.
this demonstrates that sufficient information for classification and clustering is retained in the rule generation process and that learning with random rules is efficient.
a novel method of face  gender classifier construction is proposed and evaluated.
timation techniques or by adapting a standard classification algorithm to the problem of carving out a decision boundary that describes the location of the target data.
it is centred on the concept of treating sets of labels as single labels.
{pattern discovery for object categorization}, booktitle = {proc 23rd international conference image and vision computing new zealand}, abstract =
thus, it is impossible for a single study to cover this expanding space of learning approaches.
further  results show that techniques for utilising additional unlabeled training data  improve accuracy of classification in the semi-supervised setting.
{thousands of machine learning research papers contain experimental comparisons  that usually have been conducted with a single focus of interest, often losing  detailed results after publication.
we present an empirical study investigating the efficacy of alternative base learners for miles, and compare miles to other mi algorithms.
{learning instance weights in multi-instance learning},  school = {department of computer science, university of waikato}, year = 2008,  pdf = {http://hdl.handle.net/10289/2460},
propositionalisation does not need such a measure and allows the use of any propositional learner including kernel-based approaches.
preliminary experimental results indicate that propositionalization generated on the full dataset, i.e. the semi- supervised approach, tends to outperform the other two more standard approaches.}, http = {
{pattern discovery for object categorization}, booktitle = {proc  23rd international conference image and vision computing new zealand}, abstract  = {
adaptive feature thresholding for off-line signature verification}, booktitle = {proc 23rd international conference image and vision computing new zealand},
we draw parallels between how experiments are being curated in  other sciences, and consecutively discuss how both the empirical and  theoretical details of learning experiments can be expressed, organized and  made universally accessible.
previously, kernel approaches have been proposed to generate a discriminative description for an hmm, but require the explicit definition of a similarity measure for hmms.
however, a significant amount of the world's data is relational.
this paper presents a  pruned sets method (ps) for multi-label classification.
booktitle = {proc 8th ieee international conference on data mining}, year = 2008, pages = {995-1000}, http = {http://dx.doi.org/10.1109/icdm.2008.74}, abstract = {this paper presents a pruned sets method (ps) for multi-label classification.
an empirical investigation compares semi-supervised propositionalization to standard propositionalization using just the labeled data portion, as well as to a variant that also just uses the labeled data portion but includes the label information in an attempt to improve the resulting propositionalization.
{revisiting multiple-instance learning via embedded instance selection}, booktitle = {proc 21st
experiments use three machine learning techniques; static prediction models, continuous learning, and reinforcement learning.
this indicates a need for algorithms that can operate efficiently on relational data and exploit the larger body of work produced in the area of single-table techniques.
{1-5}, year = 2008, series = {christchurch, new zealand}, publisher = {ieee},  http =
we also  compare the method to one-class classification using support vector machines.} } @inproceedings{hall08:_combin_naive_bayes_decis_tables, author =
{485-496}, ee = {http://dx.doi.org/10.1007/978-3-540-89197-0_45}, abstract =
propositionalisation does not need such a measure  and allows the use of any propositional learner including kernel-based  approaches.
experimental results show that our methods produce competitive results.} } @inproceedings{hempstalk08:_discr_again_new_class, author = {kathryn hempstalk and eibe frank}, title =
additionally statistical models like profile hidden markov models are used as representations.
kathryn  hempstalk and eibe frank and ian h. witten}, title
a variant, profile hidden markov models are a special case used in bioinformatics to represent, for example, protein families.
by pruning these sets, ps focuses only on the most important correlations, which reduces complexity and improves accuracy.
one-class classification by combining density and class probability estimation}, booktitle = {proc 12th european conference on principles and practice of knowledge discovery in databases and 19th european conference on machine learning}, year = 2008, series = {antwerp, belgium}, publisher =
by combining  pruned sets in an ensemble scheme (eps), new label sets can be formed to adapt  to irregular or complex data.
us- ing uci datasets, and data from a typist recognition problem, we show that the combined model, consisting of both a density estimator and a class probability estimator, can improve on using either component tech- nique alone when used for one-class classification.
the assumption is that random rules enable efficient and  effective relational learning, and this thesis presents evidence that this is  indeed the case.
in this paper we  investigate an approach to semi-supervised learning based on randomized  propositionalization, which allows for applying standard propositional  classification algorithms like support vector machines to multi-relational  data.
unsupervised and supervised solutions exist that either segment the data into pre-defined bins or sort the data and search for the best split points.
this paper presents a new approach for the object categorization problem.
alongside performing  elaborate comparisons of algorithms, we also investigate the effects of  algorithm parameters and data properties, and seek deeper insights into the  behavior of learning algorithms by studying their learning curves and  bias-variance profiles.}, publisher = {springer}, series = {hanoi, vietnam} } @inproceedings{read08:_multi_class_using_ensem_pruned_sets, author =
further results show that techniques for utilising additional unlabeled training data improve accuracy of classification in the semi-supervised setting.
static models show the highest  initial performance but are not able to beat a simple opponent.
reinforcement learning methods have the highest rate of  improvement but the lowest initial performance.
unfortunately, none of  these solutions carry over particularly well to a data stream environment.
this is a more general assumption than most  existing approaches use, and thus is more widely applicable.
eibe frank and mark hall}, title = {additive regression applied to a large-scale collaborative filtering problem}, booktitle =
we show empirically that using propositionalisation leads to higher  accuracies in comparison with phmms on benchmark datasets.} } @inproceedings{wu08:_minin_arbit_large_datas_using, author =
the thesis  also develops a novel algorithm for building random forests by making efficient  use of random rules to generate trees and leaves in parallel.} } @inproceedings{vanschoren08:_exper_datab, title = {experiment databases:  creating a new platform for meta-learning research}, author = {joaquin  vanschoren and hendrik blockeel and bernhard pfahringer and geoffrey holmes},  year = 2008, booktitle = {proc icml/colt/uai 2008 planning to learn workshop},
the assumption is that random rules enable efficient and effective relational learning, and this thesis presents evidence that this is indeed the case.
we show that the resulting ranker, compared to ei- ther component technique, frequently significantly increases auc.
{proc 21set australasian joint  conference on artificial intelligence}, year = 2008, series = {auckland, new  zealand}, publisher = {springer}, pdf = {
only if the learning algorithm is  stable, fewer samples, a smaller test set size or lower number of folds may be  justified.} } @inproceedings{foulds08:_revis_multip_instan_learn_via, author = {james  foulds and eibe frank}, title = {
finally, we discuss a range of possible services such a resource can offer, either used directly or integrated into data mining tools.} } @inproceedings{larkins08:_adapt, author =
australasian joint conference on artificial intelligence}, year = 2008, series = {auckland, new zealand}, publisher = {springer}, pdf = { http://www.cs.waikato.ac.nz/~ml/publications/2008/ai2008.pdf}, abstract = {hidden markov models are a widely used generative model for analysing sequence data.
instead, our model attempts to discover intermediate representations for each object class.
in this paper we investigate the application of forward stage-wise additive modeling to the netflix problem, using two regression schemes as base learners: ensembles of weighted simple linear regressors and k-means clustering---the latter being interpreted as a tool for multi- variate regression in this context.
discriminating against new classes:  one-class versus multi-class classification}, booktitle =
{http://hdl.handle.net/10289/2562},
the demanding nature of the netflix data has lead to some interesting and ingenious modifications to standard learning methods in the name of efficiency and speed.
it is simple and effective but has a time complexity that is the product of the number of instances and the number of dimensions.
to this end, we extend an existing approximation approach, based on simple gaussian approximation.
aft enhances how a simple image feature of a signature  is converted to a binary feature vector by significantly improving its  representation in relation to the training signatures.
preliminary experimental results indicate that  propositionalization generated on the full dataset, i.e. the semi- supervised  approach, tends to outperform the other two more standard approaches.}, http = {
this is a more general assumption than most existing approaches use, and thus is more widely applicable.
australasian  joint conference on artificial intelligence}, year = 2008, series = {auckland,  new zealand}, publisher = {springer}, pdf = {
there are three  basic methods that have been applied in most approaches to the netflix problem  so far: stand-alone neighborhood-based methods, latent factor models based on  singular-value decomposition, and ensembles consisting of variations of these  techniques.
the solutions cover a range  of options from perfectly accurate and memory intensive to highly approximate.
australasian joint  conference on artificial intelligence}, year = 2008, series = {auckland, new  zealand}, publisher = {springer}, pdf = { http://www.cs.waikato.ac.nz/~ml/publications/2008/miles.pdf}, abstract =  {multiple-instance learning via embedded instance selection (miles) is a  recently proposed multiple-instance (mi) classification al- gorithm that  applies a single-instance base learner to a propositional- ized version of mi  data.
previously, researchers have assumed that a computationally expensive face alignment step (in which the face image is transformed so that facial landmarks such as the eyes, nose, chin, etc, are in uniform locations in the image) is required in order to maximize the accuracy of predictions on new face images.
to test our hypothesis, we evaluate this automatic training dataset expansion method with two types of image classifier, the first based on weak features such as local binary pattern histograms, and the second based on sift keypoints.
for some  datasets it significantly improves on both techniques.
2008, series = {auckland, new zealand}, publisher = {springer}, pdf = { http://www.cs.waikato.ac.nz/~ml/publications/2008/ai2008.pdf},
{practical bias variance decomposition}, booktitle = {proc 21st
these algorithms include direct classification, classification by propositionalisation, clustering, semi-supervised learning and generating random forests.
in this paper we  assume that this scenario holds and inves- tigate under what conditions  multi-class and two-class naive bayes clas- sifiers are preferable to the  corresponding one-class model when the aim is to identify examples from a new  'attacker' class.
the results show that the inclusion of spatial relationships leads to a measurable increase in performance for two of the most challenging datasets.}, pages = {1 - 6}, year = 2008, series = {christchurch, new zealand}, publisher = {ieee}, http = { http://hdl.handle.net/10289/2173} } @mastersthesis{miles08:_machin_learn_adapt_comput_game_oppon, author =
results show that the methods are competitive with nns in terms of accuracy but significantly faster. } } @inproceedings{vanschoren08:_organ_machin_learn_infor, author = {joaquin vanschoren and hendrik blockeel and bernhard pfahringer and geoffrey holmes}, title = {organizing the world's machine learning information}, booktitle = {proc 3rd international symposium on leveraging applications of formal methods, verification and validation}, year = 2008, pages = {693-708}, http = { http://dx.doi.org/10.1007/978-3-540-88479-8_50}, publisher = {springer}, series = {porto sani, greece}, abstract = {all around the globe, thousands of learning experiments are being executed on a daily basis, only to be discarded after interpretation.
in this paper we investigate a simple method for one-class classification that combines the application of a density es- timator, used to form a reference distribution, with the induction of a standard model for class probability estimation.
on the cedar dataset we achieved a classification accuracy of 92% for manual and 90% for automatic, while on the gpds dataset we achieved over 87% and 85% respectively.
joaquin vanschoren and bernhard pfahringer and geoffrey holmes}, title =
although miles provides competitive performance when compared to other mi learners, we identify simpler propositionaliza- tion methods that require shorter training times while retaining miles' strong classification performance on the datasets we tested.} } @inproceedings{frank08:_addit_regres_applied_to_large, author = {
this approach works by partitioning the image into  smaller regions then computing the spatial relationships between all of the  informative image keypoints in the region.
{in the field of machine learning, methods for learning from  single-table data have received much more attention than those for learning  from multi-table, or relational data, which are generally more computationally  complex.
we investigate a simple semi-naive bayesian ranking method that combines naive bayes with induction of decision tables.
{learning from  the past with experiment databases}, booktitle = {proc 10th pacific rim  international conference on artificial intelligence}, year = 2008, pages =
surprisingly, the experimental comparison shows that the most approximate  methods produce the most accurate trees by allowing for faster tree growth.} } @mastersthesis{foulds08:_learn_instan_weigh_multi_instan_learn, author =
the solutions cover a range of options from perfectly accurate and memory intensive to highly approximate.
we explain how the density function of the reference distribution can be combined with the class probability estimates obtained in this way to form an adjusted estimate of the density function of the target class.
osaka, japan},  abstract = {
http://www.cs.waikato.ac.nz/~ml/publications/2008/netflix.pdf}, abstract = {
randomization based on random relational rules can work both with and without a class attribute and can therefore be applied simultaneously to both the labeled and the unlabeled portion of the data present in semi-supervised learning.
{learning from the past with experiment databases}, booktitle = {proc 10th pacific rim international conference on artificial intelligence}, year = 2008, pages = {485-496}, ee = {http://dx.doi.org/10.1007/978-3-540-89197-0_45},
the method allows the use of phmms discriminatively in a classification  task.
http://www.cs.waikato.ac.nz/~ml/publications/2008/bias.pdf}, abstract = {bias  variance decomposition for classifiers is a useful tool in understanding  classifier behavior.
to this end we first identify a way of performing a fair comparison between the techniques concerned and present an adaptation of standard cross-validation.
both stem from recent developments in the field of data  stream classification.
pages = {1-5}, year = 2008, series = {christchurch, new zealand}, publisher = {ieee},
one-class classification  by combining density and class probability estimation}, booktitle = {proc 12th  european conference on principles and practice of knowledge discovery in  databases and 19th european conference on machine learning}, year = 2008,  series = {antwerp, belgium}, publisher
{mining arbitrarily large datasets using heuristic k-nearest neighbour search}, booktitle = {proc 21st australasian joint conference on artificial intelligence}, year = 2008, series = {auckland, new zealand}, publisher = {springer}, pages = {355-361}, http = { http://dx.doi.org/10.1007/978-3-540-89378-3_35}, abstract = {nearest neighbour search (nns) is one of the top ten data mining algorithms.
in this paper we  introduce a simple propositionalisation method for profile hidden markov  models.
naive bayes and decision tables can both be trained effi- ciently, and the same holds true for the combined semi-naive model.
in this paper we investigate a simple method for one-class  classification that combines the application of a density es- timator, used to  form a reference distribution, with the induction of a standard model for class  probability estimation.
in this paper we investigate the application of forward stage-wise  additive modeling to the netflix problem, using two regression schemes as base  learners: ensembles of weighted simple linear regressors and k-means  clustering---the latter being interpreted as a tool for multi- variate  regression in this context.
the first uses hoeffding trees, an extension of decision  trees to streams and the second is a direct stream extension of nns.
to test our hypothesis, we evaluate this  automatic training dataset expansion method with two types of image classifier,  the first based on weak features such as local binary pattern histograms, and  the second based on sift keypoints.
to this end, a system for generating random relational rules  is described, and algorithms using these rules are evaluated.
abstract =  {hidden markov models are a widely used generative model for analysing sequence  data.
in this paper, we hope to stimulate the development of  such learning experiment repositories by providing a bird's-eye view of how  they can be created and used in practice, bringing together existing approaches  and new ideas.
the first uses hoeffding trees, an extension of decision trees to streams and the second is a direct stream extension of nns.
continuous learning is able to improve the performance achieved with static models but the rate of improvement drops over time and the computer player is still unable to beat the opponent.
{exploiting propositionalization based on random  relational rules for semi-supervised learning}, booktitle = {proc 12th  pacific-asia conference on knowledge discovery and data mining}, publisher =
they offer the advantage to provide sound, probabilistic scores.
this demonstrates that sufficient  information for classification and clustering is retained in the rule  generation process and that learning with random rules is efficient.
abstract = {thousands of machine learning research papers contain experimental comparisons that usually have been conducted with a single focus of interest, often losing detailed results after publication.
mark  hall and eibe frank}, title =
http://hdl.handle.net/10289/1428} } @inproceedings{pfahringer08:_handl_numer_attrib_hoeff_trees, author =
{xing wu and geoffrey holmes and bernhard pfahringer}, title =
the new algorithms are shown to achieve better root mean squared error rates than existing approaches on artificial data generated according to the underlying assumptions.
= {springer}, pdf = { http://www.cs.waikato.ac.nz/~ml/publications/2008/hfw08-oneclassclassification.pdf }, abstract = {one-class classification has important applications such as  outlier and novelty detection.
us- ing uci datasets, and data from a typist recognition  problem, we show that the combined model, consisting of both a density  estimator and a class probability estimator, can improve on using either  component tech- nique alone when used for one-class classification.
james foulds and eibe frank}, title =
experiments use three machine learning techniques; static prediction models,  continuous learning, and reinforcement learning.
one possible approach to this kind of verification problem is one-class classification, learning a description of the target class concerned based solely on data from this class.
we present an empirical study  investigating the efficacy of alternative base learners for miles, and compare  miles to other mi algorithms.
additionally statistical models like profile hidden markov  models are used as representations.
this way we get a simple, extendable representation of multiple sequence alignments which facilitates further analysis by machine learning algorithms.} } @inproceedings{pfahringer08:_exploit, author =
{jesse read and bernhard pfahringer and geoffrey holmes}, title = {multi-label  classification using ensembles of pruned sets}, booktitle = {proc 8th ieee  international conference on data mining}, year = 2008, pages = {995-1000}, http  = {http://dx.doi.org/10.1109/icdm.2008.74}, abstract = {
the experimental results show that these algorithms perform competitively with previously published results for the datasets used, while often exhibiting lower runtime than other tested systems.
for conventional machine learning classification algorithms  handling numeric attributes is relatively straightforward.
} @inproceedings{vanschoren08:_learn_past_exper_datab, author = {
in this paper, we make use of such a  database to answer various interesting research questions about learning  algorithms and to verify a number of recent studies.
based on the experimental results obtained, we then show under what conditions  which group of techniques is likely to be preferable.
{multiple sequence alignments play a central role in bioinformatics.
australasian joint conference on artificial intelligence}, year = 2008, series = {auckland, new zealand}, publisher = {springer}, pdf = { http://www.cs.waikato.ac.nz/~ml/publications/2008/bias.pdf}, abstract = {bias variance decomposition for classifiers is a useful tool in understanding classifier behavior.
{remco r. bouckaert}, title =
by combining pruned sets in an ensemble scheme (eps), new label sets can be formed to adapt to irregular or complex data.
we explain how the density function of the  reference distribution can be combined with the class probability estimates  obtained in this way to form an adjusted estimate of the density function of  the target class.
thus, it is impossible for a single study  to cover this expanding space of learning approaches.
we, however,  argue that this step is not necessary, and that machine learning classifiers  can be made robust to face misalignments by automatically expanding the  training data with examples of faces that have been deliberately misaligned  (for example, translated or rotated).
kathryn hempstalk and eibe frank and ian h. witten}, title
improving face gender classification by adding deliberately misaligned  faces to the training data}, booktitle = {proc 23rd international conference  image and vision computing new zealand}, abstract = {
propositionalisation allows single-table algorithms for classification and clustering to be applied to the resulting data, reducing the amount of relational processing required.
mark hall and eibe frank}, title =
the similarity between signatures is then easily computed from their corresponding binary feature vectors.
{rober larkins and michael  mayo}, title
we illustrate how  organizing this information in a central database can create a practical public  platform for any kind of exploitation of meta-knowledge, allowing effective  reuse of previous experimentation and targeted analysis of the collected  results.} } @inproceedings{hempstalk08:_one_class_class_by_combin, author = {
this approach works by partitioning the image into smaller regions then computing the spatial relationships between all of the informative image keypoints in the region.
in this paper we investigate a range of  methods for multi-class tree-based classification where the handling of numeric  attributes takes place as the tree is constructed.
{jesse read and bernhard pfahringer and geoffrey holmes}, title = {multi-label classification using ensembles of pruned sets},
we then compare this method with four approaches from the literature arriving at eight final algorithm configurations for testing.
we, however, argue that this step is not necessary, and that machine learning classifiers can be made robust to face misalignments by automatically expanding the training data with examples of faces that have been deliberately misaligned (for example, translated or rotated).
further applications of random rules are investigated.
the thesis also develops a novel algorithm for building random forests by making efficient use of random rules to generate trees and leaves in parallel.} } @inproceedings{vanschoren08:_exper_datab, title = {experiment databases: creating a new platform for meta-learning research}, author = {joaquin vanschoren and hendrik blockeel and bernhard pfahringer and geoffrey holmes}, year = 2008, booktitle = {proc icml/colt/uai 2008 planning to learn workshop}, http = {http://hdl.handle.net/10289/1801}, series = {helsinki, finland}, publisher = {
in this paper we investigate an approach to semi-supervised learning based on randomized propositionalization, which allows for applying standard propositional classification algorithms like support vector machines to multi-relational data.
most alignment representations are designed to facilitate knowledge extraction by human experts.
the similarity between  signatures is then easily computed from their corresponding binary feature  vectors.
we illustrate how organizing this information in a central database can create a practical public platform for any kind of exploitation of meta-knowledge, allowing effective reuse of previous experimentation and targeted analysis of the collected results.} } @inproceedings{hempstalk08:_one_class_class_by_combin, author = {
both stem from recent developments in the field of data stream classification.
{many studies in machine learning try to investigate what makes an algorithm succeed or fail on certain datasets.
the  experimental results show that these algorithms perform competitively with  previously published results for the datasets used, while often exhibiting  lower runtime than other tested systems.
yet, the information contained in these experiments might have uses beyond their original intent and, if properly stored, could be of great use to future research.
our results show that boosted decision stumps can  in some cases provide better classification accuracy than the 1-norm svm as a  base learner for miles.
{eibe  frank and mark hall}, title = {additive regression applied to a large-scale  collaborative filtering problem}, booktitle =
{proc 21set  australasian joint conference on artificial intelligence}, year = 2008, series  = {auckland, new zealand}, publisher = {springer}, pdf = { http://www.cs.waikato.ac.nz/~ml/publications/2008/hf08-domainsforocc.pdf},  abstract =
abstract = {multi-instance (mi)
in this method, the ref- erence distribution is used to  generate artificial data that is employed to form a second, artificial class.
alongside performing elaborate comparisons of algorithms, we also investigate the effects of algorithm parameters and data properties, and seek deeper insights into the behavior of learning algorithms by studying their learning curves and bias-variance profiles.}, publisher = {springer}, series = {hanoi, vietnam} } @inproceedings{read08:_multi_class_using_ensem_pruned_sets, author =
yet, when collecting all these past experiments in experiment databases, they can readily be reused for additional and possibly much broader investigation.
{random relational rules}, school = {department of computer science,  university of waikato}, year = 2008, http = {http://hdl.handle.net/10289/2562},
the results from experimental evaluation on a variety of multi-label datasets show that [e]ps can achieve better performance and train much faster than other multi-label methods.}, series = {pisa, italy}, publisher = {ieee computer society} } @inproceedings{bouckaert08, author =
in this paper, we propose a community-based approach for the analysis of learning algorithms, driven by sharing meta-data from previous experiments in a uniform way.
unfortunately, the literature does not provide consistent guidelines on how to apply a bias variance decomposition.
it is centred on the  concept of treating sets of labels as single labels.
all algorithms in this thesis are based on the generation of random  relational rules.
this thesis investigates the case  where each instance has a weight value determining the level of influence that  it has on its s class label.
this paper describes and evaluates two ways to make nns  efficient for datasets that are arbitrarily large in the number of instances  and dimensions.
{jonathan david miles}, title = {machine learning for adaptive computer game opponents}, school = {department of computer science, university of waikato}, year = 2008, abstract = {
to this end, a system for generating random relational rules is described, and algorithms using these rules are evaluated.
unfortunately, none of these solutions carry over particularly well to a data stream environment.
these algorithms  include direct classification, classification by propositionalisation,  clustering, semi-supervised learning and generating random forests.
this is also the case when attribute selection is performed in naive bayes and its semi-naive variant.} } @inproceedings{mutter08:_propos, author = {stefan mutter and bernhard pfahringer and geoffrey holmes}, title = {propositionalisation of multiple sequence alignments using probabilistic models},
previously,  researchers have assumed that a computationally expensive face alignment step  (in which the face image is transformed so that facial landmarks such as the  eyes, nose, chin, etc, are in uniform locations in the image) is required in  order to maximize the accuracy of predictions on new face images.
yet, when collecting all these past  experiments in experiment databases, they can readily be reused for additional  and possibly much broader investigation.
http://www.cs.waikato.ac.nz/~ml/publications/2008/miles.pdf}, abstract = {multiple-instance learning via embedded instance selection (miles) is a recently proposed multiple-instance (mi) classification al- gorithm that applies a single-instance base learner to a propositional- ized version of mi data.
based on this study, we recommend to use ten fold cross validation as sampling method and take 100 samples within each fold with a test set size of at least 2000.
school = {department of computer science, university of waikato}, year = 2008, http =
aft was tested on the cedar and gpds benchmark datasets, with  classification using either a manual or an automatic variant.
{bernhard pfahringer and  grant anderson}, title
this allows the classification process to inherently take into account correlations between labels.
mi learning has applications in areas such as drug activity prediction, fruit disease management and image classification.
when the number of dimensions is greater than two there are no known solutions that can guarantee a sublinear retrieval time.
in conjunction with the target class, this artificial class is the basis for a  standard two-class learning problem.
an existing approach known as miles is retroactively identified as an  algorithm that uses instance weights for mi learning, and is evaluated using a  variety of base learners on benchmark problems.
instead, our model attempts to discover intermediate representations  for each object class.
we  then compare this method with four approaches from the literature arriving at  eight final algorithm configurations for testing.
aft enhances how a simple image feature of a signature is converted to a binary feature vector by significantly improving its representation in relation to the training signatures.
this limits the effectiveness  of reinforcement learning because a large number of episodes are required  before performance becomes sufficient to match the opponent.}, http = { http://hdl.handle.net/10289/2779} } @phdthesis{anderson08:_random_relat_rules, author =
a variant, profile hidden markov models are a special case used in  bioinformatics to represent, for example, protein families.
{learning instance weights in multi-instance learning}, school = {department of computer science, university of waikato}, year = 2008, pdf = {http://hdl.handle.net/10289/2460}, abstract = {multi-instance (mi) learning is a variant of supervised machine learning, where each learning example contains a bag of instances instead of just a single feature vector.
for some datasets it significantly improves on both techniques.
randomization based on random relational rules can work both with and  without a class attribute and can therefore be applied simultaneously to both  the labeled and the unlabeled portion of the data present in semi-supervised  learning.
this way  we get a simple, extendable representation of multiple sequence alignments  which facilitates further analysis by machine learning algorithms.} } @inproceedings{pfahringer08:_exploit, author =
{springer}, pdf = { http://www.cs.waikato.ac.nz/~ml/publications/2008/hfw08-oneclassclassification.pdf }, abstract = {one-class classification has important applications such as outlier and novelty detection.
http = {http://hdl.handle.net/10289/1801}, series = {helsinki, finland},  publisher = {
{many studies in machine  learning try to investigate what makes an algorithm succeed or fail on certain  datasets.
{http://www.cs.waikato.ac.nz/~ml/publications/2008/mutternzcsrsc2008.pdf},  abstract =
all methods are tested using the hoeffding tree classification algorithm.
however, if known non-target classes are available at training time, it is also  possible to use standard multi-class or two-class classification, exploiting  the negative data to infer a description of the target class.
handling  numeric attributes in hoeffding trees}, booktitle = {proc 12th pacific-asia  conference on knowledge discovery and data mining}, publisher = {springer},  year = 2008, pages = {296-307}, http = { http://dx.doi.org/10.1007/978-3-540-68125-0_27}, series = {
{ieee}, http = {ttp://hdl.handle.net/10289/2174} } @inproceedings{mayo08:_improv, author = {michael mayo and edmond zhang},  title = {
booktitle = {new zealand computer science research student conference (nzcsrsc 2008)}, year = 2008, series = {christchurch, new zealand}, month = {april}, pages = {234-237}, pdf = {http://www.cs.waikato.ac.nz/~ml/publications/2008/mutternzcsrsc2008.pdf},
mining arbitrarily large  datasets using heuristic k-nearest neighbour search}, booktitle = {proc 21st  australasian joint conference on artificial intelligence}, year = 2008, series  = {auckland, new zealand}, publisher = {springer}, pages = {355-361}, http = { http://dx.doi.org/10.1007/978-3-540-89378-3_35}, abstract = {nearest neighbour  search (nns) is one of the top ten data mining algorithms.
we also compare the method to one-class classification using support vector machines.} } @inproceedings{hall08:_combin_naive_bayes_decis_tables, author =
learning is a variant of supervised machine learning, where each learning  example contains a bag of instances instead of just a single feature vector.
results show that the methods are competitive with nns in terms of  accuracy but significantly faster. } } @inproceedings{vanschoren08:_organ_machin_learn_infor, author = {joaquin  vanschoren and hendrik blockeel and bernhard pfahringer and geoffrey holmes},  title = {organizing the world's machine learning information}, booktitle =  {proc 3rd international symposium on leveraging applications of formal methods,  verification and validation}, year = 2008, pages = {693-708}, http = { http://dx.doi.org/10.1007/978-3-540-88479-8_50}, publisher = {springer}, series  = {porto sani, greece}, abstract = {all around the globe, thousands of learning  experiments are being executed on a daily basis, only to be discarded after  interpretation.
in this paper we investigate a range of methods for multi-class tree-based classification where the handling of numeric attributes takes place as the tree is constructed.
unfortunately, the literature does not provide consistent  guidelines on how to apply a bias variance decomposition.
this thesis investigates the use of machine learning techniques in computer games to create a computer player that adapts to its opponent's game-play.
{springer}, year = 2008, series = {osaka, japan}, abstract = {
in this paper we introduce a simple propositionalisation method for profile hidden markov models.
{discriminating against new classes: one-class versus multi-class classification}, booktitle = {proc 21set australasian joint conference on artificial intelligence}, year = 2008, series = {auckland, new zealand}, publisher = {springer}, pdf = { http://www.cs.waikato.ac.nz/~ml/publications/2008/hf08-domainsforocc.pdf},
reinforcement learning methods have the highest rate of improvement but the lowest initial performance.
{exploiting propositionalization based on random relational rules for semi-supervised learning}, booktitle = {proc 12th pacific-asia conference on knowledge discovery and data mining}, publisher = {springer}, year = 2008, series = {osaka, japan}, abstract = {
based on this study, we recommend to use  ten fold cross validation as sampling method and take 100 samples within each  fold with a test set size of at least 2000.
this paper introduces adaptive feature thresholding (aft) which is a novel method of person-dependent off-line signature verification.
adaptive feature thresholding for off-line signature  verification}, booktitle = {proc 23rd international conference image and vision  computing new zealand}, abstract = {
however, the original authors consider only one single-instance base learner for the algorithm --- the 1-norm svm.
based on the experimental results obtained, we then show under what conditions which group of techniques is likely to be preferable.
on the cedar  dataset we achieved a classification accuracy of 92% for manual and 90% for  automatic, while on the gpds dataset we achieved over 87% and 85% respectively.
in this paper, we hope to stimulate the development of such learning experiment repositories by providing a bird's-eye view of how they can be created and used in practice, bringing together existing approaches and new ideas.
{james foulds}, title =