a hierarchical structure having many short paths, i.e. a decision tree, is advantageous in speed but is notoriously bad at generalisation.a boosting classifier has been so successful owing to its fast computation and yet comparable accuracy to kernel methods, being a standard method in related fields over past decades.the classification speed is not just a matter of time-efficiency but is often crucial to achieve good accuracy, which is manifest in e.g. tracking problems.the flat structure ensures reasonably smooth decision regions for good generalisation, however, is not optimal in classification time.in this tutorial, we review boosting and random forest and present comparative studies with insightful discussions.boosting as a representative ensemble learning method, which aggregates simple weak learners, can be seen as a flat tree structure when each learner is a decision-stump.standard kernel machines e.g. support vector machine and gaussian process classifier are slow and methods for rapid classification have been pursued.it is also pertinent for online learning for adaptation and tracking.toshiba research europe ltd cambridge, uk bjorn.stenger[at]crl.toshiba.co.uk abstract many visual recognition tasks such as object tracking, detection and segmentation favour fast and yet accurate classification methods.tracking using online feature selection and a local generative model.j. shotton, m. johnson, r. cipolla, semantic texton forests for image categorization and segmentation.learning to track with multiple observers.aidia - adaptive interface for display interaction.segmentation and recognition using structure from motion point clouds.