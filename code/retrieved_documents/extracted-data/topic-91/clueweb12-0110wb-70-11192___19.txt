we show that the resulting ranker, compared to  ei- ther component technique, frequently significantly increases auc.
[18] propositionalisation of multiple sequence alignments using probabilistic models stefan mutter, bernhard pfahringer, and geoffrey holmes.
this thesis investigates the case where each instance has a weight value determining the level of influence that it has on its s class label.
[ bib | http ] for conventional machine learning classification algorithms handling numeric attributes is relatively straightforward.
propositionalisation does not need  such a measure and allows the use of any propositional learner including  kernel-based approaches.
inproc 3rd  international symposium on leveraging applications of formal methods,  verification and validation, porto sani, greece, pages 693-708.
[ bib ] thousands of machine learning research papers contain experimental comparisons that usually have been conducted with a single focus of interest, often losing detailed results after publication.
aft was tested on the cedar and gpds benchmark datasets, with classification using either a manual or an automatic variant.
[1] learning from the past with experiment databases joaquin  vanschoren, bernhard pfahringer, and geoffrey holmes.
inproc icml/colt/uai 2008 planning to learn workshop,  helsinki, finland.
[ bib | http ] all around the globe, thousands of learning experiments are being executed on a daily basis, only to be discarded after interpretation.
discriminating against  new classes: one-class versus multi-class classification.
florida artificial intelligence research society conference, miami, florida.
revisiting multiple-instance learning via  embedded instance selection.
our main finding is that multi-class and two-class classification becomes preferable to one-class classification when a sufficiently large number of non-target classes is available.
the method allows the use of phmms discriminatively in a classification task.
by combining pruned sets in an ensemble scheme (eps), new label sets  can be formed to adapt to irregular or complex data.
this is also the case  when attribute selection is performed in naive bayes and its semi-naive variant.
adaptive feature thresholding for off-line signature verification.
this is one of the main contributions of the paper.
although miles provides competitive performance when compared to other mi learners, we identify simpler propositionaliza- tion methods that require shorter training times while retaining miles' strong classification performance on the datasets we tested.
[20] handling numeric attributes in hoeffding trees bernhard pfahringer, geoffrey holmes, and richard kirkby.
[ bib | http ] a novel method of face gender classifier construction is proposed and evaluated.
an existing approach known as miles is retroactively identified as an algorithm that uses instance weights for mi learning, and is evaluated using a variety of base learners on benchmark problems.
experiments use three machine  learning techniques; static prediction models, continuous learning, and  reinforcement learning.
this thesis presents algorithms for learning from relational data that mitigate, to some extent, the complexity normally associated with such learning.
australasian joint conference on artificial intelligence,  auckland, new zealand, pages 355-361.
we draw parallels between how experiments are being curated in other  sciences, and consecutively discuss how both the empirical and theoretical  details of learning experiments can be expressed, organized and made  universally accessible.
instead, our model attempts to discover intermediate  representations for each object class.
[ bib | http ] this paper presents a new approach for the object categorization  problem.
the new algorithms are shown to achieve better root mean squared error rates  than existing approaches on artificial data generated according to the  underlying assumptions.
experiment databases: creating a new platform for meta-learning research.
there are three basic methods that have been applied in most approaches to the netflix problem so far: stand-alone neighborhood-based methods, latent factor models based on singular-value decomposition, and ensembles consisting of variations of these techniques.
however, if known non-target classes are available at training time, it is also possible to use standard multi-class or two-class classification, exploiting the negative data to infer a description of the target class.
australasian joint  conference on artificial intelligence, auckland, new zealand.
both stem from recent developments  in the field of data stream classification.
[ bib | www: ] this paper introduces adaptive feature thresholding (aft) which is a novel method of person-dependent off-line signature verification.
timation techniques or by adapting a standard classification algorithm to the  problem of carving out a decision boundary that describes the location of the  target data.
[12] pattern discovery for object categorization edmond zhang and michael mayo.
alongside performing elaborate comparisons of algorithms, we also investigate  the effects of algorithm parameters and data properties, and seek deeper  insights into the behavior of learning algorithms by studying their learning  curves and bias-variance profiles.
many applications require the ability to identify data that is  anomalous with respect to a target group of observations, in the sense of  belonging to a new, previously unseen 'attacker' class.
in this method, the ref- erence distribution is used to generate artificial data that is employed to form a second, artificial class.
improving face gender classification by adding deliberately misaligned faces to the training data.
[20] handling numeric attributes in hoeffding trees bernhard pfahringer,  geoffrey holmes, and richard kirkby.
the methods are evaluated in terms of their accuracy and the time taken to find the neighbours.
bias variance decomposition for classifiers is a useful tool in  understanding classifier behavior.
static models show the highest initial performance but are not able to beat a simple opponent.
all algorithms in this thesis are based on the generation of random relational rules.
in conjunction with the target class, this artificial class is the basis for a standard two-class learning problem.
we present an  empirical study investigating the efficacy of alternative base learners for  miles, and compare miles to other mi algorithms.
we, however, argue that this step is not necessary, and that  machine learning classifiers can be made robust to face misalignments by  automatically expanding the training data with examples of faces that have been  deliberately misaligned (for example, translated or rotated).
this  indicates a need for algorithms that can operate efficiently on relational data  and exploit the larger body of work produced in the area of single-table  techniques.
we also compare the method to one-class classification using support vector machines.
this is also the case when attribute selection is performed in naive bayes and its semi-naive variant.
machine learning for adaptive computer game  opponents.
[ bib | http ] in the field of machine learning, methods for learning from  single-table data have received much more attention than those for learning  from multi-table, or relational data, which are generally more computationally  complex.
pattern discovery for object categorization.
australasian joint conference on artificial intelligence, auckland, new zealand.
[5] additive regression applied to a large-scale collaborative filtering  problem eibe frank and mark hall.
[ bib | http ] in this paper we investigate an approach to semi-supervised learning based on randomized propositionalization, which allows for applying standard propositional classification algorithms like support vector machines to multi-relational data.
further  applications of random rules are investigated.
to this end, we extend an  existing approximation approach, based on simple gaussian approximation.
only  if the learning algorithm is stable, fewer samples, a smaller test set size or  lower number of folds may be justified.
the results show that the inclusion of spatial relationships leads to a measurable increase in performance for two of the most challenging datasets.
[ bib | http ] nearest neighbour search (nns) is one of the top ten data mining  algorithms.
this thesis investigates the case where each instance has a weight value  determining the level of influence that it has on its s class label.
inproc 23rd international conference image and vision computing new zealand, christchurch, new zealand, pages 1-6.
in this paper, we make use of such a database to answer various interesting research questions about learning algorithms and to verify a number of recent studies.
propositionalisation of multiple sequence alignments using probabilistic models.
australasian joint conference on  artificial intelligence, auckland, new zealand.
we draw parallels between how experiments are being curated in other sciences, and consecutively discuss how both the empirical and theoretical details of learning experiments can be expressed, organized and made universally accessible.
the challenge is to accurately estimate these weights in order to make predictions at the bag level.
[ bib | www: ] this paper introduces adaptive feature thresholding (aft) which  is a novel method of person-dependent off-line signature verification.
[13] machine learning for adaptive computer game opponents jonathan david miles.
the thesis also develops a novel algorithm for building random forests by making efficient use of random rules to generate trees and leaves in parallel.
[ bib | http ] this thesis investigates the use of machine learning techniques in computer games to create a computer player that adapts to its opponent's game-play.
this paper examines the various parameters and variants of empirical bias variance decompositions through an extensive simulation study.
inproc 21set australasian joint conference on artificial intelligence, auckland, new zealand.
the methods are best described as heuristic as they are neither exact nor approximate.
experiment databases: creating a new platform for meta-learning  research.
inproc 12th pacific-asia conference on knowledge discovery and data mining, osaka, japan.
however, the original authors consider only one single-instance base learner for the algorithm - the 1-norm svm.
naive bayes and  decision tables can both be trained effi- ciently, and the same holds true for  the combined semi-naive model.
this paper describes and evaluates two ways to make nns efficient for datasets that are arbitrarily large in the number of instances and dimensions.
[ bib  |.pdf ] multiple-instance learning via embedded instance selection  (miles) is a recently proposed multiple-instance (mi) classification
one possible approach  to this kind of verification problem is one-class classification, learning a  description of the target class concerned based solely on data from this class.
this way we get a simple, extendable representation of  multiple sequence alignments which facilitates further analysis by machine  learning algorithms.
this paper describes and evaluates two  ways to make nns efficient for datasets that are arbitrarily large in the  number of instances and dimensions.
the much-publicized netflix competition has put the spot- light on the application domain of collaborative filtering and has sparked interest in machine learning algorithms that can be applied to this sort of problem.
additive regression applied to a  large-scale collaborative filtering problem.
[10] adaptive feature thresholding for off-line signature verification rober larkins and michael mayo.
[ bib | .pdf ] hidden markov models are a widely used generative model for analysing sequence data.
inproc 8th ieee international conference on  data mining, pisa, italy, pages 995-1000.
this includes first confirming that machine learning algorithms can be integrated into a modern computer game without have a detrimental effect on game performance, then experimenting with different machine learning techniques to maximize the computer player's performance.
inproc 23rd international conference image and vision computing new zealand, christchurch, new zealand, pages 1-5.
inproc 23rd international conference image and vision computing new  zealand, christchurch, new zealand, pages 1-5.
exploiting propositionalization based on random relational rules for semi-supervised learning.
the challenge is to accurately estimate these weights in  order to make predictions at the bag level.
propositionalisation of profile hidden markov models for biological sequence  analysis.
in this  paper, we make use of such a database to answer various interesting research  questions about learning algorithms and to verify a number of recent studies.
university of porto, 2008.
we show empirically that using propositionalisation  leads to higher accuracies in comparison with phmms on benchmark datasets.
aft  enhances how a simple image feature of a signature is converted to a binary  feature vector by significantly improving its representation in relation to the  training signatures.
innew zealand computer science research student conference (nzcsrsc  2008), christchurch, new zealand, pages 234-237, april 2008.
it is commonly tackled using density es-
we investigate a simple semi-naive bayesian ranking method that  combines naive bayes with induction of decision tables.
the basic idea we present in this paper is to use the structure of a profile hidden markov model for propositionalisation.
[15] experiment databases: creating a new platform for meta-learning research joaquin vanschoren, hendrik blockeel, bernhard pfahringer, and geoffrey  holmes.
our results show that boosted decision stumps can in some cases provide better classification accuracy than the 1-norm svm as a base learner for miles.
this limits the effectiveness of reinforcement learning because a large number of episodes are required before performance becomes sufficient to match the opponent.
solutions for data streams have been proposed by several authors but as yet none have been compared empirically.
new algorithms for learning instance weights for mi learning are also proposed and rigorously evaluated on both artificial and real-world datasets.
[ bib |  http ] a novel method of face gender classifier construction is proposed  and evaluated.
in  this paper we introduce a simple propositionalisation method for profile hidden  markov models.
an empirical investigation compares  semi-supervised propositionalization to standard propositionalization using  just the labeled data portion, as well as to a variant that also just uses the  labeled data portion but includes the label information in an attempt to  improve the resulting propositionalization.
unsupervised and  supervised solutions exist that either segment the data into pre-defined bins  or sort the data and search for the best split points.
our model is based on the successful `bag of words' approach.
[ bib | http ] for conventional machine learning classification algorithms  handling numeric attributes is relatively straightforward.
inproc 21set australasian  joint conference on artificial intelligence, auckland, new zealand.
an existing approach known as miles  is retroactively identified as an algorithm that uses instance weights for mi  learning, and is evaluated using a variety of base learners on benchmark  problems.
our results show that boosted  decision stumps can in some cases provide better classification accuracy than  the 1-norm svm as a base learner for miles.
however, unlike the original model, image features (keypoints) are not seen as independent and orderless.
[bib | http ] this paper presents a pruned sets method (ps) for multi-label classification.
this thesis presents algorithms for learning from relational data  that mitigate, to some extent, the complexity normally associated with such  learning.
the much-publicized netflix competition has put the spot- light  on the application domain of collaborative filtering and has sparked interest  in machine learning algorithms that can be applied to this sort of problem.
solutions for data streams have been proposed by several authors but as yet  none have been compared empirically.
in this paper we assume that this scenario holds and inves- tigate under what conditions multi-class and two-class naive bayes clas- sifiers are preferable to the corresponding one-class model when the aim is to identify examples from a new 'attacker' class.
propositionalisation allows  single-table algorithms for classification and clustering to be applied to the  resulting data, reducing the amount of relational processing required.
[8] mining arbitrarily large datasets using heuristic k-nearest neighbour  search xing wu, geoffrey holmes, and bernhard pfahringer.
to this end we first identify a way of performing a fair  comparison between the techniques concerned and present an adaptation of  standard cross-validation.
bias variance decomposition for classifiers is a useful tool in understanding classifier behavior.
2008 [1] learning from the past with experiment databases joaquin vanschoren, bernhard pfahringer, and geoffrey holmes.
this demonstrates that sufficient information for classification and clustering is retained in the rule generation process and that learning with random rules is efficient.
experimental results also demonstrate that the new  algorithms are competitive with existing approaches on real-world problems.
australasian joint conference on artificial intelligence, auckland, new zealand, pages 355-361.
it is centred on the concept of treating sets of labels as single labels.
timation techniques or by adapting a standard classification algorithm to the problem of carving out a decision boundary that describes the location of the target data.
using a benchmark face gender classification dataset recently proposed in the literature, we obtain a state-of-the-art accuracy of 92.5%, thus validating our approach.
further  results show that techniques for utilising additional unlabeled training data  improve accuracy of classification in the semi-supervised setting.
they offer the  advantage to provide sound, probabilistic scores.
master's thesis,  department of computer science, university of waikato, 2008.
we present an empirical study investigating the efficacy of alternative base learners for miles, and compare miles to other mi algorithms.
propositionalisation does not need such a measure and allows the use of any propositional learner including kernel-based approaches.
practical bias variance decomposition.
[21] learning instance weights in multi-instance learning james foulds.
on the cedar dataset we achieved a classification accuracy  of 92% for manual and 90% for automatic, while on the gpds dataset we achieved  over 87% and 85% respectively.
this paper examines the various parameters and variants of empirical bias  variance decompositions through an extensive simulation study.
yet, when  collecting all these past experiments in experiment databases, they can readily  be reused for additional and possibly much broader investigation.
[11] improving face gender classification by adding deliberately misaligned  faces to the training data michael mayo and edmond zhang.
previously, kernel approaches have been proposed to generate a discriminative description for an hmm, but require the explicit definition of a similarity measure for hmms.
however, a significant amount of the world's data is relational.
an empirical investigation compares semi-supervised propositionalization to standard propositionalization using just the labeled data portion, as well as to a variant that also just uses the labeled data portion but includes the label information in an attempt to improve the resulting propositionalization.
experiments use three machine learning techniques; static prediction models, continuous learning, and reinforcement learning.
this indicates a need for algorithms that can operate efficiently on relational data and exploit the larger body of work produced in the area of single-table techniques.
to test our  hypothesis, we evaluate this automatic training dataset expansion method with  two types of image classifier, the first based on weak features such as local  binary pattern histograms, and the second based on sift keypoints.
ieee computer society, 2008.
this limits the effectiveness of reinforcement  learning because a large number of episodes are required before performance  becomes sufficient to match the opponent.
inproc 8th ieee international conference on data mining, pisa, italy, pages 995-1000.
[7] propositionalisation of profile hidden markov models for biological  sequence analysis stefan mutter, bernhard pfahringer, and geoffrey holmes.
additionally statistical models like profile hidden markov models are used as representations.
a variant, profile hidden markov models are a special case used in bioinformatics to represent, for example, protein families.
by pruning these sets, ps focuses only on the most important correlations, which reduces complexity and improves accuracy.
reinforcement learning methods have the highest rate of improvement but the  lowest initial performance.
us- ing uci datasets, and data from a typist recognition problem, we show that the combined model, consisting of both a density estimator and a class probability estimator, can improve on using either component tech- nique alone when used for one-class classification.
continuous learning is able to improve  the performance achieved with static models but the rate of improvement drops  over time and the computer player is still unable to beat the opponent.
inproc 12th european conference on principles and practice of knowledge  discovery in databases and 19th european conference on machine learning,  antwerp, belgium.
however,  unlike the original model, image features (keypoints) are not seen as  independent and orderless.
the assumption is that random rules enable efficient and  effective relational learning, and this thesis presents evidence that this is  indeed the case.
alongside performing elaborate comparisons of algorithms, we also investigate the effects of algorithm parameters and data properties, and seek deeper insights into the behavior of learning algorithms by studying their learning curves and bias-variance profiles.
unsupervised and supervised solutions exist that either segment the data into pre-defined bins or sort the data and search for the best split points.
[ bib |  .pdf ] multiple sequence alignments play a central role in  bioinformatics.
further results show that techniques for utilising additional unlabeled training data improve accuracy of classification in the semi-supervised setting.
surprisingly, the experimental comparison shows that the most approximate  methods produce the most accurate trees by allowing for faster tree growth.
combining naive bayes and decision tables.
aft was tested on the cedar  and gpds benchmark datasets, with classification using either a manual or an  automatic variant.
[ bib |.pdf ] multiple-instance learning via embedded instance selection (miles) is a recently proposed multiple-instance (mi) classification
unfortunately, none of  these solutions carry over particularly well to a data stream environment.
mining arbitrarily large datasets using heuristic k-nearest neighbour search.
inproc 12th european conference on principles and practice of knowledge discovery in databases and 19th european conference on machine learning, antwerp, belgium.
the assumption is that random rules enable efficient and effective relational learning, and this thesis presents evidence that this is indeed the case.
randomization based on random relational rules can  work both with and without a class attribute and can therefore be applied  simultaneously to both the labeled and the unlabeled portion of the data  present in semi-supervised learning.
we show that the resulting ranker, compared to ei- ther component technique, frequently significantly increases auc.
mi learning has applications in areas such as  drug activity prediction, fruit disease management and image classification.
the  demanding nature of the netflix data has lead to some interesting and ingenious  modifications to standard learning methods in the name of efficiency and speed.
for both datasets aft is less complex and requires fewer images features than the existing state of the art methods, while achieving competitive results.
[2] multi-label classification using ensembles of pruned sets jesse  read, bernhard pfahringer, and geoffrey holmes.
mining  arbitrarily large datasets using heuristic k-nearest neighbour search.
instead, our model attempts to discover intermediate representations for each object class.
innew zealand computer science research student conference (nzcsrsc 2008), christchurch, new zealand, pages 234-237, april 2008.
when the  number of dimensions is greater than two there are no known solutions that can  guarantee a sublinear retrieval time.
machine learning for adaptive computer game opponents.
[14] grant anderson.
[17] combining naive bayes and decision tables mark hall and eibe frank.
the demanding nature of the netflix data has lead to some interesting and ingenious modifications to standard learning methods in the name of efficiency and speed.
it is simple and effective but has a time complexity that is the product of the number of instances and the number of dimensions.
to this end, we extend an existing approximation approach, based on simple gaussian approximation.
this is a more general assumption than most existing approaches use, and thus is more widely applicable.
[16] one-class classification by combining density and class probability  estimation kathryn hempstalk, eibe frank, and ian h. witten.
[18] propositionalisation of multiple sequence alignments using probabilistic  models stefan mutter, bernhard pfahringer, and geoffrey holmes.
the solutions cover a range  of options from perfectly accurate and memory intensive to highly approximate.
previously, researchers have assumed that a computationally expensive face alignment step (in which the face image is transformed so that facial landmarks such as the eyes, nose, chin, etc, are in uniform locations in the image) is required in order to maximize the accuracy of predictions on new face images.
to test our hypothesis, we evaluate this automatic training dataset expansion method with two types of image classifier, the first based on weak features such as local binary pattern histograms, and the second based on sift keypoints.
gorithm that applies a single-instance base learner to a propositional- ized version of mi data.
for some  datasets it significantly improves on both techniques.
we show empirically that using propositionalisation leads to higher accuracies in comparison with phmms on benchmark datasets.
these algorithms include direct classification, classification by propositionalisation, clustering, semi-supervised learning and generating random forests.
in this paper we  assume that this scenario holds and inves- tigate under what conditions  multi-class and two-class naive bayes clas- sifiers are preferable to the  corresponding one-class model when the aim is to identify examples from a new  'attacker' class.
inproc 12th pacific-asia conference on knowledge  discovery and data mining, osaka, japan.
in this paper we investigate the application of forward stage-wise additive modeling to the netflix problem, using two regression schemes as base learners: ensembles of weighted simple linear regressors and k-means clustering-the latter being interpreted as a tool for multi- variate regression in this context.
master's thesis, department of computer science, university of  waikato, 2008.
in this paper we investigate a simple method for one-class classification that combines the application of a density es- timator, used to form a reference distribution, with the induction of a standard model for class probability estimation.
on the cedar dataset we achieved a classification accuracy of 92% for manual and 90% for automatic, while on the gpds dataset we achieved over 87% and 85% respectively.
we investigate a simple semi-naive bayesian ranking method that combines naive bayes with induction of decision tables.
[ bib | http ] this thesis investigates the use of machine learning techniques  in computer games to create a computer player that adapts to its opponent's  game-play.
this is a  more general assumption than most existing approaches use, and thus is more  widely applicable.
the solutions cover a range of options from perfectly accurate and memory intensive to highly approximate.
master's thesis, department of computer science, university of waikato, 2008.
by pruning these sets, ps focuses only on  the most important correlations, which reduces complexity and improves  accuracy.
[12] pattern discovery for object categorization edmond zhang and  michael mayo.
the results from experimental evaluation on a variety of multi-label datasets show that [e]ps can achieve better performance and train much faster than other multi-label methods.
we explain how the density function of the reference distribution can be combined with the class probability estimates obtained in this way to form an adjusted estimate of the density function of the target class.
random relational rules .
[13] machine learning for adaptive computer game opponents jonathan david miles.
however, the original authors consider only one  single-instance base learner for the algorithm - the 1-norm svm.
inproc 23rd international conference image and vision computing new zealand, christchurch, new zealand, pages 1 - 6.
yet, the  information contained in these experiments might have uses beyond their  original intent and, if properly stored, could be of great use to future  research.
[ bib | .pdf ] one-class classification has important applications such as  outlier and novelty detection.
the methods are evaluated in terms of their accuracy and the  time taken to find the neighbours.
randomization based on random relational rules can work both with and without a class attribute and can therefore be applied simultaneously to both the labeled and the unlabeled portion of the data present in semi-supervised learning.
to this end we first identify a way of performing a fair comparison between the techniques concerned and present an adaptation of standard cross-validation.
based on this  study, we recommend to use ten fold cross validation as sampling method and  take 100 samples within each fold with a test set size of at least 2000.
a variant, profile hidden markov models are a special  case used in bioinformatics to represent, for example, protein families.
handling numeric attributes in hoeffding  trees.
naive bayes and decision tables can both be trained effi- ciently, and the same holds true for the combined semi-naive model.
inproc 10th pacific rim international conference  on artificial intelligence, hanoi, vietnam, pages 485-496.
in this paper we investigate a simple method for one-class  classification that combines the application of a density es- timator, used to  form a reference distribution, with the induction of a standard model for class  probability estimation.
preliminary experimental results indicate that propositionalization generated on the full dataset, i.e. the semi- supervised approach, tends to outperform the other two more standard approaches.
inproc 21set  australasian joint conference on artificial intelligence, auckland, new  zealand.
to this end, a system for generating random relational rules  is described, and algorithms using these rules are evaluated.
many applications require the ability to identify data that is anomalous with respect to a target group of observations, in the sense of belonging to a new, previously unseen 'attacker' class.
organizing the world's machine learning information.
[6] discriminating against new classes: one-class versus multi-class  classification kathryn hempstalk and eibe frank.
using a  benchmark face gender classification dataset recently proposed in the  literature, we obtain a state-of-the-art accuracy of 92.5%, thus validating our  approach.
[6] discriminating against new classes: one-class versus multi-class classification kathryn hempstalk and eibe frank.
previously, researchers have assumed that a computationally  expensive face alignment step (in which the face image is transformed so that  facial landmarks such as the eyes, nose, chin, etc, are in uniform locations in  the image) is required in order to maximize the accuracy of predictions on new  face images.
the first uses hoeffding trees, an extension of decision trees to streams and the second is a direct stream extension of nns.
continuous learning is able to improve the performance achieved with static models but the rate of improvement drops over time and the computer player is still unable to beat the opponent.
gorithm that applies a single-instance base learner to a propositional- ized  version of mi data.
[2] multi-label classification using ensembles of pruned sets jesse read, bernhard pfahringer, and geoffrey holmes.
they offer the advantage to provide sound, probabilistic scores.
adaptive feature thresholding for off-line  signature verification.
the similarity between signatures is then easily computed  from their corresponding binary feature vectors.
this demonstrates that sufficient  information for classification and clustering is retained in the rule  generation process and that learning with random rules is efficient.
[9] organizing the world's machine learning information joaquin vanschoren, hendrik blockeel, bernhard pfahringer, and geoffrey holmes.
the first uses hoeffding trees, an  extension of decision trees to streams and the second is a direct stream  extension of nns.
preliminary experimental results  indicate that propositionalization generated on the full dataset, i.e. the  semi- supervised approach, tends to outperform the other two more standard  approaches.
the new algorithms are shown to achieve better root mean squared error rates than existing approaches on artificial data generated according to the underlying assumptions.
us- ing uci datasets, and data from a typist recognition  problem, we show that the combined model, consisting of both a density  estimator and a class probability estimator, can improve on using either  component tech- nique alone when used for one-class classification.
[ bib | http ] nearest neighbour search (nns) is one of the top ten data mining algorithms.
[3] practical bias variance decomposition remco r. bouckaert.
one possible approach to this kind of verification problem is one-class classification, learning a description of the target class concerned based solely on data from this class.
[15] experiment databases: creating a new platform for meta-learning research joaquin vanschoren, hendrik blockeel, bernhard pfahringer, and geoffrey holmes.
[16] one-class classification by combining density and class probability estimation kathryn hempstalk, eibe frank, and ian h. witten.
finally, we discuss a range of possible services such a resource can offer, either used directly or integrated into data mining tools.
the experimental results show that these algorithms perform competitively with previously published results for the datasets used, while often exhibiting lower runtime than other tested systems.
surprisingly, the experimental comparison shows that the most approximate methods produce the most accurate trees by allowing for faster tree growth.
based on the experimental results obtained, we then show under what conditions  which group of techniques is likely to be preferable.
results show that the methods are  competitive with nns in terms of accuracy but significantly faster.
[ bib | .pdf ] hidden markov models are a widely used generative model for  analysing sequence data.
by combining pruned sets in an ensemble scheme (eps), new label sets can be formed to adapt to irregular or complex data.
[ bib ] thousands of machine learning research papers contain  experimental comparisons that usually have been conducted with a single focus  of interest, often losing detailed results after publication.
we explain how the density function of the  reference distribution can be combined with the class probability estimates  obtained in this way to form an adjusted estimate of the density function of  the target class.
[4] revisiting multiple-instance learning via embedded instance selection james foulds and eibe frank.
improving face  gender classification by adding deliberately misaligned faces to the training  data.
results show that the methods are competitive with nns in terms of accuracy but significantly faster.
multiple sequence alignments play a central role in bioinformatics.
revisiting multiple-instance learning via embedded instance selection.
finally, we discuss a range of possible services such a  resource can offer, either used directly or integrated into data mining tools.
this way we get a simple, extendable representation of multiple sequence alignments which facilitates further analysis by machine learning algorithms.
our main finding is that  multi-class and two-class classification becomes preferable to one-class  classification when a sufficiently large number of non-target classes is  available.
inproc 23rd international conference image and  vision computing new zealand, christchurch, new zealand, pages 1-6.
propositionalisation allows single-table algorithms for classification and clustering to be applied to the resulting data, reducing the amount of relational processing required.
[ bib | http ] multi-instance (mi) learning is a variant of supervised machine  learning, where each learning example contains a bag of instances instead of  just a single feature vector.
the similarity between signatures is then easily computed from their corresponding binary feature vectors.
this approach works by partitioning the image into smaller regions then computing the spatial relationships between all of the informative image keypoints in the region.
the basic idea we present in  this paper is to use the structure of a profile hidden markov model for  propositionalisation.
in this paper we investigate a range of  methods for multi-class tree-based classification where the handling of numeric  attributes takes place as the tree is constructed.
[8] mining arbitrarily large datasets using heuristic k-nearest neighbour search xing wu, geoffrey holmes, and bernhard pfahringer.
[5] additive regression applied to a large-scale collaborative filtering problem eibe frank and mark hall.
handling numeric attributes in hoeffding trees.
we then compare this method with four approaches from the literature arriving at eight final algorithm configurations for testing.
[ bib | http ] all around the globe, thousands of learning experiments are being  executed on a daily basis, only to be discarded after interpretation.
we, however, argue that this step is not necessary, and that machine learning classifiers can be made robust to face misalignments by automatically expanding the training data with examples of faces that have been deliberately misaligned (for example, translated or rotated).
further applications of random rules are investigated.
multi-label classification  using ensembles of pruned sets.
[bib | http ] this paper presents a pruned sets method (ps) for multi-label  classification.
most alignment representations are designed to facilitate knowledge extraction by human experts.
additive regression applied to a large-scale collaborative filtering problem.
[19] exploiting propositionalization based on random relational rules for  semi-supervised learning bernhard pfahringer and grant anderson.
both stem from recent developments in the field of data stream classification.
the  experimental results show that these algorithms perform competitively with  previously published results for the datasets used, while often exhibiting  lower runtime than other tested systems.
yet, the information contained in these experiments might have uses beyond their original intent and, if properly stored, could be of great use to future research.
the methods are best described as heuristic  as they are neither exact nor approximate.
it is simple and effective but has a time complexity that is the  product of the number of instances and the number of dimensions.
in this method, the ref- erence distribution is used to  generate artificial data that is employed to form a second, artificial class.
[9] organizing the world's machine learning information joaquin  vanschoren, hendrik blockeel, bernhard pfahringer, and geoffrey holmes.
[7] propositionalisation of profile hidden markov models for biological sequence analysis stefan mutter, bernhard pfahringer, and geoffrey holmes.
yet, when collecting all these past experiments in experiment databases, they can readily be reused for additional and possibly much broader investigation.
the results show that the  inclusion of spatial relationships leads to a measurable increase in  performance for two of the most challenging datasets.
inproc icml/colt/uai 2008 planning to learn workshop, helsinki, finland.
there are three basic methods that have been applied in most approaches to the  netflix problem so far: stand-alone neighborhood-based methods, latent factor  models based on singular-value decomposition, and ensembles consisting of  variations of these techniques.
[ bib | http  ] in this paper we investigate an approach to semi-supervised  learning based on randomized propositionalization, which allows for applying  standard propositional classification algorithms like support vector machines  to multi-relational data.
[3] practical bias variance decomposition remco r. bouckaert.
experimental results also demonstrate that the new algorithms are competitive with existing approaches on real-world problems.
for both datasets aft is less complex and  requires fewer images features than the existing state of the art methods,  while achieving competitive results.
unfortunately, the literature does not provide consistent guidelines on how to apply a bias variance decomposition.
[ bib | http ] multi-instance (mi) learning is a variant of supervised machine learning, where each learning example contains a bag of instances instead of just a single feature vector.
phd thesis, department of computer science, university of waikato, 2008.
one-class classification by combining density and class probability estimation.
all algorithms in this thesis are based on the generation of random  relational rules.
learning from the past with experiment databases.
australasian joint conference on artificial  intelligence, auckland, new zealand.
[11] improving face gender classification by adding deliberately misaligned faces to the training data michael mayo and edmond zhang.
the thesis  also develops a novel algorithm for building random forests by making efficient  use of random rules to generate trees and leaves in parallel.
florida artificial  intelligence research society conference, miami, florida.
inproc 12th pacific-asia conference on knowledge discovery and data  mining, osaka, japan, pages 296-307.
to this end, a system for generating random relational rules is described, and algorithms using these rules are evaluated.
this allows the classification process to inherently take into  account correlations between labels.
propositionalisation of profile hidden markov models for biological sequence analysis.
unfortunately, none of these solutions carry over particularly well to a data stream environment.
only if the learning algorithm is stable, fewer samples, a smaller test set size or lower number of folds may be justified.
exploiting propositionalization based on random relational rules for  semi-supervised learning.
the results from  experimental evaluation on a variety of multi-label datasets show that [e]ps  can achieve better performance and train much faster than other multi-label  methods.
these algorithms  include direct classification, classification by propositionalisation,  clustering, semi-supervised learning and generating random forests.
inproc 10th pacific rim international conference on artificial intelligence, hanoi, vietnam, pages 485-496.
experimental results show that our methods produce competitive results.
based on this study, we recommend to use ten fold cross validation as sampling method and take 100 samples within each fold with a test set size of at least 2000.
propositionalisation of multiple sequence alignments using probabilistic  models.
inproc 3rd international symposium on leveraging applications of formal methods, verification and validation, porto sani, greece, pages 693-708.
this allows the classification process to inherently take into account correlations between labels.
learning from the past  with experiment databases.
mi learning has applications in areas such as drug activity prediction, fruit disease management and image classification.
when the number of dimensions is greater than two there are no known solutions that can guarantee a sublinear retrieval time.
in conjunction with the target class, this artificial class is the basis for a  standard two-class learning problem.
discriminating against new classes: one-class versus multi-class classification.
[14] random relational rules grant anderson.
[ bib | .pdf ] one-class classification has important applications such as outlier and novelty detection.
the method allows the use of phmms discriminatively in a  classification task.
we  then compare this method with four approaches from the literature arriving at  eight final algorithm configurations for testing.
aft enhances how a simple image feature of a signature is converted to a binary feature vector by significantly improving its representation in relation to the training signatures.
this approach works by partitioning the  image into smaller regions then computing the spatial relationships between all  of the informative image keypoints in the region.
we also  compare the method to one-class classification using support vector machines.
for some datasets it significantly improves on both techniques.
multi-label classification using ensembles of pruned sets.
experimental results show that our  methods produce competitive results.
although miles provides competitive  performance when compared to other mi learners, we identify simpler  propositionaliza- tion methods that require shorter training times while  retaining miles' strong classification performance on the datasets we tested.
[19] exploiting propositionalization based on random relational rules for semi-supervised learning bernhard pfahringer and grant anderson.
this includes first confirming that machine learning algorithms can  be integrated into a modern computer game without have a detrimental effect on  game performance, then experimenting with different machine learning techniques  to maximize the computer player's performance.
in this paper, we hope to stimulate the development of such learning  experiment repositories by providing a bird's-eye view of how they can be  created and used in practice, bringing together existing approaches and new  ideas.
all methods are tested using the hoeffding tree classification algorithm.
inproc 23rd  international conference image and vision computing new zealand,  christchurch, new zealand, pages 1 - 6.
however, if known non-target classes are available at training time, it is also  possible to use standard multi-class or two-class classification, exploiting  the negative data to infer a description of the target class.
in this paper we investigate the application of  forward stage-wise additive modeling to the netflix problem, using two  regression schemes as base learners: ensembles of weighted simple linear  regressors and k-means clustering-the latter being interpreted as a tool for  multi- variate regression in this context.
static models show the highest initial performance but  are not able to beat a simple opponent.
[ bib | http ] in the field of machine learning, methods for learning from single-table data have received much more attention than those for learning from multi-table, or relational data, which are generally more computationally complex.
it is centred on the concept of treating sets of labels as  single labels.
in this paper we investigate a range of methods for multi-class tree-based classification where the handling of numeric attributes takes place as the tree is constructed.
new algorithms for learning instance weights for mi learning are also  proposed and rigorously evaluated on both artificial and real-world datasets.
in this paper we introduce a simple propositionalisation method for profile hidden markov models.
reinforcement learning methods have the highest rate of improvement but the lowest initial performance.
most alignment representations are designed to facilitate  knowledge extraction by human experts.
additionally statistical models like  profile hidden markov models are used as representations.
learning instance weights in multi-instance learning.
[ bib | http ] this paper presents a new approach for the object categorization problem.
previously, kernel approaches have been proposed to  generate a discriminative description for an hmm, but require the explicit  definition of a similarity measure for hmms.
based on the experimental results obtained, we then show under what conditions which group of techniques is likely to be preferable.
inproc 12th pacific-asia conference on knowledge discovery and data mining, osaka, japan, pages 296-307.
unfortunately, the literature does not  provide consistent guidelines on how to apply a bias variance decomposition.
in this paper, we hope to stimulate the development of such learning experiment repositories by providing a bird's-eye view of how they can be created and used in practice, bringing together existing approaches and new ideas.