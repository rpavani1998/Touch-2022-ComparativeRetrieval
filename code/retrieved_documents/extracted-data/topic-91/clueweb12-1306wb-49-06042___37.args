while most of the previous studies extracted features which are based onbyte n-grams[12,13], in this study, we use opcode n-gram patterns, generated by disassembling the inspected executable files, to represent the files.
secondly, it is not clear what is the required period of time needed to observe the appearance of the malicious activity for each malware.
thus, we ran all the product combinations of five training sets and five test-sets for a total of 25 runs for each classifier.
the comparisons show that for all classifiers, excluding the nb and bnb, the best averaged setting yields similar performance.
the ann performance was generally low and dropped significantly for 5%, 15% and 50% mfp in the training set.
this is, however, different from our goal in which we attempt to classify unknown suspicious files as malicious or benign in order to detect new malware.
in such cases the classifier tends to misclassify the instances of the less represented classes.
anti-virus vendors are facing huge quantities (thousands) of suspicious files every day[2].
thus, having a relatively high false-positive is reasonable in order to decrease the probability of missing an unknown malicious file.
a total of 67 malware executables were compared with the aggregate statistics of 20 non-malicious samples.
publisher full text moskovitch r, elovici y, rokach l: detection of unknown computer worms based on behavioral classification of the host.
in the second experiment, we investigated the relationship between the malicious file percentage (mfp) in the test-set, which represents real-life scenario, and in the training set, which is used for training the classifier.
based on the reported experiments and results, we suggest that when setting up a classifier for real-life purposes, one should first use the opcode representation and, if the disassemble of the file is not feasible, use the byte representation[12], which appears to be less accurate.
3.2 dataset creation we created a dataset of malicious and benign executables for the windows operating system, the system most commonly used and attacked today.
by processing these vectors, the learning algorithm trains a classifier.
- top 1,800 over all n-gram sizes tf representation, 300 features selected by the gr measure - denoted by [top1800all;tf;top300;gr].
in this set, all opcode n-grams, of all sizes, were sorted according to their df value.
we created five levels of malicious files percentage (mfp) in the training set (5, 10, 15, 30, and 50%).
[17] also used byte n-grams representation, however the vector ofn-gram features was binary, presenting the presence or absence of a feature in the file and ignoring the frequency of feature appearances (in the file).
it is shown that all classifiers, excluding ann, had a similar trend and perform better when using mfp of 15% - 30% in the training set, while random forest and boosted decision tree outperformed all other classifiers exceeding 94.5% accuracy and 87.1% tpr, while keeping the fpr bellow 4%.
we created five levels of malicious files percentage (mfp) in the training set (5, 10, 15, 30, and 50%).
for example, when referring to 15%, we assert that 15% of the files in the training set were malicious and 85% were benign.
the mean accuracy, tpr and g-mean of the 2-gram outperforms all the othern-grams with the lowest mean fpr for all classifiers.
this is an open access article distributed under the terms of the creative commons attribution license (http://creativecommons.org/licenses/by/2.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.
[19] conducted several experiments in which they evaluated the combinations of seven feature selection methods, three classifiers, and byte n-gram size.
seeing as we assume that in most real-life scenarios low proportions of malicious files are present, training sets should be designed accordingly.
the results show that malicious software opcode distributions differ significantly from non-malicious software and suggests that the method can be used to detect malicious code.
[12] published the results of a study which used a test collection containing more than 30,000 files, in which the files were represented by byten-grams.
in the second experiment, we investigated the relationship between the malicious file percentage (mfp) in the test-set, which represents real-life scenario, and in the training set, which is used for training the classifier.
the performance of both the naïve bayes and the boosted naïve bayes was the worst for all then-gram sizes, having the lowest mean tpr, accuracy and g-mean, and highest mean fpr.
thus, we first extracted the 1,000 features (i.e., opcoden -grams patterns) with the highestdocument frequency values and on which three feature selection methods were later applied.
fs performed very well, especially when fewer features were used (top 50 and top 100).
recent studies, which we survey in the next section, have shown that by using byten-grams to represent the binary file features, classifiers with very accurate classification results can be trained, yet there still remains room for improvement.
distribution of n-gram sizes, chosen by each feature selection method, for the twon-grams sets that consist of varyingn-grams sizes.
the process of streamlining an executable starts with disassembling it.
in addition, one should consider the expected proportion of malicious files in the stream of data.
publisher full text abou-assaleh t, keselj v, sweidan r: n-gram based detection of new malicious code.
in this set, all opcode n-grams, of all sizes, were sorted according to their df value.
mcafee study finds 4% of search results malicious [ http://www.newsfactor.com/story.xhtml?story_id = 010000ceueqo] webcite frederick lane 2007.
this can be explained by the fact that for training sets with higher mfp most of the test sets are have a lower mfp, which in turn results in higher fpr.
we believe that the application of cost-sensitive classification depends on the goals to be achieved, and accordingly the cost of having a misclassification of each type.
the operations of an opcode may include arithmetic, data manipulation, logical operations, and program control.
thus, we ran all the product combinations of five training sets and five test-sets for a total of 25 runs for each classifier.
in the first experiment, we found that the tfidf representation has no added value over the tf representation, which is not the case in many information retrieval applications.
we believe that the application of cost-sensitive classification depends on the goals to be achieved, and accordingly the cost of having a misclassification of each type.
publisher full text shabtai a, potashnik d, fledel y, moskovitch r, elovici e: monitoring, analysis and filtering system for purifying network traffic of known and unknown malicious content.
indynamic analysis(also known as behavioral analysis) the detection of malware consists of information that is collected from the operating system at runtime (i.e., during the execution of the program) such as system calls, network access and files and memory modifications[3-7].
the first example pertains to for anti-virus companies that need to analyze dozens of thousands of maliciously suspected (or unknown) files, including benign files, every day.
each time the training set was chosen from one part and the test set was chosen from the other part, thus forming a 2-fold cross validation-like evaluation to render the results more significant.
moreover, the df and fs performance was more stable for varying numbers of top feature in terms accuracy and g-mean.
as a case in point, a recent mcafee survey[14] indicates that about 4% of search results from the major search engines on the web contain malicious code.
the remaining the classifiers performed very well, having the random forest, boosted decision trees and decision trees outperforming.
detailed description of the accuracy, tpr and fpr for the malicious file percentage levels in the two sets in a 3-dimensional presentation for each classifier.
in particular, these approaches search for methods for incorporating misclassification costs into the classification process and assigning higher misclassification costs to the minority class so as to compensate for its small size.
in this analysis we set out to answer the second part of research question 2 and to understand whether a combination of different sizes of opcoden -grams, as features in the classification task, may result in better detection performance.
these results are quite similar in their magnitude to the results in figure7, although here the performance level was higher.
the 2-gram opcodes outperformed the others and the df was the best feature selection method.
mean accuracy, fpr, trp and g-mean (over all the mfp levels in the test-sets) for each mfp in the training set.
previous studies presented evaluations based on test collections having similar proportions of malicious and benign files in the test collections.
in these methods the binary code of a file is represented, for example, using byte sequence (i.e., byten-grams), and classifiers are used to learn patterns in the code in order to classify new (unknown) files as malicious or benign[1,10].
another important aspect when using binary classifiers for the detection of unknown malicious code is the imbalance problem.
then, the first 1,800n-grams with the top df score were selected.
unlike byte sequence, opcode expressions, extracted from the executable file, are expected to provide a more meaningful representation of the code.
finally, for all classifiers, when testing on 2007 examples, a significant decrease in the accuracy was observed; a fact that might indicate that new types of malware were released during 2007.
the results show that using various sizes of opcode n-grams patterns does not improve the detection performance and in fact for most classifiers, the performance accuracy was deteriorated.
while most of the previous studies extracted features which are based onbyte n-grams[12,13], in this study, we use opcode n-gram patterns, generated by disassembling the inspected executable files, to represent the files.
we performed an extensive evaluation using a test collection comprising more than 30,000 files.
figure10 presents the results with a 50% mfp in the training set and10% mfp in the testing set for the two best classifiers bdt and rf (the graphs for the rest of the classifiers are provided in additional file2).
while being very precise, signature-based methods are useless against unknown malicious code[9].
the kaspersky anti-virus program was used to verify that these files did not contain any malicious code.
the chronological evaluation showed a clear trend in which the performance improves as the training set is more updated.
in the trainingphase, a training-set of benign and malicious files is provided to the system.
we believe that disregarding the parameters would provide a more general representation of the files, which is expected to be more effective for purposes of classification into benign and malicious files.
the representative vectors of the files in the training set and their real (known) classification are the input for a learning algorithm (such as a decision tree or artificial neural network algorithms).
moreover, these malicious files are written in varying frameworks which result in differing patterns.
for this we used three opcoden-grams sets on which the three feature selection methods were applied with four top-selections (50, 100, 200 or 300): - constant n-gram size this option refers to the 6 opcode n-grams sets that were used in the previous experiments, in which then-grams in each set are of the same size (1, 2, 3, 4, 5 and 6).
thus, we divided the test collection into years and evaluated training sets of selected years on the next years.
generally, df outperformed on all sizes of top features, while fs performed very well, especially when fewer top features were used (top 50 and top 100).
for each malicious and benign class a representative profile was constructed.
df was accurate for all sizes of top features.
these proportions do not reflect real-life situations in which malicious code is significantly lower than 50% and therefore might report optimistic results.
using 10% malicious files in the training set showed a clear trend in which the performance improves when the training set is updated on a yearly basis.
these files could not be disassembled by disassembler software and therefore, after converting the files into opcode representation we ended up with 5,677 malicious and 20,416 benign files (total of 26,093 files).
mean accuracy, fpr, trp and g-mean (over all the mfp levels in the test-sets) for each mfp in the training set.
in this analysis we set out to answer the second part of research question 2 and to understand whether a combination of different sizes of opcoden -grams, as features in the classification task, may result in better detection performance.
figure 7 presents the mean accuracy, fpr, tpr, and g-mean (i.e., averaged over all the mfp levels in the test-sets) of each classifier and for each training mfp level.
these results are quite similar in their magnitude to the results in figure7, although here the performance level was higher.
in such cases, where many of the vectors are sparse, the detection accuracy will be decreased.
after determining the optimal settings when using the opcode representation, we compared the achieved accuracy to the byten -gram representation used in [12].
the next and final step in streamlining the executable is achieved by extracting the sequence of opcodes generated during the disassembly process.
ida-pro implements sophisticated techniques which enabled us to disassemble most of our malware collection successfully (approximately 74% of the malware files).
then, the first 1,800n-grams with the top df score were selected.
the test-set represents the real-life situation while the training set represents the set-up of the classifier, which is controlled.
evaluation results indicate that the evaluated methodology achieves a level of accuracy higher than 96% (with tpr above 0.95 and fpr approximately 0.1), which slightly improves the results in previous studies that use byten-gram representation.
based on the reported experiments and results, we suggest that when setting up a classifier for real-life purposes, one should first use the opcode representation and, if the disassemble of the file is not feasible, use the byte representation[12], which appears to be less accurate.
chronological evaluation: accuracy, tpr and fpr with a 50% mfp in the training set and 10% mfp in the testing set for all classifiers.
we investigated the imbalance problem, referring to several real-life scenarios in which malicious files are expected to be about 10% of the total inspected files.
this can be explained by the fact that for eachn-gram size, the top 1,000 opcode n-grams, having the highest document frequency (df) value, were selected.
additionally, it is shown that the fpr grows for all classifiers with the increasing of the mfp in the training set.
in the analogy to text categorization, using letters or sequences of letters as features is analogous to using byte sequences, while using words or sequences of words is analogous to the opcode sequences.
each file in the test-set is first parsed and the representative vector is extracted using the same vocabulary as in the training phase.
finally, in the third experiment, we performed a chronological evaluation to determine how well a classifier, which was trained on past examples, can detect new malicious file and to investigate the importance and need in updating the training set frequently.
anti-virus vendors are facing huge quantities (thousands) of suspicious files every day[2].
in addition, we can see that in most cases, fs and gr tend to selectn-grams of size 2, 3 and 4 which we conclude to be more informative and with a tendency to discriminate better between the malicious and benign classes in the classification task.
based on our experiments, using opcode sequences improves the detection performance significantly.
for the imbalance analysis, where the accuracy measure can sometimes be misleading, we also computed the g-means measure.
the main advantage of static analysis is that it is able to detect a file without actually executing it and thereby providing rapid classification[8].
a total of 67 malware executables were compared with the aggregate statistics of 20 non-malicious samples.
each file is then parsed and a vector representing each file is extracted based on a pre-determined vocabulary (which can be an outcome of setup feature selection process).
the large amount of files makes efficient and effective inspection of files particularly challenging.
however, it is not clear to what extent it is essential to retrain the classifier with the new files.
in particular, researchers have experimented with random (e.g.,[26]), directed (e.g., [24,26 ]), and artificial sampling[27].
this can be explained by the fact that for eachn-gram size, the top 1,000 opcode n-grams, having the highest document frequency (df) value, were selected.
feature selection was applied on the collection of 1,800 n-grams patterns.
additionally, we investigate the imbalance problem and evaluate through various malicious-benign proportions, the best settings for a training set given a test set.
by processing these vectors, the learning algorithm trains a classifier.
in the third experiment, we addressed our 6th research question in order to understand the need in updating the training set.
this signifies that the sequence of two opcodes is more representative than single opcodes, however, longer grams decreased the accuracy.
in this paper, which is an extended version of [11], we use a methodology for malware categorization by implementing concepts from the text categorization domain, as was presented by part of the authors in[12].
another aspect in the maintenance of such a framework is the importance of updating the training set with new known malicious files.
the mean accuracy, tpr and fpr for different mfp levels in the training and test sets for the two best classifiers bdt and rf (the graphs for the rest of the classifiers are provided in additional file1).
publisher full text griffin k, schneider s, hu x, chiueh t: automatic generation of string signatures for malware detection.
consequently, the selected opcoden -grams appear in both sets and therefore eliminate the idf factor in the tf-idf measure.
thus, it is necessary to know the real class of the files in the test-set in order to compare their real class with the class that was derived by the classifier.
the result of this experiment showed no improvement when using opcoden-grams of different sizes.
these files are collected from various sources including dedicated honeypots, third party providers and files reported by customers either automatically or explicitly.
the 2-gram opcodes outperformed the others and the df was the best feature selection method.
the mean accuracy, fpr, tpr and g-mean for 10% mfp in the test-set, for each mfp in the training set.
in attempts to estimate their ability to detect malicious codes based on their issue dates, these techniques were trained on files issued before july 2003, and then tested on files issued from that point in time through august 2004.
we acquired 7,688 malicious files from the vx heaven website[34].
[13] introduced a framework that uses the common n-gram (cng) method and thek-nearest neighbor (knn) classifier for the detection of malware.
however, in the textual domain, it was shown that thetfidf is a richer and more successful representation for the retrieval and categorization purposes[39] and thus we expected that using the tfidf weighting would lead to better performance than thetf.
the results show that malicious software opcode distributions differ significantly from non-malicious software and suggests that the method can be used to detect malicious code.
for example, these common engines may be located in varying locations inside the executables, and thus may be mapped to different addresses in memory or even perturbed slightly.
in this set, for each opcode n-gram size (1- to 6-gram), the first 300n-grams with the top df score were selected (i.e., total of 1,800 n-grams).
later, thenormalized term frequency (tf) and tfinverse document frequency (tfidf) representations were calculated for each opcoden-grams patterns in each file.
thus, we divided the test collection into years and evaluated training sets of selected years on the next years.
additionally, it is important to identify the terms that appear in most of the files in order to avoid vectors that contain many zeros.
[19] conducted several experiments in which they evaluated the combinations of seven feature selection methods, three classifiers, and byte n-gram size.
the graphs show that the random forest and boosted decision tree yielded the highest accuracy and lowest fpr.
in our second experiment, we addressed our 5th research question in order to find the best malicious file percentage (mfp) among the training-set files for varying mfp in the test-set files, and more specifically, for low mfp in the test-set (10-15%), which resembles a real-life scenario.
5.2 experiment 2 - the imbalance problem in our second experiment, we addressed our 5th research question in order to find the best malicious file percentage (mfp) among the training-set files for varying mfp in the test-set files, and more specifically, for low mfp in the test-set (10-15%), which resembles a real-life scenario.
publisher full text shabtai a, potashnik d, fledel y, moskovitch r, elovici e: monitoring, analysis and filtering system for purifying network traffic of known and unknown malicious content.
the disassembly process consists of translating the machine code instructions stored in the executable to a more human-readable language, namely, assembly language.
finally, in the third experiment, we performed a chronological evaluation to determine how well a classifier, which was trained on past examples, can detect new malicious file and to investigate the importance and need in updating the training set frequently.
the kaspersky anti-virus program was used to verify that these files did not contain any malicious code.
we had the same mfp levels for the test-sets as well.
for the imbalance analysis, where the accuracy measure can sometimes be misleading, we also computed the g-means measure.
in this study we used opcode n-gram patterns generated by disassembling the inspected executable files to extract features from the inspected files.
in such cases, static analysis methods might fail to correctly classify a packed malware
we investigated the imbalance problem, referring to several real-life scenarios in which malicious files are expected to be about 10% of the total inspected files.
evaluation performed in these studies showed that unpacking files before being classified increase the classification accuracy[37,38].
improving malware detection by applying multi-inducer ensemble.
in other methods, the lack of appearances in many files might create zeroed vectors and might consequently lead to a lower accuracy level.
next, during the testing phase, a test-set collection of new benign and malicious files which did not appear in the training-set are classified by the classifier that was generated in the training phase.
in this experiment, we found that there are classifiers which are relatively non-reactive to changes in the mfp level of the test-set.
publisher full text moskovitch r, elovici y, rokach l: detection of unknown computer worms based on behavioral classification of the host.
the evaluation showed a high accuracy level of 98.4%.
first, it is difficult to simulate the appropriate conditions in which the malicious functions of the program, such as the vulnerable application that the malware exploits, will be activated.
abstract in previous studies classification algorithms were employed successfully for the detection of unknown malicious code.
benign files, including executable and dll (dynamic linked library) files, were gathered from machines running the windows xp operating system on our campus.
this is intuitively important, because the purpose of malicious files changes over time and accordingly the patterns within the code.
in this case we would like to decrease the probability of false-negative, which will result in quarantining, deleting, or blocking of a legitimate file.
another application is as an anti-virus.
introduction modern computer and communication infrastructures are highly susceptible to various types of attacks.
out of the ann classifier, all other classifiers observed similar behavior in which higher tpr and lower fpr were achieved when training on newer files.
after determining the optimal settings when using the opcode representation, we compared the achieved accuracy to the byten -gram representation used in [12].
this is very important since using the tfidf representation introduces additional computational challenges in the maintenance of the collection when it is updated.
using a disassembler software, we extracted a sequence of opcodes from each file representing execution flow of machine operations.
a new executable file was compared with the profiles of malicious and benign classes, and was assigned to the most similar.
however, in the textual domain, it was shown that thetfidf is a richer and more successful representation for the retrieval and categorization purposes[39] and thus we expected that using the tfidf weighting would lead to better performance than thetf.
in fact, in all of the cases, the tpr was above 0.95 and fpr approximately 0.1 when training the models on a yearly basis.
thus, generalization of the detection methods is crucial in order to be able to detect unknown malware before its execution.
in a filters approach method, a measure is used to quantify the correlation of each feature to the class (malicious or benign) and estimate its expected contribution to the classification task.
in tricks of the trade, lecture notes in computer science state-of-the-art surveys.
benign files, including executable and dll (dynamic linked library) files, were gathered from machines running the windows xp operating system on our campus.
fs performed very well, especially when fewer features were used (top 50 and top 100).
distribution of n-gram sizes, chosen by each feature selection method, for the twon-grams sets that consist of varyingn-grams sizes.
this was done in order to avoid problems related to sparse data (i.e., vectors that contain many zeros).
a common method of launching these attacks is by means ofmalicious software (malware) such as worms, viruses, and trojan horses, which, when spread, can cause severe damage to private users, commercial companies and governments.
additionally, we investigate the imbalance problem and evaluate through various malicious-benign proportions, the best settings for a training set given a test set.
the files in the test-set were not in the training set, presenting unknown files to the classifier.
to identify the files, we used the kaspersky anti-virus.
although such a process seems trivial, malware writers often try to prevent the successful application of the disassembly process to prevent experts from analyzing their malwares.
we had the same mfp levels for the test-sets as well.
cf carried out the data collection and experiments.
in the first experiment, we found that the tfidf representation has no added value over the tf representation, which is not the case in many information retrieval applications.
ye and sd participated in the design of the study and its coordination.
for the rf and bdt, the highest performance level was in 10% and 15% of mfp in the training set, which is more similar to the mfp in the test-set.
[12] published the results of a study which used a test collection containing more than 30,000 files, in which the files were represented by byten-grams.
this is due to the fact that the vocabulary size may exceed millions of features; far more than can be processed by any feature selection tool within a reasonable period of time.
using 10% malicious files in the training set showed a clear trend in which the performance improves when the training set is updated on a yearly basis.
each file in the test-set is first parsed and the representative vector is extracted using the same vocabulary as in the training phase.
the files in the test-set were not in the training set, presenting unknown files to the classifier.
the mean tprs, fprs, accuracies and g-means of the tf and the tfidf were quite identical, which is good because maintaining the tfidf requires additional computational efforts each time a malcode or benign files are added to the collection.
in addition, we would like to point out that classifying benign files is also useful and can reduce the load of inspecting suspicious (or unknown) files.
the feature measure that is used by the feature selection method is independent of any classification algorithm, thus allowing us to compare the performances of the different classification algorithms.
the mean accuracy, tpr and g-mean of the 2-gram outperforms all the othern-grams with the lowest mean fpr for all classifiers, but not significantly.
while the mean tprs, fprs, accuracies and g-means of the tf and tfidf were quite identical, the mean accuracy and g-mean of the 2-gram outperforms all the othern-grams with the lowest fpr.
typically, the class imbalance problem occurs when there are significantly more instances from one class relative to other classes.
in particular, the dt and bdt classifiers behaved optimally when the mfp levels in the training-set and test-set were similar.
further to our results from the training-set point of view (figures 7 and 8 ), we present a detailed description of the accuracy, tpr and fpr for the mfp levels in the two sets in a 3-dimensional presentation for each classifier (the graphs of the two best classifiers, rf and bdt, are presented in figure9; the graphs of the rest of the classifiers are provided in additional file1).
in such an application the goal is to perform an initial filtering to reduce the amount of files to investigate manually.
most of these studies extracted features based onbyte n-gram patterns in order to represent the inspected files.
to answer the above questions we first performed a wide set of experiments to identify the best term representation,n-gram size, top-selection and feature selection method.
the large amount of files makes efficient and effective inspection of files particularly challenging.
lastly, section 6 discusses the results and future work.
format: pdf size: 1.5mb download file this file can be viewed with: adobe acrobat reader when comparing these results with the results of the byte n-grams patterns experiments in[12] we notice that in terms of accuracy, the byte n -grams classifiers are more sensitive to varying mfp levels in the training and test-sets.
feature selection was applied on the collection of 1,800n-grams patterns.
first, it is difficult to simulate the appropriate conditions in which the malicious functions of the program, such as the vulnerable application that the malware exploits, will be activated.
in general, this indicates that in order to achieve a desired tpr and fpr, only the training set can be considered and selecting the proper mfp in the training set will ensure the desired tpr and fpr for any mfp in the test set.
packing and compressing files can be achieved by using off-the-shelf packers such as armadillo, upx and themida.
in this study we represent the inspected files usingopcode n-grampatterns which are extracted from the files after disassembly.
from the results we conclude that for this problem domain, complex classifiers, such as the ensemble random forest algorithm[44] which induces many decision trees and then combines the results of all trees, and the boosted decision tree[48] generate a more accurate classifier.
finally, for all classifiers, when testing on 2007 examples, a significant decrease in the accuracy was observed; a fact that might indicate that new types of malware were released during 2007.
in this experiment, themalicious file percentage (mfp) in the training and test sets was set according to the natural proportions in the file-set at approximately 22%.
all authors read and approved the final manuscript.
publisher full text griffin k, schneider s, hu x, chiueh t: automatic generation of string signatures for malware detection.
in a filters approach method, a measure is used to quantify the correlation of each feature to the class (malicious or benign) and estimate its expected contribution to the classification task.
this observation may indicate an advantage of the opcoden-grams representation as being less sensitive to the levels of mfp in the two sets, or more specifically in the test sets which represent the changes of proportions in real life conditions.
evaluation results show that an update in the training set is needed.
in conference on detection of intrusions and malware & vulnerability assessment.
we believe that disregarding the parameters would provide a more general representation of the files, which is expected to be more effective for purposes of classification into benign and malicious files.
the tf representation is actually the representation which was used in previous papers in the domain of malicious code classification[13,16,17], where counting words was replaced by byten-grams extracted from the executable files.
in addition, we would like to point out that classifying benign files is also useful and can reduce the load of inspecting suspicious (or unknown) files.
we also evaluated the performance of classifiers when using a constant size of opcoden-grams versus using varying sizes ofn-grams.
this is due to the fact that the vocabulary size may exceed millions of features; far more than can be processed by any feature selection tool within a reasonable period of time.
in this experiment, themalicious file percentage (mfp) in the training and test sets was set according to the natural proportions in the file-set at approximately 22%.
based on our experiments, using opcode sequences improves the detection performance significantly.
the opcodes, being the building blocks of machine language, have been used for statically analyzing application behavior and detecting malware.
detailed description of the accuracy, tpr and fpr for the malicious file percentage levels in the two sets in a 3-dimensional presentation for each classifier.
we performed an extensive evaluation using a test collection comprising more than 30,000 files.
the operations of an opcode may include arithmetic, data manipulation, logical operations, and program control.
in the testing phase the performance of the generated classifier is evaluated by extracting standard accuracy measures for classifiers.
packing and compressing files can be achieved by using off-the-shelf packers such as armadillo, upx and themida.
for this we used three opcoden-grams sets on which the three feature selection methods were applied with four top-selections (50, 100, 200 or 300): this option refers to the 6 opcode n-grams sets that were used in the previous experiments, in which then-grams in each set are of the same size (1, 2, 3, 4, 5 and 6).
the mean accuracy, tpr and fpr for different mfp levels in the training and test sets for the two best classifiers bdt and rf (the graphs for the rest of the classifiers are provided in additional file1).
in this case we would like to decrease the probability of false-negative, which will result in quarantining, deleting, or blocking of a legitimate file.
additionally, in order to compare the classifiers' performance, we selected the settings which had the highest mean accuracy level over all the classifiers.
the opcoden-gram patterns are used as features for the classification process.
the mean tprs, fprs, accuracies and g-means of the tf and the tfidf were quite identical, which is good because maintaining the tfidf requires additional computational efforts each time a malcode or benign files are added to the collection.
for that, we investigate the approach of representing malicious files by opcode expressions as features in the classification task.
while being very precise, signature-based methods are useless against unknown malicious code[9].
tpr, fpr, accuracy and g-mean of each classifier when comparing the best averaged settings (i.e., 2-gram, tf representation, 300 features selected by the df measure) and the classifier's optimal settings.
a rigorous evaluation was performed using a test collection comprising of more than 30,000 files, in which various settings of opcoden-gram patterns of various size representations and eight types of classifiers were evaluated.
lastly, we present a chronological evaluation in which the frequent need for updating the training set was evaluated.
however, it is not clear to what extent it is essential to retrain the classifier with the new files.
lastly, we present a chronological evaluation in which the frequent need for updating the training set was evaluated.
based on this vector, the classifier will classify the file as either benign or malicious.
ye and sd participated in the design of the study and its coordination.
another application is as an anti-virus.
these proportions do not reflect real-life situations in which malicious code is significantly lower than 50% and therefore might report optimistic results.
in such cases, where many of the vectors are sparse, the detection accuracy will be decreased.
in such cases the classifier tends to misclassify the instances of the less represented classes.
the mean tpr, fpr, accuracy and g-mean of the evaluated feature selection methods (document frequency, fisher score, gain ratio) as a function of the number of top features (50, 100, 200 and 300) .
static analysis solutions are primarily implemented using the signature-basedmethod which relies on the identification of unique strings in the binary code[2].
another aspect in the maintenance of such a framework is the importance of updating the training set with new known malicious files.
this observation, which emphasizes the imbalance problem, signifies that in order to achieve a desired tpr and fpr, only the training set can be considered and selecting the proper mfp in the training set will ensure the desired tpr and fpr for any mfp in the test set.
each file is then parsed and a vector representing each file is extracted based on a pre-determined vocabulary (which can be an outcome of setup feature selection process).
evaluation results show that an update in the training set is needed.
in the following two experiments we used the best six classifiers (rf, dt, bdt, lr, ann, svm) when trained on the best averaged settings (2-gram, tf representation, 300 top features selected by the df measure).
for the rf and bdt, the highest performance level was in 10% and 15% of mfp in the training set, which is more similar to the mfp in the test-set.
the performance of both the naïve bayes and the boosted naïve bayes was worst for alln-gram sizes having the lowest mean tpr, accuracy and g-mean and highest mean fpr.
from the results we conclude that for this problem domain, complex classifiers, such as the ensemble random forest algorithm[44] which induces many decision trees and then combines the results of all trees, and the boosted decision tree[48] generate a more accurate classifier.
table1 depicts the top five settings with the highest mean accuracy level (averaged over all the classifiers).the outperforming setting was the: 2-gram, tf, using 300 features selected by the df measure.
in future work we plan to experiment with cost-sensitive classification in which the costs of the two types of errors (i.e., missing a malicious file and false alarm) are not equal.
in the following two experiments we used the best six classifiers (rf, dt, bdt, lr, ann, svm) when trained on the best averaged settings (2-gram, tf representation, 300 top features selected by the df measure).
generally, df outperformed on all sizes of top features, while fs performed very well, especially when fewer top features were used (top 50 and top 100).
in addition, the optimal setting of each classifier is presented, as well as the resulted accuracy for the optimal setting, and the difference compared to the accuracy achieved with the best averaged setting.
all authors read and approved the final manuscript.
most of these studies extracted features based onbyte n-gram patterns in order to represent the inspected files.
moreover, these malicious files are written in varying frameworks which result in differing patterns.
the results of each classifier when using the best mean settings (i.e., -gram, tf, using 300 features selected by the df measure), including the accuracy, tpr, fpr and g-mean are presented in table2.
shin s, jung j, balakrishnan h: malware prevalence in the kazaa file-sharing network.
we also evaluated the performance of classifiers when using a constant size of opcoden-grams versus using varying sizes ofn-grams.
[17] also used byte n-grams representation, however the vector ofn-gram features was binary, presenting the presence or absence of a feature in the file and ignoring the frequency of feature appearances (in the file).
as a case in point, we extracted 443,730 3-grams and 1,769,641 4-grams.
the extracting of sequences is in the same logical order in which the opcodes appear in the executable, disregarding the extra information available (e.g., memory location, registers, etc.)
moreover, there are malware generation utilities which use a common engine to create new malware instances; this engine may even be used to polymorph the threat as it propagates.
the ann performance was generally low and dropped significantly for 5%, 15% and 50% mfp in the training set.
for evaluation purposes, we used the true positive rate (tpr) measure, which is the number ofpositive instances classified correctly, false positive rate (fpr), which is the number of negative instances misclassified, and thetotal accuracy, which measures the number of absolutely correctly classified instances, either positive or negative, divided by the entire number of instances.
recent studies, which we survey in the next section, have shown that by using byten-grams to represent the binary file features, classifiers with very accurate classification results can be trained, yet there still remains room for improvement.
we had 7 training sets, in which training setk included samples from the year 2000 till year 200[k ] (where k = 0,1,2
this malicious and benign file collection was previously used in[12].
while the mean tprs, fprs, accuracies and g-means of the tf and tfidf were quite identical, the mean accuracy and g-mean of the 2-gram outperforms all the othern-grams with the lowest fpr.
the mean accuracy, tpr and g-mean of the 2-gram outperforms all the othern-grams with the lowest mean fpr for all classifiers, but not significantly.
the performance of both the naïve bayes and the boosted naïve bayes was worst for alln-gram sizes having the lowest mean tpr, accuracy and g-mean and highest mean fpr.
opcoden-grams are used as features during the classification process with the aim of identifying unknown malicious code.
we set out to evaluate the use of opcodes patterns for the purpose of unknown malicious code detection through three main experiments.
thus, we first extracted the 1,000 features (i.e., opcoden -grams patterns) with the highestdocument frequency values and on which three feature selection methods were later applied.
the results of each classifier when using the best mean settings (i.e., -gram, tf, using 300 features selected by the df measure), including the accuracy, tpr, fpr and g-mean are presented in table2.
additionally, in order to compare the classifiers' performance, we selected the settings which had the highest mean accuracy level over all the classifiers.
secondly, it is not clear what is the required period of time needed to observe the appearance of the malicious activity for each malware.
the classification process main goal is to detect unknown malware within a set of suspected files which will later be included in antivirus software as signatures.
next, during the testing phase, a test-set collection of new benign and malicious files which did not appear in the training-set are classified by the classifier that was generated in the training phase.
improving malware detection by applying multi-inducer ensemble.
the mean accuracy, tpr and g-mean of the 2-gram outperforms all the othern-grams with the lowest mean fpr for all classifiers.
also, the large number of malware files in our dataset that could be dissembled indicates that in order to appear benign and to pass security mechanisms (that are configured to block content that is encrypted\obfuscated and cannot be inspected), these techniques are not always used by hackers.
additionally, shin et al.[15] found that above 15% of the files in the kazaa network contained malicious code.
the opcoden-gram patterns are used as features for the classification process.
in attempts to estimate their ability to detect malicious codes based on their issue dates, these techniques were trained on files issued before july 2003, and then tested on files issued from that point in time through august 2004.
in the testing phase the performance of the generated classifier is evaluated by extracting standard accuracy measures for classifiers.
our main goal in this study is to be able to filter out unknown malicious files from the files arriving to an anti-virus vendor every day.
interestingly, a stable state is observed in the accuracy measure for any mfp level.
authors' contributions rm and as conceived of the study, studied the research domain, participated in the design of the study, performed the analysis of the results, and drafted the manuscript.
the results show that using various sizes of opcode n-grams patterns does not improve the detection performance and in fact for most classifiers, the performance accuracy was deteriorated.
the mean accuracy, fpr, tpr and g-mean for 10% mfp in the test-set, for each mfp in the training set.
from the table we can see, as expected, that the df feature selection method favors short n-grams which appear in a larger number of files.
this malicious and benign file collection was previously used in[12].
we acquired 7,688 malicious files from the vx heaven website[34].
for that, we investigate the approach of representing malicious files by opcode expressions as features in the classification task.
table1 depicts the top five settings with the highest mean accuracy level (averaged over all the classifiers).the outperforming setting was the: 2-gram, tf, using 300 features selected by the df measure.
the feature measure that is used by the feature selection method is independent of any classification algorithm, thus allowing us to compare the performances of the different classification algorithms.
this observation may indicate an advantage of the opcoden-grams representation as being less sensitive to the levels of mfp in the two sets, or more specifically in the test sets which represent the changes of proportions in real life conditions.
the opcodes, being the building blocks of machine language, have been used for statically analyzing application behavior and detecting malware.
rm and as conceived of the study, studied the research domain, participated in the design of the study, performed the analysis of the results, and drafted the manuscript.
in the third experiment, we addressed our 6th research question in order to understand the need in updating the training set.
in order to reduce the number of opcoden-gram features, which ranges from thousands to millions, we used the df measure to select the top 1,000 features and tested three feature selection methods.
this is intuitively important, because the purpose of malicious files changes over time and accordingly the patterns within the code.
interestingly, the best n-gram size of opcodes was the 2-gram with the highest accuracy and g-mean values and the lowest fpr (and with tpr similar but slightly lower from the 3-gram).
the result of this experiment showed no improvement when using opcoden-grams of different sizes.
for both scenarios it is difficult to assign the costs for the two errors (note that each type of malware can be assigned with a different cost level based on the damage it causes) and therefore in this paper we focus on exploring and identifying the settings and classifiers that can classify the files as accurately as possible, leaving the cost-sensitive analysis for future work.
later, thenormalized term frequency (tf) and tfinverse document frequency (tfidf) representations were calculated for each opcoden-grams patterns in each file.
the extracting of sequences is in the same logical order in which the opcodes appear in the executable, disregarding the extra information available (e.g., memory location, registers, etc.)
the size of vocabularies (number of distinct n-grams) extracted for the opcoden-grams representation were of 515, 39,011, 443,730, 1,769,641, 5,033,722 and 11,948,491, for 1-gram, 2-gram, 3-gram, 4-gram, 5-gram and 6-gram, respectively.
the comparisons show that for all classifiers, excluding the nb and bnb, the best averaged setting yields similar performance.
to classify the files we had to convert them into a vectorial representation.
in addition, we can see that for a given mfp in thetraining set , the tpr and the fpr of the classifiers are stable for any mfp level in the test set.
the results (accuracy, tpr and fpr) for with a 50% mfp on the training set and 10% mfp on the test set for the two best classifiers bdt and rf (the rest of the classifiers are presented in additional file2).
in addition, one should consider the expected proportion of malicious files in the stream of data.
chronological evaluation: accuracy, tpr and fpr with a 50% mfp in the training set and 10% mfp in the testing set for all classifiers.
moreover, there are malware generation utilities which use a common engine to create new malware instances; this engine may even be used to polymorph the threat as it propagates.
the remaining the classifiers performed very well, having the random forest, boosted decision trees and decision trees outperforming.
- top 300 for each n-gram size in this set, for each opcode n-gram size (1- to 6-gram), the first 300n-grams with the top df score were selected (i.e., total of 1,800 n-grams).
in the trainingphase, a training-set of benign and malicious files is provided to the system.
additionally, it is important to identify the terms that appear in most of the files in order to avoid vectors that contain many zeros.
as a case in point, a recent mcafee survey[14] indicates that about 4% of search results from the major search engines on the web contain malicious code.
thus, it is necessary to know the real class of the files in the test-set in order to compare their real class with the class that was derived by the classifier.
detailed description of the accuracy, tpr and fpr with a 50% mfp in the training set and 10% mfp in the testing set for all classifiers.
more and more researchers realized that the performance of their classifiers may be sub-optimal due to the fact that the datasets are not balanced.
the top five settings with the highest mean accuracy over all the classifiers.
to answer the above questions we first performed a wide set of experiments to identify the best term representation,n-gram size, top-selection and feature selection method.
this is very important since using the tfidf representation introduces additional computational challenges in the maintenance of the collection when it is updated.
ida-pro implements sophisticated techniques which enabled us to disassemble most of our malware collection successfully (approximately 74% of the malware files)
the results (accuracy, tpr and fpr) for with a 50% mfp on the training set and 10% mfp on the test set for the two best classifiers bdt and rf (the rest of the classifiers are presented in additional file2).
thus, generalization of the detection methods is crucial in order to be able to detect unknown malware before its execution.
for example, when referring to 15%, we assert that 15% of the files in the training set were malicious and 85% were benign.
in order to reduce the number of opcoden-gram features, which ranges from thousands to millions, we used the df measure to select the top 1,000 features and tested three feature selection methods.
interestingly, the best n-gram size of opcodes was the 2-gram with the highest accuracy and g-mean values and the lowest fpr (and with tpr similar but slightly lower from the 3-gram).
in such cases, static analysis methods might fail to correctly classify a packed malware [36].
the question asks how important it is to update the repository of malicious and benign files and whether, for specific years, the files were more contributive to the accuracy when introduced in the training set or in the test set.
typically, the class imbalance problem occurs when there are significantly more instances from one class relative to other classes.
3.3 data preparation and feature selection to classify the files we had to convert them into a vectorial representation.
in particular, the dt and bdt classifiers behaved optimally when the mfp levels in the training-set and test-set were similar.
in particular, researchers have experimented with random (e.g.,[26]), directed (e.g., [24,26 ]), and artificial sampling[27].
perdisci r, lanzi a, lee w: mcboost: boosting scalability in malware collection and analysis using statistical classification of executables.
in other methods, the lack of appearances in many files might create zeroed vectors and might consequently lead to a lower accuracy level.
indynamic analysis(also known as behavioral analysis) the detection of malware consists of information that is collected from the operating system at runtime (i.e., during the execution of the program) such as system calls, network access and files and memory modifications[3-7].
in conference on detection of intrusions and malware & vulnerability assessment.
bilar d: opcodes as predictor for malware.
the representative vectors of the files in the training set and their real (known) classification are the input for a learning algorithm (such as a decision tree or artificial neural network algorithms).
in this experiment, we found that there are classifiers which are relatively non-reactive to changes in the mfp level of the test-set.
in addition, we can see that for a given mfp in thetraining set , the tpr and the fpr of the classifiers are stable for any mfp level in the test set.
based on this vector, the classifier will classify the file as either benign or malicious.
our main goal in this study is to be able to filter out unknown malicious files from the files arriving to an anti-virus vendor every day.
from the table we can see, as expected, that the df feature selection method favors short n-grams which appear in a larger number of files.
moreover, the df and fs performance was more stable for varying numbers of top feature in terms accuracy and g-mean.
the mean tpr, fpr, accuracy and g-mean of the evaluated feature selection methods (document frequency, fisher score, gain ratio) as a function of the number of top features (50, 100, 200 and 300) .
in these methods the binary code of a file is represented, for example, using byte sequence (i.e., byten-grams), and classifiers are used to learn patterns in the code in order to classify new (unknown) files as malicious or benign[1,10].
for evaluation purposes, we used the true positive rate (tpr) measure, which is the number ofpositive instances classified correctly, false positive rate (fpr), which is the number of negative instances misclassified, and thetotal accuracy, which measures the number of absolutely correctly classified instances, either positive or negative, divided by the entire number of instances.
it is shown that all classifiers, excluding ann, had a similar trend and perform better when using mfp of 15% - 30% in the training set, while random forest and boosted decision tree outperformed all other classifiers exceeding 94.5% accuracy and 87.1% tpr, while keeping the fpr bellow 4%.
in the analogy to text categorization, using letters or sequences of letters as features is analogous to using byte sequences, while using words or sequences of words is analogous to the opcode sequences.
the accuracy, fpr, tpr and g-mean of each classifier when using the best mean settings (i the graphs in figure 5 depict the tpr, fpr, accuracy and g-mean of each classifier when comparing the best averaged settings (2-gram, tf representation, using 300 features selected by the df measure) with the classifier's optimal settings.
detailed description of the accuracy, tpr and fpr with a 50% mfp in the training set and 10% mfp in the testing set for all classifiers.
this observation can be explained by the fact that longer opcoden-grams indicates larger vocabulary (since there are more combinations of then-grams), yet on the other hand, a large number of n-grams results in fewer appearances in many files, thus creating sparse vectors.
out of the ann classifier, all other classifiers observed similar behavior in which higher tpr and lower fpr were achieved when training on newer files.
this can be explained by its criterion, which has an advantage for fewer features.
these files could not be disassembled by disassembler software and therefore, after converting the files into opcode representation we ended up with 5,677 malicious and 20,416 benign files (total of 26,093 files).
when faced with unequal class sizes, classification accuracy is often an inappropriate measure of performance.
opcoden-grams are used as features during the classification process with the aim of identifying unknown malicious code.
in previous studies classification algorithms were employed successfully for the detection of unknown malicious code.
figure8 presents the mean accuracy, fpr, tpr and g-mean for a 2-fold cross validation experiment for each mfp in the training set and with a fixed level of 10% mfp in the test-set.
we had 7 training sets, in which training setk included samples from the year 2000 till year 200[k ] (where k = 0,1,2
in fact, in all of the cases, the tpr was above 0.95 and fpr approximately 0.1 when training the models on a yearly basis.
interestingly, a stable state is observed in the accuracy measure for any mfp level.
in particular, these approaches search for methods for incorporating misclassification costs into the classification process and assigning higher misclassification costs to the minority class so as to compensate for its small size.
data mining methods (logistic regression, artificial neural networks and decision trees) are used in[21] to automatically identify critical instruction sequences that can distinguish between malicious and benign programs.
in the second experiment we investigated the imbalance problem to determine the optimal settings of the training set for each classifier in varying "real-life" conditions.
a common method of launching these attacks is by means ofmalicious software (malware) such as worms, viruses, and trojan horses, which, when spread, can cause severe damage to private users, commercial companies and governments.
indeed, in such circumstances, a trivial classifier that predicts every case as the majority class could achieve very high accuracy levels in extremely skewed domains.
in addition, the optimal setting of each classifier is presented, as well as the resulted accuracy for the optimal setting, and the difference compared to the accuracy achieved with the best averaged setting.
this signifies that the sequence of two opcodes is more representative than single opcodes, however, longer grams decreased the accuracy.
unlike byte sequence, opcode expressions, extracted from the executable file, are expected to provide a more meaningful representation of the code.
training-set malware percentage figure 7 presents the mean accuracy, fpr, tpr, and g-mean (i.e., averaged over all the mfp levels in the test-sets) of each classifier and for each training mfp level.
the classification process main goal is to detect unknown malware within a set of suspected files which will later be included in antivirus software as signatures.
the recent growth in high-speed internet connections enable malware to propagate and infect hosts very quickly, therefore it is essential to detect and eliminate new (unknown) malware in a prompt manner[1].
some of the files in our collection were either compressed or packed.
the first example pertains to for anti-virus companies that need to analyze dozens of thousands of maliciously suspected (or unknown) files, including benign files, every day.
the recent growth in high-speed internet connections enable malware to propagate and infect hosts very quickly, therefore it is essential to detect and eliminate new (unknown) malware in a prompt manner[1].
data mining methods (logistic regression, artificial neural networks and decision trees) are used in[21] to automatically identify critical instruction sequences that can distinguish between malicious and benign programs.
perdisci r, lanzi a, lee w: mcboost: boosting scalability in malware collection and analysis using statistical classification of executables.
another important aspect when using binary classifiers for the detection of unknown malicious code is the imbalance problem.
the performance of both the naïve bayes and the boosted naïve bayes was the worst for all then-gram sizes, having the lowest mean tpr, accuracy and g-mean, and highest mean fpr.
tpr, fpr, accuracy and g-mean of each classifier when comparing the best averaged settings (i.e., 2-gram, tf representation, 300 features selected by the df measure) and the classifier's optimal settings.
this was done in order to avoid problems related to sparse data (i.e., vectors that contain many zeros).
a rigorous evaluation was performed using a test collection comprising of more than 30,000 files, in which various settings of opcoden-gram patterns of various size representations and eight types of classifiers were evaluated.
static analysis solutions are primarily implemented using the signature-basedmethod which relies on the identification of unique strings in the binary code[2].
more and more researchers realized that the performance of their classifiers may be sub-optimal due to the fact that the datasets are not balanced.
in the second experiment we investigated the imbalance problem to determine the optimal settings of the training set for each classifier in varying "real-life" conditions.
in future work we plan to experiment with cost-sensitive classification in which the costs of the two types of errors (i.e., missing a malicious file and false alarm) are not equal.
the main advantage of static analysis is that it is able to detect a file without actually executing it and thereby providing rapid classification[8].
these files are collected from various sources including dedicated honeypots, third party providers and files reported by customers either automatically or explicitly.
in tricks of the trade, lecture notes in computer science state-of-the-art surveys.
also, the large number of malware files in our dataset that could be dissembled indicates that in order to appear benign and to pass security mechanisms (that are configured to block content that is encrypted\obfuscated and cannot be inspected), these techniques are not always used by hackers.
although such a process seems trivial, malware writers often try to prevent the successful application of the disassembly process to prevent experts from analyzing their malwares.
the second strategy involves modifying the classifiers in order to adapt them to the data-sets.
to identify the files, we used the kaspersky anti-virus.
consequently, the selected opcoden -grams appear in both sets and therefore eliminate the idf factor in the tf-idf measure.
(of size n=1,2) representation to ascribe malware instances to their families by measuring the similarity between files.
the size of vocabularies (number of distinct n-grams) extracted for the opcoden-grams representation were of 515, 39,011, 443,730, 1,769,641, 5,033,722 and 11,948,491, for 1-gram, 2-gram, 3-gram, 4-gram, 5-gram and 6-gram, respectively.
these techniques are also applied on benign software for copyrights protection purposes.
the chronological evaluation showed a clear trend in which the performance improves as the training set is more updated.
in our case, the data is imbalanced in real-life conditions and reflected by the test-set in our experiments, therefore, we would like to understand the optimal construction of a training-set for achieving the best performance in real-life conditions.
the next and final step in streamlining the executable is achieved by extracting the sequence of opcodes generated during the disassembly process.
the question asks how important it is to update the repository of malicious and benign files and whether, for specific years, the files were more contributive to the accuracy when introduced in the training set or in the test set.
for example, these common engines may be located in varying locations inside the executables, and thus may be mapped to different addresses in memory or even perturbed slightly.
figure10 presents the results with a 50% mfp in the training set and10% mfp in the testing set for the two best classifiers bdt and rf (the graphs for the rest of the classifiers are provided in additional file2).
for this purpose we designed a chronological experiment, based on a dataset including files from the years 2000 to 2007, trained each time on files untill yeark and tested on the following years.
thus, having a relatively high false-positive is reasonable in order to decrease the probability of missing an unknown malicious file.
for both scenarios it is difficult to assign the costs for the two errors (note that each type of malware can be assigned with a different cost level based on the damage it causes) and therefore in this paper we focus on exploring and identifying the settings and classifiers that can classify the files as accurately as possible, leaving the cost-sensitive analysis for future work.
additionally, it is shown that the fpr grows for all classifiers with the increasing of the mfp in the training set.
figure8 presents the mean accuracy, fpr, tpr and g-mean for a 2-fold cross validation experiment for each mfp in the training set and with a fixed level of 10% mfp in the test-set.
the top five settings with the highest mean accuracy over all the classifiers.
this is an open access article distributed under the terms of the creative commons attribution license (http://creativecommons.org/licenses/by/2.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.
evaluation performed in these studies showed that unpacking files before being classified increase the classification accuracy[37,38].
for each malicious and benign class a representative profile was constructed.
in our case, the data is imbalanced in real-life conditions and reflected by the test-set in our experiments, therefore, we would like to understand the optimal construction of a training-set for achieving the best performance in real-life conditions.
the test-set represents the real-life situation while the training set represents the set-up of the classifier, which is controlled.
in this study we used opcode n-gram patterns generated by disassembling the inspected executable files to extract features from the inspected files.
feature selection was applied on the collection of 1,800n-grams patterns.
format: pdf size: 1.5mb download file this file can be viewed with: adobe acrobat reader when comparing these results with the results of the byte n-grams patterns experiments in[12] we notice that in terms of accuracy, the byte n -grams classifiers are more sensitive to varying mfp levels in the training and test-sets.
indeed, in such circumstances, a trivial classifier that predicts every case as the majority class could achieve very high accuracy levels in extremely skewed domains.
using a disassembler software, we extracted a sequence of opcodes from each file representing execution flow of machine operations.
a new executable file was compared with the profiles of malicious and benign classes, and was assigned to the most similar.
the disassembly process consists of translating the machine code instructions stored in the executable to a more human-readable language, namely, assembly language.
shin s, jung j, balakrishnan h: malware prevalence in the kazaa file-sharing network.
(of size n=1,2) representation to ascribe malware instances to their families by measuring the similarity between files.
this can be explained by its criterion, which has an advantage for fewer features.
in addition, we can see that in most cases, fs and gr tend to selectn-grams of size 2, 3 and 4 which we conclude to be more informative and with a tendency to discriminate better between the malicious and benign classes in the classification task.
clearly, the files in the test were not present in the training set.
previous studies presented evaluations based on test collections having similar proportions of malicious and benign files in the test collections.
detecting unknown malicious code by applying classification techniques on opcode patterns asaf shabtai1,2*, robert moskovitch1,2, clint feher1,2, shlomi dolev3,1 and yuval elovici1,2 *
this observation can be explained by the fact that longer opcoden-grams indicates larger vocabulary (since there are more combinations of then-grams), yet on the other hand, a large number of n-grams results in fewer appearances in many files, thus creating sparse vectors.
when faced with unequal class sizes, classification accuracy is often an inappropriate measure of performance.
each time the training set was chosen from one part and the test set was chosen from the other part, thus forming a 2-fold cross validation-like evaluation to render the results more significant.
in this paper, which is an extended version of [11], we use a methodology for malware categorization by implementing concepts from the text categorization domain, as was presented by part of the authors in[12].
the second strategy involves modifying the classifiers in order to adapt them to the data-sets.
in general, this indicates that in order to achieve a desired tpr and fpr, only the training set can be considered and selecting the proper mfp in the training set will ensure the desired tpr and fpr for any mfp in the test set.
the tf representation is actually the representation which was used in previous papers in the domain of malicious code classification[13,16,17], where counting words was replaced by byten-grams extracted from the executable files.
seeing as we assume that in most real-life scenarios low proportions of malicious files are present, training sets should be designed accordingly.
the graphs show that the random forest and boosted decision tree yielded the highest accuracy and lowest fpr.
additionally, shin et al.[15] found that above 15% of the files in the kazaa network contained malicious code.
in this study we represent the inspected files usingopcode n-grampatterns which are extracted from the files after disassembly.
this is, however, different from our goal in which we attempt to classify unknown suspicious files as malicious or benign in order to detect new malware.
as a case in point, we extracted 443,730 3-grams and 1,769,641 4-grams.
the accuracy, fpr, tpr and g-mean of each classifier when using the best mean settings (i the graphs in figure 5 depict the tpr, fpr, accuracy and g-mean of each classifier when comparing the best averaged settings (2-gram, tf representation, using 300 features selected by the df measure) with the classifier's optimal settings.
in such an application the goal is to perform an initial filtering to reduce the amount of files to investigate manually.
[13] introduced a framework that uses the common n-gram (cng) method and thek-nearest neighbor (knn) classifier for the detection of malware.
for this purpose we designed a chronological experiment, based on a dataset including files from the years 2000 to 2007, trained each time on files untill yeark and tested on the following years.
publisher full text abou-assaleh t, keselj v, sweidan r: n-gram based detection of new malicious code.
this can be explained by the fact that for training sets with higher mfp most of the test sets are have a lower mfp, which in turn results in higher fpr.
this observation, which emphasizes the imbalance problem, signifies that in order to achieve a desired tpr and fpr, only the training set can be considered and selecting the proper mfp in the training set will ensure the desired tpr and fpr for any mfp in the test set.
these techniques are also applied on benign software for copyrights protection purposes.
evaluation results indicate that the evaluated methodology achieves a level of accuracy higher than 96% (with tpr above 0.95 and fpr approximately 0.1), which slightly improves the results in previous studies that use byten-gram representation.