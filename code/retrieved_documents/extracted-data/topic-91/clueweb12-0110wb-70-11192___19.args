we show that the resulting ranker, compared to ei- ther component technique, frequently significantly increases auc.
[ bib | http ] for conventional machine learning classification algorithms handling numeric attributes is relatively straightforward.
propositionalisation does not need such a measure and allows the use of any propositional learner including kernel-based approaches.
aft was tested on the cedar and gpds benchmark datasets, with classification using either a manual or an automatic variant.
the method allows the use of phmms discriminatively in a classification task.
by combining pruned sets in an ensemble scheme (eps), new label sets can be formed to adapt to irregular or complex data.
this is also the case when attribute selection is performed in naive bayes and its semi-naive variant.
adaptive feature thresholding for off-line signature verification.
although miles provides competitive performance when compared to other mi learners, we identify simpler propositionaliza- tion methods that require shorter training times while retaining miles' strong classification performance on the datasets we tested.
experiments use three machine learning techniques; static prediction models, continuous learning, and reinforcement learning.
the new algorithms are shown to achieve better root mean squared error rates than existing approaches on artificial data generated according to the underlying assumptions.
however, if known non-target classes are available at training time, it is also possible to use standard multi-class or two-class classification, exploiting the negative data to infer a description of the target class.
[ bib | www: ] this paper introduces adaptive feature thresholding (aft) which is a novel method of person-dependent off-line signature verification.
alongside performing elaborate comparisons of algorithms, we also investigate the effects of algorithm parameters and data properties, and seek deeper insights into the behavior of learning algorithms by studying their learning curves and bias-variance profiles.
in this method, the ref- erence distribution is used to generate artificial data that is employed to form a second, artificial class.
improving face gender classification by adding deliberately misaligned faces to the training data.
bias variance decomposition for classifiers is a useful tool in understanding classifier behavior.
static models show the highest initial performance but are not able to beat a simple opponent.
in conjunction with the target class, this artificial class is the basis for a standard two-class learning problem.
we, however, argue that this step is not necessary, and that machine learning classifiers can be made robust to face misalignments by automatically expanding the training data with examples of faces that have been deliberately misaligned (for example, translated or rotated).
this indicates a need for algorithms that can operate efficiently on relational data and exploit the larger body of work produced in the area of single-table techniques.
we also compare the method to one-class classification using support vector machines.
this is also the case when attribute selection is performed in naive bayes and its semi-naive variant.
machine learning for adaptive computer game opponents.
only if the learning algorithm is stable, fewer samples, a smaller test set size or lower number of folds may be justified.
the results show that the inclusion of spatial relationships leads to a measurable increase in performance for two of the most challenging datasets.
in this paper, we make use of such a database to answer various interesting research questions about learning algorithms and to verify a number of recent studies.
the challenge is to accurately estimate these weights in order to make predictions at the bag level.
[ bib | www: ] this paper introduces adaptive feature thresholding (aft) which is a novel method of person-dependent off-line signature verification.
the thesis also develops a novel algorithm for building random forests by making efficient use of random rules to generate trees and leaves in parallel.
inproc 12th pacific-asia conference on knowledge discovery and data mining, osaka, japan.
naive bayes and decision tables can both be trained effi- ciently, and the same holds true for the combined semi-naive model.
this way we get a simple, extendable representation of multiple sequence alignments which facilitates further analysis by machine learning algorithms.
this includes first confirming that machine learning algorithms can be integrated into a modern computer game without have a detrimental effect on game performance, then experimenting with different machine learning techniques to maximize the computer player's performance.
the challenge is to accurately estimate these weights in order to make predictions at the bag level.
in this paper, we make use of such a database to answer various interesting research questions about learning algorithms and to verify a number of recent studies.
we show empirically that using propositionalisation leads to higher accuracies in comparison with phmms on benchmark datasets.
aft enhances how a simple image feature of a signature is converted to a binary feature vector by significantly improving its representation in relation to the training signatures.
our results show that boosted decision stumps can in some cases provide better classification accuracy than the 1-norm svm as a base learner for miles.
this limits the effectiveness of reinforcement learning because a large number of episodes are required before performance becomes sufficient to match the opponent.
[ bib | http ] for conventional machine learning classification algorithms handling numeric attributes is relatively straightforward.
our results show that boosted decision stumps can in some cases provide better classification accuracy than the 1-norm svm as a base learner for miles.
however, unlike the original model, image features (keypoints) are not seen as independent and orderless.
propositionalisation allows single-table algorithms for classification and clustering to be applied to the resulting data, reducing the amount of relational processing required.
to this end we first identify a way of performing a fair comparison between the techniques concerned and present an adaptation of standard cross-validation.
bias variance decomposition for classifiers is a useful tool in understanding classifier behavior.
this demonstrates that sufficient information for classification and clustering is retained in the rule generation process and that learning with random rules is efficient.
experimental results also demonstrate that the new algorithms are competitive with existing approaches on real-world problems.
using a benchmark face gender classification dataset recently proposed in the literature, we obtain a state-of-the-art accuracy of 92.5%, thus validating our approach.
further results show that techniques for utilising additional unlabeled training data improve accuracy of classification in the semi-supervised setting.
they offer the advantage to provide sound, probabilistic scores.
propositionalisation does not need such a measure and allows the use of any propositional learner including kernel-based approaches.
yet, when collecting all these past experiments in experiment databases, they can readily be reused for additional and possibly much broader investigation.
[11] improving face gender classification by adding deliberately misaligned faces to the training data michael mayo and edmond zhang.
however, a significant amount of the world's data is relational.
experiments use three machine learning techniques; static prediction models, continuous learning, and reinforcement learning.
this indicates a need for algorithms that can operate efficiently on relational data and exploit the larger body of work produced in the area of single-table techniques.
to test our hypothesis, we evaluate this automatic training dataset expansion method with two types of image classifier, the first based on weak features such as local binary pattern histograms, and the second based on sift keypoints.
this limits the effectiveness of reinforcement learning because a large number of episodes are required before performance becomes sufficient to match the opponent.
additionally statistical models like profile hidden markov models are used as representations.
by pruning these sets, ps focuses only on the most important correlations, which reduces complexity and improves accuracy.
reinforcement learning methods have the highest rate of improvement but the lowest initial performance.
us- ing uci datasets, and data from a typist recognition problem, we show that the combined model, consisting of both a density estimator and a class probability estimator, can improve on using either component tech- nique alone when used for one-class classification.
continuous learning is able to improve the performance achieved with static models but the rate of improvement drops over time and the computer player is still unable to beat the opponent.
however, unlike the original model, image features (keypoints) are not seen as independent and orderless.
the assumption is that random rules enable efficient and effective relational learning, and this thesis presents evidence that this is indeed the case.
alongside performing elaborate comparisons of algorithms, we also investigate the effects of algorithm parameters and data properties, and seek deeper insights into the behavior of learning algorithms by studying their learning curves and bias-variance profiles.
further results show that techniques for utilising additional unlabeled training data improve accuracy of classification in the semi-supervised setting.
surprisingly, the experimental comparison shows that the most approximate methods produce the most accurate trees by allowing for faster tree growth.
aft was tested on the cedar and gpds benchmark datasets, with classification using either a manual or an automatic variant.
unfortunately, none of these solutions carry over particularly well to a data stream environment.
the assumption is that random rules enable efficient and effective relational learning, and this thesis presents evidence that this is indeed the case.
randomization based on random relational rules can work both with and without a class attribute and can therefore be applied simultaneously to both the labeled and the unlabeled portion of the data present in semi-supervised learning.
we show that the resulting ranker, compared to ei- ther component technique, frequently significantly increases auc.
the demanding nature of the netflix data has lead to some interesting and ingenious modifications to standard learning methods in the name of efficiency and speed.
for both datasets aft is less complex and requires fewer images features than the existing state of the art methods, while achieving competitive results.
machine learning for adaptive computer game opponents.
the demanding nature of the netflix data has lead to some interesting and ingenious modifications to standard learning methods in the name of efficiency and speed.
previously, researchers have assumed that a computationally expensive face alignment step (in which the face image is transformed so that facial landmarks such as the eyes, nose, chin, etc, are in uniform locations in the image) is required in order to maximize the accuracy of predictions on new face images.
to test our hypothesis, we evaluate this automatic training dataset expansion method with two types of image classifier, the first based on weak features such as local binary pattern histograms, and the second based on sift keypoints.
for some datasets it significantly improves on both techniques.
we show empirically that using propositionalisation leads to higher accuracies in comparison with phmms on benchmark datasets.
inproc 12th pacific-asia conference on knowledge discovery and data mining, osaka, japan.
by pruning these sets, ps focuses only on the most important correlations, which reduces complexity and improves accuracy.
the results from experimental evaluation on a variety of multi-label datasets show that [e]ps can achieve better performance and train much faster than other multi-label methods.
yet, the information contained in these experiments might have uses beyond their original intent and, if properly stored, could be of great use to future research.
randomization based on random relational rules can work both with and without a class attribute and can therefore be applied simultaneously to both the labeled and the unlabeled portion of the data present in semi-supervised learning.
to this end we first identify a way of performing a fair comparison between the techniques concerned and present an adaptation of standard cross-validation.
naive bayes and decision tables can both be trained effi- ciently, and the same holds true for the combined semi-naive model.
using a benchmark face gender classification dataset recently proposed in the literature, we obtain a state-of-the-art accuracy of 92.5%, thus validating our approach.
previously, researchers have assumed that a computationally expensive face alignment step (in which the face image is transformed so that facial landmarks such as the eyes, nose, chin, etc, are in uniform locations in the image) is required in order to maximize the accuracy of predictions on new face images.
continuous learning is able to improve the performance achieved with static models but the rate of improvement drops over time and the computer player is still unable to beat the opponent.
they offer the advantage to provide sound, probabilistic scores.
adaptive feature thresholding for off-line signature verification.
this demonstrates that sufficient information for classification and clustering is retained in the rule generation process and that learning with random rules is efficient.
the new algorithms are shown to achieve better root mean squared error rates than existing approaches on artificial data generated according to the underlying assumptions.
us- ing uci datasets, and data from a typist recognition problem, we show that the combined model, consisting of both a density estimator and a class probability estimator, can improve on using either component tech- nique alone when used for one-class classification.
the experimental results show that these algorithms perform competitively with previously published results for the datasets used, while often exhibiting lower runtime than other tested systems.
surprisingly, the experimental comparison shows that the most approximate methods produce the most accurate trees by allowing for faster tree growth.
results show that the methods are competitive with nns in terms of accuracy but significantly faster.
by combining pruned sets in an ensemble scheme (eps), new label sets can be formed to adapt to irregular or complex data.
improving face gender classification by adding deliberately misaligned faces to the training data.
results show that the methods are competitive with nns in terms of accuracy but significantly faster.
this way we get a simple, extendable representation of multiple sequence alignments which facilitates further analysis by machine learning algorithms.
propositionalisation allows single-table algorithms for classification and clustering to be applied to the resulting data, reducing the amount of relational processing required.
this approach works by partitioning the image into smaller regions then computing the spatial relationships between all of the informative image keypoints in the region.
we, however, argue that this step is not necessary, and that machine learning classifiers can be made robust to face misalignments by automatically expanding the training data with examples of faces that have been deliberately misaligned (for example, translated or rotated).
most alignment representations are designed to facilitate knowledge extraction by human experts.
the experimental results show that these algorithms perform competitively with previously published results for the datasets used, while often exhibiting lower runtime than other tested systems.
yet, the information contained in these experiments might have uses beyond their original intent and, if properly stored, could be of great use to future research.
in this method, the ref- erence distribution is used to generate artificial data that is employed to form a second, artificial class.
yet, when collecting all these past experiments in experiment databases, they can readily be reused for additional and possibly much broader investigation.
the results show that the inclusion of spatial relationships leads to a measurable increase in performance for two of the most challenging datasets.
experimental results also demonstrate that the new algorithms are competitive with existing approaches on real-world problems.
for both datasets aft is less complex and requires fewer images features than the existing state of the art methods, while achieving competitive results.
learning from the past with experiment databases.
[11] improving face gender classification by adding deliberately misaligned faces to the training data michael mayo and edmond zhang.
the thesis also develops a novel algorithm for building random forests by making efficient use of random rules to generate trees and leaves in parallel.
this allows the classification process to inherently take into account correlations between labels.
unfortunately, none of these solutions carry over particularly well to a data stream environment.
only if the learning algorithm is stable, fewer samples, a smaller test set size or lower number of folds may be justified.
the results from experimental evaluation on a variety of multi-label datasets show that [e]ps can achieve better performance and train much faster than other multi-label methods.
experimental results show that our methods produce competitive results.
this allows the classification process to inherently take into account correlations between labels.
learning from the past with experiment databases.
in conjunction with the target class, this artificial class is the basis for a standard two-class learning problem.
the method allows the use of phmms discriminatively in a classification task.
aft enhances how a simple image feature of a signature is converted to a binary feature vector by significantly improving its representation in relation to the training signatures.
this approach works by partitioning the image into smaller regions then computing the spatial relationships between all of the informative image keypoints in the region.
we also compare the method to one-class classification using support vector machines.
for some datasets it significantly improves on both techniques.
experimental results show that our methods produce competitive results.
although miles provides competitive performance when compared to other mi learners, we identify simpler propositionaliza- tion methods that require shorter training times while retaining miles' strong classification performance on the datasets we tested.
this includes first confirming that machine learning algorithms can be integrated into a modern computer game without have a detrimental effect on game performance, then experimenting with different machine learning techniques to maximize the computer player's performance.
in this paper, we hope to stimulate the development of such learning experiment repositories by providing a bird's-eye view of how they can be created and used in practice, bringing together existing approaches and new ideas.
however, if known non-target classes are available at training time, it is also possible to use standard multi-class or two-class classification, exploiting the negative data to infer a description of the target class.
static models show the highest initial performance but are not able to beat a simple opponent.
reinforcement learning methods have the highest rate of improvement but the lowest initial performance.
most alignment representations are designed to facilitate knowledge extraction by human experts.
additionally statistical models like profile hidden markov models are used as representations.
in this paper, we hope to stimulate the development of such learning experiment repositories by providing a bird's-eye view of how they can be created and used in practice, bringing together existing approaches and new ideas.