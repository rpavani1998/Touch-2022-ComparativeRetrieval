it all depends on how well the model builder works on your data, and, in fact, how you measure the performance on the model.
so, in conclusion, it is good to build multiple models using multiple model builders.
clustered box plot further resources map displays further resources preparing data data selection and extraction training and test datasets data cleaning review data selectively changing vector values replace indices by names missing values remove levels from a factor variable manipulations remove columns reorder columns remove non-numeric columns remove variables with no variance cleaning the wine dataset cleaning the cardiac dataset cleaning the survey dataset imputation nearest neighbours
the business problem solar panel efficiency water collection others other business problems fraud detection loan approval documenting the business problem summary resources exercises data data nomenclature loading data into rattle csv data datasets reading direct from url play golf weather data
the pdf version is a formatted comprehensive draft book (with over 800 pages).
a notable exception is the study by caruana and niculescu-mizil, who compared most modern model builders across numerous datasets using a variety of performance measures.
the current rattle state samples projects the rattle log further tuning models emacs and ess documenting code review chapter exercises command summary r evaluation exercises assignment libraries and packages searching for objects package management information about a package testing package availability packages and namespaces basic programming in r principles folders and files flow control
the key conclusion, they found, was that boosted trees and random forests generally perform the best, and that decision trees, logistic regression and boosted stumps generally perform the worst.
the tricky bits are tuning the model builders (requiring an understanding of the sometimes very many and very complex model builder parameters) and selecting the right criteria to assess the performance of the model (a criteria to match the task at hand--noting that raw accuracy is not always, and maybe not often, the right criteria).
getting started initial interaction with r quitting rattle and r first contact loading a dataset building a model understanding our data evaluating the model evaluating the model interacting with r interacting with rattle projects toolbar menus interacting with plots keyboard navigation summary command summary
it all depends on how well the model builder works on your data, and, in fact, how you measure the performance on the model.
formatted output automatically generate filenames reading a large file manipulating data manipulating data as sql using sqlite odbc data database connection excel access clipboard data spatial data simple map
clustered box plot further resources map displays further resources preparing data data selection and extraction training and test datasets data cleaning review data selectively changing vector values replace indices by names missing values remove levels from a factor variable manipulations remove columns reorder columns remove non-numeric columns remove variables with no variance cleaning the wine dataset cleaning the cardiac dataset cleaning the survey dataset imputation nearest neighbours
for example, if the task is one of information retrieval then a precision/recall measure may be best.
an overall conclusion from such comparative studies, then, is that often it is best to deploy different model builders over the dataset to investigate which performs the best.
so, in conclusion, it is good to build multiple models using multiple model builders.
a density map overlays and point in polygon other data formats fixed width data global positioning system documenting a dataset common data problems graphics in r basic plot controlling axes arrow axes legends and points tables within plots colour labels in plots axis labels legend labels within plots maths in labels multiple plots matplot multiple plots using ggplot2 using ggplot networks symbols other graphic elements making an animation animated mandelbrot adding a logo to a graphic graphics devices setup screen devices multiple devices file devices multiple plots copy and print devices graphics parameters plotting region locating points on a plot scientific notation and plots understanding data single variable overviews textual summaries multiple line plots separate line plots pie chart fan plot stem and leaf plots histogram barplot trellis histogram histogram uneven distribution bump chart density plot basic histogram basic histogram with density curve practical histogram multiple variable overviews scatterplot scatterplot with marginal histograms multi-dimension scatterplot correlation plot colourful correlations fluctuation plot heat map projection pursuit radviz parallel coordinates categoric and numeric measuring data distributions textual summaries boxplot multiple boxplots boxplot by class tuning a boxplot boxplot using lattice boxplot using ggplot violin plot
basic clustering hot spots alternative clustering other cluster examples kmeans export kmeans clusters discriminant coordinates plot number of clusters hierarchical clusters
perhaps more importantly though, it often depends on what is being measured as the performance criteria, and on the characteristics of the data being modelled.
the iris dataset csv data used in the book the wine dataset the cardiac arrhythmia dataset the adult survey dataset foreign formats stata data conversions reading variable width data saving data
a factor has new levels issues model selection overfitting imbalanced classification sampling cost based learning model deployment and interoperability sql pmml xml for data bibliographic notes documenting code review chapter exercises command summary moving into r interacting with r basic command line windows, icons, mouse, pointer--wimp
the current rattle state samples projects the rattle log further tuning models emacs and ess documenting code review chapter exercises command summary r evaluation exercises assignment libraries and packages searching for objects package management information about a package testing package availability packages and namespaces basic programming in r principles folders and files flow control
for example, if the task is one of information retrieval then a precision/recall measure may be best.
an overall conclusion from such comparative studies, then, is that often it is best to deploy different model builders over the dataset to investigate which performs the best.
reverse a list sorting unique values loading data interactive responses interactive data entry available datasets
the business problem solar panel efficiency water collection others other business problems fraud detection loan approval documenting the business problem summary resources exercises data data nomenclature loading data into rattle csv data datasets reading direct from url play golf weather data
further information summary overview example algorithm resources and further reading bagging support vector machine formalities tutorial example tuning parameters examples resources and further reading overview examples resources and further reading linear regression
for risk assessment, the risk charts are a good measure.
the pdf version is a formatted comprehensive draft book (with over 800 pages).
a notable exception is the study by caruana and niculescu-mizil, who compared most modern model builders across numerous datasets using a variety of performance measures.
the iris dataset csv data used in the book the wine dataset the cardiac arrhythmia dataset the adult survey dataset foreign formats stata data conversions reading variable width data saving data formatted output automatically generate filenames reading a large file manipulating data manipulating data as sql using sqlite odbc data database connection excel access clipboard data spatial data simple map a density map overlays and point in polygon other data formats fixed width data global positioning system documenting a dataset common data problems graphics in r basic plot controlling axes arrow axes legends and points tables within plots colour labels in plots axis labels legend labels within plots maths in labels multiple plots matplot multiple plots using ggplot2 using ggplot networks symbols other graphic elements making an animation animated mandelbrot adding a logo to a graphic graphics devices setup screen devices multiple devices file devices multiple plots copy and print devices graphics parameters plotting region locating points on a plot scientific notation and plots understanding data single variable overviews textual summaries multiple line plots separate line plots pie chart fan plot stem and leaf plots histogram barplot trellis histogram histogram uneven distribution bump chart density plot basic histogram basic histogram with density curve practical histogram multiple variable overviews scatterplot scatterplot with marginal histograms multi-dimension scatterplot correlation plot colourful correlations fluctuation plot heat map projection pursuit radviz parallel coordinates categoric and numeric measuring data distributions textual summaries boxplot multiple boxplots boxplot by class tuning a boxplot boxplot using lattice boxplot using ggplot violin plot
a factor has new levels issues model selection overfitting imbalanced classification sampling cost based learning model deployment and interoperability sql pmml xml for data bibliographic notes documenting code review chapter exercises command summary moving into r interacting with r basic command line windows, icons, mouse, pointer--wimp
perhaps more importantly though, it often depends on what is being measured as the performance criteria, and on the characteristics of the data being modelled.
the key conclusion, they found, was that boosted trees and random forests generally perform the best, and that decision trees, logistic regression and boosted stumps generally perform the worst.
if statement for loop functions apply methods objects system running system commands system parameters misc internet memory management memory usage garbage collection errors frivolous sudoku further resources using r specific purposes survey analysis getting help
data preparation number of algorithms repeatability performance open source data mining business case sample business case pros and cons books on r getting started initial interaction with r quitting rattle and r first contact loading a dataset building a model understanding our data evaluating the model evaluating the model interacting with r interacting with rattle projects toolbar menus interacting with plots keyboard navigation summary command summary
the tricky bits are tuning the model builders (requiring an understanding of the sometimes very many and very complex model builder parameters) and selecting the right criteria to assess the performance of the model (a criteria to match the task at hand--noting that raw accuracy is not always, and maybe not often, the right criteria).
for risk assessment, the risk charts are a good measure.
this is better than a single shot at the bullseye.