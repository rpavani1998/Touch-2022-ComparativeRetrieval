when personal bankruptcy rules became easier in  certain countries, notably in the us, it became apparent that the performance  of borrowers before they sought bankruptcy was different from those who just  defaulted on their loan.
the previous discussion though highlighted the  credit-rating agencies failure to assess the risk of consumer asset-backed  securities and the basel requirements to stress test portfolios of consumer  loans.
both are interested in maximising the profit for the organisation by  making decisions about potential and actual customers; both use statistical  methods to segment the population and to predict how likely the customer is to  perform certain events—be it purchasing a new financial product or  defaulting on an existing loan.
for example, there are classification trees in which some of the variables are a 'score' obtained using another method.
j r  stat soc b 34: 187–220.
in credit cards, this would mean varying the  interest rate charged, the credit limit offered, whether an annual fee is  charged and whether bonuses such as air miles are given for purchases made with  the card.
thus, currently lgd modelling is like estimating  a moving target.
similar ideas were previously used to identify how the likelihood of purchasing financial products depends both on the characteristics of the customer and on economic conditions (tang et al , 2007).
therefore, once again the target variable was whether the borrower would default in the next 12 months, but now it was possible to use information on the borrower's recent (usually last 12 months) repayment and purchase performance.
in the competing risk approach, one has several ways in which a loan could  finish—default, early repayment, normal repayment—and one can model  each of these separately using the fact that as far as a default is concerned,  a borrower who pays off early at timet has a history censored at that  time.
search this journal all content  advanced search journal home  >  archive  >  special issue papers  > full text special issue paper journal of the operational research society (2010) 61, 41–52.
j risk model validation 2 (3): 11–47.
the accord is presenting four challenges to credit scoring—the  internal ratings approach to consumer lending.
|  article | openurl stepanova m and thomas lc (2002).
in the proportional hazard  model, the hazard function for default at time periodt into the loan for  a borrower with characteristicsx decomposes into the product of the  baseline hazard function multiplied by an enhanced risk due to the borrower's  characteristics, namely, hence, s(x) can be considered as a risk score in that the  higher the score the less likely the borrower is to default.
j opl res soc 52: 1007–1016.
although a system that assessed the profitability of the customer is the aim of many lenders, this is proving hard to implement.
both these show the need for such risk assessment also to be modelled at the portfolio level.
these ideas have been developing over the past decade ( banasik et al , 1999; stepanova and thomas, 2001, 2002), and are now being taken on board by practitioners.
| article | openurl baesens b, van gestel t, viaene s, stepanova m, suykens j and vanthienen  j (2003b).
it considered data on applicants of 2 years ago, and looked at their performance over the subsequent year.
| article | openurl rosch d and scheule h (2008).
separating financial from commercial  customer churn: a modeling step towards resolving the conflict between the  sales and credit department.
this model can  work both as a parametric model in which the baseline hazard function is of a  specific family of distributions or semi parametrically using the results ofcox  (1972).
this is only to be expected if we recall the decomposition of the credit score in(6).
after sometime, the process is repeated and a new scorecard is constructed.
so, what methodology results in a scorecard with the best discrimination in credit scoring?
e-mail:l.thomas@soton.ac.uk received 8 june 2009; accepted 30 july 2009.
these characteristics include socio-economic data such as age and residential status; credit bureau information such as whether the applicant is on the electoral role; and in the case of behavioural scores, performance data such as the number of missed payments in the last 12 months.
the critical issue is  how to build a model of the credit risk of portfolios of consumer loans, which  includes economic and market conditions and so can then be run under the  extreme scenarios suggested by the regulators.
basel committee on banking supervision (bcbs) (2005a, comprehensive  version 2006).international convergence of capital measurement and capital  standards – a revised framework.
the first term on the rhs of (6) is the 'prior' score—the score of a randomly selected individual from  the population; this score is then increased or decreased by the score that is  based on the data that are unique to a particular individual.
however, the idea that a new methodology will produce far better discrimination using existing characteristics than the current methods is questioned by many experts.
whereas in many retail environments the horizon may be just until the next purchase or possibly just for a few years, in the consumer finance area, lifetime can really mean lifetime—pension products for example.
it considered data on applicants of 2 years ago, and  looked at their performance over the subsequent year.
there are also affordability issues, as the  interest rate charged can affect the ability of the borrower to repay, as was  seen in the subprime mortgage crisis, in which many of the borrowers only  defaulted when the interest rates went from the initial low rates to the higher  rates that came in after 2 or 3 years of the loan.
the models forecast how likely the applicant for credit is to be 'bad' and to default on the loan within a given time period.
currently, these groups see themselves as adversaries, with one group wanting to take as many applicants as they can and the other to be as discriminating as possible about who they take.
expert syst appl 36:  10475–10484.
cgfs publication 24, basel.
huang et al, 2007; bellotti and crook, 2009), genetic  algorithms (desai et al, 1997; ong et al, 2005), nearest  neighbour methods (chatterjee and barcun, 1970; henley and hand, 1997) and ant  colony optimisation (martens et al, 2007).
as many  researchers have for more than a decade addressed these problems in corporate  lending, it is reasonable to expect they will expand their research to the  consumer lending case.
still, that does not  stop people from trying, although it would be more useful if the experiments  were carried out on the sizes of samples, 10 000–50 000,  usually used in scorecard building, rather than on the small samples of less  than 1000, which are easily available in public literature.
until then, despite its importance to the individual consumer, and the fact that it was using an increasing number of those who had trained in operational research (or) and statistics, the modelling underlying it was hardly discussed in any finance course, and the number of research papers in the area was minute compared with that on the corporate credit market or on the pricing of exotic equity-based options.
overstreet ga, bradley el and kemp jr rs, (1992).
donkers et al (2007) made a comparison of a number of different  types of customer lifetime value models using insurance industry data, while verhoef and donkers (2001) made the comparison between choice-based probit  models and potential value regression type models.
lenders want to optimise all the decisions they make about the borrower, not just whether or not to offer the borrower a standard loan product.
one advantage of the survival analysis approach is that the competing risk  idea means that one can use the same data to estimate several different events.
this is a much faster-moving  environment than that for normal loans, as the loans are of such short  durations, and their repayment depends on the borrower's ability and desire to  pay back the loan that month.
translating from point-in-time default rates to through the cycle default rates highlights the time dependency of a score which we outlined in challenge 2.
the second variant of credit scoring, behavioural scoring, was introduced  in the 1980s when it was thought to be useful to assess the credit risk of  existing customers, as well as new applicants.
an alternative would have been to build a  dynamic model of how a customer has been performing, which would allow one to  forecast the future dynamic behaviour of the customer.
it is similar to a sufficient  statistic.
this final challenge is an obvious extension of challenge 9.
research paper ers-2001-01-mkt  revision, erasmus research institute of management (erim).
before doing so, it is worth recalling what a credit score is and what properties it has.
top of page top journal of the operational research society issn: 0160-5682 eissn: 1476-9360 copyright © 2012 palgrave macmillan, a division of macmillan publishers limited.
these are  still challenges for or in this area but the subprime mortgage crisis, the  failure of the ratings agencies to assess the risk of residential  mortgage-backed securities, and the consequent credit crunch, requires a  reassessment of some of the quantitative models that had proved so successful  up to then.
working paper (2008), available at the social science research network.
it's the economy  stupid: modelling financial product purchases.
moreover such loans are increasingly receiving special legislation which requires proof that their risk-assessment systems are robust.
those borrowers  who do not default on the loan within the chosen time period are 'good'.
kegan paul and co.: london, pp viii, 150.
credit scoring and its  applications.
incorporating economic information into credit risk  underwriting in (1998).
studies on the  validation of internal rating systems.
the work on modelling the collections  process for mortgage lending is directly motivated by basel (lucas, 2006).
what often happens is that the paper that introduces a new method can show that there is some small improvement by using it rather than using an existing method, but one is always slightly concerned that this may be down to the expertise of the authors in their own method and the fact that they do not take such care with existing methods.
| article | openurl banasik j, crook jn and thomas lc (1999).
eur j opl res 183: 1569–1581.
the other factor that has been affecting credit scoring in the past few years is the change in banking regulations introduced by the basel ii accord ( basel committee on bank supervision, 2005a).
the approach also assumed that the relationship between loan/borrower characteristics and credit worthiness was stable at least over a 4- of 5-year period.
even in  the initial decision, lenders now have a number of variants of a loan product  they can offer, be it platinum, gold, silver or standard credit cards, or  tracker, fixed rate and variable rate mortgages, and within each they can  decide what credit limit to offer and what interest rate and fee (the price  components) to charge.
log odds scores are produced  when one uses logistic regression to determine the classification scorecard but  can also be obtained from other approaches by scaling, therefore it is  reasonable to assume a scorecard has such a property.
researchers are beginning to address different ways of building models of the credit risk for portfolios of consumer loans, which can then be used for stress testing (breeden, 2007; breeden et al, 2008; rosch and scheule, 2008; malik and thomas, 2009b).
one can do this by sensitivity analysis in which one  changes the value of one of the factors that impacts on the model, or by  scenario analysis.
the problem of finding the optimal price at which to sell a product has  been around for many years.
this involves estimating how the score s(t,x) changes over time, which brings us back to challenge 2.
cormsis, university of southampton.
j opl res soc 54: 627–635. | article | openurl baesens b, verstraeten g, van den
this  should mean that consumer finance will have a much higher profile in university  finance and operational research courses in the future, so that entrants to the  finance industry are aware of the need for models and the challenges of  building models to solve the problems in this area.
(in 2007, it was estimated that the number of  credit cards and debit cards in circulation worldwide exceeded three billion.
a proper or sufficient score s(x) captures as much  information for predicting the probability of a performance outcome, say  good/bad, as does the original data vector,x, so that when appropriate we will drop the x dependence of the score and write one form of a score is the log odds score, where hence, a log odds score could have values from minus infinity (when p(g| x)=0) to plus infinity when (p(g|x)=1).
| article |  openurl verhoef pc and donkers acd (2001).
the aim of these actions, however, is to improve the profitability of the customer, but there might be other measures rather than default risk in the next 12 months, which give a better handle on profit.
|  article | openurl
similarly there needs to be much more empirical work on what are appropriate take probability functions.
secondly, the detailed investigations of the subprime mortgage crisis showed that the credit scores changed as the economic conditions worsened ( demyanyk and van hemert, 2008).
| article | openurl bellotti t and crook jn (2009).
it  is easy then to see that, given the hazard function, we can calculate the  probability of default over any time period because if one uses the proportional hazards or accelerated life models of  survival analysis, one is able to obtain a score that describes the 'risk' of a  consumer defaulting over any and all time horizons.
university of southampton, to appear inproduction and operation management.
one could argue that the pricing models of challenge 4 are a start but the marketing aspects of the model are not widely used, apart from the work on multiple features in credit cards ( thomaset al, 2006).
initially, it was used by mail-order companies and finance houses and only after the advent of credit cards did banks start using it—firstly for credit cards, then for personal loans and finally for mortgages.
(in 2007, it was estimated that the number of credit cards and debit cards in circulation worldwide exceeded three billion.
| isi | crook jn, edelman db and thomas lc (2007).
its philosophy was pragmatic, in that it only wanted to predict, not explain, and hence used any characteristic that improved the discriminating power of the system.
working paper 14, basel.
the edited book by altmanet al (2005) outlines the mainly regression-based models that seek  to relate rrs to economic factors and characteristics of the loan and the  defaulter in the corporate setting.
thomson south western: mason ohio.
the accord requires its ratings to have many of the properties of the existing credit-scoring systems.
all seem to give correlations between actual and predicted  values of no better than 0.1–0.2.
this suggests that the probability of default does vary, as economic conditions vary, even if the credit worthiness of the borrower is not changing and has required some ingenuity by lenders to translate a credit score, which is clearly a point in time (pit) estimate, into the through the cycle (ttc) estimate.
eur j opl res 156:  508–523.
thus, one needs  to build scorecards that can respond very quickly to changes in economic and  market behaviour and to immediate changes in the borrower's behaviour, and  circumstances.
one real change in defining good/bad in the last few years is the use of survival analysis ideas to allow the estimation of a borrower's default risk over any future time horizon, not just a fixed 12 months.
introduced in europe in 2007/2008, in the us in 2009 and scheduled to be introduced in most countries between 2008 and 2012, it was a response to the distortions in lending caused by the first accord of 1988, rather than a response to the credit crunch.
similarly there needs to be  much more empirical work on what are appropriate take probability functions.
mngt sci  49: 312–329.
moreover, laws such as the equal credit opportunity acts in the us have outlawed discrimination in the giving of credit unless there are statistical models that can defend such decisions.
the traditional way of defining a bad was a borrower who became 90 days  overdue in the next 12 months.
there is a sumerian clay tablet recording how two farmers borrowed money to purchase grain with the promise of paying back more at harvest time.
pricing and revenue optimization.
such games could involve a number of  buyers—the borrowers in this case—and sellers—the  lenders—and the use of game theory to model such pricing situations has a  long history from edgeworth's work on market games in 1881 (edgeworth, 1881) to  gibbens and kelly's work on pricing the internet (gibbens and kelly, 1999)
benefits of quantile regression for  the analysis of customer lifetime value in a contractual setting: an  application in financial services.
as many researchers have for more than a decade addressed these problems in corporate lending, it is reasonable to expect they will expand their research to the consumer lending case.
this is the pit estimate, but what one needs to do is get a ttc estimate, which if the cycle is of lengtht starting say at time t0 would be
however, that does not prevent building credit risk models for portfolios of consumer loans, which have strong parallels with the corporate portfolio models (thomas, 2009b).
in particular, the lack of models for the credit risk of portfolios of consumer loans and not modelling how economic conditions affect credit scores is now recognised as having exacerbated the credit crunch of 2008/2009.
an alternative would have been to build a dynamic model of how a customer has been performing, which would allow one to forecast the future dynamic behaviour of the customer.
initially, it was used by mail-order companies and finance houses and only  after the advent of credit cards did banks start using it—firstly for  credit cards, then for personal loans and finally for mortgages.
since there is clearly some dependence between defaults of different individuals, and often the number of defaults are very low, one needs to develop sophisticated models to cope with these problems (benjamin et al , 2006).
the approach also assumed that the relationship between  loan/borrower characteristics and credit worthiness was stable at least over a  4- of 5-year period.
| article |  openurl bank of international settlements (2005).
in the accelerated life model, one can only use the parametric approach,  but the assumption is that the probability of a borrower with characteristics x not defaulting before time t(pg(t,x))
the tremendous increase in computer storage capacity and the requirement of  the basel accord that banks have sufficient historical data to validate their  credit scoring models have meant that banks are now willing and able to store  much more consumer finance data over much longer periods than they used to do.
one of the simplest schemes would be to adjust the interest rate charged, r, to be a function of the probability, p, of the applicant being a good.
there are also affordability issues, as the interest rate charged can affect the ability of the borrower to repay, as was seen in the subprime mortgage crisis, in which many of the borrowers only defaulted when the interest rates went from the initial low rates to the higher rates that came in after 2 or 3 years of the loan.
challenge 1: finding the 'silver bullet' or is there a better way to build  risk-assessment systems discriminant analysis was the first method by which scorecards were built  (seeeisenbeis (1978) for a critique of its use in credit scoring), but by the  early 1980s, the growth in computer power meant that logistic regression had  taken over as the main way by which commercial scorecards were built (mays, 2004 ;anderson, 2007).
in fact, it is only worthwhile for banks to move to these internal ratings-based systems, if they use them for their consumer lending, as the main saving in capital compared with the alternative externally imposed capital ratios is in consumer lending.
to do this, one needs to estimate customer lifetime value.
yet  there is a need to ensure that the credit loaned is repaid, even if the time  periods involved may be very long—several years if not decades—and  there is a need to assess both the character of the individual and the  potential of the idea that the loan will initially fund.
as was suggested in challenge 6,  several models are being developed, all of which include economic conditions as  part of the model.
credit scoring  models in the credit union environment using neural networks and genetic  algorithms.
it is similar to a sufficient statistic.
| article |  openurl
freed n and glover f (1981).
a survey of credit and behavioural scoring; forecasting  financial risk of lending to consumers.
borrowing went up more than 350% in that time, and even with the housing crisis of 2007 and 2008, the amount outstanding on mortgage loans is still more than £1.2 trillion.
we assume that each consumer, be it an applicant in the case of an application score or a current borrower in the case of a behavioural score, can be described by a set of characteristicsx=(x1,x2,...,x m), xx, where x is the set of all possible borrower characteristic combinations.
jors.2009.104 consumer finance: challenges for operational research l c thomas1 1school of management, university of southampton, southampton, uk correspondence:
so, not only is  it proving difficult to get reasonable estimates of lgd and rr using existing  data, but building models to optimise or at least improve the collections  process is likely to mean that rrs in the future will be significantly improved  on those found in these data.
so, not only is it proving difficult to get reasonable estimates of lgd and rr using existing data, but building models to optimise or at least improve the collections process is likely to mean that rrs in the future will be significantly improved on those found in these data.
| article | openurl breeden jl (2007).
resource pricing and the evolution of  congestion control.
however, that does not prevent building credit risk models  for portfolios of consumer loans, which have strong parallels with the  corporate portfolio models (thomas, 2009b).
marketing engineering.
although behavioural scoring was an obvious extension of application scoring,  it was also an opportunity missed.
although there  have been several surveys of what stress testing banks currently do (bis, 2005;  fsa, 2005), these point out to the lack of a consistent stress-testing  methodology for credit risk as opposed to market risk.
clearly, standard risk-assessment systems cannot work for people who have no history of being advanced credit previously and no involvement with a banking system.
more emphasis was being put by lenders on the use of or  models in the marketing of these products, since the traditional approach of  one market 'price' (namely the interest rate being charged on the loan) was  giving way to variable pricing.
eur j opl res 136:  190–211.
it is true that some methods performed slightly better than others—neural nets, support vector machines, logistic regression—but the differences were small and often the hypothesis that two scorecards were equally good at discriminating could not be rejected.
a nonparametric approach to credit  screening.
if we include the time at which the score is being used, then what we require at timet is the score s( x,t)=spop(t)+sinf(x,t ).
top of page conclusion given the turmoil in the financial markets during 2007 and 2008, which has  at last made practitioners and researchers realise how large a proportion of  the banking industry is based on consumer lending, there is no question that  research in this area will be very active for the foreseeable future.
rosch d and scheule h (2003).
eur j opl res 183:  1477–1487.
the type of marketing models that can be used in consumer finance can be found in examples such aslilien and rangaswamy (2004).
there had been little analytic modelling of the collections process for any  form of lending until the advent of the basel accord.
this assumption has been challenged in  the last few years, first by the basel accord, which makes a point that its  definition of probability of default is a long-run average (ie averaging over a  full economic cycle) and not just the point in time probability of default.
both these show the need for such risk assessment also to be modelled at  the portfolio level.
the initial approaches  have looked at linear and logistic regression, non-linear transformation so as  to fit beta or log-log distributions, mixture models (especially to identify  the 'won't pay' (lgd=1), and even quantile regression ideas (somers and  whittaker, 2007).
for example, there are some marketing models that seek to assess the 'emotions' of the customer from their interactions with the company (coussement and van den poel, 2009) but there is no risk-assessment model that includes the customers 'emotions'.
principles and practice of consumer credit  risk management.
borrowing went up more than 350% in that time, and even with the housing crisis  of 2007 and 2008, the amount outstanding on mortgage loans is still more than  £1.2 trillion.
one way that lenders are seeking to increase their profit is by offering generic loan products such as credit cards, but by tailoring the details of the product for each individual.
one is to estimate the response function (the take probability) as above, whereas the second is to model the situation as a game.
ong cs, haung jj and tzeng g (2005).
consumer credit has been around for 4000 years.
similarly, one might have a regression approach in which one characteristic is the different nodes of a classification tree.
the models used by marketers to segment customers  and to estimate propensity of purchase are very similar to the ones used by the  risk teams to determine how many different scorecards to develop and then to  estimate the likelihood of default for each customer.
challenge 8: modelling loss given default and the collection process
cox showed that one can first calculate the score without making any assumptions about the distribution and then use the kaplan meier approach to estimate the empirical distribution forh0(t) that best fits the data.
donkers b, verhoef p and jong m (2007).
figure 1 shows how the total household borrowing in the us overtook that of total business borrowing in the late 1980s, and that by 2004 the total borrowing on mortgages had also exceeded the total business borrowing, although that has drawn level again in 2008.figure 2 similarly shows the growth in consumer borrowing in the uk in the 15 years since 1992.
such scores are now used by almost all lenders and are routinely updated each month.
it also presupposes that the score to probability of default transformation stays as a log odds transformation and ignores what happens when scores are recalibrated during the cycle.
thomas lc, edelman db and crook jn (2004).
a second challenge is that the accord requires estimates of the long-run average of the 12-month default rate (the ttc default rate) for a segment of borrowers while a credit score estimates the default rate in the next 12 months (the pit estimate).
one of the most surprising aspects of consumer lending in most financial organisations is the lack of integration between the marketing and credit risk groups.
expert syst appl 30: 507–518.
specifying the score of an event is equivalent to specifying its probability because we can write the probability in terms of the score: one interesting feature of a log odds score is that it separates out completely the information about the population from information about the individual borrower being scored.
if the take probability or response rate of an applicant to a loan offer with interest rater is q(r), then the expected profit to the lender of making an offerr is differentiating (11) and setting the derivative to zero gives where we assume that s is a log odds application score
challenge 5: expanding approaches to deal with new forms of credit granting as well as new modelling challenges in existing forms of credit granting  there are new types of loans that need risk-assessment systems that are  different from those that have worked for personal loans, credit cards and  mortgages.
what we have is s(x,t0)=spop(t0 )
instead, what has  happened is that lenders score separately a number of the events that affect  profitability.
financial services authority (2005).
in the proportional hazard model, the hazard function for default at time periodt into the loan for a borrower with characteristicsx decomposes into the product of the baseline hazard function multiplied by an enhanced risk due to the borrower's characteristics, namely, hence, s(x) can be considered as a risk score in that the higher the score the less likely the borrower is to default.
in the latter approach one identifies a combination of the overall conditions that can lead to poor economic performance.
this model splits the problem into whether the mortgaged property needs to be repossessed and then into forecasting what price the property will be sold for.
siam: philadelphia, us.
|  article | openurl van den poel d and larivière b (2004).
j am stat assoc 65: 150–154.
thus, one needs to build lifetime value models that can cope with the changes in economic and market conditions over long time intervals as well as forecasting the changes in the customer's situation and priorities.
is the chance a consumer rated low will be good.
| article | openurl gibbens rj and kelly fp (1999).
one could argue that the pricing  models of challenge 4 are a start but the marketing aspects of the model are  not widely used, apart from the work on multiple features in credit cards ( thomaset al, 2006).
all these models  concentrate on the purchase aspects—time to and value of next purchase  and churn—and do not include the default risk elements that can affect  profitability in a major way.
whether the loan was profitable to the lender, whether the borrower would continue to repay beyond this period, how much the borrower used the loan facility—none of these risks were considered.
basel  committee on banking supervision, basel, pp 60–76.
secondly, the detailed investigations of the subprime mortgage crisis  showed that the credit scores changed as the economic conditions worsened ( demyanyk and van hemert, 2008).
this is not  possible nor sensible for portfolios of consumer loans as default there does  not depend on the value of assets but on cash flow considerations and personal  attitudes to debt.
cox showed that one can first calculate the score without making any  assumptions about the distribution and then use the kaplan meier approach to  estimate the empirical distribution forh0(t) that best fits the  data.
the credit scoring toolkit theory and practice for  retail credit risk management and decision automation.
therefore, once again the target  variable was whether the borrower would default in the next 12 months, but now  it was possible to use information on the borrower's recent (usually last 12  months) repayment and purchase performance.
expert syst appl 28: 743–752.
process scoring for micro credit loans,  http://www.few.vu.nl/stagebureau/stage/stageverslagen/stageverslag-mokg.pdf.
| article | openurl burez j and van den poel d (2008).
a third problem is the basel accord's instance on stress testing, which means predicting the future performance of a portfolio of loans under extreme economic conditions.
for a log odds score, equation(4) shows how this probability is related to the credit score of the applicant.
li and hand (2002) suggested that  instead of assessing default risk directly, one should try to predict future  values of other aspects of the borrower's performance, such as the balance on  the account, and then from these estimate the risk of default.
even in the initial decision, lenders now have a number of variants of a loan product they can offer, be it platinum, gold, silver or standard credit cards, or tracker, fixed rate and variable rate mortgages, and within each they can decide what credit limit to offer and what interest rate and fee (the price components) to charge.
| article | openurl malik m and thomas lc (2009a).
building credit scoring models using  genetic programming.
one of the simplest schemes would be to adjust the interest rate charged, r, to be a function of the probability, p, of the applicant being  a good.
is given by or where again s(x) is the equivalent of a risk score.
classification and  regression trees.
in the accelerated life model, one can only use the parametric approach, but the assumption is that the probability of a borrower with characteristics x not defaulting before time t(pg(t,x)) is given by or where again s(x) is the equivalent of a risk score.
so if t is the time when default occurs, pb (t) is the probability that there has been default by time t,  (pb'(t) its derivative) and pg(t)=1- pb(t), then: this is not the probability that a borrower will default at a time t into the loan but rather the probability that given the fact that the borrower  is still active at timet, he will default in the next period of time.
the problem of finding the optimal price at which to sell a product has been around for many years.
buckinx et al (2007) use the transactional  information to estimate the customer loyalty to the organisation, whilevan den  poel and larivière (2004) model which product features prevent customers  churning to another organisation.
this is only to be expected if we recall the  decomposition of the credit score in(6).
thus, bankruptcy scores were developed where a bad was  someone who went bankrupt in the next 12 months.
bayesian kernel based classification for financial distress  detection.
similarly, one might  have a regression approach in which one characteristic is the different nodes  of a classification tree.
there is very little  mathematical modelling of what are appropriate variable rate functions to  charge apart from phillips's book (phillips, 2005).
in survival analysis,  one is interested in estimating the default hazard rate,h(t),  whereh(t)t is the conditional probability of  default in (t,t+t], given there has been no default  in (0,t].
demyanyk y and van hemert
quant marketing econ 5:  163–190.
this performance was used to determine whether the applicant was bad (the specific risk occurred) or good (it did not occur).
| article | openurl li hg and hand dj (2002).
as there are so many  combinations that could be considered, there are experimental design problems  for any lender to obtain this sort of information efficiently.
construction of a k-nearest neighbour  credit scoring system.
malik m and thomas lc (2009b).
moreover, profitability is as much about marketing as about risk assessment, and hence there is a need to combine the work done by financial organisations' marketing and risk assessment or groups.
with approaches such as the competing risk idea  in survival analysis it should be possible to combine these two major factors  that affect customer profitability.
lookahead scorecards for new fixed term  credit products.
the loan is taken out usually at the  middle or towards the end of the month and the lender is given a post-dated  cheque or a way of accessing the borrower's current account on the day the pay  cheque is paid in at the end of the month.
transition matrix models for consumer  credit ratings.
portfolio-level credit risk models were developed more than a decade ago for corporate loans with models that allowed the correlation in share prices to be surrogates for the correlation in defaults.
the accord requires its ratings to have many of  the properties of the existing credit-scoring systems.
for example, many of the newer  methods essentially construct non-linear scorecards with interactions between  characteristics, but experts in the linear approaches to credit scorecard  building—logistic and linear regression—tend to know from  experience about such interactions and allow for them by building separate  scorecards for different segments of the population or by introducing  interaction variables.
recently, there has been some initial work on how one would need to modify standard credit scoring systems to deal with these questions (mok, 2008).
+sinf(x,t0), where t0 is the time at which the sample on which the scorecard was built was performing.
evaluating alternative linear programming  models to solve the two-group discriminant problem.
still, that does not stop people from trying, although it would be more useful if the experiments were carried out on the sizes of samples, 10 000–50 000, usually used in scorecard building, rather than on the small samples of less than 1000, which are easily available in public literature.
| article | openurl tang ll, thomas lc, thomas s and bozzetto j-f (2007).
eur j opl res 172: 979–1003.
this is because of adverse selection ( ausubel, 1999; calem et al, 2006) in which more bads apply for consumer credit at higher interest rates than might be expected.
modelling consumer  acceptance probabilities.
usage scores assess how much a borrower will use the loan  product.
|  article | openurl calem ps, gordy mb and mester lj (2006).
before this, there had been some work on estimating rrs in  corporate lending as these affect the price of risky bonds.
the united  nations declared 2005 to be the international year of microcredit.
cib publishing: canterbury.
i j forecasting 16:  149–172.
similar ideas were previously used to  identify how the likelihood of purchasing financial products depends both on  the characteristics of the customer and on economic conditions (tang et al , 2007).
one can  model purchasing as well as attrition and default events separately and then  seek to combine them to get a customer lifetime value approach (challenge 10).
li and hand (2002) suggested that instead of assessing default risk directly, one should try to predict future values of other aspects of the borrower's performance, such as the balance on the account, and then from these estimate the risk of default.
readings in credit scoring.
another popular alternative is to use classification trees, with  its origins both in statistics (breiman et al, 1984) and machine  learning (quinlan, 1993), although this of course ends up not with a scorecard  but with groups of customers described by combinations of their  characteristics, where each group is classified as either good or bad.
such an indirect approach requires both that the intermediate elements be predicted well and that there is a strong relationship between them and the default risk.
proportional hazards  analysis behavioural scores.
fitzroy dearborn publishers: chicago, pp.
j ban financ 30:  1653–1685.
the second variant of credit scoring, behavioural scoring, was introduced in the 1980s when it was thought to be useful to assess the credit risk of existing customers, as well as new applicants.
in the past few years, credit scoring had been changing, as lenders want  credit scoring to support their business objectives of profitability and market  share.
consider a very simple example where 1 unit is lent, the cost of capital for the lender isrf (the risk free rate), the loss given default (the fraction of the amount outstanding at default which is finally lost) isld, and the lender will charge an interest rater(p), which is related to the probability p of the applicant being a good.
forecasting retail portfolio credit risk.
as mentioned in challenge 2, survival analysis can also be used to introduce economic conditions into scorecards.
such two-stage models could also be used for other secured loans like car  finance.
comput  stat data an 51: 4761–4785.
moreover, behavioural scoring only used static characteristics about  the customer's past performance and used these to estimate the customer's  status at a fixed time in the future.
there is a view (overstreet et al, 1992) that there are a large number of quite different scorecards that have close to the best discrimination possible—the flat maximum effect—and so in the large samples used to build commercial scorecards, it is likely that most methods will find one of these almost optimal scorecards.
the models used by marketers to segment customers and to estimate propensity of purchase are very similar to the ones used by the risk teams to determine how many different scorecards to develop and then to estimate the likelihood of default for each customer.
applying bayes' rule in the case of the probability of a good or a bad having attributesx with the distribution of goods and bads in the population given bypg and pb , respectively, gives where p(x) is the probability that an applicant will have attributesx.
matuszyk a, mues c and thomas lc (2009).
improving customer attrition  prediction by integrating emotions from client/company interaction emails and  evaluating multiple classifiers.
for example, up to 5 years ago, most banks had hardly any data on the outcome of their collections and recoveries process, but the need to estimate lgd for all consumer loans means that such data are now carefully recorded and analysed.
before this, there had been some work on estimating rrs in corporate lending as these affect the price of risky bonds.
this suggests that the probability of default does vary, as economic conditions  vary, even if the credit worthiness of the borrower is not changing and has  required some ingenuity by lenders to translate a credit score, which is  clearly a point in time (pit) estimate, into the through the cycle (ttc)  estimate.
thus, bankruptcy scores were developed where a bad was someone who went bankrupt in the next 12 months.
moreover, behavioural scoring only used static characteristics about the customer's past performance and used these to estimate the customer's status at a fixed time in the future.
| article | openurl zandi m (1998).
in the latter approach one identifies a combination of the  overall conditions that can lead to poor economic performance.
lenders want to optimise all the decisions they make about the borrower,  not just whether or not to offer the borrower a standard loan product.
some of these involve developing more robust risk assessment systems, whereas  others are to expand the use of such modelling to deal with the current  objectives of lenders and the new decisions they have to make in consumer  finance.
this performance was used  to determine whether the applicant was bad (the specific risk occurred) or good  (it did not occur).
the flat maximum effect  and generic linear scoring models:
so if t is the time when default occurs, pb (t) is the probability that there has been default by time t, (pb'(t) its derivative) and pg(t)=1- pb(t), then: this is not the probability that a borrower will default at a time t into the loan but rather the probability that given the fact that the borrower is still active at timet, he will default in the next period of time.
optimizing the  collections process in consumer credit.
ann eugenic 7: 179–188.
thus, there seems to be a great deal more research that is required to  develop more appropriate good/bad assessments both in terms of expanding from  default to profitability and in removing any pre-defined time horizon on the  time over which the customer is assessed.
thus, currently lgd modelling is like estimating a moving target.
j syst sci syst eng 15:  419–435.
the assumption that credit worthiness is time independent over intervals of 3 or 4 years meant that credit scores have been built using the socio-demographic characteristics of the borrower, the credit bureau information about the borrower, details of the loan and even the repayment performance of the borrower on the loan, but not using anything about the current economic and market conditions.
these statistically based automated approaches to assessing consumer credit risk go under the name of credit scoring.
a proper or sufficient score s(x) captures as much information for predicting the probability of a performance outcome, say good/bad, as does the original data vector,x, so that when appropriate we will drop the x dependence of the score and write one form of a score is the log odds score, where hence, a log odds score could have values from minus infinity (when p(g| x)=0) to plus infinity when (p(g|x)=1).
now it is time to turn to the challenges that or in consumer finance faces.
stress testing in financial institutions.
palgrave macmillan journals - partner ofinasp, jdp, cross ref, counter, cope and ithenticate.
log odds scores are produced when one uses logistic regression to determine the classification scorecard but can also be obtained from other approaches by scaling, therefore it is reasonable to assume a scorecard has such a property.
recently, there has  been some initial work on how one would need to modify standard credit scoring  systems to deal with these questions (mok, 2008).
| article | openurl breeden jl and thomas lc (2008).
there had been little analytic modelling of the collections process for any form of lending until the advent of the basel accord.
this sample was then used to build a classification system that best separated the goods from the bads, using the characteristics of the loan and the borrower.
introduced in europe in 2007/2008, in the us in 2009 and scheduled to be  introduced in most countries between 2008 and 2012, it was a response to the  distortions in lending caused by the first accord of 1988, rather than a  response to the credit crunch.
the accord also concentrates on the  long-run probability of default, not just the probability of default, in the  next 12 months; it emphasises the need to stress test models and also requires  some completely new estimates such as loss given default, which we will return  to later.
this is a much faster-moving environment than that for normal loans, as the loans are of such short durations, and their repayment depends on the borrower's ability and desire to pay back the loan that month.
ieee t evolut comput 11:  651–665.
survival analysis has also been used to build scorecards when  only a few months data are available (hand and kelly, 2001).
they used a decision-tree  approach to model the strategic-level decision of whether to collect the debt  in house, use an agent or sell off the debt.
the two that are attracting most interest at present are microcredit and payday loans.
in the competing risk approach, one has several ways in which a loan could finish—default, early repayment, normal repayment—and one can model each of these separately using the fact that as far as a default is concerned, a borrower who pays off early at timet has a history censored at that time.
similarly, lenders are more  likely to adjust the product or offer alternative or extra products during  their relationship with the customer and so are anxious to know what impact  such changes will have on the default risk and the profitability of the  customer.
other approaches based on linear programming ( freed and  glover, 1981, 1986) and maximising divergence ( thomas, 2009a) are also used  commercially.
j opl res soc 50: 1185–1190.
whereas  in many retail environments the horizon may be just until the next purchase or  possibly just for a few years, in the consumer finance area, lifetime can  really mean lifetime—pension products for example.
in credit cards, this would mean varying the interest rate charged, the credit limit offered, whether an annual fee is charged and whether bonuses such as air miles are given for purchases made with the card.
discriminant analysis was the first method by which scorecards were built (seeeisenbeis (1978) for a critique of its use in credit scoring), but by the early 1980s, the growth in computer power meant that logistic regression had taken over as the main way by which commercial scorecards were built (mays, 2004 ;anderson, 2007).
figure 1 shows how the total household borrowing in the us
(baesens et al, 2003a; martens et al, 2008).
one also usually assumes that the score has a monotonic increasing  relationship with the probability of being good; hence, if a borrower has a  higher score than a second borrower, the first borrower has a higher  probability of being good than does the second.
| article | openurl hand dj and kelly mg (2001).
university of maryland.
challenge 2: introducing economics and market conditions into  risk-assessment systems
mathematical psychics: an essay on the application  of mathematics to the moral sciences.
survival analysis has also been used to build scorecards when only a few months data are available (hand and kelly, 2001).
the aim of these actions, however, is to  improve the profitability of the customer, but there might be other measures  rather than default risk in the next 12 months, which give a better handle on  profit.
xiao w, zhao q and fei q (2006).
in  particular, the lack of models for the credit risk of portfolios of consumer  loans and not modelling how economic conditions affect credit scores is now  recognised as having exacerbated the credit crunch of 2008/2009.
this competing risk approach can be expanded in two directions.
the first term on the rhs of (6) is the 'prior' score—the score of a randomly selected individual from the population; this score is then increased or decreased by the score that is based on the data that are unique to a particular individual.
microcredit involves giving very small loans to those in poverty in order to help them develop a business, which will sustain them and their family and so bring them out of poverty.
wadsworth: belmont, california.
by applying monte carlo simulation, using different future economic scenarios, one can then use such a model to estimate portfolio-level default rates.
somers m and whittaker j (2007).
this follows breiman's introduction of random forests (breiman, 2001), which consists of a large number of classification trees, each built on a subset of the data and only using a subset of the characteristics.
the consumer lending decision can then be modelled as a decision tree.
clearly, for lending to consumers,  these internal risk-rating systems are application and behavioural scoring  systems.
baesens et al (2004) used bayesian network classifiers to estimate the parameters of where in the life cycle a customer might currently be.
this is because of adverse selection ( ausubel, 1999; calem et  al, 2006) in which more bads apply for consumer credit at higher interest  rates than might be expected.
as there are so many combinations that could be considered, there are experimental design problems for any lender to obtain this sort of information efficiently.
researchers are beginning to address different ways of building models of the  credit risk for portfolios of consumer loans, which can then be used for stress  testing (breeden, 2007; breeden et al, 2008; rosch and scheule, 2008;  malik and thomas, 2009b).
so, what methodology results in a scorecard with the best discrimination in  credit scoring?
oxford university press: oxford.
as was suggested in challenge 6, several models are being developed, all of which include economic conditions as part of the model.
classification with ant colony optimization.
baesens et al (2003b) undertook a careful  comparison of different methods andxiao et al (2006) compared the more  recently applied methods.
challenge 4: variable- and risk-based pricing one way that lenders are seeking to increase their profit is by offering  generic loan products such as credit cards, but by tailoring the details of the  product for each individual.
a new case is then classified by each of these trees and its predicted class is taken to be that which the majority of the trees predict.
applying bayes' rule in the case of the  probability of a good or a bad having attributesx with the distribution  of goods and bads in the population given bypg and pb , respectively, gives where p(x) is the probability that an applicant will have  attributesx.
the most powerful  characteristics are whether the borrowers have recently been in arrears and the  current information from the credit bureau on their overall credit performance.
so one needs to be confident  in the translation of score to probability of default and to use the standard  chi-square and normal distribution-type tests to validate the model by  backtesting to compare actual numbers of defaults with predicted ones (bcbs,  2005b).
its philosophy was  pragmatic, in that it only wanted to predict, not explain, and hence used any  characteristic that improved the discriminating power of the system.
full figure and legend (15 k) figure 2.
the critical assumption in credit scoring is that the score is all that is required for predicting the probability of the applicant being good.
the other factor that has been affecting credit scoring in the past few  years is the change in banking regulations introduced by the basel ii accord ( basel committee on bank supervision, 2005a).
so a scorecard built  on a 2-year-old sample is used to determine which applicants to take for the  next few years.
specifying the score of an event is equivalent to specifying its  probability because we can write the probability in terms of the score: one interesting feature of a log odds score is that it separates out  completely the information about the population from information about the  individual borrower being scored.
j opl res soc, advance online publication 10  december, doi:10.1057/jors.2008.130.
as mentioned earlier, the introduction of the new banking regulations, the basel ii accord (bcbs, 2005a), concerning the amount of capital that banks need to set aside to cover their risk, has had a major impact on credit scoring.
one could possibly  argue thatsinf(x) is independent of t, although  that is highly unlikely, but there is no wayspop(t) cannot  depend on the current economic and market conditions.
it also presupposes that the  score to probability of default transformation stays as a log odds  transformation and ignores what happens when scores are recalibrated during the  cycle.
there are some recent  suggestions of how to include these economic conditions, either directly into a  regression scorecard (zandi, 1998), or using survival analysis ( malik and  thomas, 2009a; bellotti and crook, 2008).
applying this in equation (3) gives thus, a log odds score is the sum of a term depending only on the  population odds (spop=lnopop) and a term that  depends of the information of the borrowerx.
huang c-l, chen m-c and wang c-j (2007).
attrition scores assess whether the borrower will cancel the loan product shortly.
we also discuss what re-evaluation is needed of the  methodology that underpins scoring because of the problems of the last few  years in consumer lending and the mis-pricing of the securitised products based  on such lending.
the use of interaction terms and time-dependent coefficients,  which proved so successful there, can obviously be taken across to building  economy-based credit scorecards.
given the amount of research that has gone into  corporate credit risk models, one suspects that there will be considerably more  research into these consumer equivalents, given the realisation by bankers now  of how much more is being lent to households than to companies.
fitzroy  dearborn publishers: chicago.
before doing so, it is worth recalling what a credit score is  and what properties it has.
ifs(t,x) is a log odds score at time t for a borrower with characteristics x then the probability of  defaulting in the next 12 monthspt(b,x) starting at t is
for unsecured consumer credit, matuszyk et al (2009) have recognised  that the rr depends both on decisions by the lender as well as the uncertainty  about the borrower's ability and intention to repay.
| article  | openurl lilien gr and rangaswamy a (2004).
the lender should then accept  applicants with high credit scores if and accept applicants with low credit scores if credit scoring began in the 1950s when it was realised that statistical  classification methods—the first being discriminant analysis (fisher, 1936 )—could be used to classify loans into goods (non-defaulting) and bads  (defaulting), using the characteristics of the loan and the borrowers.
huang et al, 2007; bellotti and crook, 2009), genetic algorithms (desai et al, 1997;
although a system that assessed the profitability of the customer is the  aim of many lenders, this is proving hard to implement.
it is true that some methods performed slightly  better than others—neural nets, support vector machines, logistic  regression—but the differences were small and often the hypothesis that  two scorecards were equally good at discriminating could not be rejected.
| article | openurl mays e (1998).
more  sophisticated versions of these regression approaches have been looked at,  including projection pursuit regression and multivariate adaptive regression  splines (lee and chen, 2005).
in the past few years, credit scoring had been changing, as lenders want credit scoring to support their business objectives of profitability and market share.
using the competing risk idea.
lenders want to use 'credit scoring' to help make these variable  pricing decisions and to determine the long-term profitability of a customer  under different lender actions.
for example it defines  default as 90 days overdue in the next 12 months (although some national  regulators such as the financial services authority in the uk had modified this  to 180 days overdue).
one also usually assumes that the score has a monotonic increasing relationship with the probability of being good; hence, if a borrower has a higher score than a second borrower, the first borrower has a higher probability of being good than does the second.
there is very little mathematical modelling of what are appropriate variable rate functions to charge apart from phillips's book (phillips, 2005).
working paper centre for risk research.
they used a decision-tree approach to model the strategic-level decision of whether to collect the debt in house, use an agent or sell off the debt.
desai vs, conway dg, crook jn and overstreet ga (1997).
there seem to be so many obvious benefits in  seeking to integrate the ideas and the models in the two areas.
decision sci 12: 68–74.
consider a very simple example where 1  unit is lent, the cost of capital for the lender isrf (the risk  free rate), the loss given default (the fraction of the amount outstanding at  default which is finally lost) isld, and the lender will charge  an interest rater(p), which is related to the probability p of the applicant being a good.
given the turmoil in the financial markets during 2007 and 2008, which has at last made practitioners and researchers realise how large a proportion of the banking industry is based on consumer lending, there is no question that research in this area will be very active for the foreseeable future.
the overall  goal of marketing and credit risk modelling is to improve the profitability of  the customer to the financial organisation by improving customer relationship  management.
challenge 10: developing valid customer lifetime value models when  lifetime means lifetime
portfolio-level credit risk models were developed more  than a decade ago for corporate loans with models that allowed the correlation  in share prices to be surrogates for the correlation in defaults.
this assumption has been challenged in the last few years, first by the basel accord, which makes a point that its definition of probability of default is a long-run average (ie averaging over a full economic cycle) and not just the point in time probability of default.
challenge 7: modelling the credit risk of portfolios of consumer loans credit scoring has proved very successful at assessing the relative risk of  individual borrowers defaulting.
yet there is a need to ensure that the credit loaned is repaid, even if the time periods involved may be very long—several years if not decades—and there is a need to assess both the character of the individual and the potential of the idea that the loan will initially fund.
having seen what impact the failure to control the risks in consumer  lending have had on the world economy, regulators and bankers will want to  develop suitable models (and have enough analysts to build and monitor them) to  control these risks in the future—or at least for the next decade.
in survival analysis, one is interested in estimating the default hazard rate,h(t), whereh(t)t is the conditional probability of default in (t,t+t], given there has been no default in (0,t].
for unsecured consumer credit, matuszyk et al (2009) have recognised that the rr depends both on decisions by the lender as well as the uncertainty about the borrower's ability and intention to repay.
challenge 9: developing combined marketing and risk-assessment models that  help with the operations management of borrower's accounts one of the most surprising aspects of consumer lending in most financial  organisations is the lack of integration between the marketing and credit risk  groups.
j  risk financ 5: 16–32.
the book by beck and siegel (2001) outlines the way marketing is used in  consumer lending, but there are surprisingly few integrated models that include  risk and marketing features in consumer lending.
both are interested in maximising the profit for the organisation by making decisions about potential and actual customers; both use statistical methods to segment the population and to predict how likely the customer is to perform certain events—be it purchasing a new financial product or defaulting on an existing loan.
for a log odds score, equation(4) shows how this probability is related  to the credit score of the applicant.
modelling lgd for unsecured  personal loans; decision tree approach.
understanding the subprime mortgage  crisis.
although it should have had some effect on the  lending that precipitated the subprime mortgage crisis if it had been in effect  then, it would not have dealt with the liquidity risk or the fact that some  lenders thought securitisation meant they can absolve themselves of the risks  of their lending.
both groups use the same data about a customer to build  their models and, yet, rarely are combined models built.
stanford business  books: stanford, california.
applying this in equation (3) gives thus, a log odds score is the sum of a term depending only on the population odds (spop=lnopop) and a term that depends of the information of the borrowerx.
switching costs and adverse  selection in the market for credit cards: new evidence.
| article | openurl benjamin n, cathcart a and ryan k (2006).
| article | openurl cox dr (1972).
tang et al (2007) built a  survival analysis model that included the interactions between economic and  socio-demographic variables to estimate changes in the purchases of pension  products.
other factors must also be important, such as the rates being charged by other lenders, whether the product offers other features, such as air miles or free travel insurance, and in the case of revolving credit, whether the applicants believe they will be transactors (pay off their balance every month) or revolvers (and so have balances on which interest is charged).
moreover, it concentrated on a very specific risk—the chance a borrower will become 90 days overdue in their repayments in the next 12 months.
what often happens is that the paper that introduces a new  method can show that there is some small improvement by using it rather than  using an existing method, but one is always slightly concerned that this may be  down to the expertise of the authors in their own method and the fact that they  do not take such care with existing methods.
ima j mngt math 4: 97–109.
the use of interaction terms and time-dependent coefficients, which proved so successful there, can obviously be taken across to building economy-based credit scorecards.
a comparative study of data mining  methods in consumer loans credit scoring management.
both groups use the same data about a customer to build their models and, yet, rarely are combined models built.
however, it also requires much more of credit scoring,  with its emphasis on validating the probability of default estimates rather  than just ensuring the ranking of borrowers is accurate, which was how credit  scoring systems were previously judged.
the methods used are very similar—almost all the methods mentioned in challenge 1 could be applied to build marketing prediction models.
this involves estimating how the score s(t,x) changes  over time, which brings us back to challenge 2.
buckinx et al (2007) use the transactional information to estimate the customer loyalty to the organisation, whilevan den poel and larivière (2004) model which product features prevent customers churning to another organisation.
for further details on the basics of credit scoring and the different approaches to building a scorecard, one can look at the books bymays (1998), mcnab and wynn (2000), thomas et al (2002, 2004), mays (2004), anderson (2007) and thomas (2009a) and the review papers by hand and henley (1997), thomas (2000), thomas et al (2005) and crook et al (2007).
after sometime, the process is repeated and a new scorecard is  constructed.
expert syst appl 36:  6127–6134.
this sample was then used to build a classification system  that best separated the goods from the bads, using the characteristics of the  loan and the borrower.
| article | openurl martens d, huysmans j, setiono r, vanthienen j and baesens b (2008).
microcredit involves giving very small loans to those in poverty in order  to help them develop a business, which will sustain them and their family and  so bring them out of poverty.
another popular alternative is to use classification trees, with its origins both in statistics (breiman et al, 1984) and machine learning (quinlan, 1993), although this of course ends up not with a scorecard but with groups of customers described by combinations of their characteristics, where each group is classified as either good or bad.
this is so important we identify  it as a separate challenge (challenge 7) and discuss it further later.
| article | openurl thomas lc, edelman db and crook jn (2002).
instead, what has happened is that lenders score separately a number of the events that affect profitability.
there is a view (overstreet et al, 1992)  that there are a large number of quite different scorecards that have close to  the best discrimination possible—the flat maximum effect—and so in
in the middle ages, the discussion on whether it was right to charge interest on loans not only gave the focal point of a shakespearean play but also exercised both moslem and catholic theologians.
financial  services authority: london.
however, the idea that banks  need to build models of the credit risk of their lending and the output of  these is used to set their capital requirements—the internal based rating  approach—will remain.
thomas lc, oliver rw and hand dj (2005).
this paper reviews the development of credit scoring—the way of assessing risk in consumer finance—and what is meant by a credit score.
accepted 30 july 2009.top of page consumer finance has become one of the most important areas of banking, both because of the amount of money being lent and the impact of such credit on global economy and the realisation that the credit crunch of 2008 was partly due to incorrect modelling of the risks in such lending.
tang et al (2007) built a survival analysis model that included the interactions between economic and socio-demographic variables to estimate changes in the purchases of pension products.
these ideas have been developing over the past decade ( banasik et al , 1999; stepanova and thomas, 2001, 2002), and are now being taken on board by  practitioners.
the edited book by altmanet al (2005) outlines the mainly regression-based models that seek to relate rrs to economic factors and characteristics of the loan and the defaulter in the corporate setting.
full figure and legend (176k) such a growth in consumer lending could not have been possible without an  automated approach to assessing the credit risk that the loan to an individual  consumer would not be repaid.
a second challenge is that the accord requires estimates of the long-run  average of the 12-month default rate (the ttc default rate) for a segment of  borrowers while a credit score estimates the default rate in the next 12 months  (the pit estimate).
eur j opl res 157:  196–217.
the reality is that the take probability q is a function of r andp.
recent developments in  consumer credit risk assessment.
although it should have had some effect on the lending that precipitated the subprime mortgage crisis if it had been in effect then, it would not have dealt with the liquidity risk or the fact that some lenders thought securitisation meant they can absolve themselves of the risks of their lending.
the types of models developed so far include reputation-based  models (muniz de andrade and thomas, 2007), dual time dynamics ( breeden, 2007;  breeden and thomas, 2008), survival analysis ( malik and thomas, 2009a;  bellotti and crook, 2008) and correlation models with added economic variables ( rosch and scheule, 2003).
credit scoring for risk managers, the handbook for lenders .
| article | openurl thomas lc, jung km, thomas sda and wu y (2006).
similarly, lenders are more likely to adjust the product or offer alternative or extra products during their relationship with the customer and so are anxious to know what impact such changes will have on the default risk and the profitability of the customer.
credit scoring has proved very successful at assessing the relative risk of individual borrowers defaulting.
eur j opl res 18: 1447–1465.
low default portfolios: a  proposal for conservative estimation of default probabilities.
a third problem is the basel accord's instance on stress testing, which  means predicting the future performance of a portfolio of loans under extreme  economic conditions.
mcnab h and wynn a (2000).
this will prove a vital tool in meeting several of the challenges outlined  previously.
having seen what impact the failure to control the risks in consumer lending have had on the world economy, regulators and bankers will want to develop suitable models (and have enough analysts to build and monitor them) to control these risks in the future—or at least for the next decade.
expert syst appl 36:  3302–3308.
one advantage of the survival analysis approach is that the competing risk idea means that one can use the same data to estimate several different events.
a linear programming approach to the  discriminant problem.
decision sci 17:  151–162.
muniz de andrade fw and thomas lc (2007).
one real change in defining good/bad in the last few years is the use of  survival analysis ideas to allow the estimation of a borrower's default risk  over any future time horizon, not just a fixed 12 months.
this will prove a vital tool in meeting several of the challenges outlined previously.
lenders want to use 'credit scoring' to help make these variable pricing decisions and to determine the long-term profitability of a customer under different lender actions.
a company registered in england and wales under company number: 785998 with its registered office at brunel road, houndmills, basingstoke, hants, rg21 6xs, united kingdom.
other approaches based on linear programming ( freed and glover, 1981, 1986) and maximising divergence ( thomas, 2009a) are also used commercially.
| article | openurl baesens b, mues c, martens d and vanthienen j (2008).
benchmarking state-of-the-art classification algorithms for credit  scoring.
baesens b, setiono r, mues c and vanthienen j (2003a).
at the other extreme of time scale is payday loans.
this was because the risk models developed in the 1950s and 1960s still seemed to be working well and were surprisingly robust to changes in economic conditions.
for example,  there are some marketing models that seek to assess the 'emotions' of the  customer from their interactions with the company (coussement and van den poel,  2009) but there is no risk-assessment model that includes the customers  'emotions'.
a score,s(x), is then a function of the characteristics x of a potential borrower, which can be translated into the probability estimate that the borrower will be good.
regression models and life tables (with discussion).
expert syst appl 33:  847–856.
the traditional way of defining a bad was a borrower who became 90 days overdue in the next 12 months.
j risk model validation 2(2): 43–62.
not if but when will borrowers  default.
full text access provided to carnegie mellon university by hunt library---acquisitions journal of the operational research society (2010) 61, 41–52.
the methods used are very similar—almost  all the methods mentioned in challenge 1 could be applied to build marketing  prediction models.
rule  extraction from support vector machines: an overview of issues and application  in credit scoring.
this paper has sought to  identify some of these challenges.
morgan kaufman:  san mateo, california.
modelling credit risk of portfolio of  consumer loans.
thus, one needs to build scorecards that can respond very quickly to changes in economic and market behaviour and to immediate changes in the borrower's behaviour, and circumstances.
all seem to give correlations between actual and predicted values of no better than 0.1–0.2.
one is to estimate  the response function (the take probability) as above, whereas the second is to  model the situation as a game.
this was because the risk models developed in the 1950s and 1960s  still seemed to be working well and were surprisingly robust to changes in  economic conditions.
the use of multiple measurements in taxonomic problems.
differentiating between good credits  and bad credits using neuro-fuzzy systems.
the review paper by baesens et al (2008) explains how or models and data-mining methods are used for  a number of such classification problems, particularly in credit scoring.
martens d, de backer m, haesen r, vanthienen j, snoeck m and baesens b  (2007).
this is the pit estimate, but what one needs to do is get a ttc estimate,  which if the cycle is of lengtht starting say at time t0 would be
the loan is taken out usually at the middle or towards the end of the month and the lender is given a post-dated cheque or a way of accessing the borrower's current account on the day the pay cheque is paid in at the end of the month.
benoit and van den poel (2009) have used quantile regression to estimate customer lifetime value.
consumer finance, credit scoring, risk-based pricing, classification techniques, customer lifetime valuetop of page consumer finance was the sleeping giant of the modern economy, until it awoke with a vengeance in 2007 and showed what impact problems with the risk assessment of consumer borrowing and the consequent mis-pricing of financial instruments based on this borrowing could have.
| article | openurl stepanova m and thomas lc (2001).
a survey of the issues in  consumer credit modelling research.
the work on modelling the collections process for mortgage lending is directly motivated by basel (lucas, 2006).
moreover, in several countries, one has to be able to explain why one rejects an applicant for credit, and therefore 'black box' methods such as neural nets and support vector machines would not be allowed.
survival analysis methods for personal  loan data.
int j bank marketing 25:  22–38.
however, it is only in the last 50 years, with the advent of  credit cards (first issued in the us in 1958 and then in the uk in 1966) and  the growth in home ownership and hence mortgage loans, that consumer credit has  become so widespread.
in particular, how does the take probability vary according to the risk score of the applicant and the rate charged by the lender.
this should mean that consumer finance will have a much higher profile in university finance and operational research courses in the future, so that entrants to the finance industry are aware of the need for models and the challenges of building models to solve the problems in this area.
the review paper by baesens et al (2008) explains how or models and data-mining methods are used for a number of such classification problems, particularly in credit scoring.
stress testing at major  financial institutions: survey results and practice.
one way of finding an improved risk system is to use a combination of  methods.
this is not possible nor sensible for portfolios of consumer loans as default there does not depend on the value of assets but on cash flow considerations and personal attitudes to debt.
with approaches such as the competing risk idea in survival analysis it should be possible to combine these two major factors that affect customer profitability.
it is likely that some governments will now impose tighter regulations than those proposed in the accord.
it does have the advantage, however, although that it may be possible to use these intermediate components to estimate profitability as well as default risk.
full figure and legend (15 k) total consumer borrowing (calculated by credit action based on bank of england statistics).full figure and legend (176k) such a growth in consumer lending could not have been possible without an automated approach to assessing the credit risk that the loan to an individual consumer would not be repaid.
currently, these groups see themselves as adversaries, with one group wanting  to take as many applicants as they can and the other to be as discriminating as  possible about who they take.
lc thomas, school of management, university of southampton,  southampton, so17 1bj, uk.
this paper has sought to identify some of these challenges.
other factors  must also be important, such as the rates being charged by other lenders,  whether the product offers other features, such as air miles or free travel  insurance, and in the case of revolving credit, whether the applicants believe  they will be transactors (pay off their balance every month) or revolvers (and  so have balances on which interest is charged).
in this paper, we outline some of the challenges that these developments in credit scoring bring.
the growth in the internet and the telephone as ways of  undertaking the application process means applications are essentially private  and so the product can be 'customised' to depend on the applicants'  characteristics, allowing for variable pricing.
moreover such loans are increasingly receiving special  legislation which requires proof that their risk-assessment systems are robust.
the tremendous increase in computer storage capacity and the requirement of the basel accord that banks have sufficient historical data to validate their credit scoring models have meant that banks are now willing and able to store much more consumer finance data over much longer periods than they used to do.
total consumer borrowing (calculated by credit action based on bank of  england statistics).
|  article | openurl buckinx w, verstraeten g and van den poel d (2007).
math comput simulat 20:  2525–2534.
moreover, the data that banks are now  storing systematically on the outcomes of their collections process are being  used to develop models of the sequence and timing of the collections operations  so as to optimise the rr (de almeida filho et al, 2008).
bayesian network classifiers for identifying the  slope of the customer lifecycle of long-life customers.
under these new regulations, banks  are allowed to use the estimates from their own internal risk-rating systems in  the formula, which determines the minimum capital they have to set aside to  cover the credit risk in their lending.
shows a simplified case where the credit score just takes two values—one  corresponds to a high chance of being good (good risk), the other to a low  chance of being good (bad risk).
the initial approaches have looked at linear and logistic regression, non-linear transformation so as to fit beta or log-log distributions, mixture models (especially to identify the 'won't pay' (lgd=1), and even quantile regression ideas (somers and whittaker, 2007).
baesens et al (2004)  used bayesian network classifiers to estimate the parameters of where in the  life cycle a customer might currently be.
50 years of data  mining and or: upcoming trends and challenges.
however, any classification approach can be applied to the credit scoring problem and so in the past 20 years researchers have tried neural nets (desai et al, 1997; malhotra and malhotra, 2002), support vector machines ( van gestel et al, 2006;
so a scorecard built on a 2-year-old sample is used to determine which applicants to take for the next few years.
modelling the credit risk for portfolios of consumer  loans: analogies with corporate loan models.
in the middle ages, the discussion  on whether it was right to charge interest on loans not only gave the focal  point of a shakespearean play but also exercised both moslem and catholic  theologians.
c4.5: programs for machine learning.
donkers et al (2007) made a comparison of a number of different types of customer lifetime value models using insurance industry data, while verhoef and donkers (2001) made the comparison between choice-based probit models and potential value regression type models.
this  follows breiman's introduction of random forests (breiman, 2001), which  consists of a large number of classification trees, each built on a subset of  the data and only using a subset of the characteristics.
it began in the indian subcontinent but is now  being used by many other countries and is even recognised by major  international banks as a significant source of future lending.
this paper reviews the  development of credit scoring—the way of assessing risk in consumer  finance—and what is meant by a credit score.
ima j math appl bus indust 8: 323–346.
thus, researchers are looking to see whether they can devise classification trees that mimic the performance of the 'black box' and hence give reasons for assuming the applicant is bad and should be rejected.
it then outlines 10  challenges for operational research to support modelling in consumer finance.
challenge 6: meeting the regulatory challenge, particularly that in the  basel accord as mentioned earlier, the introduction of the new banking regulations, the  basel ii accord (bcbs, 2005a), concerning the amount of capital that banks need  to set aside to cover their risk, has had a major impact on credit scoring.
those borrowers who do not default on the loan within the chosen time period are 'good'.
this initial  use of credit scoring, which is called application scoring, was to support the  decision of whether to grant credit to a new applicant.
beck re and siegel sm (2001).
lgd is related to rr (ie, the  percentage of the debt outstanding which the collections department recovers)  by lgd=1-rr.
if we include the time at which the  score is being used, then what we require at timet is the score s( x,t)=spop(t)+sinf(x,t ).
challenge 3: dealing with new ways of assessing what is a good customer
| article  | openurl
| article | openurl chatterjee s and barcun s (1970).
more emphasis was being put by lenders on the use of or models in the marketing of these products, since the traditional approach of one market 'price' (namely the interest rate being charged on the loan) was giving way to variable pricing.
having decided on what risk is being assessed—say repayments being more than 90 days overdue in the next 12 months—those for which that event occurs are bads and the others are goods.
this is so important we identify it as a separate challenge (challenge 7) and discuss it further later.
j opl res soc 52: 989–996.
however, the idea that a new methodology will produce far better  discrimination using existing characteristics than the current methods is  questioned by many experts.
poel d, egmont-petersen m, van kenhove  p and vanthienen j (2004).
credit scoring with macroeconomic  variables using survival analysis.
ifs(t,x) is a log odds score at time t for a borrower with characteristics x then the probability of defaulting in the next 12 monthspt(b,x) starting at t is
propensity scores assess how likely it is that the lender can up sell  or cross sell other products to the borrower.
the standard classification methods result in a  scorecard and a cut-off so that those with scores above the cut-off are  considered good (and would be accepted if they apply) and those below it are  classified as bad (and would be rejected if they apply).
until then, despite its  importance to the individual consumer, and the fact that it was using an  increasing number of those who had trained in operational research (or) and  statistics, the modelling underlying it was hardly discussed in any finance  course, and the number of research papers in the area was minute compared with  that on the corporate credit market or on the pricing of exotic equity-based  options.
clearly, for lending to consumers, these internal risk-rating systems are application and behavioural scoring systems.
this  model splits the problem into whether the mortgaged property needs to be  repossessed and then into forecasting what price the property will be sold for.
overtook that of total business borrowing in the late 1980s, and that by 2004  the total borrowing on mortgages had also exceeded the total business  borrowing, although that has drawn level again in 2008.figure 2 similarly shows  the growth in consumer borrowing in the uk in the 15 years since 1992.
the large samples used to build commercial scorecards, it is likely that most  methods will find one of these almost optimal scorecards.
| article |  openurl coussement k and van den poel d (2009).
payday loans are small, very short-term loans with extremely high interest rates that are effectively advances on a borrower's next pay packet.
these are still challenges for or in this area but the subprime mortgage crisis, the failure of the ratings agencies to assess the risk of residential mortgage-backed securities, and the consequent credit crunch, requires a reassessment of some of the quantitative models that had proved so successful up to then.
a score,s(x), is then a function of the characteristics x of a potential borrower, which can be translated into the probability  estimate that the borrower will be good.
keywords: consumer finance, credit scoring, risk-based pricing, classification  techniques, customer lifetime value top of page introduction consumer finance was the sleeping giant of the modern economy, until it  awoke with a vengeance in 2007 and showed what impact problems with the risk  assessment of consumer borrowing and the consequent mis-pricing of financial  instruments based on this borrowing could have.
in fact, it is only worthwhile for banks to move to these internal  ratings-based systems, if they use them for their consumer lending, as the main  saving in capital compared with the alternative externally imposed capital  ratios is in consumer lending.
if the take probability or response rate of an  applicant to a loan offer with interest rater is q(r),  then the expected profit to the lender of making an offerr is differentiating (11) and setting the derivative to zero gives where we assume that s is a log odds application score
oxford university press:  oxford.
support vector machines for credit  scoring and discovery of significant features.
the critical issue is how to build a model of the credit risk of portfolios of consumer loans, which includes economic and market conditions and so can then be run under the extreme scenarios suggested by the regulators.
one way of finding an improved risk system is to use a combination of methods.
modelling the amount recovered  overall (or under one of these strategies) in terms of the characteristics of  the debtor and the loan is proving to be very difficult.
by applying monte carlo simulation, using different future  economic scenarios, one can then use such a model to estimate portfolio-level  default rates.
the first is the need to validate the probability of default predictions that the scorecard makes rather, than the relative ranking of the borrowers, which was what is important in deciding which applicants for credit to accept.
propensity scores assess how likely it is that the lender can up sell or cross sell other products to the borrower.
a two-stage hybrid credit scoring model  using artificial neural networks and multivariate adaptive regression splines.
modeling clv: a test of competing  models in the insurance industry.
clearly,  standard risk-assessment systems cannot work for people who have no history of  being advanced credit previously and no involvement with a banking system.
the critical assumption in credit  scoring is that the score is all that is required for predicting the  probability of the applicant being good.
the two that are attracting most interest at present are microcredit  and payday loans.
one can model purchasing as well as attrition and default events separately and then seek to combine them to get a customer lifetime value approach (challenge 10).
what we have is s(x,t0)=spop(t0 )+sinf(x,t0), where t0 is the time at which  the sample on which the scorecard was built was performing.
benoit and van den poel (2009) have  used quantile regression to estimate customer lifetime value.
the accord is presenting four challenges to credit scoring—the internal ratings approach to consumer lending.
the accord though requires banks to estimate lgd (bennett et al, 2005) for all loan segments whether they have yet defaulted or not.
modelling the amount recovered overall (or under one of these strategies) in terms of the characteristics of the debtor and the loan is proving to be very difficult.
this idea of building a large number of models and choosing what the majority predicts could be used with all the classification methodologies, not just classification trees.
automatica 35: 1969–1985. | article  | isi | openurl hand dj and henley we (1997).
american bankers  association: washington dc.
for example, there are classification trees in which some of the  variables are a 'score' obtained using another method.
top  of page abstract consumer finance has become one of the most important areas of banking,  both because of the amount of money being lent and the impact of such credit on  global economy and the realisation that the credit crunch of 2008 was partly  due to incorrect modelling of the risks in such lending.
such scores are now used by almost  all lenders and are routinely updated each month.
such an indirect  approach requires both that the intermediate elements be predicted well and  that there is a strong relationship between them and the default risk.
under these new regulations, banks are allowed to use the estimates from their own internal risk-rating systems in the formula, which determines the minimum capital they have to set aside to cover the credit risk in their lending.
ong et al, 2005), nearest neighbour methods (chatterjee and barcun, 1970; henley and hand, 1997) and ant colony optimisation (martens et al, 2007).
however, the idea that banks need to build models of the credit risk of their lending and the output of these is used to set their capital requirements—the internal based rating approach—will remain.
see ssrn.com/abstract=1020396.
so proven ability to handle such short-term loans, and the local economic situation are important features.
it does  have the advantage, however, although that it may be possible to use these  intermediate components to estimate profitability as well as default risk.
such games could involve a number of buyers—the borrowers in this case—and sellers—the lenders—and the use of game theory to model such pricing situations has a long history from edgeworth's work on market games in 1881 (edgeworth, 1881) to gibbens and kelly's work on pricing the internet (gibbens and kelly, 1999) as well as new modelling challenges in existing forms of credit granting there are new types of loans that need risk-assessment systems that are different from those that have worked for personal loans, credit cards and mortgages.
another area in which researchers are seeking to find improved credit scoring methods—that is find the silver bullet which will be 'the' best way of building scorecards—is ensemble methods.
so one needs to be confident in the translation of score to probability of default and to use the standard chi-square and normal distribution-type tests to validate the model by backtesting to compare actual numbers of defaults with predicted ones (bcbs, 2005b).
in: mays e (ed).credit risk modeling, design and  application.
the models forecast how likely the applicant for credit is to  be 'bad' and to default on the loan within a given time period.
credit risk modeling, design and application.
for further details on the basics of credit scoring and the different  approaches to building a scorecard, one can look at the books bymays (1998),  mcnab and wynn (2000), thomas et al (2002, 2004), mays (2004), anderson  (2007) and thomas (2009a) and the review papers by hand and henley (1997),  thomas (2000), thomas et al (2005) and crook et al (2007).
ima j math appl bus indust 8: 305–321.
bank for international settlements:  basel.
one would need a lot of analysts to subjectively decide whether all those cards  should be issued.)
attrition scores assess whether the borrower will cancel the  loan product shortly.
this initial use of credit scoring, which is called application scoring, was to support the decision of whether to grant credit to a new applicant.
it then outlines 10 challenges for operational research to support modelling in consumer finance.
when personal bankruptcy rules became easier in certain countries, notably in the us, it became apparent that the performance of borrowers before they sought bankruptcy was different from those who just defaulted on their loan.
similarly, the fourth issue that the basel accord has highlighted, the need to model the recovery rate (rr) (or alternatively the loss given default (lgd), where rr=1-lgd) of what percentage of a defaulted loan will subsequently be recovered is also so important that it deserves to be considered as a separate challenge (challenge 8).
comparison of us household and business debt.
there are two main approaches.
full figure and legend (20k )
| article | openurl van gestel t, baesens b, suykens jak, van den poel d, baestaens de and  willekens m (2006).
at the same time, some lenders sought to  integrate all the models into a customer lifetime value framework.
the united nations declared 2005 to be the international year of microcredit.
alternatively, one can concentrate on default only but recognise that default  can occur for different reasons—financial naivety, loss of employment,  fraud, marital breakdown, for example—and seek to model the time until  default for these different reasons separately before finally combining them
we also discuss what re-evaluation is needed of the methodology that underpins scoring because of the problems of the last few years in consumer lending and the mis-pricing of the securitised products based on such lending.
breiman l, friedman jh, olshen ra and stone cj (1984).
so proven ability to handle such short-term  loans, and the local economic situation are important features.
however,  any classification approach can be applied to the credit scoring problem and so  in the past 20 years researchers have tried neural nets (desai et al,  1997; malhotra and malhotra, 2002), support vector machines ( van gestel et  al, 2006;
another area in which researchers are seeking to find  improved credit scoring methods—that is find the silver bullet which will  be 'the' best way of building scorecards—is ensemble methods.
credit scoring with a data  mining approach based on support vector machines.
bellotti t and crook jn (2008).
structural models in consumer  credit.
| article | openurl lee t-s and chen i-f (2005).
eisenbeis ra (1978) problems in applying discriminant analysis in credit  scoring models.
a new case is then  classified by each of these trees and its predicted class is taken to be that  which the majority of the trees predict.
this is possible because the use of the internet and the telephone as  application channels means the application process is much more private and so  varying offers can be made without applicants being aware of what is being  offered to others.
firstly, it is not used to support a specific decision but rather it is used by the lender as part of a customer relationship strategy to determine whether to increase credit limits, seek to up sell or cross-sell other products.
translating from point-in-time default rates to through the  cycle default rates highlights the time dependency of a score which we outlined  in challenge 2.
consumer credit models, pricing, profit and portfolios .
basel committee on banking supervision (bcbs) (2005b).
thus, one needs to  build lifetime value models that can cope with the changes in economic and  market conditions over long time intervals as well as forecasting the changes  in the customer's situation and priorities.
such two-stage models could also be used for other secured loans like car finance.
it is easy then to see that, given the hazard function, we can calculate the probability of default over any time period because if one uses the proportional hazards or accelerated life models of survival analysis, one is able to obtain a score that describes the 'risk' of a consumer defaulting over any and all time horizons.
for example, many of the newer methods essentially construct non-linear scorecards with interactions between characteristics, but experts in the linear approaches to credit scorecard building—logistic and linear regression—tend to know from experience about such interactions and allow for them by building separate scorecards for different segments of the population or by introducing interaction variables.
adverse selection in the credit card market.
stress testing retail loan  portfolios with dual-time dynamics.
the lender should then accept applicants with high credit scores if and accept applicants with low credit scores if credit scoring began in the 1950s when it was realised that statistical classification methods—the first being discriminant analysis (fisher, 1936 )—could be used to classify loans into goods (non-defaulting) and bads (defaulting), using the characteristics of the loan and the borrowers.
de almeida filho at, mues c and thomas lc (2008).
| article | openurl thomas lc (2000).
predicting customer potential value:  an application in the insurance industry.
one could possibly argue thatsinf(x) is independent of t, although that is highly unlikely, but there is no wayspop(t) cannot depend on the current economic and market conditions.
more sophisticated versions of these regression approaches have been looked at, including projection pursuit regression and multivariate adaptive regression splines (lee and chen, 2005).
the book by beck and siegel (2001) outlines the way marketing is used in consumer lending, but there are surprisingly few integrated models that include risk and marketing features in consumer lending.
full figure and legend (20k ) the notation of figure 3 says that the profit to lender if the loan is  repaid isg; -l is the loss if the loan is not repaid; q is  the chance the consumer will take the loan if offered it;p(h) is  the probability that a consumer rated high will be good; andp(l)
moreover,  it concentrated on a very specific risk—the chance a borrower will become  90 days overdue in their repayments in the next 12 months.
j opl res soc 56:  1006–1015.
baesens et al (2003b) undertook a careful comparison of different methods andxiao et al (2006) compared the more recently applied methods.
http://www3.imperial.ac.uk/portal/pls/portallive/docs/1/7287866.pdf.
all these models concentrate on the purchase aspects—time to and value of next purchase and churn—and do not include the default risk elements that can affect profitability in a major way.
top of page references altman e, resti a and sironi a (2005).
freed n and glover f (1986).
expert syst appl 32:  125–134.
it is likely that some governments will now impose tighter  regulations than those proposed in the accord.
moreover, laws such as the equal credit opportunity acts in  the us have outlawed discrimination in the giving of credit unless there are  statistical models that can defend such decisions.
expert syst appl 35: 497–514.
we assume that each consumer, be it an applicant in the case of an  application score or a current borrower in the case of a behavioural score, can  be described by a set of characteristicsx=(x1,x2,...,x m), xx, where x is the set of all possible  borrower characteristic combinations.
malhotra r and malhotra dk (2002).
journal of the operational research  society, advance online publication, 14 october,  doi:10.1057/jors.2009.67.
the accord though  requires banks to estimate lgd (bennett et al, 2005) for all loan  segments whether they have yet defaulted or not.
the  consumer lending decision can then be modelled as a decision tree.
similarly, the fourth issue that the basel accord has highlighted, the need  to model the recovery rate (rr) (or alternatively the loss given default (lgd),  where rr=1-lgd) of what percentage of a defaulted loan will subsequently be  recovered is also so important that it deserves to be considered as a separate  challenge (challenge 8).
some of these involve developing more robust risk assessment systems, whereas others are to expand the use of such modelling to deal with the current objectives of lenders and the new decisions they have to make in consumer finance.
the most powerful characteristics are whether the borrowers have recently been in arrears and the current information from the credit bureau on their overall credit performance.
e-mail:l.thomas@soton.ac.uk received 8 june 2009;
the types of models developed so far include reputation-based models (muniz de andrade and thomas, 2007), dual time dynamics ( breeden, 2007; breeden and thomas, 2008), survival analysis ( malik and thomas, 2009a; bellotti and crook, 2008) and correlation models with added economic variables ( rosch and scheule, 2003).
the growth in the internet and the telephone as ways of undertaking the application process means applications are essentially private and so the product can be 'customised' to depend on the applicants' characteristics, allowing for variable pricing.
one would need a lot of analysts to subjectively decide whether all those cards should be issued.)
firstly, it is not used to support a  specific decision but rather it is used by the lender as part of a customer  relationship strategy to determine whether to increase credit limits, seek to  up sell or cross-sell other products.
jors.2009.104 l c thomas1 1school of management, university of southampton, southampton, uk correspondence: lc thomas, school of management, university of southampton, southampton, so17 1bj, uk.
decision tree of consumer lending decisions.
the relationship between default and  economic cycle for retail portfolios across countries.
these characteristics include  socio-economic data such as age and residential status; credit bureau  information such as whether the applicant is on the electoral role; and in the  case of behavioural scores, performance data such as the number of missed  payments in the last 12 months.
whether the loan was  profitable to the lender, whether the borrower would continue to repay beyond  this period, how much the borrower used the loan facility—none of these  risks were considered.
since there is clearly some dependence between defaults of different  individuals, and often the number of defaults are very low, one needs to  develop sophisticated models to cope with these problems (benjamin et al , 2006).
bennett rl, catarineu e and moral g (2005).
opns res 50: 277–289.
figure 3 shows a simplified case where the credit score just takes two values—one corresponds to a high chance of being good (good risk), the other to a low chance of being good (bad risk).
statistical classification methods in  consumer credit scoring: a review.
however, it is only in the last 50 years, with the advent of credit cards (first issued in the us in 1958 and then in the uk in 1966) and the growth in home ownership and hence mortgage loans, that consumer credit has become so widespread.
there seem to be so many obvious benefits in seeking to integrate the ideas and the models in the two areas.
moreover, in several countries, one has to be able to explain why one rejects  an applicant for credit, and therefore 'black box' methods such as neural nets  and support vector machines would not be allowed.
lgd is related to rr (ie, the percentage of the debt outstanding which the collections department recovers) by lgd=1-rr.
rule extraction from support vector machines, springer: new  york, pp 33–63.
there are some recent suggestions of how to include these economic conditions, either directly into a regression scorecard (zandi, 1998), or using survival analysis ( malik and thomas, 2009a; bellotti and crook, 2008).
| article  | openurl henley we and hand dj (1997).
it began in the indian subcontinent but is now being used by many other countries and is even recognised by major international banks as a significant source of future lending.
in fact,burez and van den poel  (2008) produce a churn model in a paper entitled 'resolving the conflict  between the sales and credit department'.
for example, up to 5 years ago, most banks had hardly any data on  the outcome of their collections and recoveries process, but the need to  estimate lgd for all consumer loans means that such data are now carefully  recorded and analysed.
j banking and finance 2: 205–219; reprinted, in:  thomas lc, edelman db and crook jn (eds)readings in credit scoring (2004) oup:  oxford, pp 17–32.
there is a sumerian clay  tablet recording how two farmers borrowed money to purchase grain with the  promise of paying back more at harvest time.
the notation of figure 3 says that the profit to lender if the loan is repaid isg; -l is the loss if the loan is not repaid; q is the chance the consumer will take the loan if offered it;p(h) is the probability that a consumer rated high will be good; andp(l) is the chance a consumer rated low will be good.
thus, researchers are looking  to see whether they can devise classification trees that mimic the performance  of the 'black box' and hence give reasons for assuming the applicant is bad and  should be rejected.
as mentioned in  challenge 2, survival analysis can also be used to introduce economic  conditions into scorecards.
breeden jw, thomas lc and mcdonald jw (2008).
the previous discussion though highlighted the credit-rating agencies failure to assess the risk of consumer asset-backed securities and the basel requirements to stress test portfolios of consumer loans.
for example it defines default as 90 days overdue in the next 12 months (although some national regulators such as the financial services authority in the uk had modified this to 180 days overdue).
basel ii problem solving.
these statistically based  automated approaches to assessing consumer credit risk go under the name of  credit scoring.
the standard classification methods result in a scorecard and a cut-off so that those with scores above the cut-off are considered good (and would be accepted if they apply) and those below it are classified as bad (and would be rejected if they apply).
having decided on what risk is being  assessed—say repayments being more than 90 days overdue in the next 12  months—those for which that event occurs are bads and the others are  goods.
payday loans are small,  very short-term loans with extremely high interest rates that are effectively  advances on a borrower's next pay packet.
predicting customer  loyalty using the internal transactional database.
however, it also requires much more of credit scoring, with its emphasis on validating the probability of default estimates rather than just ensuring the ranking of borrowers is accurate, which was how credit scoring systems were previously judged.
although behavioural scoring was an obvious extension of application scoring, it was also an opportunity missed.
top of page defining a credit score in this paper, we outline some of the challenges that these developments in  credit scoring bring.
although there have been several surveys of what stress testing banks currently do (bis, 2005; fsa, 2005), these point out to the lack of a consistent stress-testing methodology for credit risk as opposed to market risk.
using neural  network rule extraction and decision tables for credit-risk evaluation.
this idea of building a large number  of models and choosing what the majority predicts could be used with all the  classification methodologies, not just classification trees.
the overall goal of marketing and credit risk modelling is to improve the profitability of the customer to the financial organisation by improving customer relationship management.
customer attrition analysis  for financial services using proportional hazard models.
discussion paper  05/02, london.
j opl res soc 60:  s16–s23.
moreover, the data that banks are now storing systematically on the outcomes of their collections process are being used to develop models of the sequence and timing of the collections operations so as to optimise the rr (de almeida filho et al, 2008).
in fact,burez and van den poel (2008) produce a churn model in a paper entitled 'resolving the conflict between the sales and credit department'.
given the amount of research that has gone into corporate credit risk models, one suspects that there will be considerably more research into these consumer equivalents, given the realisation by bankers now of how much more is being lent to households than to companies.
journal of the operational research society, advance online  publication, 28 october, doi:10.1057/jors.2009.123.
edgeworth fy (1881).
thus, there seems to be a great deal more research that is required to develop more appropriate good/bad assessments both in terms of expanding from default to profitability and in removing any pre-defined time horizon on the time over which the customer is assessed.
the assumption that credit worthiness is time independent over intervals of  3 or 4 years meant that credit scores have been built using the  socio-demographic characteristics of the borrower, the credit bureau  information about the borrower, details of the loan and even the repayment  performance of the borrower on the loan, but not using anything about the  current economic and market conditions.
alternatively, one can concentrate on default only but recognise that default can occur for different reasons—financial naivety, loss of employment, fraud, marital breakdown, for example—and seek to model the time until default for these different reasons separately before finally combining them using the competing risk idea.
the  type of marketing models that can be used in consumer finance can be found in  examples such aslilien and rangaswamy (2004).
moreover, profitability is as much about  marketing as about risk assessment, and hence there is a need to combine the  work done by financial organisations' marketing and risk assessment or groups.
this model can work both as a parametric model in which the baseline hazard function is of a specific family of distributions or semi parametrically using the results ofcox (1972).
one can do this by sensitivity analysis in which one changes the value of one of the factors that impacts on the model, or by scenario analysis.
this is possible because the use of the internet and the telephone as application channels means the application process is much more private and so varying offers can be made without applicants being aware of what is being offered to others.
in  particular, how does the take probability vary according to the risk score of  the applicant and the rate charged by the lender.
j opl res soc 53: 647–654.
usage scores assess how much a borrower will use the loan product.
| article | openurl thomas lc (2009a).
loss given default validation  studies on the validation of internal rating systems.
direct versus indirect credit scoring  classifications.
benoit df and van den poel d (2009).
the first is the need to  validate the probability of default predictions that the scorecard makes  rather, than the relative ranking of the borrowers, which was what is important  in deciding which applicants for credit to accept.
the accord also concentrates on the long-run probability of default, not just the probability of default, in the next 12 months; it emphasises the need to stress test models and also requires some completely new estimates such as loss given default, which we will return to later.
quantile regression for modelling  distributions of profit and loss.
modeling data with multiple time dimensions.
at the same time, some lenders sought to integrate all the models into a customer lifetime value framework.