such a knowledge base would enable much more effective retrieval of web information, and promote new uses of the web to support knowledge-based inference and problem solving.such methods can provide automatic indexing and keyword assignment capabilities that are at least as accurate as human indexers in many applications.there is strong empirical and theoretic evidence that combination of retrieval methods can improve performance.benchmark experiments showed that their predictive performance were roughly comparable, especially on clean and well organized data sets.our techniques considerably improve the robustness and accuracy of the classification outcome, as shown in systematic experimental comparisons with previously published methods on three different real-world datasets.existing techniques for such "distributional clustering" of words are agglomerative in nature and result in (i) sub-optimal word clusters and (ii) high computational cost.these knowledge-based categorization methods are more powerful and accurate than statistical techniques.comparison with manually assigned classes shows that link information enhances classification in data with sufficiently high link density, but is detrimental to performance at low link densities or if the quality of the links is degraded.the results suggest that information extraction techniques can support high-precision text classification and, in general, using more extracted information improves performance.a stochastic decision list is an ordered sequence of if-then-else rules, and our method can be viewed as a rule-based method for text classification having advantages of readability and refinability of acquired knowledge.conventional methods such as decision trees have had competitive, but not optimal, predictive performance.the advantages of this approach over the knowledge engineering approach (consisting in the manual definition of a classifier by domain experts) are a very good effectiveness, considerable savings in terms of expert manpower, and straightforward portability to different domains.we present empirical studies (controlled experiments on boolean decision trees and a large-scale text categorization problem) which show that the model selection algorithm leads to error rates which are often as low as those obtained by 10-fold cross validation (sometimes even lower).our experiments on a variety of text categorization tasks indicate that there is significant potential in improving classifier performance by feature reweighting, beyond that achieved via selective sampling alone (standard active learning) if we have access to an oracle that can point to the important (most predictive) features.svms achieve substantial improvements over the currently best performing methods and behave robustly over a variety of different learning tasks.