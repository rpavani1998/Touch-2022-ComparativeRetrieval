each of these packages is selected by the distribution vendors to be a genuine and stable release of that package.
on one hand, they may find a flaw in these internals that can be indirectly exploited to compromise the security of a server.
there may also have been subtle changes in the file system layout.
commercial unix third party software that has been ported to linux will pose very little problem at all.
what's nice about rpm based distributions (redhat, mandrake, and others) is that almost all developers provide redhat .rpm
the hacker may go one step further to cause those machines that are compromised to begin executing those same programs.
linux has read and write support for all these file systems.
for those who are paranoid that the software they have downloaded is not the genuine article distributed by the maintainer of that software, digital signatures can verify the packager of that software.
cost of dedicated software that provides functions not inherently supported by the operating system.
linux can interoperate seamlessly with windows shared file systems, so this is one area where you will have few migration problems.
there are hence no prohibitive compatibility problems between linux distributions.
it will run almost any 16-bit or 32-bit dos application.
linux is also considered far easier to maintain than any commercial unix system because of its widespread use and hence easy access to linux expertise.
of the popular server operating systems, unix certainly has the most versatile, flexible, and applicable security model and file system structure.
a further issue is that when a security hole is discovered, system administrators fail to heed the warnings announced to the linux community.
with commercial systems, users are too stingy to share their knowledge because they feel that they owe nothing for having spent money on software.
smtp and pop/imap servers are an internet standard and can be replaced with linux servers.
if you are using scrap hardware, an adequate machine for the x window system should not have less than an intel 486 100 mhz processor and 8 megabytes of ram.
you will then have to compile your own kernel for the processor you are using and possibly recompile packages.
fundamentally, linux is just a unix system, and a very user-friendly one at that, so any difficulties with linux ought not to be greater than those with your proprietary unix system.
in our experience (from both discussions and development), linux's critical operations are always pedantically optimized--far more than would normally be encouraged in a commercial organization.
that is doubly if you are also paying for an operating system.
if this were to support a virus, it would only be able to damage the user's restricted space, but then it would be the application that is insecure, not l inux per se.
this tends to cost you in time or support charges.
new linux users discover that help abounds and that they never lack friendly discussions about any computing problem they may have.
in this way, you can trust linux far more than commercial institutions that think they have a lot to lose by disclosing flaws in their software.
gnu means doing things once in the best way possible, providing solutions instead of quick fixes and looking exhaustively at possibilities instead of going for the most brightly colored or expedient approach.
this tends to cost you in time or support charges.
it is only because of their efforts that the many critical packages that go into a unix distribution are available.
do not develop using tools that are tied very closely to the operating system and are therefore unlikely to ever have unix versions; there are free cross platform development tools that are more effective than popular commercial ides: use these languages instead.
note that recently some distributions are coming out with pentium-only compilations.
another issue is that linux servers are often installed by lazy people who do not take the time to follow the simplest of security guidelines, even though these guidelines are widely available and easy to follow.
finally, many professional companies provide assistance at comparable hourly rates.
watch thelinux weekly news to catch these.
should their basic unix knowledge be incomplete, a book like this one will provide a good reference.
the hacker may also mechanically try to attack a large number of machines by using custom programs.
there are web mail and web groupware services that run on linux servers that can be used from internet explorer.
because all packages require this library, this was said to introduce incompatibility.
the different distributions are very similar and share binary compatibility (provided that they are for the same type of processor of course)--that is, linux binaries compiled on one system will work on another.
when you get linux, it will be inside a standard distribution, probably on a cd.
if you are a private individual with no unix expertise available to help you when you run into problems and you are not interested in learning about the underlying workings of a unix system, then you shouldn't install linux.
this makes linux more secure because security holes are discovered and reported by a wide network of programers.
you can browse the installation documentation on the cd (if it has any) using internet explorer.
it is slightly less elegant to install.
depending on the area you look at, either linux or freebsd will have a better implementation.
linux is supposed to lack proper smp support and therefore not be as scalable as other oss.
i personally prefer to have access to the source code so that i know what my software is doing.
in addition, linux supports a wide range of other file systems like those of os/2, amiga, and other unix systems.
depending on the area you look at, either linux or freebsd will have a better implementation.
bit binaries with little to no performance penalty.
negative cost of multiple servers: linux can run many services (mail, file, web) from the same server rather than requiring dedicated servers, and this can be a tremendous saving.
another partial reason for this superiority is that gnu software is often written by people from academic institutions who are in the center of it research and are most qualified to dictate software solutions.
for instance, make a policy that all documents must be saved in a portable format that is not bound to a particular wordprocessor package.
downloading from an ftp site is going to take a long time unless you have a really fast link.
the average secretary will take many frustrating weeks gaining confidence with a different platform, while the system administrator will battle for much longer.
for instance, it is entirely feasible to run apache (a web server package) on a sco, irix, or sun systems, yet managers will request, for example, that their staff be taught how to configure a linux ``web server'' in order to avoid web server licensing fees.
for instance, document font sizes, page breaking, and spacing will not be preserved exactly.
cost of essential upgrades.
because users constantly interact and discuss linux issues, 99% of the problems a user is likely to have would have already been documented or covered in mailing list archives, often obviating the need to ask anyone at all.
because many of the critical components of a typical linux distribution are really just gnu tools developed long before linux, it is unfair to merely call a distribution ``linux''.
because gnu software is open source, any hacker can easily research the internal workings of critical system services.
with 64 megabytes of ram and a 2-megabyte graphics card (i.e., capable of run 1024x768 screen resolution in 15/16 bit color).
in general, well-established brand names will always work, but will tend to cost more.
because all packages require this library, this was said to introduce incompatibility.
the web is also an excellent place for support.
unfortunately, it's not a marketable term because it requires this very explanation, which tends to bore people who don't really care about licensing issues.
commercial distributions may contain proprietary software that you may not be allowed to install multiple times.
should their basic unix knowledge be incomplete, a book like this one will provide a good reference.
debian package management is vastly superior to any other.
another important consideration is that the freebsd maintainers go to far more effort securing freebsd than does any linux vendor.
freebsd is like a linux distribution in that it also relies on a large number of gnu packages.
the developer who does the porting will need to be an expert in unix development and an expert in windows development.
proprietary unix systems are not as user friendly as linux.
for those who are paranoid that the software they have downloaded is not the genuine article distributed by the maintainer of that software, digital signatures can verify the packager of that software.
proprietary software is often looked down upon in the free software world for many reasons: the result of these limitations is that proprietary software gnu software, on the other hand, is open for anyone to scrutinize.
on the other hand, your windows or os/2 server, for example, has to be licensed.
for people to feel it is useful means that they have to have used it over a period of time; in this way only good, thoroughly reviewed software gets included.
each of these packages is selected by the distribution vendors to be a genuine and stable release of that package.
at boot time, a boot prompt will ask you to select which operating system you would like to boot into.
you as the user are not going to download arbitrary untested software any more than you would if you were using windows.
using a newsgroup has the benefit of the widest possible audience.
this makes freebsd a more trustworthy alternative.
it runs a great number of 32-bit dos games as well.
debian: this is probably the most technically advanced.
an office tends to operate organically with individuals learning tricks from each other over long periods of time.
if you are an absolute beginner and don't really feel like thinking about what distribution to get, one of the most popular and easiest to install is mandrake.
you can make a linux system completely airtight by following a few simple guidelines, like being careful about what system services you expose, not allowing passwords to be compromised, and installing utilities that close possible vulnerabilities.
when the word gnu is mentioned, it usually evokes feelings of extreme left-wing geniuses who in their spare time produce free software that is far superior to anything even large corporations can come up with through years of dedicated development.
sometimes this means that development takes longer as more people quibble over the best way of doing things.
in addition, linux supports a wide range of other file systems like those of os/2, amiga, and other unix systems.
most distributions have very comprehensive installation guides, which is the reason i do not cover installation in this book.
you still have to buy windows though.
it helps to think more laterally when trying to get information about linux : would-be l inux users everywhere need to know how to install l inux.
finally, many professional companies provide assistance at comparable hourly rates.
it's a pain to install and manage, although school kids who don't know any better love it.
if this were to support a virus, it would only be able to damage the user's restricted space, but then it would be the application that is insecure, not l inux per se.
the dos emulator package for linux is called dosemu.
a useful distribution of packages that includes the x window system (unix's graphical environment) will occupy less than 1 gigabyte.
you will be able to cut and paste between windows and linux application.
for example, if you distribute copies of such a program, whether gratis or for a fee, you must give the recipients all the rights that you have.
collaborated effort between different developers means that code is shared and effort is not replicated.
do not develop using tools that are tied very closely to the operating system and are therefore unlikely to ever have unix versions; there are free cross platform development tools that are more effective than popular commercial ides: use these languages instead.
remember also that with linux, a sufficient understanding of the system makes it possible to easily detect and repair the corruption, without have to do anything drastic, like reinstalling or buying expensive virus detection software.
i personally prefer to have access to the source code so that i know what my software is doing.
gui applications written specifically for windows are difficult to port to a unix system.
it is especially noticeable how fast the file system access is and how it scales smoothly when multiple services are being used simultaneously.
the hacker may also mechanically try to attack a large number of machines by using custom programs.
you can make a linux system completely airtight by following a few simple guidelines, like being careful about what system services you expose,
it is also because of them that a freely available, comprehensive, legally definitive, free-software license is available.
it is not found, for instance, that security holes are covered up by maintainers for commercial reasons.
for instance, make a policy that all documents must be saved in a portable format that is not bound to a particular wordprocessor package.
at boot time, a boot prompt will ask you to select which operating system you would like to boot into.
also make sure you have the latest version of whatever it is you're buying or downloading.
linux has several times the installed base of any unix system.
most probably, a team of core developers would take over the task if linus no longer worked on the kernel.
this means that your old 386 will no longer work.
for technical reasons, however, the swap space formerly required division into separate partitions of 128 megabytes each.
the average secretary will take many frustrating weeks gaining confidence with a different platform, while the system administrator will battle for much longer.
get a grip on what this means: you can run minesweep under linux and it will come up on yourx window screen next to your other linux applications and look exactly like what it does under windows--and you don't have to buy windows.
there may also have been subtle changes in the file system layout.
hence, rather ask around who locally sells linux on cd.
because of the legal terms of the gpl, for linux to be distributed under a different copyright would require the consent of all 200+ persons that have ever contributed to the linux source code.
this may not be up-to-date, so it's best to go to the various references listed in this document and get the latest information.
this may not be up-to-date, so it's best to go to the various references listed in this document and get the latest information.
new linux users discover that help abounds and that they never lack friendly discussions about any computing problem they may have.
linux can interoperate seamlessly with windows shared file systems, so this is one area where you will have few migration problems.
linux programs will work regardless of the kernel version.
unfortunately, it's not a marketable term because it requires this very explanation, which tends to bore people who don't really care about licensing issues.
sometimes this means that development takes longer as more people quibble over the best way of doing things.
availability of used hardware and the os's capacity to support it.
for example, unix inherently restricts access to files outside the user's privilege space, so a virus would have nothing to infect.
note that no corporate body oversees linux.
on one hand, they may find a flaw in these internals that can be indirectly exploited to compromise the security of a server.
another partial reason for this superiority is that gnu software is often written by people from academic institutions who are in the center of it research and are most qualified to dictate software solutions.
force your developers to test their web pages on netscape/mozilla as well as internet explorer.
learn about the capabilities of linux by watching internet publications: a manager who is not prepared to do this much should not expect their staff to do better.
the term gnu/linux is more accurate and gives credit to the larger part of linux.
also make sure you have the latest version of whatever it is you're buying or downloading.
however, many applications (especially large and complex ones) do not display correctly under linux or crash during operation.
viruses are small programs that exploit social engineering, logistics, and the inherent flexibility of a computer system to do undesirable things.
unix systems are used as database, file, and internet servers.
it is true, however, that multiple versions of libraries can coexist on the same system, and hence no serious compatibility problem was ever introduced in this transition.
it is really academia that develops the theoretical models for computer science--industry only implements these.
another issue is that linux servers are often installed by lazy people who do not take the time to follow the simplest of security guidelines, even though these guidelines are widely available and easy to follow.
unix systems that run on specialized hardware are almost never worth what you paid for them in terms of a cost/performance ratio.
it is important to gauge whether your staff have a real understanding of the tcp/ip networks and unix systems that you are depending on, rather then merely using a trial-and-error approach to configuring your machines.
because of the community nature of linux users, there is openness and honesty with regard to security issues.
because source code can be viewed by anyone, developers write code more carefully and are more inspired and more meticulous.
of the popular server operating systems, unix certainly has the most versatile, flexible, and applicable security model and file system structure.
get a grip on what this means: you can run minesweep under linux and it will come up on yourx window screen next to your other linux applications and look exactly like what it does under windows--and you don't have to buy windows.
allowing passwords to be compromised, and installing utilities that close possible vulnerabilities.
there are more examples of linux versions of windows languages, however, any application that interfaces with many proprietary tools and is written in a proprietary language is extremely difficult to port.
many windows games do, however, work quite well under linux, including those with accelerated 3d graphics.
however, most of the time peer review results in a more reliable product.
hence, your other partitions will be readable from linux.
hence, your other partitions will be readable from linux.
a net search will reveal the enormous amount of information available.
linux might even split into different development teams if a disagreement did break out about some programming issue, and it might rejoin later on.
unix systems are multitasking and multiuser systems, meaning that multiple concurrent users running multiple concurrent programs can connect to and use the same machine.
although linux is free, a good knowledge of unix is required to install and configure a reliable server.
hence, if you get one of these on cd, feel free to install it as many times as you like.
there are more examples of linux versions of windows languages, however, any application that interfaces with many proprietary tools and is written in a proprietary language is extremely difficult to port.
viruses are small programs that exploit social engineering, logistics, and the inherent flexibility of a computer system to do undesirable things.
in other cases, authors write software for their own use out of their own dissatisfaction for existing proprietary software--a powerful motivation.
hence, if your hardware is not performing the absolute best it can, it's by a very small margin.
typical users should purchase an entry-level pc with at least 16 megabytes of ram if they are going to run the x window system (unix's graphical environment) smoothly.
costs far more than it is worth.
winelib is a part of the wine package (see below) and allows windows c applications to be recompiled to work under linux.
in general, the performance improvement of a linux machine is quite visible to users and administrators.
linux typically performs 50% to 100% better than other operating systems on the same hardware.
be aware that people will make any excuse to avoid having to learn something new.
because source code can be viewed by anyone, developers write code more carefully and are more inspired and more meticulous.
identify common problems and create procedures for solving them.
this will not only improve code quality but will make the code more portable.
it sometimes refers to any proprietary vendor releasing source code to their package, even though that source code is not free in the sense of users being able to modify it and redistribute it.
on the other hand, individuals may find a flaw in these internals that they can report to the authors of that package, who will quickly (sometimes within hours) correct the insecurity and release a new version on the internet.
what is clear is that the number of linux users is doubling consistently every year.
there are web mail and web groupware services that run on linux servers that can be used from internet explorer.
if you are an absolute beginner and don't really feel like thinking about what distribution to get, one of the most popular and easiest to install is mandrake.
it is also doesn't matter to the end user because the end user has selected a popular linux distribution packaged by someone who has already dealt with these issues.
one gigabyte of free disk space is necessary.
because the unix name is a registered trademark, most systems are not called unix.
linux typically performs 50% to 100% better than other operating systems on the same hardware.
typical users should purchase an entry-level pc with at least 16 megabytes of ram if they are going to run the x window system (unix's graphical environment) smoothly.
in this case, it will be essential to hire an experienced developer who is familiar with the gnu compiler tools.
most can (and do) actually work on any other of the unix systems mentioned above.
the hacker may go one step further to cause those machines that are compromised to begin executing those same programs.
identify common problems and create procedures for solving them.
on the other hand, debian packages are mostly created by people on the debian development team, who have rigorous standards to adhere to.
it will run almost any 16-bit or 32-bit dos application.
gnu software, on the other hand, is open for anyone to scrutinize.
however, although linux cannot itself execute a virus, it may be able to pass on a virus meant for a windows machine should a linux machine act as a mail or file server.
open industry and academic standards are adhered to, to make software consistent and compatible.
before installing any linux machines, you should identify what each person in your organization does with their computer.
thousands of web pages are devoted to different free software packages.
the installation procedure will be completely different for each distribution.
a useful distribution of packages that includes the x window system (unix's graphical environment) will occupy less than 1 gigabyte.
it is not the case that any person is free to modify original distributions of packages and thereby hurt the names of the maintainers of that package.
this enables mostly flawless running of windows under linux if you really have to and at a large performance penalty.
what is often missed, is that their staff have little basic unix experience to begin with.
you as the user are not going to download arbitrary untested software any more than you would if you were using windows.
can do anything behind your back without your knowing.
browse around your cd to find it or consult your vendor's web site.
linux users, on the other hand, are very supportive of other linux users.
linux has a far more dedicated and ``beginner friendly'' documentation project than any commercial unix, and many more user-friendly interfaces and commands.
usually these studies are done with one or other competing system having better expertise at its disposal and are, hence, grossly biased.
linux's up-and-coming graphical user interfaces (gui) are the most functional and aesthetically pleasing ever to have graced the computer screen.
it doesn't really matter much from the end user's perspective, since gnu software by its nature always tends to gravitate towards consistency and improvement, one way or another.
such systems are sitting ducks and are often attacked.
as linux begins to dominate the embedded market, that number will soon surpass the number of all other operating systems combined.
it can do anything that any other network server can do, more efficiently and reliably.
it is not the case that any person is free to modify original distributions of packages and thereby hurt the names of the maintainers of that package.
being an in-house application, the primary concern of the developers was to ``get it working'', and that might have been accomplished only by a very small margin.
on the other hand, debian packages are mostly created by people on the debian development team, who have rigorous standards to adhere to.
one gigabyte of free disk space is necessary.
note that scrap hardware can bevery time consuming to configure.
even if it did happen, new developers would probably rally in defiance and continue to work on the kernel as it is.
suddenly running the code on a different platform will unleash havoc, especially if it was badly written.
the different distributions are very similar and share binary compatibility (provided that they are for the same type of processor of course)--that is, linux binaries compiled on one system will work on another.
if you really need this much memory, you should be using a 64-bit system, like a dec alpha, or sun ultrasparc machine.
note that recently some distributions are coming out with pentium-only compilations.
gnu also means a healthy disrespect for the concept of a deadline and a release schedule.
you may not be able to migrate to linux immediately, but you can save yourself enormous effort by taking steps in anticipation of that possibility.
this means that in the event of a power failure, there is very little chance that the file system would ever be corrupted, or that manual intervention would be required to fix the file system.
linux itself can operate as a web, file, smb (winnt), novell, printer, ftp, mail, sql, masquerading, firewall, and pop server to name but a few.
a further issue is that when a security hole is discovered, system administrators fail to heed the warnings announced to the linux community.
wean people off tools and network services that do not have unix equivalents.
these people come from such a variety of places, that such a task is logistically infeasible.
companies will have to make careful decisions about standardizing what people use, and creating customizations peculiar to their needs.
whereas windows does not offer a wide range of options with regards to desktops and office suites, the look-and-feel of a linux machine can be as different between the desktops of two users as is windows 98 different from an apple macintosh.
freebsd is like a linux distribution in that it also relies on a large number of gnu packages.
however, all software specifically written for linux will recompile without any modifications on another linux platform in addition to compiling withfew modifications on other unix systems.
linux programs will work regardless of the kernel version.
yes, linux will occupy two or more partitions, while windows will sit in one of the primary partitions.
most distributions have very comprehensive installation guides, which is the reason i do not cover installation in this book.
some distributions are, however, created for specific hardware, and thus their packages will only run on that hardware.
linux is said to be posix compliant, meaning that it confirms to a certain definite computing standard laid down by academia and industry.
the installation procedure will be completely different for each distribution.
some distributions are, however, created for specific hardware, and thus their packages will only run on that hardware.
there are many kernel developers who have sufficient knowledge to do the job of linus.
the upshot of this is that although your proprietary unix system will perform as reliably as linux, it will be more time consuming to maintain.
using a newsgroup has the benefit of the widest possible audience.
this makes linux more secure because security holes are discovered and reported by a wide network of programers.
another important consideration is that the freebsd maintainers go to far more effort securing freebsd than does any linux vendor.
implicit costs of server downtime because of security breaches.
for example, you may get linux up and running on many other hardware platforms, but it would take some time and expertise to install, and you might not have graphics capabilities.
make the necessary books available to them.
i have heard that linux does not suffer from virus attacks.
it is important to gauge whether your staff have a real understanding of the tcp/ip networks and unix systems that you are depending on, rather then merely using a trial-and-error approach to configuring your machines.
because a unix system does not allow this kind of flexibility in the first place, there is categorically no such thing as a virus for it.
hence, if your hardware is not performing the absolute best it can, it's by a very small margin.
note that word and excel documents can be read by various linux office applicationsbut complex formatting will not convert cleanly.
network servers can run on a 386 with 4 megabytes of ram and a 200-megabyte hard drive.
if you are developing using a compiler language, your developers should ensure that code compiles cleanly with independent brands of compiler.
each new incarnation of a distribution will have newer versions of packages contained therein and better installation software.
note that scrap hardware can bevery time consuming to configure.
unix systems that run on specialized hardware are almost never worth what you paid for them in terms of a cost/performance ratio.
linux contains a highly advanced dos emulator.
however, although linux cannot itself execute a virus, it may be able to pass on a virus meant for a windows machine should a linux machine act as a mail or file server.
because it is easy to survey online machines, it is well-established that over 25% of all web servers run linux.
if you have any custom applications, you need to identify what they do and create a detailed specification of their capabilities.
there are many kernel developers who have sufficient knowledge to do the job of linus.
because a unix system does not allow this kind of flexibility in the first place, there is categorically no such thing as a virus for it.
this free kernel would amass more followers and would quickly become the standard, with or without linus.
collaborated effort between different developers means that code is shared and effort is not replicated.
learn about the capabilities of linux by watching internet publications: a manager who is not prepared to do this much should not expect their staff to do better.
the distribution has legendary technical excellence and stability.
if you really need this much memory, you should be using a 64-bit system, like a dec alpha, or sun ultrasparc machine.
a network server that does not have to run x can get away with about 100-300 megabytes.
applicationsbut complex formatting will not convert cleanly.
in 1984 the free software foundation (fsf) set out to create a free unix -like system.
you will be able to cut and paste between windows and linux application.
force your developers to test their web pages on netscape/mozilla as well as internet explorer.
such systems are sitting ducks and are often attacked.
what is often missed, is that their staff have little basic unix experience to begin with.
users have close and direct contact with developers, ensuring that bugs are fixed quickly and that user needs are met.
if you are developing using a compiler language, your developers should ensure that code compiles cleanly with independent brands of compiler.
it is not found, for instance, that security holes are covered up by maintainers for commercial reasons.
on the whole, freebsd is thought to have a better architecture, although linux has had the benefit of having been ported to many platforms, has a great many more features, and supports far more hardware.
when you get linux, it will be inside a standard distribution, probably on a cd.
linux supports a full 64 gigabytes of memory, with 1 gigabyte of unshared memory per process.
linux might even split into different development teams if a disagreement did break out about some programming issue, and it might rejoin later on.
the developer who does the porting will need to be an expert in unix development and an expert in windows development.
for example, unix inherently restricts access to files outside the user's privilege space, so a virus would have nothing to infect.
all applications, network server programs, and utilities that go into a full linux machine are free software programs recompiled to run under the linux kernel.
it typically runs applications much faster than does normal dos because of linux's faster file system access and system calls.
on the other hand, conditions sometimes allow an intelligent hacker to target a machine and eventually gain access.
most packages have email lists where the very developers are available for questions.
remember also that with linux, a sufficient understanding of the system makes it possible to easily detect and repair the corruption, without have to do anything drastic, like reinstalling or buying expensive virus detection software.
because it is easy to survey online machines, it is well-established that over 25% of all web servers run linux.
downloading from an ftp site is going to take a long time unless you have a really fast link.
you may not be able to migrate to linux immediately, but you can save yourself enormous effort by taking steps in anticipation of that possibility.
implicit costs of server downtime because of software bugs.
it runs a great number of 32-bit dos games as well.
it can run in an x window just like a dos window under windows.
these people come from such a variety of places, that such a task is logistically infeasible.
gui applications written specifically for windows are difficult to port to a unix system.
in our experience (from both discussions and development), linux's critical operations are always pedantically optimized--far more than would normally be encouraged in a commercial organization.
l inux can run on as little as a single stiffy disk--that's 1.4 megabytes--and still perform various network services.
you will then have to compile your own kernel for the processor you are using and possibly recompile packages.
what is clear is that the number of linux users is doubling consistently every year.
cost of maintenance.
linux is supposed to lack proper smp support and therefore not be as scalable as other oss.
well written unix applications (even gui applications) will, however, port very easily to linux and of course to other unix systems.
browse around your cd to find it or consult your vendor's web site.
for people to feel it is useful means that they have to have used it over a period of time; in this way only good, thoroughly reviewed software gets included.
most packages have email lists where the very developers are available for questions.
gnu means doing things once in the best way possible, providing solutions instead of quick fixes and looking exhaustively at possibilities instead of going for the most brightly colored or expedient approach.
however, mandrake, redhat, debian, and slackware are all committed to freedom and hence will not have any software that is not redistributable.
this will not only improve code quality but will make the code more portable.
when the word gnu is mentioned, it usually evokes feelings of extreme left-wing geniuses who in their spare time produce free software that is far superior to anything even large corporations can come up with through years of dedicated development.
suddenly running the code on a different platform will unleash havoc, especially if it was badly written.
an office tends to operate organically with individuals learning tricks from each other over long periods of time.
users can (and do) freely fix and enhance software for their own needs, and then allow others the benefit of their extensions.
you are allowed to charge for the service of distributing, installing, and maintaining software.
for technical reasons, however, the swap space formerly required division into separate partitions of 128 megabytes each.
network servers can run on a 386 with 4 megabytes of ram and a 200-megabyte hard drive.
although linux is free, a good knowledge of unix is required to install and configure a reliable server.
fails to build on existing software because of licensing issues.
in general, the performance improvement of a linux machine is quite visible to users and administrators.
fundamentally, linux is just a unix system, and a very user-friendly one at that, so any difficulties with linux ought not to be greater than those with your proprietary unix system.
be aware that people will make any excuse to avoid having to learn something new.
in this way, linux isless secure because security holes can be discovered by arbitrary individuals.
even if it did happen, new developers would probably rally in defiance and continue to work on the kernel as it is.
by not upgrading that service, they leave open a window to opportunistic hackers.
it is especially noticeable how fast the file system access is and how it scales smoothly when multiple services are being used simultaneously.
because gnu software is open source, any hacker can easily research the internal workings of critical system services.
smtp and pop/imap servers are an internet standard and can be replaced with linux servers.
our general public licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for this service if you wish), that you receive source code or can get it if you want it, that you can change the software or use pieces of it in new free programs; and that you know you can do these things.
wean people off tools and network services that do not have unix equivalents.
but a package will not find its way into a distribution unless someone feels that it is a useful one.
linux has a proper journalling file system called reiserfs.
with 64 megabytes of ram and a 2-megabyte graphics card (i.e., capable of run 1024x768 screen resolution in 15/16 bit color).
many windows games do, however, work quite well under linux, including those with accelerated 3d graphics.
this means that linux is largely compatible with other unix systems (the same program can be easily ported to run on another unix system with few (sometimes no) modifications) and will network seamlessly with other unix systems.
you are allowed to charge for the service of distributing, installing, and maintaining software.
you still have to buy windows though.
linux has a far more dedicated and ``beginner friendly'' documentation project than any commercial unix, and many more user-friendly interfaces and commands.
it is the nonprohibition to redistribute and modify gnu software that is meant by the word free.
if you have any custom applications, you need to identify what they do and create a detailed specification of their capabilities.
however, all software specifically written for linux will recompile without any modifications on another linux platform in addition to compiling withfew modifications on other unix systems.
well written unix applications (even gui applications) will, however, port very easily to linux and of course to other unix systems.
note that the gpl does not say that gnu software is without cost.
on the whole, freebsd is thought to have a better architecture, although linux has had the benefit of having been ported to many platforms, has a great many more features, and supports far more hardware.
because of the community nature of linux users, there is openness and honesty with regard to security issues.
most probably, a team of core developers would take over the task if linus no longer worked on the kernel.
the result of these limitations is that proprietary software does not conform to good standards for information technology.
being an in-house application, the primary concern of the developers was to ``get it working'', and that might have been accomplished only by a very small margin.
users can (and do) freely fix and enhance software for their own needs, and then allow others the benefit of their extensions.
hence, if you get one of these on cd, feel free to install it as many times as you like.
commercial unix third party software that has been ported to linux will pose very little problem at all.
users are not allowed to share the software.
for instance, it is entirely feasible to run apache (a web server package) on a sco, irix, or sun systems, yet managers will request, for example, that their staff be taught how to configure a linux ``web server'' in order to avoid web server licensing fees.
on the other hand, individuals may find a flaw in these internals that they can report to the authors of that package, who will quickly (sometimes within hours) correct the insecurity and release a new version on the internet.
but a package will not find its way into a distribution unless someone feels that it is a useful one.
in this way, you can trust linux far more than commercial institutions that think they have a lot to lose by disclosing flaws in their software.
l inux can run on as little as a single stiffy disk--that's 1.4 megabytes--and still perform various network services.
it doesn't really matter much from the end user's perspective, since gnu software by its nature always tends to gravitate towards consistency and improvement, one way or another.
a network server that does not have to run x can get away with about 100-300 megabytes.
in this case, it will be essential to hire an experienced developer who is familiar with the gnu compiler tools.
on 64-bit systems, linux supports more memory than most first-world governments can afford to buy.
this makes freebsd a more trustworthy alternative.
users are unable to add features to the software.
the upshot of this is that although your proprietary unix system will perform as reliably as linux, it will be more time consuming to maintain.
for instance, document font sizes, page breaking, and spacing will not be preserved exactly.
smb file servers can be replaced by linux samba servers.
however, many applications (especially large and complex ones) do not display correctly under linux or crash during operation.
maintainers of packages ensure that official releases are downloadable from their home pages and will upload original versions onto well-established ftp servers.
maintainers of packages ensure that official releases are downloadable from their home pages and will upload original versions onto well-established ftp servers.
however, mandrake, redhat, debian, and slackware are all committed to freedom and hence will not have any software that is not redistributable.
it is true, however, that multiple versions of libraries can coexist on the same system, and hence no serious compatibility problem was ever introduced in this transition.
in other cases, authors write software for their own use out of their own dissatisfaction for existing proprietary software--a powerful motivation.
our general public licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for this service if you wish), that you receive source code or can get it if you want it, that you can change the software or use pieces of it in new free programs; and that you know you can do these things.
if you buy one of these, you might have to wait many months before support becomes available (if ever).
wastes a lot of time duplicating the effort of other proprietary software.
it is completely free and very well structured as well as standards conformant.
the linux kernel version does not affect the linux user.
before installing any linux machines, you should identify what each person in your organization does with their computer.
users are unable to correct errors (bugs) in the software.
on the other hand, conditions sometimes allow an intelligent hacker to target a machine and eventually gain access.
would-be l inux users everywhere need to know how to install l inux.
this means that in the event of a power failure, there is very little chance that the file system would ever be corrupted, or that manual intervention would be required to fix the file system.
you must make sure that they, too, receive or can get the source code.
each new incarnation of a distribution will have newer versions of packages contained therein and better installation software.
linux supports a full 64 gigabytes of memory, with 1 gigabyte of unshared memory per process.
for example, if you distribute copies of such a program, whether gratis or for a fee, you must give the recipients all the rights that you have.
smb file servers can be replaced by linux samba servers.
whereas windows does not offer a wide range of options with regards to desktops and office suites, the look-and-feel of a linux machine can be as different between the desktops of two users as is windows 98 different from an apple macintosh.
on 64-bit systems, linux supports more memory than most first-world governments can afford to buy.
this enables mostly flawless running of windows under linux if you really have to and at a large performance penalty.
you can browse the installation documentation on the cd (if it has any) using internet explorer.
on page, and the web sites entry in the index.
users have close and direct contact with developers, ensuring that bugs are fixed quickly and that user needs are met.
tries to be better than other proprietary software without meeting real technical and practical needs.
it typically runs applications much faster than does normal dos because of linux's faster file system access and system calls.
open industry and academic standards are adhered to, to make software consistent and compatible.
people can get far better support from the internet community than they would from their commercial software vendors.
in general, well-established brand names will always work, but will tend to cost more.
linux also performs well when loaded by many services simultaneously.
commercial distributions may contain proprietary software that you may not be allowed to install multiple times.
linux also performs well when loaded by many services simultaneously.
this free kernel would amass more followers and would quickly become the standard, with or without linus.
it is really academia that develops the theoretical models for computer science--industry only implements these.
gnu also means a healthy disrespect for the concept of a deadline and a release schedule.
usually these studies are done with one or other competing system having better expertise at its disposal and are, hence, grossly biased.
a unix system is the standard choice when a hardware vendor comes out with a new computer platform because unix is most amenable to being ported.
however, most of the time peer review results in a more reliable product.
with commercial systems, users are too stingy to share their knowledge because they feel that they owe nothing for having spent money on software.
there are hence no prohibitive compatibility problems between linux distributions.
by not upgrading that service, they leave open a window to opportunistic hackers.
slackware: this was the first l inux distribution and is supposed to be the most current (software is always the latest).
it may do other damage.
companies will have to make careful decisions about standardizing what people use, and creating customizations peculiar to their needs.
as linux begins to dominate the embedded market, that number will soon surpass the number of all other operating systems combined.
in this way, linux isless secure because security holes can be discovered by arbitrary individuals.
redhat is also supported quite well in industry.
it is also doesn't matter to the end user because the end user has selected a popular linux distribution packaged by someone who has already dealt with these issues.
yes, linux will occupy two or more partitions, while windows will sit in one of the primary partitions.
it is the nonprohibition to redistribute and modify gnu software that is meant by the word free.
most vendors try to comply with this standard, and hence l inux systems will look very similar from one distribution to another.
linux supports as much swap space as you like.
it sometimes refers to any proprietary vendor releasing source code to their package, even though that source code is not free in the sense of users being able to modify it and redistribute it.
if you are using scrap hardware, an adequate machine for the x window system should not have less than an intel 486 100 mhz processor and 8 megabytes of ram.
if you buy one of these, you might have to wait many months before support becomes available (if ever).
people can get far better support from the internet community than they would from their commercial software vendors.
because users constantly interact and discuss linux issues, 99% of the problems a user is likely to have would have already been documented or covered in mailing list archives, often obviating the need to ask anyone at all.
that is doubly if you are also paying for an operating system.
linux is also considered far easier to maintain than any commercial unix system because of its widespread use and hence easy access to linux expertise.
note that word and excel documents can be read by various linux office
because of the legal terms of the gpl, for linux to be distributed under a different copyright would require the consent of all 200+ persons that have ever contributed to the linux source code.
on the other hand, your windows or os/2 server, for example, has to be licensed.