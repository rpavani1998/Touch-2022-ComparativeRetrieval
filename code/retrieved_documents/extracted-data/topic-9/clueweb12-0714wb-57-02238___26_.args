under heavy i/o, journalling can guarantee filesystem data integrity (modulo coding bugs).a modern journalling filesystem should not experience any corruption after a crash, because journal recovery is supposed to keep data structures consistent.especially when you troubleshoot a server with a subfolder containing 12gb of log files, and have no direction or policy about what to do with those old log files, you could safely enable compression on the folder and they magically take up less space.file level encryption is useful for volumes where bitlocker can't be used.microsoft has done one thing well, and that is to lower the expectations of their users so far, that what should have been a few second journal recovery turned into a big outage and manual recovery of a massively corrupted filesystem, and that gains them "absolute respect".it is also able to cloud data across multiple volumes on different machines from what i read.cold fusion supports providing us with unlimited power from a glass of water, it prints money, it gives the user eternal life, it allows the user to travel faster than the speed of life and -- when activated -- attractive women jump out of the core reactor demanding money shot after money shot.not only that, but no filesystem, journalling or not, should cause a kernel crash if it is corrupted.the bug only surfaces when you're part of an enterprise active directory network that has group policies & domain admins, and it only crops up with specific combinations of group policy settings that look innocent in and of themselves, but have disabling the creation of symlinks by local admin members (but nobody else) as an unintended side effect.let's see: 32k file name and path limits (instad of 255), on-line recovery from corruption (no more "check disk" or offline recovery-rebuild), faster performance, built in recovery of data on failed disks (via storage spaces), hot-adding-more-storage to volumes, better control of allocation and localization on the drive, attribute checksums (and auto detection and recovery from "bitrot")....in that regard, it is more like zfs and btrfs, and on par with the best filesystems out there.if you have a relatively small array and it still takes 45 days to rebuild then you have a hardware issue, or you are using an siig card, which has horrible performance under all the unix/linux variants i have used.apple are good at complete systems, they are not as good at components that work nicely with others .ntfs is overly complex and unpredictable as a disk format 3) ntfs is outdated and doesn't support modern features point 1 is evidenced by how basic tools (explorer, file dialogs, etc.) don't support many of the features.the big change in osx is that the api and developer tools promote file extensions over metadata.