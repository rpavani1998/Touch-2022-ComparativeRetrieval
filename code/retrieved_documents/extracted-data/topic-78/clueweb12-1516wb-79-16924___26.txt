add(right[0]);  right.removeat(0); } else { rv.add(left[0]); left.removeat(0); } for (int i =
function to merge sort a list: # let rec merge_sort = function | [] | [_] as list -> list | list -> let l1, l2 = halve list in merge (merge_sort l1, merge_sort l2) ;; val sort : 'a list -> 'a list =
l until h > r loop a.item  (h) := b.item (h) h := h+1 end end feature --
[6; 7; 0; 8; 3; 2; 4; 9; 5; 1];; - : int list =
mergesort(right) result =
integer, dimension(n) :: a = (/ 1, 5, 2, 7, 3, 9, 4, 6 /) integer,  dimension ((n+1)/2) :: t call mergesort(a,n,t)  write(*,'(a,/,10i3)')'sorted array :',a end program testmergesort [edit] groovy def mergesort(list){
while (len(result)  (cdar primero) (cdar segundo)) (cons (car segundo) (mergelist primero (cdr segundo));;second main case ) ) ) ) version without additional storage const proc: mergesort (inout array elemtype: arr, in var integer: lo, in integer: hi) is func local var integer:
ada implementation uses type data_t for the data array.
ys (*merges two sorted lists to form a sorted list *) | merge  (xs,[]) =
j until h > r loop b.item (k+h-j) := a.item  (h) h := h+1 end elseif j > m then from h :=
a sorted vector of integers  //!
[y|rest], merge([x|xs], ys, rest) ).
the discrepancy is due to knuth analyzing a variant  implementation of merge sort that is slightly sub-optimal.
while(left_it  using namespace std; void merge(int a[], const int low, const int mid, const int high) { // variables declaration.
a def merge(a as (a::as),b as (b::bs) )
\brief merges two sorted vectors into one sorted vector //!
int * b =  new int[high+1-low]; int h,i,j,k; h=low; i=0; j=mid+1; //
nc integer, intent(in out) :: a(na)  !
merge([x|xs], [y|ys],  zs) :- ( x @= zs =
mid is 0; var elemtype: help is  elemtype.value; var integer: k is 0; begin if lo  hi or arr[t_lo]  0 && [set lright
in this application, we sort each new piece that is received using any sorting algorithm, and then merge it into our sorted list so far using the merge operation.
mid is 0; var elemtype: help is elemtype.value; var integer: k is 0; begin if lo  hi or arr[t_lo]  0 && [set lright [llength $right]] > 0} { if {[lindex $left 0]  0} {lappend res {*}$left} if {$lright > 0} {set res [concat $res $right]} return $res } fun mergesort [] =
however, iterative, non-recursive, implementations of  merge sort, avoiding method call overhead, are not difficult to code.
in terms  of moves, merge sort's worst case complexity is o(n log n)—the same  complexity as quicksort's best case, and merge sort's best case takes about  half as many iterations as the worst case.
if( list.size()  0 || right.size() > 0) if(left.get(0)  [a] -> [a] sort [] =
on the plus side, merge sort is a stable sort, parallelizes better, and is more efficient at handling slow-to-access sequential media.
> 0 append left to resultif length(right) > 0 append right to result return result
if x<y then x::merge (xs,y::ys) else  y::merge (x::xs,ys)  ; val half = length(lst) div 2; in merge (mergesort  (list.take (lst, half)),mergesort (list.drop (lst, half))) end ; [edit] analysis in sorting n items, merge sort has an average and worst-case performance of  o(n log n).
finishes the copy of the uncopied part of the array if i > m then from h :=
[array!y | y  list | h1::t1, h2::t2 -> if h1  'a list =  this function is included in the ocaml stdlib as list.merge but is also included here for clarity.
note, the worst case number  given here does not agree with that given in knuth's art of computer  programming, vol 3.
recursive implementations of merge sort make 2n - 1 method calls in the  worst case, compared to quicksort's n, thus has roughly twice as much recursive  overhead as quicksort.
v endif return endif na=(n+1)/2 nb=n-na call mergesort(a,na,t) call mergesort(a(na+1),nb,t) if (a(na) > a(na+1))
this opportunity might change if fast memory becomes very cheap again, or if exotic architectures like the tera mta become commonplace.
in the worst case, merge sort does exactly (n ⌈log n⌉ -  2⌈log n⌉ + 1) comparisons, which is between (n log n - n + 1) and  (n log n - 0.9139·n + 1)
this page was last modified on 18 january 2012, at 21:52.
1: return arr m = len(arr) / 2 l = mergesort(arr[:m]) r =
the closed form follows from the master theorem.
in the worst case, merge sort does about 39% fewer comparisons than  quicksort does in the average case; merge sort always makes fewer comparisons  than quicksort, except in extremely rare cases, when they tie, where merge  sort's worst case is found simultaneously with quicksort's best case.
rest(left)else append first(right) to result right =
[] | [_] as t1 -> t1, [] | h::t -> let t1, t2 = halve t in h::t2, t1 ;; val halve : 'a list -> 'a list * 'a list =
if (sizeof($arraytosort) 0 && count($rf)>0) { if ($lf[0]  rs = xs  ; split is l//2, length(front0, split),  append(front0, back0, xs), ms(front0, front), ms(back0, back), merge(front,  back, rs) ).
merge_sort(left); right = merge_sort(right); return merge(left, right); } and here is the implementation of the merge function: //!
if (((icomparable)left[0]).compareto(right[0]) > 0) { rv.
then t(1:na)=a(1:na) call merge(t,na,a(na+1),nb,a,n) endif return end subroutine mergesort program testmergesort integer, parameter :: n = 8 integer, dimension(n) ::
its average-case complexity is o(n log n), with a much smaller coefficient, in good implementations, than merge sort's, even though it is quadratic in the worst case.
merge(left, right)return result
function to halve a list: # let rec halve = function |
merge(xs, [], xs) :- !.
; j = 1; k = 1; do while(i  a(2)) then v = a(1) a(1) = a(2) a(2) =
while (len(result)   (cdar primero) (cdar segundo)) (cons (car segundo) (mergelist primero (cdr  segundo));;second main case ) ) ) )
mergesort's merge operation is useful in online sorting, where the list to be sorted is received a piece at a time, instead of all at the beginning.
[x] | mergesort lst = let fun  merge ([],ys) =
quicksort, however, is  considered by many to be the fastest general-purpose sort algorithm in  practice.
\param left a sorted vector of integers //!
although heap sort has the same time bounds as merge sort, it requires only ω(1) auxiliary space instead of merge sort's ω(n), and is consequently often faster in practical implementations.
however, this approach can be expensive in time and space if the  received pieces are small compared to the sorted list — a better approach  in this case is to store the list in a self-balancing binary search tree and  add elements to it as they are received.
% merge of lists: merge(+list1, +list2, -result) merge([], xs,  xs) :- !.
i = 1; j = 1; k = 1; do while(i   a(2))
1: return arr m = len(arr) /
designing a merge sort to perform optimally often requires adjustment to available hardware, eg. number of tape drives, or size and speed of the relevant cache memory levels.
in the worst case, merge sort does about 39% fewer comparisons than quicksort does in the average case; merge sort always makes fewer comparisons than quicksort, except in extremely rare cases, when they tie, where merge sort's worst case is found simultaneously with quicksort's best case.
this opportunity  might change if fast memory becomes very cheap again, or if exotic  architectures like the tera mta become commonplace.
[edit] comparison with other sort algorithms
rest(right)if length(left)
count > 0) if  (((icomparable)left[0]).compareto(right[0]) > 0) { rv.
[edit] fortran subroutine merge(a,na,b,nb,c,nc) integer, intent(in) :: na,nb,nc   !
retrieved from " http://www.codecodex.com/wiki/merge_sort"
in java, the arrays.sort() methods use  mergesort and a tuned quicksort depending on the datatypes.
if(vec.size() == 1) { return vec; } // determine the location of the middle element in the vector std::vector::iterator middle = vec.begin() + (vec.size() / 2); vector left(vec.begin(), middle); vector right(middle, vec.end()); // perform a merge sort on the two smaller vectors left = merge_sort(left);
finishes the copy of the uncopied part of the array if i  > m then from h :=
a sorted vector of integers //!
[0; 1; 2; 3; 4; 5; 6; 7; 8; 9] signature: signature merge[alpha, bool fun mergesort: seq[alpha] -> seq[alpha] implementation implementation merge[alpha, seq[alpha] def merge((<>),b)
[array!y | y  list | h1::t1,  h2::t2 -> if h1  'a list =   this function is included in the ocaml stdlib as list.merge but is also  included here for clarity.
merge sort is much more efficient than quicksort if the data to be sorted  can only be efficiently accessed sequentially, and is thus popular in languages  such as lisp, where sequentially accessed data structures are very common.
attributes array: array[integer] merge_sort(list) when length(list) =
in some circumstances, cache reloading might impose unacceptable overhead and a carefully crafted merge sort might result in a significant improvement in running time.
2 l =  mergesort(arr[:m]) r = mergesort(arr[m:]) if not len(l) or not len(r): return l  or r result =
designing a merge sort to perform optimally often requires adjustment to  available hardware, eg. number of tape drives, or size and speed of the  relevant cache memory levels.
in some sense, main ram can be  seen as a fast tape drive, level 3 cache memory as a slightly faster one, level  2 cache memory as faster still, and so on.
[x|rest], merge(xs, [y|ys], rest) ;
the closed  form follows from the master theorem.
although heap sort has the same time bounds as merge sort, it requires only  ω(1) auxiliary space instead of merge sort's ω(n), and is  consequently often faster in practical implementations.
on the plus side, merge sort is a stable sort,  parallelizes better, and is more efficient at handling slow-to-access  sequential media.
int elementsina2 = array.length - elementsina1;  int arr1[] = new int[elementsina1]; int arr2[] = new int[elementsina2]; for(int  i = 0; i  0 && rl > 0) {  if (left[0]  0) {  result.push.apply(result, left); } else if (rl > 0) {  result.push.apply(result, right); } return result; } [edit] miranda sort [] =
merge sort is often the best choice for sorting a linked  list: in this situation it is relatively easy to implement a merge sort in such  a way that it does not require ω(n) auxiliary space (instead only  ω(1)), and the slow random-access performance of a linked list makes some  other algorithms (such as quick sort) perform poorly, and others (such as  heapsort) completely impossible.
merge sort is much more efficient than quicksort if the data to be sorted can only be efficiently accessed sequentially, and is thus popular in languages such as lisp, where sequentially accessed data structures are very common.
nc integer, intent(in out) :: a(na) !
in the worst case, merge sort does exactly (n ⌈log n⌉ - 2⌈log n⌉ + 1) comparisons, which is between (n log n - n + 1) and (n log n - 0.9139·n + 1)
splitat (length xs  `div` 2) xs merge [] xs =
recursive implementations of merge sort make 2n - 1 method calls in the worst case, compared to quicksort's n, thus has roughly twice as much recursive overhead as quicksort.
merge (sort left) (sort right) where left =
j until h > r loop b.item (k+h-j) := a.item (h) h := h+1 end elseif j > m then from h :=
v endif return endif na=(n+1)/2 nb=n-na  call mergesort(a,na,t) call mergesort(a(na+1),nb,t) if (a(na) > a(na+1))
sorting in-place is possible but requires an extremely complicated  implementation and hurts performance.
unlike some (inefficient) implementations of quicksort, merge sort is a stable  sort as long as the merge operation is implemented properly.
in some circumstances, cache  reloading might impose unacceptable overhead and a carefully crafted merge sort  might result in a significant improvement in running time.
there are several variants for the merge() function, the simplest variant  could look like this: function merge(left,right) var list result while length(left) > 0 and length(right) > 0 if first(left)  ≤ first(right) append first(left) to result left =
list; merge_sort(list)  -> {left, right} = lists:split(length(list) div 2, list),  lists:merge(merge_sort(left), merge_sort(right)).
#!/usr/bin/perl use strict; use warnings; sub mergesort; # to suppress  prototype warnings sub mergesort(&@) { my $comp = shift; return @_ if @_  > 1; merge( $comp, [ mergesort $comp,  @_ ], [ mergesort $comp, @tail ] ); } sub merge { my ( $comp, $head, $tail ) =
[0; 1;  2; 3; 4; 5; 6; 7; 8; 9] [edit] opal signature: signature merge[alpha, bool fun  mergesort: seq[alpha] -> seq[alpha] implementation implementation merge[alpha, seq[alpha] def merge((<>),b)
right = merge_sort(right); return merge(left, right); }
if the running time of merge sort for a list of length n is t(n),  then the recurrence t(n) = 2t(n/2) + n follows from the definition of the  algorithm (apply the algorithm to two lists of half the size of the original  list, and add the n steps taken to merge the resulting two lists).
sorting in-place is possible but requires an extremely complicated implementation and hurts performance.
<> def mergesort(a as  (a::(<>)))
fyi as of perl's built-in sort is merge sort by default.
@_; my @ret; while ( @$head && @$tail ) { push @ret, ( $comp->( $head->[0], $tail->[0] )  $_[1] } @rnd ), "\n"; print join( ",", sort { $a  $b } @rnd ), "\n"; function merge_sort(&$arraytosort) {
as of perl 5.8, merge sort is its default sorting algorithm (it was quicksort in previous versions of perl).
merge (sort left) (sort right
if x<y then x::merge (xs,y::ys) else y::merge (x::xs,ys) ; val half = length(lst) div 2; in merge (mergesort (list.take (lst, half)),mergesort (list.drop (lst, half))) end ; in sorting n items, merge sort has an average and worst-case performance of o(n log n).
its average-case complexity is o(n log n), with a much smaller  coefficient, in good implementations, than merge sort's, even though it is  quadratic in the worst case.
merge sort examples in 24 languages.
[x] | mergesort lst = let fun merge ([],ys) =
@_; my @ret; while ( @$head && @$tail ) { push @ret, ( $comp->(  $head->[0], $tail->[0] )  $_[1] } @rnd ), "\n";  print join( ",", sort { $a  $b } @rnd ), "\n"; [edit] php function merge_sort(&$arraytosort) {
in  this application, we sort each new piece that is received using any sorting  algorithm, and then merge it into our sorted list so far using the merge  operation.
0; i  m or j > r  loop -- begins the merge and copies it into an array "b" if a.item  (i)  a.item (j) then b.item (k) := a.item (j) j := j+1 end  k :=
[edit] utility in online sorting mergesort's merge operation is useful in online sorting, where the list to  be sorted is received a piece at a time, instead of all at the beginning.
[] = xs merge (x:xs) (y:ys) | x  1) { int  elementsina1 =
for large n and a randomly ordered input list, merge sort's expected (average) number of comparisons approaches α·n fewer than the worst case, where α = -1
for example: # merge_sort
merge sort's most common implementation does not sort in place, meaning memory the size of the input must be allocated for the sorted output to be stored in.
normal usage: na+nb =
i  m or j > r loop -- begins the merge and copies it into an array "b" if a.item (i)  a.item (j) then b.item (k) := a.item (j) j :=
function to merge sort a list: # let rec merge_sort = function | [] | [_] as list -> list | list  -> let l1, l2 = halve list in merge (merge_sort l1, merge_sort l2) ;; val  sort : 'a list -> 'a list =
merge  sort's most common implementation does not sort in place, meaning memory the  size of the input must be allocated for the sorted output to be stored in.
[] = xs merge (x:xs) (y:ys) | x  1) { int elementsina1 =
\param  left a sorted vector of integers //!
ys (*merges two sorted lists to form a sorted list *) | merge (xs,[])
[edit] seed7 version without additional storage const proc: mergesort (inout array elemtype: arr, in var integer: lo, in  integer: hi) is func local var integer:
merges the two array's into b[] until the first one is finish while((hmid) {
then t(1:na)=a(1:na) call merge(t,na,a(na+1),nb,a,n) endif return end  subroutine mergesort program testmergesort integer, parameter ::
[edit] python def mergesort(arr): if len(arr)
b overlays c(na+1:nc) integer, intent(in)  :: b(nb) integer, intent(in  out) :: c(nc) integer :: i,j,k
[llength $right]] > 0} { if  {[lindex $left 0]   0} {lappend res {*}$left} if {$lright > 0} {set res [concat $res $right]}
as of perl 5.8, merge sort is its default sorting algorithm (it was  quicksort in previous versions of perl).
unlike some (inefficient) implementations of quicksort, merge sort is a stable sort as long as the merge operation is implemented properly.
merge([x|xs], [y|ys], zs) :- ( x @= zs =
if (sizeof($arraytosort) 0 && count($rf)>0) { if ($lf[0]  rs = xs ; split is l//2, length(front0, split), append(front0, back0, xs), ms(front0, front), ms(back0, back), merge(front, back, rs) ).
[x|rest], merge(xs, [y|ys], rest)  ;  zs =
#!/usr/bin/perl use strict; use warnings; sub mergesort; # to suppress prototype warnings sub mergesort(&@) { my $comp = shift; return @_ if @_ > 1; merge( $comp, [ mergesort $comp, @_ ], [ mergesort $comp, @tail ] ); } sub merge { my ( $comp, $head, $tail ) =
for(k=j;k 0 && right.
splitat (length xs `div` 2) xs merge [] xs =
this page has been  accessed 73,552 times.
merges the two  array's into b[] until the first one is finish  while((hmid) {
as (a::as),b as (b::bs) )
for large n and a randomly ordered input list, merge sort's expected  (average) number of comparisons approaches α·n fewer than the  worst case, where α = -1
vector merge(const vector& left, const vector& right) { // fill the resultant vector with sorted results from both vectors vector result; unsigned left_it = 0, right_it = 0;
merge(xs, [], xs) :- !.
there are several variants for the merge() function, the simplest variant could look like this: function merge(left,right) var list result while length(left) > 0 and length(right) > 0 if first(left) ≤ first(right) append first(left) to result left =
then v = a(1) a(1) = a(2) a(2) =
add(right[0]); right.removeat(0); } else { rv.add(left[0]); left.removeat(0); } for (int i = 0;
def mergesort(arr): if len(arr)
in terms of moves, merge sort's worst case complexity is o(n log n)—the same complexity as quicksort's best case, and merge sort's best case takes about half as many iterations as the worst case.
function mergesort (data : in data_t) return data_t is begin if  data'length   merge_sort(vector& vec) { // termination condition: list is  completely sorted if it // only contains a single element.
b overlays c(na+1:nc) integer, intent(in) :: b(nb) integer, intent(in out) :: c(nc) integer :: i,j,k
related content: function mergesort(m) var list left, right if length(m) ≤ 1return m else middle = length(m) / 2 for each x in m up to middle add x to left for each x in mafter middle add x to right left =
split(half,lst) in merge(mergesort(a),mergesort(b))
int * b = new int[high+1-low]; int h,i,j,k; h=low; i=0; j=mid+1; //
merge sort is often the best choice for sorting a linked list: in this situation it is relatively easy to implement a merge sort in such a way that it does not require ω(n) auxiliary space (instead only ω(1)), and the slow random-access performance of a linked list makes some other algorithms (such as quick sort) perform poorly, and others (such as heapsort) completely impossible.
\return a sorted vector that is the result of merging two sorted //!
however, iterative, non-recursive, implementations of merge sort, avoiding method call overhead, are not difficult to code.
[edit] ada ada implementation uses type data_t for the data array.
and here is the implementation of the merge function: //!
{ return vec; } // determine the location of the middle element in the vector  std::vector::iterator middle = vec.begin() + (vec.size() / 2);  vector left(vec.begin(), middle); vector right(middle,  vec.end()); // perform a merge sort on the two smaller vectors left =
mergesort(arr[m:]) if not len(l) or not len(r): return l or r result =
i until h > m loop b.item (k+h-i) := a.item (h) h := h+1 end end -- "begins the copy to the real array" from h :=
4 comparison with other sort algorithms 5 utility in online sorting [edit] implementations [edit] pseudocode function mergesort(m) var list left, right if length(m) ≤ 1return m else middle =
quicksort, however, is considered by many to be the fastest general-purpose sort algorithm in practice.
vector merge(const vector& left, const  vector& right) { // fill the resultant vector with sorted  results from both vectors vector result; unsigned left_it = 0,  right_it = 0; while(left_it  using namespace std; void merge(int a[], const  int low, const int mid, const int high) { // variables declaration.
l until h > r loop a.item (h) := b.item (h) h := h+1 end end feature --
this might seem to be of historical interest only, but on modern computers, locality of reference is of paramount importance in software optimization, because multi-level memory hierarchies are used.
a = (/ 1, 5, 2, 7, 3, 9, 4, 6 /) integer, dimension ((n+1)/2) :: t call mergesort(a,n,t) write(*,'(a,/,10i3)')'sorted array :',a end program testmergesort def mergesort(list){
retrieved from "  http://www.codecodex.com/wiki/merge_sort" categories: sort algorithms  |recursion | pseudocode | ada | c | c++ | common lisp | eiffel | erlang |  fortran | groovy | haskell | java | javascript | miranda | objective caml | perl  |php | prolog | python | ruby | scheme | seed7 | standard ml
[edit] perl fyi as of perl's built-in sort is merge sort by default.
array[integer] [edit] erlang merge_sort(list) when length(list) =
return $res } [edit]  standard ml fun mergesort [] =
[] | [_] as t1 -> t1, [] | h::t ->  let t1, t2 = halve t in h::t2, t1  ;; val halve : 'a list -> 'a  list * 'a list =
in java, the arrays.sort() methods use mergesort and a tuned quicksort depending on the datatypes.
if the running time of merge sort for a list of length n is t(n), then the recurrence t(n) = 2t(n/2) + n follows from the definition of the algorithm (apply the algorithm to two lists of half the size of the original list, and add the n steps taken to merge the resulting two lists).
[6; 7; 0; 8; 3; 2; 4; 9; 5; 1];; - : int list =
note, the worst case number given here does not agree with that given in knuth's art of computer programming, vol 3.
length(m) / 2 for each x in m up to middle add x to left for each x in mafter middle add x to right left =
<> def mergesort(a as (a::(<>)))
int elementsina2 = array.length - elementsina1; int arr1[] = new int[elementsina1]; int arr2[] = new int[elementsina2]; for(int i = 0; i  0 && rl > 0) { if (left[0]  0) { result.push.apply(result, left); } else if (rl > 0) { result.push.apply(result, right); } return result; } sort [] =
list; merge_sort(list) -> {left, right} = lists:split(length(list) div 2, list), lists:merge(merge_sort(left), merge_sort(right)).
subroutine merge(a,na,b,nb,c,nc) integer, intent(in) :: na,nb,nc !
however, this approach can be expensive in time and space if the received pieces are small compared to the sorted list — a better approach in this case is to store the list in a self-balancing binary search tree and add elements to it as they are received.
xs | merge (x::xs,y::ys) =
the discrepancy is due to knuth analyzing a variant implementation of merge sort that is slightly sub-optimal.
in some sense, main ram can be seen as a fast tape drive, level 3 cache memory as a slightly faster one, level 2 cache memory as faster still, and so on.
% merge of lists: merge(+list1, +list2, -result) merge([], xs, xs) :- !.
[edit] optimizing merge sort this might seem to be of historical interest only, but on modern computers,  locality of reference is of paramount importance in software optimization,  because multi-level memory hierarchies are used.
merge (sort left) (sort right) where (left, right) =
> 0  append left to resultif length(right) > 0 append right to result return result
i until h > m loop  b.item (k+h-i) := a.item (h) h := h+1 end end -- "begins the  copy to the real array" from h :=
function mergesort (data : in data_t) return data_t is begin if data'length  merge_sort(vector& vec) { // termination condition: list is completely sorted if it // only contains a single element.