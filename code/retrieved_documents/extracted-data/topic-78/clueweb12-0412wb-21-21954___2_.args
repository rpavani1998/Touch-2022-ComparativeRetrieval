because of the way most algorithms work (comparing and swapping pairs of items) sorting often takes precious time.in addition, we will show how to parallelize merge to run on any number of spus which will improve performance even further.it allocates spu memory for all arrays, copy the data from ppu to spu, merge both arrays and copies the result back to the ppu once finished.with multi-core architectures like the ps3 it makes sense to parallelize this operation to maximize the use of these cores.as we have seen, the recursive structure of our parallel sort implementation limits the number of spus we can use.interestingly, different sort algorithms perform differently with different data types.our implementation can use any sort function (that can run inside an offload™ block) to sort array chunks small enough to fit in a spu's local memory.this results in 6-11x speed-ups for sorting float and integers arrays of over 20k elements and 2.5-3x speed-ups for sorting similarly-sized arrays of our user-definedface struct.parallel sort on 4 spus as we have seen, the recursive structure of our parallel sort implementation limits the number of spus we can use.with offload™ we can enqueue more blocks than there are spus but some spus will be idle at the end: if we enqueue 8 blocks, 6 will be processed in parallel at the same time and when they have been sorted the last 2 blocks will be processed.with float and integer arrays the speed-ups are lower (~4x over merge sort).up to 4 spus are used for sorting and up to 6 spus for merging.for example, our parallel merge sort (with parallel merge) implementation sees 7-11x speed-ups for float and int arrays >40k on 4 spus.for example, sorting transparent objects before rendering or sorting objects by state attribute (e.g. texture) to improve batching.on the other hand, the parallel quicksort (with parallel merge) sees 5-6x speed-ups (over merge sort) on the same face arrays.