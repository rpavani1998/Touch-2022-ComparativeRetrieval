for example: # merge_sort
merge_sort(left); right = merge_sort(right); return merge(left, right); } and here is the implementation of the merge function: //!
ys (*merges two sorted lists to form a sorted list *) | merge  (xs,[]) =
merge(left, right)return result
1: return arr m = len(arr) /
recursive implementations of merge sort make 2n - 1 method calls in the  worst case, compared to quicksort's n, thus has roughly twice as much recursive  overhead as quicksort.
a def merge(a as (a::as),b as (b::bs) )
% merge of lists: merge(+list1, +list2, -result) merge([], xs, xs) :- !.
xs | merge (x::xs,y::ys) =
quicksort, however, is considered by many to be the fastest general-purpose sort algorithm in practice.
there are several variants for the merge() function, the simplest variant could look like this: function merge(left,right) var list result while length(left) > 0 and length(right) > 0 if first(left) ≤ first(right) append first(left) to result left =
in this application, we sort each new piece that is received using any sorting algorithm, and then merge it into our sorted list so far using the merge operation.
in some sense, main ram can be  seen as a fast tape drive, level 3 cache memory as a slightly faster one, level  2 cache memory as faster still, and so on.
in java, the arrays.sort() methods use mergesort and a tuned quicksort depending on the datatypes.
rest(left)else append first(right) to result right =
however, this approach can be expensive in time and space if the received pieces are small compared to the sorted list — a better approach in this case is to store the list in a self-balancing binary search tree and add elements to it as they are received.
however, iterative, non-recursive, implementations of  merge sort, avoiding method call overhead, are not difficult to code.
4 comparison with other sort algorithms 5 utility in online sorting [edit] implementations [edit] pseudocode function mergesort(m) var list left, right if length(m) ≤ 1return m else middle =
merges the two  array's into b[] until the first one is finish  while((hmid) {
[edit] ada ada implementation uses type data_t for the data array.
a sorted vector of integers  //!
related content: function mergesort(m) var list left, right if length(m) ≤ 1return m else middle = length(m) / 2 for each x in m up to middle add x to left for each x in mafter middle add x to right left =
then v = a(1) a(1) = a(2) a(2) =
i = 1; j = 1; k = 1; do while(i   a(2))
[x|rest], merge(xs, [y|ys], rest) ;
merge([x|xs], [y|ys],  zs) :- ( x @= zs =
[] | [_] as t1 -> t1, [] | h::t ->  let t1, t2 = halve t in h::t2, t1  ;; val halve : 'a list -> 'a  list * 'a list =
[llength $right]] > 0} { if  {[lindex $left 0]   0} {lappend res {*}$left} if {$lright > 0} {set res [concat $res $right]}
[y|rest], merge([x|xs], ys, rest) ).
normal usage: na+nb =
function mergesort (data : in data_t) return data_t is begin if  data'length   merge_sort(vector& vec) { // termination condition: list is  completely sorted if it // only contains a single element.
then t(1:na)=a(1:na) call merge(t,na,a(na+1),nb,a,n) endif return end subroutine mergesort program testmergesort integer, parameter :: n = 8 integer, dimension(n) ::
if(vec.size() == 1) { return vec; } // determine the location of the middle element in the vector std::vector::iterator middle = vec.begin() + (vec.size() / 2); vector left(vec.begin(), middle); vector right(middle, vec.end()); // perform a merge sort on the two smaller vectors left = merge_sort(left);
quicksort, however, is  considered by many to be the fastest general-purpose sort algorithm in  practice.
while (len(result)  (cdar primero) (cdar segundo)) (cons (car segundo) (mergelist primero (cdr segundo));;second main case ) ) ) ) version without additional storage const proc: mergesort (inout array elemtype: arr, in var integer: lo, in integer: hi) is func local var integer:
in some sense, main ram can be seen as a fast tape drive, level 3 cache memory as a slightly faster one, level 2 cache memory as faster still, and so on.
[] | [_] as t1 -> t1, [] | h::t -> let t1, t2 = halve t in h::t2, t1 ;; val halve : 'a list -> 'a list * 'a list =
merge([x|xs], [y|ys], zs) :- ( x @= zs =
[0; 1;  2; 3; 4; 5; 6; 7; 8; 9] [edit] opal signature: signature merge[alpha, bool fun  mergesort: seq[alpha] -> seq[alpha] implementation implementation merge[alpha, seq[alpha] def merge((<>),b)
if (sizeof($arraytosort) 0 && count($rf)>0) { if ($lf[0]  rs = xs  ; split is l//2, length(front0, split),  append(front0, back0, xs), ms(front0, front), ms(back0, back), merge(front,  back, rs) ).
in  this application, we sort each new piece that is received using any sorting  algorithm, and then merge it into our sorted list so far using the merge  operation.
[edit] fortran subroutine merge(a,na,b,nb,c,nc) integer, intent(in) :: na,nb,nc   !
def mergesort(arr): if len(arr)
ada implementation uses type data_t for the data array.
as of perl 5.8, merge sort is its default sorting algorithm (it was  quicksort in previous versions of perl).
0; i  m or j > r  loop -- begins the merge and copies it into an array "b" if a.item  (i)  a.item (j) then b.item (k) := a.item (j) j := j+1 end  k :=
2 l =  mergesort(arr[:m]) r = mergesort(arr[m:]) if not len(l) or not len(r): return l  or r result =
[array!y | y  list | h1::t1, h2::t2 -> if h1  'a list =  this function is included in the ocaml stdlib as list.merge but is also included here for clarity.
function to merge sort a list: # let rec merge_sort = function | [] | [_] as list -> list | list -> let l1, l2 = halve list in merge (merge_sort l1, merge_sort l2) ;; val sort : 'a list -> 'a list =
@_; my @ret; while ( @$head && @$tail ) { push @ret, ( $comp->( $head->[0], $tail->[0] )  $_[1] } @rnd ), "\n"; print join( ",", sort { $a  $b } @rnd ), "\n"; function merge_sort(&$arraytosort) {
int * b =  new int[high+1-low]; int h,i,j,k; h=low; i=0; j=mid+1; //
while (len(result)   (cdar primero) (cdar segundo)) (cons (car segundo) (mergelist primero (cdr  segundo));;second main case ) ) ) )
if (((icomparable)left[0]).compareto(right[0]) > 0) { rv.
merge(xs, [], xs) :- !.
in the worst case, merge sort does exactly (n ⌈log n⌉ - 2⌈log n⌉ + 1) comparisons, which is between (n log n - n + 1) and (n log n - 0.9139·n + 1)
its average-case complexity is o(n log n), with a much smaller  coefficient, in good implementations, than merge sort's, even though it is  quadratic in the worst case.
length(m) / 2 for each x in m up to middle add x to left for each x in mafter middle add x to right left =
sorting in-place is possible but requires an extremely complicated  implementation and hurts performance.
in the worst case, merge sort does about 39% fewer comparisons than quicksort does in the average case; merge sort always makes fewer comparisons than quicksort, except in extremely rare cases, when they tie, where merge sort's worst case is found simultaneously with quicksort's best case.
b overlays c(na+1:nc) integer, intent(in)  :: b(nb) integer, intent(in  out) :: c(nc) integer :: i,j,k
add(right[0]); right.removeat(0); } else { rv.add(left[0]); left.removeat(0); } for (int i = 0;
[edit] perl fyi as of perl's built-in sort is merge sort by default.
note, the worst case number given here does not agree with that given in knuth's art of computer programming, vol 3.
[edit] seed7 version without additional storage const proc: mergesort (inout array elemtype: arr, in var integer: lo, in  integer: hi) is func local var integer:
[6; 7; 0; 8; 3; 2; 4; 9; 5; 1];; - : int list =
v endif return endif na=(n+1)/2 nb=n-na  call mergesort(a,na,t) call mergesort(a(na+1),nb,t) if (a(na) > a(na+1))
the discrepancy is due to knuth analyzing a variant implementation of merge sort that is slightly sub-optimal.
l until h > r loop a.item  (h) := b.item (h) h := h+1 end end feature --
if( list.size()  0 || right.size() > 0) if(left.get(0)  [a] -> [a] sort [] =
list; merge_sort(list) -> {left, right} = lists:split(length(list) div 2, list), lists:merge(merge_sort(left), merge_sort(right)).
recursive implementations of merge sort make 2n - 1 method calls in the worst case, compared to quicksort's n, thus has roughly twice as much recursive overhead as quicksort.
1: return arr m = len(arr) / 2 l = mergesort(arr[:m]) r =
in some circumstances, cache reloading might impose unacceptable overhead and a carefully crafted merge sort might result in a significant improvement in running time.
splitat (length xs `div` 2) xs merge [] xs =
unlike some (inefficient) implementations of quicksort, merge sort is a stable sort as long as the merge operation is implemented properly.
a = (/ 1, 5, 2, 7, 3, 9, 4, 6 /) integer, dimension ((n+1)/2) :: t call mergesort(a,n,t) write(*,'(a,/,10i3)')'sorted array :',a end program testmergesort def mergesort(list){
nc integer, intent(in out) :: a(na) !
> 0 append left to resultif length(right) > 0 append right to result return result
however, iterative, non-recursive, implementations of merge sort, avoiding method call overhead, are not difficult to code.
l until h > r loop a.item (h) := b.item (h) h := h+1 end end feature --
subroutine merge(a,na,b,nb,c,nc) integer, intent(in) :: na,nb,nc !
<> def mergesort(a as (a::(<>)))
retrieved from "  http://www.codecodex.com/wiki/merge_sort" categories: sort algorithms  |recursion | pseudocode | ada | c | c++ | common lisp | eiffel | erlang |  fortran | groovy | haskell | java | javascript | miranda | objective caml | perl  |php | prolog | python | ruby | scheme | seed7 | standard ml
\param  left a sorted vector of integers //!
mergesort(right) result =
merge sort is much more efficient than quicksort if the data to be sorted  can only be efficiently accessed sequentially, and is thus popular in languages  such as lisp, where sequentially accessed data structures are very common.
count > 0) if  (((icomparable)left[0]).compareto(right[0]) > 0) { rv.
#!/usr/bin/perl use strict; use warnings; sub mergesort; # to suppress prototype warnings sub mergesort(&@) { my $comp = shift; return @_ if @_ > 1; merge( $comp, [ mergesort $comp, @_ ], [ mergesort $comp, @tail ] ); } sub merge { my ( $comp, $head, $tail ) =
function to halve a list: # let rec halve = function |
[edit] python def mergesort(arr): if len(arr)
there are several variants for the merge() function, the simplest variant  could look like this: function merge(left,right) var list result while length(left) > 0 and length(right) > 0 if first(left)  ≤ first(right) append first(left) to result left =
in terms of moves, merge sort's worst case complexity is o(n log n)—the same complexity as quicksort's best case, and merge sort's best case takes about half as many iterations as the worst case.
note, the worst case number  given here does not agree with that given in knuth's art of computer  programming, vol 3.
vector merge(const vector& left, const  vector& right) { // fill the resultant vector with sorted  results from both vectors vector result; unsigned left_it = 0,  right_it = 0; while(left_it  using namespace std; void merge(int a[], const  int low, const int mid, const int high) { // variables declaration.
this page was last modified on 18 january 2012, at 21:52.
[x] | mergesort lst = let fun merge ([],ys) =
[array!y | y  list | h1::t1,  h2::t2 -> if h1  'a list =   this function is included in the ocaml stdlib as list.merge but is also  included here for clarity.
int elementsina2 = array.length - elementsina1;  int arr1[] = new int[elementsina1]; int arr2[] = new int[elementsina2]; for(int  i = 0; i  0 && rl > 0) {  if (left[0]  0) {  result.push.apply(result, left); } else if (rl > 0) {  result.push.apply(result, right); } return result; } [edit] miranda sort [] =
this opportunity  might change if fast memory becomes very cheap again, or if exotic  architectures like the tera mta become commonplace.
@_; my @ret; while ( @$head && @$tail ) { push @ret, ( $comp->(  $head->[0], $tail->[0] )  $_[1] } @rnd ), "\n";  print join( ",", sort { $a  $b } @rnd ), "\n"; [edit] php function merge_sort(&$arraytosort) {
integer, dimension(n) :: a = (/ 1, 5, 2, 7, 3, 9, 4, 6 /) integer,  dimension ((n+1)/2) :: t call mergesort(a,n,t)  write(*,'(a,/,10i3)')'sorted array :',a end program testmergesort [edit] groovy def mergesort(list){
split(half,lst) in merge(mergesort(a),mergesort(b))
% merge of lists: merge(+list1, +list2, -result) merge([], xs,  xs) :- !.
although heap sort has the same time bounds as merge sort, it requires only  ω(1) auxiliary space instead of merge sort's ω(n), and is  consequently often faster in practical implementations.
[6; 7; 0; 8; 3; 2; 4; 9; 5; 1];; - : int list =
[edit] optimizing merge sort this might seem to be of historical interest only, but on modern computers,  locality of reference is of paramount importance in software optimization,  because multi-level memory hierarchies are used.
rest(right)if length(left)
a sorted vector of integers //!
i until h > m loop  b.item (k+h-i) := a.item (h) h := h+1 end end -- "begins the  copy to the real array" from h :=
merges the two array's into b[] until the first one is finish while((hmid) {
<> def mergesort(a as  (a::(<>)))
function to merge sort a list: # let rec merge_sort = function | [] | [_] as list -> list | list  -> let l1, l2 = halve list in merge (merge_sort l1, merge_sort l2) ;; val  sort : 'a list -> 'a list =
if (sizeof($arraytosort) 0 && count($rf)>0) { if ($lf[0]  rs = xs ; split is l//2, length(front0, split), append(front0, back0, xs), ms(front0, front), ms(back0, back), merge(front, back, rs) ).
j until h > r loop b.item (k+h-j) := a.item  (h) h := h+1 end elseif j > m then from h :=
merge sort is often the best choice for sorting a linked list: in this situation it is relatively easy to implement a merge sort in such a way that it does not require ω(n) auxiliary space (instead only ω(1)), and the slow random-access performance of a linked list makes some other algorithms (such as quick sort) perform poorly, and others (such as heapsort) completely impossible.
mergesort(arr[m:]) if not len(l) or not len(r): return l or r result =
mid is 0; var elemtype: help is elemtype.value; var integer: k is 0; begin if lo  hi or arr[t_lo]  0 && [set lright [llength $right]] > 0} { if {[lindex $left 0]  0} {lappend res {*}$left} if {$lright > 0} {set res [concat $res $right]} return $res } fun mergesort [] =
merge (sort left) (sort right
[] = xs merge (x:xs) (y:ys) | x  1) { int elementsina1 =
finishes the copy of the uncopied part of the array if i  > m then from h :=
\return a sorted vector that is the result of merging two sorted //!
the discrepancy is due to knuth analyzing a variant  implementation of merge sort that is slightly sub-optimal.
merge sort's most common implementation does not sort in place, meaning memory the size of the input must be allocated for the sorted output to be stored in.
its average-case complexity is o(n log n), with a much smaller coefficient, in good implementations, than merge sort's, even though it is quadratic in the worst case.
while(left_it  using namespace std; void merge(int a[], const int low, const int mid, const int high) { // variables declaration.
fyi as of perl's built-in sort is merge sort by default.
[edit] comparison with other sort algorithms
on the plus side, merge sort is a stable sort, parallelizes better, and is more efficient at handling slow-to-access sequential media.
in the worst case, merge sort does about 39% fewer comparisons than  quicksort does in the average case; merge sort always makes fewer comparisons  than quicksort, except in extremely rare cases, when they tie, where merge  sort's worst case is found simultaneously with quicksort's best case.
function mergesort (data : in data_t) return data_t is begin if data'length  merge_sort(vector& vec) { // termination condition: list is completely sorted if it // only contains a single element.
nc integer, intent(in out) :: a(na)  !
\param left a sorted vector of integers //!
i  m or j > r loop -- begins the merge and copies it into an array "b" if a.item (i)  a.item (j) then b.item (k) := a.item (j) j :=
splitat (length xs  `div` 2) xs merge [] xs =
[0; 1; 2; 3; 4; 5; 6; 7; 8; 9] signature: signature merge[alpha, bool fun mergesort: seq[alpha] -> seq[alpha] implementation implementation merge[alpha, seq[alpha] def merge((<>),b)
b overlays c(na+1:nc) integer, intent(in) :: b(nb) integer, intent(in out) :: c(nc) integer :: i,j,k
for large n and a randomly ordered input list, merge sort's expected (average) number of comparisons approaches α·n fewer than the worst case, where α = -1
right = merge_sort(right); return merge(left, right); }
in the worst case, merge sort does exactly (n ⌈log n⌉ -  2⌈log n⌉ + 1) comparisons, which is between (n log n - n + 1) and  (n log n - 0.9139·n + 1)
however, this approach can be expensive in time and space if the  received pieces are small compared to the sorted list — a better approach  in this case is to store the list in a self-balancing binary search tree and  add elements to it as they are received.
the closed form follows from the master theorem.
j until h > r loop b.item (k+h-j) := a.item (h) h := h+1 end elseif j > m then from h :=
[] = xs merge (x:xs) (y:ys) | x  1) { int  elementsina1 =
designing a merge sort to perform optimally often requires adjustment to  available hardware, eg. number of tape drives, or size and speed of the  relevant cache memory levels.
merge  sort's most common implementation does not sort in place, meaning memory the  size of the input must be allocated for the sorted output to be stored in.
although heap sort has the same time bounds as merge sort, it requires only ω(1) auxiliary space instead of merge sort's ω(n), and is consequently often faster in practical implementations.
attributes array: array[integer] merge_sort(list) when length(list) =
ys (*merges two sorted lists to form a sorted list *) | merge (xs,[])
in java, the arrays.sort() methods use  mergesort and a tuned quicksort depending on the datatypes.
in some circumstances, cache  reloading might impose unacceptable overhead and a carefully crafted merge sort  might result in a significant improvement in running time.
> 0  append left to resultif length(right) > 0 append right to result return result
mergesort's merge operation is useful in online sorting, where the list to be sorted is received a piece at a time, instead of all at the beginning.
if the running time of merge sort for a list of length n is t(n), then the recurrence t(n) = 2t(n/2) + n follows from the definition of the algorithm (apply the algorithm to two lists of half the size of the original list, and add the n steps taken to merge the resulting two lists).
merge sort is often the best choice for sorting a linked  list: in this situation it is relatively easy to implement a merge sort in such  a way that it does not require ω(n) auxiliary space (instead only  ω(1)), and the slow random-access performance of a linked list makes some  other algorithms (such as quick sort) perform poorly, and others (such as  heapsort) completely impossible.
this page has been  accessed 73,552 times.
if x<y then x::merge (xs,y::ys) else y::merge (x::xs,ys) ; val half = length(lst) div 2; in merge (mergesort (list.take (lst, half)),mergesort (list.drop (lst, half))) end ; in sorting n items, merge sort has an average and worst-case performance of o(n log n).
{ return vec; } // determine the location of the middle element in the vector  std::vector::iterator middle = vec.begin() + (vec.size() / 2);  vector left(vec.begin(), middle); vector right(middle,  vec.end()); // perform a merge sort on the two smaller vectors left =
finishes the copy of the uncopied part of the array if i > m then from h :=
for(k=j;k 0 && right.
if the running time of merge sort for a list of length n is t(n),  then the recurrence t(n) = 2t(n/2) + n follows from the definition of the  algorithm (apply the algorithm to two lists of half the size of the original  list, and add the n steps taken to merge the resulting two lists).
for large n and a randomly ordered input list, merge sort's expected  (average) number of comparisons approaches α·n fewer than the  worst case, where α = -1
on the plus side, merge sort is a stable sort,  parallelizes better, and is more efficient at handling slow-to-access  sequential media.
[edit] utility in online sorting mergesort's merge operation is useful in online sorting, where the list to  be sorted is received a piece at a time, instead of all at the beginning.
unlike some (inefficient) implementations of quicksort, merge sort is a stable  sort as long as the merge operation is implemented properly.
[x|rest], merge(xs, [y|ys], rest)  ;  zs =
array[integer] [edit] erlang merge_sort(list) when length(list) =
merge (sort left) (sort right) where left =
as of perl 5.8, merge sort is its default sorting algorithm (it was quicksort in previous versions of perl).
mid is 0; var elemtype: help is  elemtype.value; var integer: k is 0; begin if lo  hi or arr[t_lo]  0 && [set lright
and here is the implementation of the merge function: //!
return $res } [edit]  standard ml fun mergesort [] =
merge sort is much more efficient than quicksort if the data to be sorted can only be efficiently accessed sequentially, and is thus popular in languages such as lisp, where sequentially accessed data structures are very common.
merge(xs, [], xs) :- !.
add(right[0]);  right.removeat(0); } else { rv.add(left[0]); left.removeat(0); } for (int i =
this opportunity might change if fast memory becomes very cheap again, or if exotic architectures like the tera mta become commonplace.
list; merge_sort(list)  -> {left, right} = lists:split(length(list) div 2, list),  lists:merge(merge_sort(left), merge_sort(right)).
int elementsina2 = array.length - elementsina1; int arr1[] = new int[elementsina1]; int arr2[] = new int[elementsina2]; for(int i = 0; i  0 && rl > 0) { if (left[0]  0) { result.push.apply(result, left); } else if (rl > 0) { result.push.apply(result, right); } return result; } sort [] =
then t(1:na)=a(1:na) call merge(t,na,a(na+1),nb,a,n) endif return end  subroutine mergesort program testmergesort integer, parameter ::
the closed  form follows from the master theorem.
as (a::as),b as (b::bs) )
[x] | mergesort lst = let fun  merge ([],ys) =
if x<y then x::merge (xs,y::ys) else  y::merge (x::xs,ys)  ; val half = length(lst) div 2; in merge (mergesort  (list.take (lst, half)),mergesort (list.drop (lst, half))) end ; [edit] analysis in sorting n items, merge sort has an average and worst-case performance of  o(n log n).
this might seem to be of historical interest only, but on modern computers, locality of reference is of paramount importance in software optimization, because multi-level memory hierarchies are used.
vector merge(const vector& left, const vector& right) { // fill the resultant vector with sorted results from both vectors vector result; unsigned left_it = 0, right_it = 0;
merge sort examples in 24 languages.
i until h > m loop b.item (k+h-i) := a.item (h) h := h+1 end end -- "begins the copy to the real array" from h :=
v endif return endif na=(n+1)/2 nb=n-na call mergesort(a,na,t) call mergesort(a(na+1),nb,t) if (a(na) > a(na+1))
retrieved from " http://www.codecodex.com/wiki/merge_sort"
sorting in-place is possible but requires an extremely complicated implementation and hurts performance.
#!/usr/bin/perl use strict; use warnings; sub mergesort; # to suppress  prototype warnings sub mergesort(&@) { my $comp = shift; return @_ if @_  > 1; merge( $comp, [ mergesort $comp,  @_ ], [ mergesort $comp, @tail ] ); } sub merge { my ( $comp, $head, $tail ) =
; j = 1; k = 1; do while(i  a(2)) then v = a(1) a(1) = a(2) a(2) =
\brief merges two sorted vectors into one sorted vector //!
int * b = new int[high+1-low]; int h,i,j,k; h=low; i=0; j=mid+1; //
merge (sort left) (sort right) where (left, right) =
designing a merge sort to perform optimally often requires adjustment to available hardware, eg. number of tape drives, or size and speed of the relevant cache memory levels.
in terms  of moves, merge sort's worst case complexity is o(n log n)—the same  complexity as quicksort's best case, and merge sort's best case takes about  half as many iterations as the worst case.