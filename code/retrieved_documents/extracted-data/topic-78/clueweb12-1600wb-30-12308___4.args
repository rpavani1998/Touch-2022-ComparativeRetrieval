fortunately, the overhead did not in this case mask which alternative would run faster when instrumentation is turned back off.
by including its own qsort(), those who submitted eqntott to the spec organization as a benchmark could provide a reference output file to go with the reference input file; whereas if eqntott used the system qsort(), then the reference output file might not match eqntott's output on a given platform even though the difference would be entirely due to sort stability, and would not make the resulting output incorrect.
(times were quite consistent for runs which used the same sort and had the same sortedness of input, differing only on the random seed.)
investigation readily uncovered that the linux system qsort() is supplied by the gnu implementation of the libc library; by default, it does not use the quicksort algorithm, but rather uses the merge sort algorithm if it can allocate enough temporary buffer to perform a standard two-space merge sort, only falling back to an in-place quicksort if the attempt to allocate memory fails.
it's not hard to convince oneself that the code in figure is equivalent figure, but might execute faster on average if , , or were common conditions.
to reiterate, if the library writer had written the system qsort() with a qif statement, then sorting performance would be improved on average, without any effort from the application programmer's part and without complicating the semantics of qsort() usage.
note that careless use of quasistatic constructs in tight inner loops resulted in spectacular profiling overhead, far greater than even that for pixie .
investigation readily uncovered that the linux system qsort() is supplied by the gnu implementation of the libc library; by default, it does not use the quicksort algorithm, but rather uses the merge sort algorithm if it can allocate enough temporary buffer to perform a standard two-space merge sort, only falling back to an in-place quicksort if the attempt to allocate memory fails.
taking advantage of evolutionary and revolutionary changes in sorting technologies sounds like fertile ground for a clever compiler.
it would be highly tedious to try them all out by hand; but a quasistatic compiler would not be deterred by impatience.
the eqntott call site to qsort() which provides cmppt() as a comparison function hands qsort() an array with just 4,106 items; note that 2,841,621 comparisons to sort 4,106 items seems more nearly o(n ), despite the fact that the quicksort implementation does have the median-of-3 modification which should prevent most (but clearly not all) cases of such degenerate behavior.
this kind of effort with blind alleys, hypotheses to shoot down, etc., is typical of of a human programmer attempting to optimize a program.
a civil engineer chooses from a wide variety of different building material technologies (e.g., wood frame, reinforced concrete, steel i-beam), based on the desired tradeoffs between cost, aesthetics, and strength, which depend on the needs of the particular project.
with quasistatic if support, the programmer can simply write the code sequence in figure and forget about it.
using gprof profiling, we see that although eqntott does spends about 90% of its time executing qsort(), about 85% of the total run-time was actually spent in cmppt(), which is only called from one particular call site of qsort().
with quasistatic if support, the programmer can simply write the code sequence in figure and forget about it.
i.e., one hypothesis is that in this case merge sort tends to be comparing elements which the comparison routine can quickly decide whetherab, whereas quicksort tends to be comparing elements which the comparison routine cannot quickly determine the ordering relationship.
fortunately, the overhead did not in this case mask which alternative would run faster when instrumentation is turned back off.
the eqntott application from the specint92 suite of benchmarks [] translates a logical representation of a boolean equation to a truth table.
this kind of effort with blind alleys, hypotheses to shoot down, etc., is typical of of a human programmer attempting to optimize a program.
it's less tedious and less error-prone to let the clever compiler manage program versions than to do so by hand.
this is in part because the current real-time profiling implementation does not customize the stopwatch start and stop routines for each place where they are used, even though they are inlined; hence the routines still have greater overhead than pixie's instrumentation code per invocation.
hence it can matter greatly to the total run-time exactly which elements are compared with each other, something which was not true for sorting integers.
if the system qsort() had been written with a qif statement to quasistatically select between a quicksort implementation or a merge sort implementation, it would not be necessary to go to this kind of effort, nor necessary to speculate about whether typical user files provided as input to eqntott tend to elicit o(n ) behavior from the quicksort used; whether or not quicksort often behaved poorly or not on user inputs would be directly observed and taken into account.
another obvious approach to improving the performance of eqntott would be to try to make cmppt() execute faster.
furthermore, casual trials with another similarly-sized input file for eqntott (modeling a 4-bit 16-input/output multiplexer) suggests that the reference input file for the specint92 benchmark use of eqntott is in fact somewhat anomalous for eliciting such poor behavior from quicksort; however, program performance for the multiplexor input file was still about 20% better with merge sort than with quicksort, consistent with the results in table which shows that the merge sort implementation tends to perform fewer comparisons --- and the number of comparisons, when each comparison can be quite expensive, will dominate the running time more than the efficiency of the inner loops of the sorting algorithm.
that at that time computer manufacturers believed that about a quarter of computer time was spent sorting.
attacking cmppt() another obvious approach to improving the performance of eqntott would be to try to make cmppt() execute faster.
however, it does serve as an example where the programmer can use the clever compiler's capabilities as a tool to simplify the task of exploring what-if scenarios to improve program performance, although judiciously (i.e., not in inner loops).
in particular, profiling indicates that there is a 79-fold reduction in the number of calls to cmppt(): quicksort calls it 2,841,621 times; merge sort, a mere 35,944 times.
table would suggest that eqntott using quicksort would be faster than eqntott using merge sort, when in fact the reverse is true.)
the eqntott call site to qsort() which provides cmppt() as a comparison function hands qsort() an array with just 4,106 items; note that 2,841,621 comparisons to sort 4,106 items seems more nearly o(n ), despite the fact that the quicksort implementation does have the median-of-3 modification which should prevent most (but clearly not all) cases of such degenerate behavior.
the number of calls to cmppt() which the merge sort issues, on the other hand, seems much closer to o(n log n).
using gprof profiling, we see that although eqntott does spends about 90% of its time executing qsort(), about 85% of the total run-time was actually spent in cmppt(), which is only called from one particular call site of qsort().
the eqntott application from the specint92 suite of benchmarks [] translates a logical representation of a boolean equation to a truth table.
it should be noted that such comparison functions are not particularly unusual: an ordering string comparison function, for example, takes variable time to run, being highly dependent on the nature of input data.
hence it can matter greatly to the total run-time exactly which elements are compared with each other, something which was not true for sorting integers.
hence which sort should be selected in a given usage will depend on both the input data pattern and on the cost of the comparison function provided to qsort().
(a difference in the wrong direction to boot: table would suggest that eqntott using quicksort would be faster than eqntott using merge sort, when in fact the reverse is true.)
the source code files for eqntott include an implementation for qsort(), which makes sense, since the stability of standard c library qsort() --- that is, whether it will or will not preserve the initial ordering of elements being sorted which compare as equal --- is intentionally undefined.
to reiterate, if the library writer had written the system qsort() with a qif statement, then sorting performance would be improved on average, without any effort from the application programmer's part and without complicating the semantics of qsort() usage.
i.e., one hypothesis is that in this case merge sort tends to be comparing elements which the comparison routine can quickly decide whetherab, whereas quicksort tends to be comparing elements which the comparison routine cannot quickly determine the ordering relationship.
forcing eqntott to use the system qsort() under sunos 4.1.3 resulted in nearly identical timings as using the included qsort(); however, forcing eqntott to use the system qsort() on linux dramatically reduced run-time, from just over 20 seconds to 2.4 seconds.
the number of calls to cmppt() which the merge sort issues, on the other hand, seems much closer to o(n log n).
great opportunity for optimization using quasistatic constructs.
a civil engineer chooses from a wide variety of different building material technologies (e.g., wood frame, reinforced concrete, steel i-beam), based on the desired tradeoffs between cost, aesthetics, and strength, which depend on the needs of the particular project.
in particular, every comparison routine defined in eqntott may take variable amounts of time to execute.
taking advantage of evolutionary and revolutionary changes in sorting technologies sounds like fertile ground for a clever compiler.
a software engineer similarly chooses from a wide variety of different sorting algorithms based on the desired tradeoffs between coding complexity, suitability to size of problem (i.e., internal vs. external sorts), average space consumption, average time consumption, variability of space/time consumption, and sort stability.
it's not hard to convince oneself that the code in figure is equivalent figure, but might execute faster on average if , , or were common conditions.
furthermore, it so happens that the problem is vastly excaberated by the fact that the current implementation of real-time profiling has a bug whereby the gnu gcc code generator believes two registers contain live data between the stopwatch start and stop routines, and this causes several of the inner loop variables to be spilled from the unusually small register set of the intel pentium processor.
hence which sort should be selected in a given usage will depend on both the input data pattern and on the cost of the comparison function provided to qsort().
however, it does serve as an example where the programmer can use the clever compiler's capabilities as a tool to simplify the task of exploring what-if scenarios to improve program performance, although judiciously (i.e., not in inner loops).
in particular, profiling indicates that there is a 79-fold reduction in the number of calls to cmppt(): quicksort calls it 2,841,621 times; merge sort, a mere 35,944 times.
by including its own qsort(), those who submitted eqntott to the spec organization as a benchmark could provide a reference output file to go with the reference input file; whereas if eqntott used the system qsort(), then the reference output file might not match eqntott's output on a given platform even though the difference would be entirely due to sort stability, and would not make the resulting output incorrect.
we see that although there is some improvement, the cmppt() comparison function did not offer great opportunity for optimization using quasistatic constructs.
forcing eqntott to use the system qsort() under sunos 4.1.3 resulted in nearly identical timings as using the included qsort(); however, forcing eqntott to use the system qsort() on linux dramatically reduced run-time, from just over 20 seconds to 2.4 seconds.
furthermore, casual trials with another similarly-sized input file for eqntott (modeling a 4-bit 16-input/output multiplexer) suggests that the reference input file for the specint92 benchmark use of eqntott is in fact somewhat anomalous for eliciting such poor behavior from quicksort; however, program performance for the multiplexor input file was still about 20% better with merge sort than with quicksort, consistent with the results in table which shows that the merge sort implementation tends to perform fewer comparisons --- and the number of comparisons, when each comparison can be quite expensive, will dominate the running time more than the efficiency of the inner loops of the sorting algorithm.
this is in part because the current real-time profiling implementation does not customize the stopwatch start and stop routines for each place where they are used, even though they are inlined; hence the routines still have greater overhead than pixie's instrumentation code per invocation.
it should be noted that such comparison functions are not particularly unusual: an ordering string comparison function, for example, takes variable time to run, being highly dependent on the nature of input data.
attacking qsort() the source code files for eqntott include an implementation for qsort(), which makes sense, since the stability of standard c library qsort() --- that is, whether it will or will not preserve the initial ordering of elements being sorted which compare as equal --- is intentionally undefined.
a software engineer similarly chooses from a wide variety of different sorting algorithms based on the desired tradeoffs between coding complexity, suitability to size of problem (i.e., internal vs. external sorts), average space consumption, average time consumption, variability of space/time consumption, and sort stability.
furthermore, it so happens that the problem is vastly excaberated by the fact that the current implementation of real-time profiling has a bug whereby the gnu gcc code generator believes two registers contain live data between the stopwatch start and stop routines, and this causes several of the inner loop variables to be spilled from the unusually small register set of the intel pentium processor.
it would be highly tedious to try them all out by hand; but a quasistatic compiler would not be deterred by impatience.
it's less tedious and less error-prone to let the clever compiler manage program versions than to do so by hand.
if the system qsort() had been written with a qif statement to quasistatically select between a quicksort implementation or a merge sort implementation, it would not be necessary to go to this kind of effort, nor necessary to speculate about whether typical user files provided as input to eqntott tend to elicit o(n ) behavior from the quicksort used; whether or not quicksort often behaved poorly or not on user inputs would be directly observed and taken into account.
(times were quite consistent for runs which used the same sort and had the same sortedness of input, differing only on the random seed.)
in particular, every comparison routine defined in eqntott may take variable amounts of time to execute.
note that careless use of quasistatic constructs in tight inner loops resulted in spectacular profiling overhead, far greater than even that for pixie .