[instructions] [search] [current] [news] [syllabus] [glance] [links] [ handouts] [project] [outlines] [labs] [assignments] [quizzes] [exams] [examples ] [eij] [jpds] [tutorial] [api] back to some sorting algorithms.
any or all of the information on the pages may be incorrect.
[instructions] [search] [current] [news] [syllabus] [glance] [links] [ handouts] [project] [outlines] [labs] [assignments] [quizzes] [exams] [examples ] [eij] [jpds] [tutorial] [api] disclaimer often, these pages were created "on the fly" with little, if any, proofreading.
but if you're willing to use extra space and know something about the original data, then you can do better.
with a little work, you can do this partitioning in place, so that there is no overhead (and so that ``glueing'' is basically a free operation).
if each partition is perfect (splits it exactly in half), we can stop the process after o(log_2(n)) levels.
running time, revisited we can also use a somewhat nontraditional analysis technique.
lb <= ub < stuff.length * post: does not affect stuff.
other versions we've written merge sort so that it does not affect the original array.
if we always chose the largest element as the pivot, this algorithm would be equivalent toselection sort, and would take time o(n*n).
pre: there is sufficient memory to allocate the new array.
running time can be a constant (as long as you can guarantee the number of items in any bucket)!
pre: there is sufficient memory to complete the creation of the * new array (and the other steps of the algorithm).
[eij] [jpds] [tutorial] [api] disclaimer often, these pages were created "on the fly" with little, if any, proofreading.
unfortunately, merge sort requires significantly more memory than do the other sorting routines (you can spend some time trying to come up with an ``in place'' merge sort, but you are quite likely to fail).
on average, we don't quite do half, but it's close enough that it doesn't make a significant difference.
any or all of the information on the pages may be incorrect.
pre: the elements in the array can be compared to each other.
pre: all elements in the array can be compared to each other.
if you can arrange things so that each bucket contains only a few elements (say no more than four), then the main cost is putting in to buckets and taking out of buckets.
* * copy a subarray (so that we can return it without affecting it).
pre: all elements in the array can be compared to each other.
however, bad choice of pivots can give significantly worse running time.
used when logging steps.
