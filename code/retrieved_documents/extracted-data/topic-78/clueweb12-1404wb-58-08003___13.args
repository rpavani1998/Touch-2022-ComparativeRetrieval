instead, it would be nice to have a type to work directly with compositekey - something whichknew it was dealing with comparers of different types, one for each part of the key.
on the other hand, as i've mentioned before, max/sum/etc haveoodles of overloads.
i'm doing this in the spirit of learning more about linq - but it's fun to try to optimize just a little bit.
the final code has some nasty generic complexity in it, but it's not too bad if you keep all the types clear in your mind.
it's an ugly expression, but it does the job.
however, it's still worth fixing of course - one never knows when the restriction will be lifted.
again, for the sake of clarity i decided to implement this using a custom struct - nested within orderedenumerable as there's no need for it to exist anywhere else:private struct leftright purists amongst you may curse at the use of internal fields rather than properties.
(that hasn't stopped them frommessing up "descending" comparers, admittedly, as i found out last night to my amusement.)
it feels like thatought to be cheaper to do explicitly than via pivoting and adding two pointless entries to the stack... but the code gets alot more complicated (to the point where i had to fiddle significantly to get it working) and from what i've seen, it doesn't make much performance difference.
all feed content is property of original publisher.
thenby and thenbydescending don't have to change at all - they were already just using the interface.
fair enough - this is just a hobby, microsoft have no doubt put a lot of performance testing effort into this.
of course, the code is all open source, so if microsoft wish to include the edulinq implementation in .net 5, they're quite at liberty to do so, as long as they abide by the terms of the licence.
now that we can compose keys in terms of both selection and comparison, we can implement createorderedenumerable:public iorderedenumerable createorderedenumerable( i'm not going to pretend that the second half of the method is anything other than ghastly.
i've left the code here as it is in source control - but looking at it now, i could certainly have used a foreach loop on the final yield part.
for type parameters it's not too bad, but for normal parameters it can be awful if you mess around with the names - particularly for those using named arguments.
now we can easily create a projection from two key selectors to a new one which selects a composite key.
the basic results are very roughly: when evaluating the whole ordered list, edulinq appears to run about 10% faster than linq to objects when evaluating only the top 5 of a large ordered list, edulinq can be much faster.
here's the non-quicksort part of the code, just to set the scene.public ienumerator getenumerator() i could certainly have combined the first two loops - i just liked the separation provided in this code.
we could create a completely separate top-level type for that... but specifying the type parameters again seems a bit daft when we can reuse them by simply creating a nested class within compositekey:internal struct compositekey this may look a little odd to begin with, but the two types really are quite deeply connected.
fixing the key selectors, and yielding early the content of the postings is owned by the respective author.
we wouldn't be able to later, admittedly...
the overloading of the word "index" here is unfortunate, but that is unfortunately life.
this site is automatically generated and cannot be reviewed for abusive content.
that's about as simple as it gets - although it could still present some interesting options.
how much faster depends on the size of the list of course, and it still has to perform the initial complete partitioning step - but on 100,000 items it's regularly about 10x faster than linq to objects.
if we're going to keep the key selectors in a strongly typed way, that means our orderedenumerable (or at leastsome type involved in the whole business) needs to become generic in the key type.
the final point to note is how we're using the indexes in the comparison, as a tie-break to keep stability.
once partition has returned where the pivot element ended up, quicksort doesn't touch that element itself (we already know it will be in the right place).
i'm sure that last night, when i was running the "yield at the end" code, my tests were running twice as slowly in edulinq as in linq to objects.
this is the bit which caused me the most headaches, until i worked out that the "if (right > left)" condition really meant "if we've got work to do"... and we're interested in the exact opposite scenario - when wedon't have any work to do, as that means everything up to and including "right" is already sorted.
this means that in the case of calling orderby(...).take(5) on a large collection, we can end up saving a lot of work...
just as a reminder, one of my aims was to be able to use iterator blocks to return some values to anyone iterating over the result stream without having to doall the sorting work.
left, i.e. we're sorting one element, or right == left - 1, which will occur if we picked a pivot which was the maximum or minimum value in the list at the previous recursive step.
that means we need to separate out the key selector from the key comparer - in other words, we need to get rid of the handy projectioncomparer we used to simplify the arguments to orderby/thenby/etc.
addendum an earlier version of this post (and the merge sort implementation) had a flawed piece of code for choosing the pivot.
wecould rename the type parameter in the generic method implementation, but i'm becoming a big believer in leaving the signatures of methods alone when i implement an interface.
on my netbook this morning, the same edulinq code seemed to be running slightly faster than linq to objects.
i blame my benchmarking methodology, which is far from rigorous.
for various reasons (mentioned inpart 26b) life is better if we execute the key selector once per input element.
wecould use something like keyvaluepair, but that doesn't really give the right impression.
while wecan do that with lazy evaluation, it makes more sense in my opinion to do it up-front.
new stack(); we initially push a value of (0, count - 1) to simulate the call to quicksort(0, count - 1) which started it all before.
wecould use the compoundcomparer class we created before, but that will end up with quite a bit of indirection.
i've tweaked theparameters of my tests quite a bit, but i haven't tried all kinds of different key and element types, etc.
i'm not quite sure how i pulled that off (merge sort didn't take long either, but it did at least have a few tweaks to fix up) but it shocked the heck out of me.
as a bit of light relief, i think i'll tackle reverse.
this evening, having pulled the "early out" code from the source repository, the edulinq implementation is running faster than the linq to objects implementation even when the "early out" isn't actually doing much good.
the memory benefits of not having a reference to "this" (where the intermediate orderedenumerable is likely to be eligible for gc collection immediately, in a typical orderby(...).thenby(...) call) are almost certainly not worth it.
if this were a production-quality library to be used in performance-critical situations i'd go further in the testing, but as it is, i'm happy to declare victory at this point.
i'm not holding my breath ;) more seriously, i fully expect there are a bunch of scenarios where my knocked-up-in-an-evening code performs slower than that in the framework.
if you find abusive content on csharpfeeds, pleasecontact us.
we're definitelycomputing the earliest results first, due to the order of the recursion - but we can't yield from the recursive method - iterator blocks just don't do that.
while i'll certainly implement all of them, i'm sure i'll only present thecode for selected interesting overloads.
one tiny micro-optimization point to note is that for each loop i'm using the length property of the array rather than "count" as the upper bound, as i believe that will reduce the amount of array boundary checking the jit will generate.
instead, we can just keep a stack of "calls" to quicksort that we want to make, and execute the appropriate code within our getenumerator() method, so we can yield at the right point.
i'm not bothered - this is a private class, and we're basically using this as a tuple.
csharpfeeds is not responsible for the contents of the postings.
i'm not sure i've ever written code which is so dense in type arguments.
after i'd fixed up the compile-time errors to arrive at the code above,it worked first time.
as soon as we've done that to our satisfaction, we're finished with ordering.
it just feels right to have both the primary and secondary key selectors in the same type, which is what will happen with the current code.
thinking ahead, our single "key" type parameter in orderedenumerable could well end up being a composite key.
previously we composed a new (element-based) comparer based on the existing comparer, and a projection comparer from the method parameters.
it works (at least according to my tests).
the actual quicksort part is reasonably standard except for the fact that i pass in both the arrays for both indexes and keys - usually there's just the one array which is being sorted.
