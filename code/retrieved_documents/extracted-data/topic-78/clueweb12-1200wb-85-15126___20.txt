subroutine uniinv (xvalt, igoest) inverse ranking of an array, with removal of duplicate entries
ranking is especially needed when the sizes of the elements are large, and  that moving them around is resource-consuming.
subroutine mrgrnk (xvalt, imult)
gives, for each array value, its  multiplicity the number of times that a value appears in the array is  computed by using inverse ranking, counting for each rank the number of values  that ``collide'' to this rank, and returning this sum to the locations in the  original set.
embedding the routine of interest into a module, and useing that module in  the procedure that calls the routine.
it does not use any work array  and is faster when xvalt is of very small size (< 20), or already almost  sorted, but worst case behavior (intially inverse sorted) can easily happen.
in that case, the total overhead for random vector simulation was nearly 1 minute.
such a routine would prove useful in finding a limited number of unique values in an array.
this subroutine simply calls indnth.
it iterates until it can bring the number of  values in ilowt to exactly nord, and then uses an insertion sort to rank this  set, since it is supposedly small.
such as the set s(i(:)) is ordered.
3, 5.3.3 -  this procedure is linear in time, and does not require to be able to  interpolate in the set as the one used in valnth/indnth.
also, orderpack contains a partial unique ranking  routine.
download all at once to download all the routines in a single source file, click here
in most cases, the quicksort or merge sort method is faster.
it iterates until it can bring the number of values in ilowt to exactly nord, and then uses an insertion sort to rank this set, since it is supposedly small.
rapknr was added first of february 2011.
subroutine rapknr (xvalt, irngt, nord) same as rnkpar, but in decreasing order (rapknr =
the ``nearbyness'' parameter ranges from 0 to 1, with 0 such that no element moves from its initial location, and 1 such that the permutation is fully random.
note that in orderpack 1.0, this routine was a function procedure, and is now changed to a subroutine.
of course, no two problems are the same, and for some of them, the following decisions may happen to be wrong.
it leaves in the  initial set only those entries that are unique, packing the array, and leaving  the order of the retained values unchanged.
it iterates until it can bring the number of  values in ilowt to exactly nord, and then takes out the original index of the  maximum value in this set.
it iterates until it can bring the number of values lower than the pivot to exactly nord, and then uses an insertion sort to rank this set, since it is supposedly small.
i joyfully mix french and english in these names, for instance, iwrkf is an  integer index (i) of temporary nature (wrk) representing an upper limit (f -- fin is end in french); that i used my pretty-printer f90ppr to indent and lay out the source code.
orderpack handles all of  these ordering needs.
it does not use any work array subroutine inspar (xvalt, nord) sorts partially xvalt, bringing the nord lowest values at the begining of the array.
in many cases, the  refined quicksort method implemented by valnthÂ / indnth is faster, though  much more difficult to read and understand.
it uses 2  temporary arrays, one where it stores the indices of the values smaller than  the pivot, and the other for the indices of values larger than the pivot that  we might still need later on.
in  most cases, the quicksort or merge sort method is faster.
it does not use any work array and is faster when nord is very small (2-5), but worst case behavior (intially inverse sorted) can easily happen.
in fact, the time was dominated by the simultation of the vector, looping, and other overhead.
we just hope that for  most cases, they will be right.
the relative proportion of initial order and random order is 1-pcls / pcls, thus when pcls = 0, there is no change in the order whereas the new order is fully random when pcls = 1.
please download the corrected  versions.
in many instances, it suits better the actual need of the user, who  can then use the index array to order other related sets or to select some  elements, than a sorting program would.
orderpack handles all of these ordering needs.
it does not use any work array and is faster when nord is very small (2-5), but worst case behavior can happen fairly probably (initially inverse sorted).
last updated: 2011/02/01
a word of apology when one looks at the description of a sorting algorithm, the process seems  pretty simple, and can usually hold in 10 to 20 lines of pseudo-code.
ranks array xvalt into index array  irngt, using merge-sort
for performance reasons, the first 2 passes are  taken out of the standard loop, and use dedicated coding.
download all at once news bugs were corrected as of fall 2010 in unirnk, uniinv (the  routine tried to access the 4th value when there are only 3) and in rnkpar (the  routine fails when the 3 first values are equal).
it iterates until it can  bring the number of values in ilowt to exactly nord, and then uses an insertion  sort to rank this set, since it is supposedly small.
the ``nearbyness'' parameter ranges from 0 to 1, with 0 such that no  element moves from its initial location, and 1 such that the permutation is  fully random.
the routine is similar to pure merge-sort  ranking, but on the last pass, it sets indices in igoest to the rank of the  original value in an ordered set with duplicates removed.
subroutine refpar (xvalt, irngt, nord) ranks partially xvalt by irngt, up to order nord this version is not optimized for performance, and is thus not as difficult to read as some other ones.
given two arrays of equal length of unordered values,  find a "matching value" in the second array for each value in the  first so that the global correlation coefficient reaches exactly a given target
as an added bonus orderpack provides an unusual routine which allows user controllable partial random permutation of arrays.
subroutine rnkpar (xvalt, irngt, nord) ranks partially xvalt by irngt, up to order nord (refined for speed) this routine uses a pivoting strategy such as the one of finding the median based on the quicksort algorithm, but we skew the pivot choice to try to bring it to nord as fast as possible.
subroutine unirnk (xvalt, irngt, nuni) ranks an array, removing duplicate entries (uses merge sort).
it uses 2 temporary arrays, one where it stores the indices of the  values smaller than the pivot, and the other for the indices of values larger  than the pivot that we might still need later on.
if you want to modify my programs, it might be useful to know:
an example of  use is provided as the test programtstvalnth.f90.
it uses 2 temporary arrays, one where it stores the indices of the values smaller than the pivot, and the other for the indices of values larger than the pivot that we might still need later on.
it iterates until it can bring the number of values lower than the pivot to  exactly nord, and then uses an insertion sort to rank this set, since it is  supposedly small.
when the resulting correlation increases from the  current value, one increases the disorder parameter.
this version is not optimized for performance, and is thus not as  difficult to read as some other ones.
the relative  proportion of initial order and random order is 1-pcls / pcls, thus when pcls =
an example of such way can be found in thefollow.f90  program, that rebuilds a curve from a set of x, y coordinates.
when the resulting  correlation lies between the current one and the target, one replaces the array  with the newly permuted one.
the above solution found another application when i was asked the following  question: i am given two arrays, representing parents' incomes and their  children's incomes, but i do not know which parents correspond to which  children.
given two arrays of equal length of unordered values, find a "matching value" in the second array for each value in the first so that the global correlation coefficient reaches exactly a given target
it was that way when i started  programming more than 20 years ago, and i have forsaken any hope that it might  become otherwise before i return to dust.
such unique ranking routines allow users to isolate individual cases  out of a mass of discrete data.
it may be noted that there could be some cases when one would get stuck in a sort of local minimum, where local perturbations cannot further reduce the correlation and where global ones lead to overpass the target.
it uses insertion sort,  limiting insertion to the first nord values.
this routine uses a  pivoting strategy such as the one of finding the median based on the quicksort  algorithm, but we skew the pivot choice to try to bring it to nord as quickly  as possible.
subroutine mrgref (xvalt, irngt)
finds out and returns the nordth value  in xvalt (ascending order)
orderpack contains conventional or unconditional sorting routines as  well.
it does not use any work array and  is faster when nord is very small (2-5), but worst case behavior (intially  inverse sorted) can easily happen.
uses subroutinemrgrnk.
the orderpack inverse ranking  routine handles this difficult case.
such partial ranking routines  have applications in statistics for rapidly computing extreme order statistics,  finding nearest neighbors, and other clustering operations.
subroutine ctrper (xvalt, pcls) permute array xvalt randomly, but  leaving elements close to their initial locations the routine takes the  1...size(xvalt) index array as real values, takes a combination of these values  and of random values as a perturbation of the index array, and sorts the  initial set according to the ranks of these perturbated indices.
random permutation: an interesting use of ranking a variation of the following problem was raised on the internet sci.math.num-analysis news group: given an array, i would like to  find a random permutation of this array that i could control with a  ``nearbyness'' parameter so that elements stay close to their initial  locations.
perhaps the following should have been under the``word of apology'' item: my programming style does not stick tightly to commonly established rules.
integer function indnth (xvalt, nord)
specifically, we know of no other fortran code which sorts or ranks only a small proportion of an array (partial ordering).
it also has better worst case  behavior than indnth, but is about 10% slower in average for random uniformly  distributed values.
the existing fortran code base provides many conventional ranking or  sorting routines, but very few specialized ranking or sorting routines.
this subroutine uses insertion sort, limiting insertion to the first nord values, and even less when one can know that the value that is considered will not be the nordth.
on  a 460 mhz alphastation with compaq fortran 90 v5.2, taking care to increase  stacksize, partial ranking by itself took 2.3 seconds,i.e. 23  milliseconds per vector.
this routine uses the recursive procedure described in knuth, the art of computer programming, vol.
make extensive use of work arrays: memory can be extended, time cannot.
returns the index of the nordth value of xvalt (in increasing order) this routine uses a pivoting strategy such as the one of finding the median based on the quicksort algorithm, but we skew the pivot choice to try to bring it to nord as fast as possible.
the routine first sorts the two arrays, so as to get the match of maximum possible correlation.
this is fine and recommended for small  programs, but yet may lead to architecture andmakefile problems for  large applications.
finds out and returns the median (((size(xvalt)+1))/2th value) of xvalt
function valnth (xvalt, nord) finds out and returns the nordth value in xvalt (ascending order)
sorts xvalt into increasing order (quick  sort)
many times the frequency of the unique values  proves interesting (e.g., empirical distributions).
when the resulting correlation goes beyond (lower than) the target correlation, one steps back and reduces the disorder parameter of the permutation.
if you want to modify my programs, it might be useful to know: that i don't state implicit none, i prefer to rely on a good compiler to  catch the sort of errors that it catches, and even more of them; that i use some naming conventions that go back to the 6-character  variable names limit, and the conventions of implicit typing.
since full randomness leads to zero correlation, the iterations meet the desired coefficient at some point.
it then iterates, applying the random permutation  algorithm of controlled disorder ctrper to the second array.
users can freely download orderpack 2.0 from this site.
the existing fortran code base provides many conventional ranking or sorting routines, but very few specialized ranking or sorting routines.
there are three main ways to implement it: when one looks at the description of a sorting algorithm, the process seems pretty simple, and can usually hold in 10 to 20 lines of pseudo-code.
for performance reasons, the first 2 passes are taken out of the standard loop, and use dedicated coding.
in many cases, the refined quicksort method is faster.
the above solution found another application when i was asked the following question: i am given two arrays, representing parents' incomes and their children's incomes, but i do not know which parents correspond to which children.
this subroutine uses quicksort in a recursive implementation, and insertion sort for the last steps with small subsets.
this subroutine uses insertion sort, limiting  insertion to the first nord values, and even less when one can know that the  value that is considered will not be the nordth.
it uses only a work array of  size nord and is faster when nord is very small (2-5), but worst case behavior  can happen fairly probably (initially inverse sorted).
a similar experiment involved 100 trials of simulating a random vector of length 1,000,000 and ranking the 20 smallest elements (keeping duplicates).
similar bugs were corrected as of march 2011 in rnkpar and rapknr (the  routines may fail when ranking 3 values out of 4).
subroutine indmed (xvalt, indm) returns the index of the median  (((size(xvalt)+1))/2th value) of xvalt
unconditional ranking subroutine mrgrnk (xvalt, imult)
since full randomness leads to zero correlation, the iterations meet the  desired coefficient at some point.
it also has better worst case behavior than valnth/indnth, and is about 20% faster in average for random uniformly distributed values.
assume that cache size is relatively small, and try to maximize cache hits.
unique ranking subroutine unirnk (xvalt, irngt, nuni) ranks an array, removing  duplicate entries (uses merge sort).
this subroutine uses merge sort unique inverse ranking.
this version is not optimized for performance, and is thus not as difficult to read as some other ones.
it uses  a temporary array, where it stores the partially ranked indices of the values.
this subroutine uses insertion sort.
it also has better worst case behavior than indnth, but is about 10% slower in average for random uniformly distributed values.
ranks array xvalt into index array irngt, using merge-sort
rnkpar spelt backwards).
it iterates until it can bring the number of values in ilowt to exactly nord, and then takes out the original index of the maximum value in this set.
an example of  including the interface block in the calling program can be found in the sample  programsort7.f90.
unique sorting subroutine unista (xvalt, nuni) removes duplicates from an array
it uses insertion sort, limiting insertion to the first nord values.
i would like to pair the elements of these arrays so that the given correlation coefficient is attained, i.e. to reconstruct a realistic dataset, though very likely not to be the true one.
this subroutine uses  insertion sort, limiting insertion to the first nord values.
also, should a  negative correlation be desired, the program should be modified to start with  one array in reverse order with respect to the other, i.e. coorelation as close  to -1 as possible.
we just hope that for most cases, they will be right.
inversion of orderings becomes difficult when  duplicates exist (not a one-to-one relation).
it uses a pivoting strategy such as the one of finding the median based on the quicksort algorithm.
subroutine rapknr (xvalt, irngt, nord) same as rnkpar, but in  decreasing order (rapknr =
please download the corrected versions.
ranks array xvalt into index array  irngt, using merge-sort this version is not optimized for performance, and  is thus not as difficult to read as the previous one.
in many cases, the refined quicksort method implemented by valnth / indnth is faster, though much more difficult to read and understand.
we tried to take into account the recent trends in computing to make our compromise choices.
so please accept my apologies that this code is often complex and difficult to read.
at all times, the nord first values in ilowt correspond to distinct values of the input array.
uses subroutineuniinv.
when the resulting correlation lies between the current one and the target, one replaces the array with the newly permuted one.
sorts xvalt into increasing order (quick sort)
most names are  made of a first letter indicating the type of the variable, a 3-letter radix  defining its fundamental meaning, and one or two suffix letters for qualifiers.
3, 5.3.3 -  this procedure is linear in time, and does not require to be able to  interpolate in the set as the one used in indnth.
in some instances, one is not actually interested in modifying the order of the elements in a set, but only in knowing how to access them in increasing -- or decreasing -- order.
that way, the target correlation is approached from above, by a controlled increase in randomness.
embedding the routine of interest as a "contained routine" into  the calling procedure.
in order to make use of fortran 90 argument passing improvements, it is  necessary to make the routine interface known to the calling program.
subroutine inssor (xvalt) sorts xvalt into increasing order (insertion sort)
the routine is similar to pure merge-sort ranking, but on the last pass, it sets indices in igoest to the rank of the original value in an ordered set with duplicates removed.
subroutine rinpar (xvalt, irngt, nord) ranks partially xvalt by irngt, up to order nord this version is not optimized for performance, and is thus not as difficult to read as some other ones.
function valmed (xvalt)
try to reduce the number of operations in the inner loops, even if it  increases code size.
the routines in orderpack have been designed to take advantage of modern machines.
on a 600 mhz piii machine using the cvf 6.1a compiler it took under 2.7 seconds for the unique partial ranking.
finally, many fortran sorting or ranking routines do not take advantage of  available memory and cache to maximize performance.
it does not use any work array partial sorting subroutine inspar (xvalt, nord) sorts partially xvalt, bringing the  nord lowest values at the begining of the array.
0, there is no change in the order whereas the new order is fully random when  pcls = 1.
i know from an independent source the value of the correlation  coefficient between the incomes of the parents and of their children.
such partial ranking routines have applications in statistics for rapidly computing extreme order statistics, finding nearest neighbors, and other clustering operations.
please download the  corrected versions.
finds out and returns the median  (((size(xvalt)+1))/2th value) of xvalt
function valnth (xvalt, nord) finds out and returns the nordth value  in xvalt (ascending order)
inversion of orderings becomes difficult when duplicates exist (not a one-to-one relation).
in many instances, it suits better the actual need of the user, who can then use the index array to order other related sets or to select some elements, than a sorting program would.
in addition, many applications need to work with only the unique values in an array (unique ordering).
ranks array xvalt into index array irngt, using merge-sort this version is not optimized for performance, and is thus not as difficult to read as the previous one.
ranking in some instances, one is not actually interested in modifying the order of  the elements in a set, but only in knowing how to access them in increasing --  or decreasing -- order.
the routines in orderpack  have been designed to take advantage of modern machines.
on a 600 mhz  piii machine using the cvf 6.1a compiler it took under 2.7 seconds for the  unique partial ranking.
in that case, the total overhead for random vector  simulation was nearly 1 minute.
orderpack contains conventional or unconditional sorting routines as well.
such unique ranking routines allow users to isolate individual cases out of a mass of discrete data.
a similar point is that the index array can be used to index other data.
one of the advantages of carrying out ranking rather than sorting is that the index array can be computed without the performance penalty of moving the elements around when they are of large sizes.
it does not use  any work array and is faster when nord is very small (2-5), but worst case  behavior can happen fairly probably (initially inverse sorted).
to download all the routines in a single source file, click here
it may be noted that there could be some  cases when one would get stuck in a sort of local minimum, where local  perturbations cannot further reduce the correlation and where global ones lead  to overpass the target.
in the end, the number of lines of source code may be multiplied tenfold, and the readability decreased in a similar proportion.
in order to make use of fortran 90 argument passing improvements, it is necessary to make the routine interface known to the calling program.
as an added bonus orderpack provides an  unusual routine which allows user controllable partial random permutation of  arrays.
gives, for each array value, its multiplicity the number of times that a value appears in the array is computed by using inverse ranking, counting for each rank the number of values that ``collide'' to this rank, and returning this sum to the locations in the original set.
it then iterates, applying the random permutation algorithm of controlled disorder ctrper to the second array.
when the resulting correlation increases from the current value, one increases the disorder parameter.
subroutine ctrper (xvalt, pcls) permute array xvalt randomly, but leaving elements close to their initial locations the routine takes the 1...size(xvalt) index array as real values, takes a combination of these values and of random values as a perturbation of the index array, and sorts the initial set according to the ranks of these perturbated indices.
ranking, as it is called, provides the index array i(:)
since we wanted to provide generic versions of the  routines, and to bef-compatible, this is the way we used here.
but if one wants an optimized program, one takes this simple implementation, and looks for redundant operations, investigates runs with sample data sets with a profiling tool, and is led to duplicate code with slight modifications rather than use tests in inner loops, to process differently the first and the last iterations, or to take into account some special cases that are only special in that they can be done faster.
in fact, the time was dominated by the simultation of  the vector, looping, and other overhead.
but if  one wants an optimized program, one takes this simple implementation, and looks  for redundant operations, investigates runs with sample data sets with a  profiling tool, and is led to duplicate code with slight modifications rather  than use tests in inner loops, to process differently the first and the last  iterations, or to take into account some special cases that are only special in  that they can be done faster.
it uses a temporary array, where it stores the partially ranked indices of the values.
partial ranking subroutine rnkpar (xvalt, irngt, nord) ranks partially xvalt by irngt,  up to order nord (refined for speed) this routine uses a pivoting strategy  such as the one of finding the median based on the quicksort algorithm, but we  skew the pivot choice to try to bring it to nord as fast as possible.
at all times, the nord  first values in ilowt correspond to distinct values of the input array.
subroutine mulcnt (xvalt, imult)
3, 5.3.3 - this procedure is linear in time, and does not require to be able to interpolate in the set as the one used in valnth/indnth.
there are  three main ways to implement it: explicit interfaces, either included in the body of the calling routine,  or gathered in an ``interface module''.
author: michel olagnon similar bugs were corrected as of march 2011 in rnkpar and rapknr (the routines may fail when ranking 3 values out of 4).
3, 5.3.3 - this procedure is linear in time, and does not require to be able to interpolate in the set as the one used in indnth.
returns the index of the nordth  value of xvalt (in increasing order) this routine uses a pivoting strategy  such as the one of finding the median based on the quicksort algorithm, but we  skew the pivot choice to try to bring it to nord as fast as possible.
subroutine refpar (xvalt, irngt, nord) ranks partially xvalt by irngt,  up to order nord this version is not optimized for performance, and is  thus not as difficult to read as some other ones.
in many cases, the refined quicksort method  is faster.
mrgref was slightly modifed as of january 2012 to make the sort stable.
a variation of the following problem was raised on the internet sci.math.num-analysis news group: given an array, i would like to find a random permutation of this array that i could control with a ``nearbyness'' parameter so that elements stay close to their initial locations.
interfaces for alldefault real orderpack procedures are provided in fileinterfaces.f90.
the routine first sorts the two arrays, so as to get the match of maximum  possible correlation.
ranking is especially needed when the sizes of the elements are large, and that moving them around is resource-consuming.
finds out and returns the nordth value in xvalt (ascending order)
one of the advantages of carrying out  ranking rather than sorting is that the index array can be computed without the  performance penalty of moving the elements around when they are of large sizes.
many times the frequency of the unique values proves interesting (e.g., empirical distributions).
optimization choices we tried to take into account the recent trends in computing to make our  compromise choices.
to show the potential speed gains, we conducted an experiment involving  100,000 trials of simulating a random vector of length 500 with duplicates and  ranking the 9 smallest unique elements (duplicates discarded).
unfortunately, this is the price to pay for speed of execution.
for performance reasons, the first 2 passes are taken out  of the standard loop, and use dedicated coding.
so please accept my apologies that  this code is often complex and difficult to read.
for performance  reasons, the first 2 passes are taken out of the standard loop, and use  dedicated coding.
note that in orderpack 1.0, this routine was a function procedure, and  is now changed to a subroutine.
when the resulting  correlation goes beyond (lower than) the target correlation, one steps back and  reduces the disorder parameter of the permutation.
finally, many fortran sorting or ranking routines do not take advantage of available memory and cache to maximize performance.
also, should a negative correlation be desired, the program should be modified to start with one array in reverse order with respect to the other, i.e. coorelation as close to -1 as possible.
this routine uses a pivoting strategy such as the one of finding the median based on the quicksort algorithm, but we skew the pivot choice to try to bring it to nord as quickly as possible.
i know from an independent source the value of the correlation coefficient between the incomes of the parents and of their children.
that way, the target  correlation is approached from above, by a controlled increase in randomness.
subroutine unista (xvalt, nuni) removes duplicates from an array
in the end, the number of lines of source code may be multiplied tenfold,  and the readability decreased in a similar proportion.
programming style programming style is personal, and difficult to modify when one has been  programming for several decades.
the orderpack inverse ranking routine handles this difficult case.
this routine uses the recursive  procedure described in knuth, the art of computer programming, vol.
subroutine rinpar (xvalt, irngt, nord) ranks partially xvalt by irngt,  up to order nord this version is not optimized for performance, and is  thus not as difficult to read as some other ones.
specifically, we know of no other fortran code which sorts or ranks only a  small proportion of an array (partial ordering).
it seems easier to restart the program with a different seed when this occurs than to design an avoidance scheme.
it does not use any work array and is faster when xvalt is of very small size (< 20), or already almost sorted, but worst case behavior (intially inverse sorted) can easily happen.
a similar experiment involved 100 trials of simulating a random vector of  length 1,000,000 and ranking the 20 smallest elements (keeping duplicates).
the routine is similar to pure merge-sort ranking, but on the last pass, it discards indices that correspond to duplicate entries.
it uses only a work array of size nord and is faster when nord is very small (2-5), but worst case behavior can happen fairly probably (initially inverse sorted).
subroutine unipar (xvalt, irngt, nord) ranks partially xvalt by irngt, up to order nord at most, removing duplicate entries
in addition, many  applications need to work with only the unique values in an array (unique  ordering).
it was that way when i started programming more than 20 years ago, and i have forsaken any hope that it might become otherwise before i return to dust.
i would  like to pair the elements of these arrays so that the given correlation  coefficient is attained, i.e. to reconstruct a realistic dataset, though very  likely not to be the true one.
in many cases,  the refined quicksort method is faster.
function fndnth (xvalt, nord)
ranking versus sorting ranking consists in finding, for each element of a set, its rank in the  sorted set, without effectively changing the initial order (or disorderÂ !)
ranking consists in finding, for each element of a set, its rank in the sorted set, without effectively changing the initial order (or disorder !) of the set.
subroutine uniinv (xvalt, igoest) inverse ranking of an array, with  removal of duplicate entries
subroutine indmed (xvalt, indm) returns the index of the median (((size(xvalt)+1))/2th value) of xvalt
it leaves in the initial set only those entries that are unique, packing the array, and leaving the order of the retained values unchanged.
also, orderpack contains a partial unique ranking routine.
as time goes by, we hope to extend orderpack, and welcome your suggestions  to this aim.
last updated: 2011/02/01 back to top michel olagnon ifremer brest / michel.olagnon@ifremer.fr
this subroutine uses insertion sort, limiting insertion to the first nord values.
this subroutine uses quicksort in a  recursive implementation, and insertion sort for the last steps with small  subsets.
subroutine refsor (xvalt)
to show the potential speed gains, we conducted an experiment involving 100,000 trials of simulating a random vector of length 500 with duplicates and ranking the 9 smallest unique elements (duplicates discarded).
unfortunately, this is  the price to pay for speed of execution.
of course, no two problems are the same, and for some of  them, the following decisions may happen to be wrong.
subroutine unipar (xvalt, irngt, nord) ranks partially xvalt by irngt,  up to order nord at most, removing duplicate entries
the routine is similar to pure  merge-sort ranking, but on the last pass, it discards indices that correspond  to duplicate entries.
as time goes by, we hope to extend orderpack, and welcome your suggestions to this aim.
sorting subroutine inssor (xvalt) sorts xvalt into increasing order (insertion  sort)
perhaps the following should have been under  the``word of apology'' item: my programming style does not stick tightly  to commonly established rules.
such a routine would prove useful in finding a limited number of  unique values in an array.
it uses a pivoting strategy  such as the one of finding the median based on the quicksort algorithm.
it also has better  worst case behavior than valnth/indnth, and is about 20% faster in average for  random uniformly distributed values.
programming style is personal, and difficult to modify when one has been programming for several decades.
ranking, as it is called, provides the index array i(:) such as the set s(i(:)) is ordered.
on a 460 mhz alphastation with compaq fortran 90 v5.2, taking care to increase stacksize, partial ranking by itself took 2.3 seconds,i.e. 23 milliseconds per vector.
it seems easier to restart the program with a different  seed when this occurs than to design an avoidance scheme.