i wasn't able to get your homeworks graded because i was spending time developing today's lab.
in each round, we spend o(n) time taking stuff out of the vector (assuming that we can append to each bucket in constant time) and o(m+n) time putting stuff back into the vector.
we then step through our array, copying or moving each element to the appropriate bucket.
if you are restricted to compare and swap, it turns out that you can't do better than n*log_2(n) steps.
- for part of today's class, we'll work on lab 9, which focuses on the quicksort algorithm.
if we know that the elements in our array are in a restricted range, we can do a sort that array without comparing and swapping, if we're willing to use some extra space.
we then step through our array, copying or moving each element to the appropriate bucket.
a careful analysis will show you that if you use fewer steps, you won't have been able to compare each element to every other element (directly or indirectly).
[tutorial] [api] disclaimer often, these pages were created "on the fly" with little, if any, proofreading.
any or all of the information on the pages may be incorrect.
(in the extreme case, we only use two buckets in each sort or subsort, giving us something close to quick sort.)
- in radix sort, one repeatedly partitions the objects based on one of the elements of the sequence, moving from least significant to most significant element of the sequence.
quicksort work on lab 9 for approximately twenty minutes to improve your understanding of the operation of quicksort.
if each object to be sorted can be represented as a sequence of values (e.g., a sequence of digits in a decimal number, a sequence of characters in words, a sequence of bits in the binary representation of the object) and sorting can be based on that sequence, then it is possible to sort based on those sequences.
one to look forward to isheap sort.
other sorting algorithms administrivia i have decided not to assign another homework before break since most of you will be working hard on homeworks, essays, and such for your other classes.
one (quicksort) is expected o(n*log_2(n)), but can behave significantly worse.
* * radix sort the vector, starting with the bth-least significant * bit.
when we're done copying elements, we can simply pull them out of the buckets in order (since the buckets are ordered).
silly sort here is an interesting sorting algorithm that relies on limitations to the input to ensure quicker sorting.
a careful analysis will show you that if you use fewer steps, you won't have been able to compare each element to every other element (directly or indirectly).
[tutorial] [api] outline of class 26: sorting without swapping held: friday, march 6, 1998 - short lab: quicksort - faster sorting methods - silly sort - bucket sort - radix sort - other sorting algorithms administrivia - i have decided not to assign another homework before break since most of you will be working hard on homeworks, essays, and such for your other classes.
any or all of the information on the pages may be incorrect.
[tutorial] [api] disclaimer often, these pages were created "on the fly" with little, if any, proofreading.
- i wasn't able to get your homeworks graded because i was spending time developing today's lab.
- space usage is o(n+m), for the temporary buckets.
this can save some space, but may then require extra time.
space usage is o(n+m), for the temporary buckets.
when we're done copying elements, we can simply pull them out of the buckets in order (since the buckets are ordered).
if we know that the elements in our array are in a restricted range, we can do a sort that array without comparing and swapping, if we're willing to use some extra space.
as we learn some more data structures, we'll also learn some more sorting methods that depend on those data structures.
(in the extreme case, we only use two buckets in each sort or subsort, giving us something close to quick sort.)
other sorting algorithms - as we learn some more data structures, we'll also learn some more sorting methods that depend on those data structures.
if you are restricted to compare and swap, it turns out that you can't do better than n*log_2(n) steps.
most often, we simply use bits for the partitioning, as these are easiest to check and use.
in radix sort, one repeatedly partitions the objects based on one of the elements of the sequence, moving from least significant to most significant element of the sequence.
in each round, we spend o(n) time taking stuff out of the vector (assuming that we can append to each bucket in constant time) and o(m+n) time putting stuff back into the vector.
* * radix sort the vector, starting with the bth-least significant * bit.
- one (quicksort) is expected o(n*log_2(n)), but can behave significantly worse.
faster sorting methods we've seen a number of sorting routines.
- most often, we simply use bits for the partitioning, as these are easiest to check and use.
for part of today's class, we'll work on lab 9, which focuses on the quicksort algorithm.
one to look forward to isheap sort.
quicksort work on lab 9 for approximately twenty minutes to improve your understanding of the operation of quicksort.
if each object to be sorted can be represented as a sequence of values (e.g., a sequence of digits in a decimal number, a sequence of characters in words, a sequence of bits in the binary representation of the object) and sorting can be based on that sequence, then it is possible to sort based on those sequences.
