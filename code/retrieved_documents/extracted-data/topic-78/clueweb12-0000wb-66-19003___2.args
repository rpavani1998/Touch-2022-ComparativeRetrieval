performance would probably be better with larger buffers.
a simple mergesort that didnot build initial sorted runs took 451 seconds.
this buffer is then sorted in main memory by using quicksort.
according to shaffer, a multiway merge using half a megabyte of ram and a disk block size of 4 kb could hold 128 disk blocks in ram at once.
the handlemerges function has the job of merging all of these sorted runs, two at a time, until all of the data is merged back under the original file name.
note that the header file has a symbol debug that can be defined if you want to see debugging output.
other than the special cases, the typical pattern used is to merge extsorttemp.0 and extsorttemp.1 into extsorttempa.0, then the next 2 sorted runs are merged into extsorttempa.1, etc.
general cis information curriculum  ap exam scholarships request more information  apply online software design using c++ external sorting introduction external sorting refers to the sorting of a file that is on disk (or tape).
the above output shows that the promised pattern of merges was indeed used by the external sort program.
also, since the words were already in order, the file was sorted, with the linux sort command, starting at the third character of each line.
the buffers were kept small so that the merge portion of the algorithm could be observed without needing a huge test file.
note that when the number of sorted runs is odd, the remaining file is simply renamed.
the final merge shows that when only 2 sorted runs remain, they are merged back into the original file.
also, the performance may not be too great due to the large amount of time it takes to access data on disk.
perhaps the simplest form of external sorting is to use a fast internal sort with goodlocality of reference (which means that it tends to reference nearby items, not widely scattered items) and hope that your operating system's virtual memory can handle it.
note that the test data file contained 45429 words, one per line.
if the file is too huge, however, even virtual memory might be unable to fit it.
note that when the program is creating a sorted run, it uses a single 64 kb buffer, but when it is merging a couple of sorted runs, it uses three 64 kb buffers.
this would allow 128 runs to be merged together in one pass.
a key place where this is true is that the example program merges only 2 sorted files at a time; it does not attempt to do a multiway merge (such as the 128-way merge mentioned above).
a 2-way mergesort that used initial runs of 128 kb took only 160 seconds.
note that you do not want to jump back and forth between 2 or more files in trying to merge them (while writing to a third file).
the temporary files for these sorted runs are placed in the current directory in files named extsorttemp.0, extsorttemp.1, etc.
the reason to take the higher-numbered files first this time is that the highest numbered sorted run may be a short remnant that was left over because we had an odd number of runs.
the average initial run size would be 1 mb.
after the sorted runs have been generated, a merge algorithm is used to combine sorted files into longer sorted files.
the final merge shows that when only 2 sorted runs remain, they are merged back into the original file.
the reason to take the higher-numbered files first this time is that the highest numbered sorted run may be a short remnant that was left over because we had an odd number of runs.
we also merge the top-numbered pair of extsorttempa files first, placing the merged data into a file named extsorttemp.0, then we merge the next pair of extsorttempa files into a file named extsorttemp.1, etc.
this would likely produce a lot of time-consuming disk seeks.
perhaps the simplest form of external sorting is to use a fast internal sort with goodlocality of reference (which means that it tends to reference nearby items, not widely scattered items) and hope that your operating system's virtual memory can handle it.
note that the header file has a symbol debug that can be defined if you want to see debugging output.
the main concern with external sorting is to minimize disk access since reading a disk block takes about a million times longer than accessing an item in ram (according to shaffer -- see the reference at the end of this document).
the following example attempts to show the main features used in most any external sort: producing sorted initial runs, the merging of sorted runs, and the buffering of data.
note that you do not want to jump back and forth between 2 or more files in trying to merge them (while writing to a third file).
the program also uses buffers of size 64 kb, which is no doubt smaller than necessary.
however, the design used is simpler than that which is most likely used in a real-world external sort.
instead, on a single-user pc, it is better to read a block of each of the 2 (or more) files into ram and carry out the merge algorithm there, with the output also kept in a buffer in ram until the buffer is filled (or we are out of data) and only then writing it out to disk.
this would likely produce a lot of time-consuming disk seeks.
in this experiment a 4 mb file was sorted on a particular computer.
when the merge algorithm exhausts one of the blocks of data, refill it by reading from disk another block of the associated file.
we also merge the top-numbered pair of extsorttempa files first, placing the merged data into a file named extsorttemp.0, then we merge the next pair of extsorttempa files into a file named extsorttemp.1, etc.
on a larger machine where the disk drive is being shared among many users, it may not make sense to worry about this as the read/write head is going to be seeking all over the place anyway.
also, since the words were already in order, the file was sorted, with the linux sort command, starting at the third character of each line.
they typically break a large data file into a number of shorter, sorted runs.
when the merge algorithm exhausts one of the blocks of data, refill it by reading from disk another block of the associated file.
enter the name of the text file to be sorted: linux.txt merging extsorttemp.0 and extsorttemp.1 to extsorttempa.0 merging extsorttemp.2 and extsorttemp.3 to extsorttempa.1 merging extsorttemp.4 and extsorttemp.5 to extsorttempa.2 merging extsorttemp.6 and extsorttemp.7 to extsorttempa.3 merging extsorttemp.8 and extsorttemp.9 to extsorttempa.4 merging extsorttemp.10 and extsorttemp.11 to extsorttempa.5 merging extsorttemp.12 and extsorttemp.13 to extsorttempa.6 merging extsorttemp.14 and extsorttemp.15 to extsorttempa.7 merging extsorttemp.16 and extsorttemp.17 to extsorttempa.8 merging extsorttemp.18 and extsorttemp.19 to extsorttempa.9 merging extsorttemp.20 and extsorttemp.21 to extsorttempa.10
note that when the number of sorted runs is odd, the remaining file is simply renamed.
practical data shaffer presents the following practical data concerning external sorting.
a file of size 16 gigabytes could be sorted in just 3 passes.
methods most external sort routines are based on mergesort.
this scrambled the order of the words, giving appropriate test data for the external sort program.)
these can be produced by repeatedly reading a section of the data file into ram, sorting it with ordinary quicksort, and writing the sorted data to disk.
a more likely scenario in a good external sort is that the same amount of memory is used in both cases, no matter how many buffers exist in each case.
the makesortedruns function copies into a buffer a chunk of data from the file being sorted.
on a larger machine where the disk drive is being shared among many users, it may not make sense to worry about this as the read/write head is going to be seeking all over the place anyway.
other than the special cases, the typical pattern used is to merge extsorttemp.0 and extsorttemp.1 into extsorttempa.0, then the next 2 sorted runs are merged into extsorttempa.1, etc.
note that the test data file contained 45429 words, one per line.
the output data is placed back under the original file name.
a file of size 128 mb could be sorted in 2 passes (one to build the initial runs and one to merge them).
this scrambled the order of the words, giving appropriate test data for the external sort program.)
buffers all of the same size were used to keep the example simpler.
the makesortedruns function copies into a buffer a chunk of data from the file being sorted.
(for example, there is no guarantee what order the sort will place the words macintosh and macintosh since they are seen as identical.
this buffer is then sorted in main memory by using quicksort.
the temporary files for these sorted runs are placed in the current directory in files named extsorttemp.0, extsorttemp.1, etc.
example program the ideas behind an external sort seem simple enough, but implementing a working program is fairly complex.
enter the name of the text file to be sorted: linux.txt merging extsorttemp.0 and extsorttemp.1 to extsorttempa.0 merging extsorttemp.2 and extsorttemp.3 to extsorttempa.1 merging extsorttemp.4 and extsorttemp.5 to extsorttempa.2 merging extsorttemp.6 and extsorttemp.7 to extsorttempa.3 merging extsorttemp.8 and extsorttemp.9 to extsorttempa.4 merging extsorttemp.10 and extsorttemp.11 to extsorttempa.5 merging extsorttemp.12 and extsorttemp.13 to extsorttempa.6 merging extsorttemp.14 and extsorttemp.15 to extsorttempa.7 merging extsorttemp.16 and extsorttemp.17 to extsorttempa.8 merging extsorttemp.18 and extsorttemp.19 to extsorttempa.9 merging extsorttemp.20 and extsorttemp.21 to extsorttempa.10
the handlemerges function has the job of merging all of these sorted runs, two at a time, until all of the data is merged back under the original file name.
also, the performance may not be too great due to the large amount of time it takes to access data on disk.
a multiway mergesort that used the same initial runs took only 103 seconds.
if the file is too huge, however, even virtual memory might be unable to fit it.
extsort.h extsort.cpp the example program does a case-insensitive sort of the text file that the user supplies when prompted by the program.
clearly, using initial sorted runs dramatically speeds up the sorting.
instead, on a single-user pc, it is better to read a block of each of the 2 (or more) files into ram and carry out the merge algorithm there, with the output also kept in a buffer in ram until the buffer is filled (or we are out of data) and only then writing it out to disk.
the sorted data is written out to a temporary file.
the above output shows that the promised pattern of merges was indeed used by the external sort program.