ada implementation uses type data_t for the data array.
in this application, we sort each new piece that is received using any sorting algorithm, and then merge it into our sorted list so far using the merge operation.
however, iterative, non-recursive, implementations of merge sort, avoiding method call overhead, are not difficult to code.
on the plus side, merge sort is a stable sort, parallelizes better, and is more efficient at handling slow-to-access sequential media.
if x<y then x::merge (xs,y::ys) else y::merge (x::xs,ys)  ; val half = length(lst) div 2; in merge (mergesort (list.take (lst, half)),mergesort (list.drop (lst, half))) end ; [edit] analysis in sorting n items, merge sort has an average and worst-case performance of o(n log n).
recursive implementations of merge sort make 2n - 1 method calls in the worst case, compared to quicksort's n, thus has roughly twice as much recursive overhead as quicksort.
this opportunity might change if fast memory becomes very cheap again, or if exotic architectures like the tera mta become commonplace.
in the worst case, merge sort does exactly (n ⌈log n⌉ - 2⌈log n⌉ + 1) comparisons, which is between (n log n - n + 1) and (n log n - 0.9139·n + 1)
in the worst case, merge sort does about 39% fewer comparisons than quicksort does in the average case; merge sort always makes fewer comparisons than quicksort, except in extremely rare cases, when they tie, where merge sort's worst case is found simultaneously with quicksort's best case.
mergesort's merge operation is useful in online sorting, where the list to be sorted is received a piece at a time, instead of all at the beginning.
although heap sort has the same time bounds as merge sort, it requires only ω(1) auxiliary space instead of merge sort's ω(n), and is consequently often faster in practical implementations.
however, this approach can be expensive in time and space if the received pieces are small compared to the sorted list — a better approach in this case is to store the list in a self-balancing binary search tree and add elements to it as they are received.
designing a merge sort to perform optimally often requires adjustment to available hardware, eg. number of tape drives, or size and speed of the relevant cache memory levels.
in the worst case, merge sort does about 39% fewer comparisons than quicksort does in the average case; merge sort always makes fewer comparisons than quicksort, except in extremely rare cases, when they tie, where merge sort's worst case is found simultaneously with quicksort's best case.
this opportunity might change if fast memory becomes very cheap again, or if exotic architectures like the tera mta become commonplace.
in java, the arrays.sort() methods use mergesort and a tuned quicksort depending on the datatypes.
merge sort is much more efficient than quicksort if the data to be sorted can only be efficiently accessed sequentially, and is thus popular in languages such as lisp, where sequentially accessed data structures are very common.
in some circumstances, cache reloading might impose unacceptable overhead and a carefully crafted merge sort might result in a significant improvement in running time.
designing a merge sort to perform optimally often requires adjustment to available hardware, eg. number of tape drives, or size and speed of the relevant cache memory levels.
in some sense, main ram can be seen as a fast tape drive, level 3 cache memory as a slightly faster one, level 2 cache memory as faster still, and so on.
although heap sort has the same time bounds as merge sort, it requires only ω(1) auxiliary space instead of merge sort's ω(n), and is consequently often faster in practical implementations.
on the plus side, merge sort is a stable sort, parallelizes better, and is more efficient at handling slow-to-access sequential media.
merge sort is often the best choice for sorting a linked list: in this situation it is relatively easy to implement a merge sort in such a way that it does not require ω(n) auxiliary space (instead only ω(1)), and the slow random-access performance of a linked list makes some other algorithms (such as quick sort) perform poorly, and others (such as heapsort) completely impossible.
merge sort is much more efficient than quicksort if the data to be sorted can only be efficiently accessed sequentially, and is thus popular in languages such as lisp, where sequentially accessed data structures are very common.
in the worst case, merge sort does exactly (n ⌈log n⌉ - 2⌈log n⌉ + 1) comparisons, which is between (n log n - n + 1) and (n log n - 0.9139·n + 1)
recursive implementations of merge sort make 2n - 1 method calls in the worst case, compared to quicksort's n, thus has roughly twice as much recursive overhead as quicksort.
sorting in-place is possible but requires an extremely complicated implementation and hurts performance.
in some circumstances, cache reloading might impose unacceptable overhead and a carefully crafted merge sort might result in a significant improvement in running time.
sorting in-place is possible but requires an extremely complicated implementation and hurts performance.
as of perl 5.8, merge sort is its default sorting algorithm (it was quicksort in previous versions of perl).
if x<y then x::merge (xs,y::ys) else y::merge (x::xs,ys) ; val half = length(lst) div 2; in merge (mergesort (list.take (lst, half)),mergesort (list.drop (lst, half))) end ; in sorting n items, merge sort has an average and worst-case performance of o(n log n).
in this application, we sort each new piece that is received using any sorting algorithm, and then merge it into our sorted list so far using the merge operation.
[edit] utility in online sorting mergesort's merge operation is useful in online sorting, where the list to be sorted is received a piece at a time, instead of all at the beginning.
merge sort's most common implementation does not sort in place, meaning memory the size of the input must be allocated for the sorted output to be stored in.
merge sort's most common implementation does not sort in place, meaning memory the size of the input must be allocated for the sorted output to be stored in.
as of perl 5.8, merge sort is its default sorting algorithm (it was quicksort in previous versions of perl).
function mergesort (data : in data_t) return data_t is begin if data'length  merge_sort(vector& vec) { // termination condition: list is completely sorted if it // only contains a single element.
merge sort is often the best choice for sorting a linked list: in this situation it is relatively easy to implement a merge sort in such a way that it does not require ω(n) auxiliary space (instead only ω(1)), and the slow random-access performance of a linked list makes some other algorithms (such as quick sort) perform poorly, and others (such as heapsort) completely impossible.
however, iterative, non-recursive, implementations of merge sort, avoiding method call overhead, are not difficult to code.
[edit] ada ada implementation uses type data_t for the data array.
this might seem to be of historical interest only, but on modern computers, locality of reference is of paramount importance in software optimization, because multi-level memory hierarchies are used.
[edit] perl fyi as of perl's built-in sort is merge sort by default.
in java, the arrays.sort() methods use mergesort and a tuned quicksort depending on the datatypes.
however, this approach can be expensive in time and space if the received pieces are small compared to the sorted list — a better approach in this case is to store the list in a self-balancing binary search tree and add elements to it as they are received.
in some sense, main ram can be seen as a fast tape drive, level 3 cache memory as a slightly faster one, level 2 cache memory as faster still, and so on.
[edit] optimizing merge sort this might seem to be of historical interest only, but on modern computers, locality of reference is of paramount importance in software optimization, because multi-level memory hierarchies are used.
function mergesort (data : in data_t) return data_t is begin if data'length merge_sort(vector& vec) { // termination condition: list is completely sorted if it // only contains a single element.