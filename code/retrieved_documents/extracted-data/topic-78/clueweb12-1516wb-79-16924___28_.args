merge sort is much more efficient than quicksort if the data to be sorted can only be efficiently accessed sequentially, and is thus popular in languages such as lisp, where sequentially accessed data structures are very common.in some circumstances, cache reloading might impose unacceptable overhead and a carefully crafted merge sort might result in a significant improvement in running time.merge sort is often the best choice for sorting a linked list: in this situation it is relatively easy to implement a merge sort in such a way that it does not require ω(n) auxiliary space (instead only ω(1)), and the slow random-access performance of a linked list makes some other algorithms (such as quick sort) perform poorly, and others (such as heapsort) completely impossible.mergesort's merge operation is useful in online sorting, where the list to be sorted is received a piece at a time, instead of all at the beginning.on the plus side, merge sort is a stable sort, parallelizes better, and is more efficient at handling slow-to-access sequential media.however, this approach can be expensive in time and space if the received pieces are small compared to the sorted list — a better approach in this case is to store the list in a self-balancing binary search tree and add elements to it as they are received.[edit] optimizing merge sort this might seem to be of historical interest only, but on modern computers, locality of reference is of paramount importance in software optimization, because multi-level memory hierarchies are used.although heap sort has the same time bounds as merge sort, it requires only ω(1) auxiliary space instead of merge sort's ω(n), and is consequently often faster in practical implementations.sorting in-place is possible but requires an extremely complicated implementation and hurts performance.designing a merge sort to perform optimally often requires adjustment to available hardware, eg. number of tape drives, or size and speed of the relevant cache memory levels.recursive implementations of merge sort make 2n - 1 method calls in the worst case, compared to quicksort's n, thus has roughly twice as much recursive overhead as quicksort.however, iterative, non-recursive, implementations of merge sort, avoiding method call overhead, are not difficult to code.merge sort's most common implementation does not sort in place, meaning memory the size of the input must be allocated for the sorted output to be stored in.in this application, we sort each new piece that is received using any sorting algorithm, and then merge it into our sorted list so far using the merge operation.as of perl 5.8, merge sort is its default sorting algorithm (it was quicksort in previous versions of perl).