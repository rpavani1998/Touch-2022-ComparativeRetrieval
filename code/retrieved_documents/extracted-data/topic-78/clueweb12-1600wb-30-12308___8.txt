fortunately, the overhead did not in this case mask which alternative would run faster when instrumentation is turned back off.
examples eqntott (specint92) in a 1975 paper [], donald e. knuth asserted (without further citation)
so if the particular quicksort implementation beats the merge sort implementation on both randomized and on already-sorted inputs, what accounts for the nearly an order of magnitude difference in eqntott performance?
by including its  own qsort(), those who submitted  eqntott to the spec organization as a  benchmark could provide a reference output file to go with the reference input  file; whereas if eqntott used the system  qsort(), then the reference output  file might not match eqntott's output on a given platform even though the  difference would be entirely due to sort stability, and would not make the  resulting output incorrect.
(times were quite consistent for runs which used the same sort and had the same sortedness of input, differing only on the random seed.)
investigation readily uncovered that the linux system  qsort() is supplied  by the gnu implementation of the libc library; by default, it does not use the  quicksort algorithm, but rather uses the merge sort algorithm if it can  allocate enough temporary buffer to perform a standard two-space merge sort,  only falling back to an in-place quicksort if the attempt to allocate memory  fails.
author: pshuang@ai.mit.edu (ping  huang)
in a 1975 paper [], donald e. knuth asserted (without further citation) that at that time computer manufacturers believed that about a quarter of computer time was spent sorting.
several other possible transformations to improve eqntott performance, which might benefit from quasistatic constructs, were not fully explored for lack of time.
it's not hard to convince oneself that the code in figure is equivalent figure, but might execute faster on average if , , or were common conditions.
to reiterate, if the library writer had written the system qsort() with a qif statement, then sorting performance would be improved on average, without any effort from the application programmer's part and without complicating the semantics of qsort() usage.
note that careless use of quasistatic constructs in tight inner loops resulted in spectacular profiling overhead, far greater than even that for pixie .
investigation readily uncovered that the linux system qsort() is supplied by the gnu implementation of the libc library; by default, it does not use the quicksort algorithm, but rather uses the merge sort algorithm if it can allocate enough temporary buffer to perform a standard two-space merge sort, only falling back to an in-place quicksort if the attempt to allocate memory fails.
taking advantage of evolutionary and  revolutionary changes in sorting technologies sounds like fertile ground for a  clever compiler.
next: matrix manipulations up: examples previous: examples reinventing computing, mit ai lab.
plus, each of the and  clauses contains two sub-clauses and'ed together, which  can also be permuted --- for a total of 24 possible versions.
figure: a restructuring of the cmppt() inner loop.
since the  qsort() routine supplied with  eqntott  dates back to at least 1983 (it claims to be better than the system qsort() of  the day...), i was curious if qsort() implementations had noticeably improved  since then.
as attractive a hypothesis as this might be, however, it does not stand up  to scrutiny.
that is responsible for the  reduced run time for eqntott, and not a hypothesized reduction in the average  latency for a call to cmppt().
it would be highly tedious to try them all out by hand; but a quasistatic compiler would not be deterred by impatience.
they are described in appendix.
the eqntott call site to qsort() which provides cmppt() as a comparison function hands qsort() an array with just 4,106 items; note that 2,841,621 comparisons to sort 4,106 items seems more nearly o(n ), despite the fact that the quicksort implementation does have the median-of-3 modification which should prevent most (but clearly not all) cases of such degenerate behavior.
this kind of effort with blind alleys, hypotheses to shoot down, etc., is typical of of a human programmer attempting to optimize a program.
a civil engineer chooses from a wide variety of different building material technologies (e.g., wood frame, reinforced concrete, steel i-beam), based on the desired tradeoffs between cost, aesthetics, and strength, which depend on the needs of the particular project.
both merge sort and quicksort are on average o(n log n) algorithms;  however, in the real world, constant factors and not just asymptotic  algorithmic complexity matters.
with quasistatic if support, the programmer can  simply write the code sequence in figure and forget about it.
using gprof profiling, we see that although  eqntott  does spends about 90% of its time executing qsort(), about 85% of the total  run-time was actually spent in cmppt(), which is only called from one  particular call site of qsort().
with quasistatic if support, the programmer can simply write the code sequence in figure and forget about it.
note the total  number of permutations is actually far greater than the three which happen to  be shown: the three clauses or'ed together can be arranged 6 different ways;
it includes the following characterization in its description: this characterization of eqntott execution is strictly speaking correct but rather misleading.
i.e., one hypothesis is that in this case merge sort  tends to be comparing elements which the comparison routine can quickly decide  whetherab, whereas quicksort tends to  be comparing elements which the comparison routine cannot quickly determine the  ordering relationship.
fortunately, the overhead did not in this case mask which alternative would run  faster when instrumentation is turned back off.
it  includes the following characterization in its description: this characterization of  eqntott execution is strictly speaking correct  but rather misleading.
the  eqntott application from the specint92 suite of benchmarks []  translates a logical representation of a boolean equation to a truth table.
table  shows the performance numbers for a few of the possible versions;  only one of the listed versions performs better than the original version.
this kind of effort with blind alleys, hypotheses to shoot down, etc., is  typical of of a human programmer attempting to optimize a program.
it's less tedious and less error-prone to let the clever compiler manage program versions than to do so by hand.
this is in part because the current real-time profiling implementation does not customize the stopwatch start and stop routines for each place where they are used, even though they are inlined; hence the routines still have greater overhead than pixie's instrumentation code per invocation.
we see that although there is  some improvement, the cmppt() comparison function did not offer
is the specint92 reference input file particularly unusual in eliciting this kind of behavior from the quicksort implementation?
hence it can matter greatly to the total run-time exactly which elements are compared with each other, something which was not true for sorting integers.
if the system  qsort() had been written with a  qif statement to quasistatically select  between a quicksort implementation or a merge sort implementation, it would not  be necessary to go to this kind of effort, nor necessary to speculate about whether typical user files provided as input to eqntott tend to elicit o(n ) behavior from the quicksort used; whether or not quicksort often behaved  poorly or not on user inputs would be directly observed and taken into account.
another obvious approach to improving the performance of eqntott would be to try to make cmppt() execute faster.
furthermore, casual trials with another similarly-sized input file for eqntott (modeling a 4-bit 16-input/output multiplexer) suggests that the reference input file for the specint92 benchmark use of eqntott is in fact somewhat anomalous for eliciting such poor behavior from quicksort; however, program performance for the multiplexor input file was still about 20% better with merge sort than with quicksort, consistent with the results in table which shows that the merge sort implementation tends to perform fewer comparisons --- and the number of comparisons, when each comparison can be quite expensive, will dominate the running time more than the efficiency of the inner loops of the sorting algorithm.
comparison routine  cmppt()'s  inner loop.
table: merge sort and median-of-3 quicksort on arrays of integers.
that at that time computer manufacturers believed that about a quarter of  computer time was spent sorting.
attacking cmppt() another obvious approach to improving the performance of  eqntott would be  to try to make cmppt() execute faster.
however, it does  serve as an example where the programmer can use the clever compiler's  capabilities as a tool to simplify the task of exploring what-if  scenarios to improve program performance, although judiciously (i.e., not in  inner loops).
in particular, profiling indicates that there is a 79-fold  reduction in the number of calls to cmppt(): quicksort calls it 2,841,621  times; merge sort, a mere 35,944 times.
however, it's unclear which of the three terms should come first in the conditionally evaluated boolean-or expression for best performance; presumably, this is dependent on the input to eqntott.
table would suggest that  eqntott  using quicksort would be faster than  eqntott using merge sort, when  in fact the reverse is true.)
the  eqntott call site to  qsort() which provides  cmppt() as a comparison function hands  qsort() an array with just 4,106  items; note that 2,841,621 comparisons to sort 4,106 items seems more nearly o(n ), despite the fact that the quicksort implementation does have the median-of-3  modification which should prevent most (but clearly not all) cases of such  degenerate behavior.
one possibility is that most analyses of sort  algorithms assume that comparisons take constant time; this is not always true.
the number of calls to cmppt() which the merge sort  issues, on the other hand, seems much closer to o(n log n).
using gprof profiling, we see that although eqntott does spends about 90% of its time executing qsort(), about 85% of the total run-time was actually spent in cmppt(), which is only called from one particular call site of qsort().
the eqntott application from the specint92 suite of benchmarks [] translates a logical representation of a boolean equation to a truth table.
it should be noted that such comparison functions are not particularly unusual: an ordering string comparison function, for example, takes variable time to run, being highly dependent on the nature of input data.
both merge sort and quicksort are on average o(n log n) algorithms; however, in the real world, constant factors and not just asymptotic algorithmic complexity matters.
regardless of whether that fraction was true then, or what that fraction would be today, sorting is an example of software algorithms as technology.
hence it can matter greatly to the total run-time  exactly which elements are compared with each other, something which was not  true for sorting integers.
hence which sort should be selected in a given usage will depend on both the input data pattern and on the cost of the comparison function provided to qsort().
(a difference in the wrong direction to boot: table would suggest that eqntott using quicksort would be faster than eqntott using merge sort, when in fact the reverse is true.)
the source code files for eqntott include an implementation for qsort(), which makes sense, since the stability of standard c library qsort() --- that is, whether it will or will not preserve the initial ordering of elements being sorted which compare as equal --- is intentionally undefined.
figure  shows the inner loop of the  comparison function.
to reiterate, if the library writer  had written the system qsort() with a  qif statement, then sorting performance  would be improved on average, without any effort from the application  programmer's part and without complicating the semantics of qsort() usage.
that is responsible for the reduced run time for eqntott, and not a hypothesized reduction in the average latency for a call to cmppt().
i.e., one hypothesis is that in this case merge sort tends to be comparing elements which the comparison routine can quickly decide whetherab, whereas quicksort tends to be comparing elements which the comparison routine cannot quickly determine the ordering relationship.
forcing eqntott to use the system qsort() under sunos 4.1.3 resulted in nearly identical timings as using the included qsort(); however, forcing eqntott to use the system qsort() on linux dramatically reduced run-time, from just over 20 seconds to 2.4 seconds.
next: matrix manipulations up: examples previous:
(a  difference in the wrong direction to boot:
the number of calls to cmppt() which the merge sort issues, on the other hand, seems much closer to o(n log n).
great  opportunity for optimization using quasistatic constructs.
a civil engineer chooses from a wide variety of  different building material technologies (e.g., wood frame, reinforced  concrete, steel i-beam), based on the desired tradeoffs between cost,  aesthetics, and strength, which depend on the needs of the particular project.
in particular, every comparison routine defined in eqntott may take variable  amounts of time to execute.
taking advantage of evolutionary and revolutionary changes in sorting technologies sounds like fertile ground for a clever compiler.
a software engineer similarly chooses from a wide variety of different sorting algorithms based on the desired tradeoffs between coding complexity, suitability to size of problem (i.e., internal vs. external sorts), average space consumption, average time consumption, variability of space/time consumption, and sort stability.
it is generally acknowledged that implementations of some of the quicksort variants have the lowest constant factors of well-known comparison-based sorting routines; this is borne out by some basic experimentation --- each row of table was generated by summing the times and comparisons for 5 different runs, each run sorting 1,000,000 integers generated by random() with seed values 0, 1, 2, 3, and 4 respectively.
figure: quasistatic version of cmppt() inner loop.
it's not hard to convince oneself that the code in figure  is equivalent figure, but might execute faster on average if , , or  were  common conditions.
since the qsort() routine supplied with eqntott dates back to at least 1983 (it claims to be better than the system qsort() of the day...), i was curious if qsort() implementations had noticeably improved since then.
figure: a restructuring of the  cmppt()  inner loop.
figure: quasistatic version of  cmppt()  inner loop.
one possibility is that most analyses of sort algorithms assume that comparisons take constant time; this is not always true.
furthermore, it so  happens that the problem is vastly excaberated by the fact that the current  implementation of real-time profiling has a bug whereby the gnu gcc code  generator believes two registers contain live data between the stopwatch start  and stop routines, and this causes several of the inner loop variables to be  spilled from the unusually small register set of the intel pentium processor.
hence which sort should be selected in a  given usage will depend on both the input data pattern and on the cost of the  comparison function provided to qsort().
it is generally acknowledged that  implementations of some of the quicksort variants have the lowest constant  factors of well-known comparison-based sorting routines; this is borne out by  some basic experimentation --- each row of table was generated by summing the  times and comparisons for 5 different runs, each run sorting 1,000,000 integers  generated by random() with seed values 0, 1, 2, 3, and 4 respectively.
however, it does serve as an example where the programmer can use the clever compiler's capabilities as a tool to simplify the task of exploring what-if scenarios to improve program performance, although judiciously (i.e., not in inner loops).
in particular, profiling indicates that there is a 79-fold reduction in the number of calls to cmppt(): quicksort calls it 2,841,621 times; merge sort, a mere 35,944 times.
as attractive a hypothesis as this might be, however, it does not stand up to scrutiny.
table: performance of different rearrangements of boolean terms.
by including its own qsort(), those who submitted eqntott to the spec organization as a benchmark could provide a reference output file to go with the reference input file; whereas if eqntott used the system qsort(), then the reference output file might not match eqntott's output on a given platform even though the difference would be entirely due to sort stability, and would not make the resulting output incorrect.
table: performance of different  rearrangements of boolean terms.
we see that although there is some improvement, the cmppt() comparison function did not offer great opportunity for optimization using quasistatic constructs.
forcing eqntott to use the system  qsort() under sunos 4.1.3  resulted in nearly identical timings as using the included qsort(); however,  forcing eqntott to use the system  qsort() on linux dramatically reduced run-time, from just over 20 seconds to 2.4 seconds.
furthermore, casual trials with another similarly-sized input file for eqntott  (modeling a 4-bit 16-input/output multiplexer) suggests that the reference  input file for the specint92 benchmark use of eqntott is in fact somewhat  anomalous for eliciting such poor behavior from quicksort; however, program  performance for the multiplexor input file was still about 20% better with  merge sort than with quicksort, consistent with the results in table which  shows that the merge sort implementation tends to perform fewer comparisons --- and the number of comparisons, when each comparison can be quite  expensive, will dominate the running time more than the efficiency of the inner  loops of the sorting algorithm.
regardless of whether that fraction was true  then, or what that fraction would be today, sorting is an example of software  algorithms as technology.
figure shows the inner loop of the comparison function.
this is in part because the current real-time profiling implementation does  not customize the stopwatch start and stop routines for each place where they  are used, even though they are inlined; hence the routines still have greater  overhead than pixie's instrumentation code per invocation.
comparison routine cmppt()'s inner loop.
table shows the performance numbers for a few of the possible versions; only one of the listed versions performs better than the original version.
it should be noted that such comparison functions are  not particularly unusual: an ordering string comparison function, for example,  takes variable time to run, being highly dependent on the nature of input data.
is the specint92  reference input file particularly unusual in eliciting this kind of behavior  from the quicksort implementation?
attacking qsort() the source code files for  eqntott include an implementation for  qsort(),  which makes sense, since the stability of standard c library qsort() --- that  is, whether it will or will not preserve the initial ordering of elements being  sorted which compare as equal --- is intentionally undefined.
however, it's unclear which of the three terms should come  first in the conditionally evaluated boolean-or expression for best  performance; presumably, this is dependent on the input to eqntott.
a software engineer similarly chooses from a wide variety of different sorting  algorithms based on the desired tradeoffs between coding complexity,  suitability to size of problem (i.e., internal vs. external sorts), average  space consumption, average time consumption, variability of space/time  consumption, and sort stability.
furthermore, it so happens that the problem is vastly excaberated by the fact that the current implementation of real-time profiling has a bug whereby the gnu gcc code generator believes two registers contain live data between the stopwatch start and stop routines, and this causes several of the inner loop variables to be spilled from the unusually small register set of the intel pentium processor.
in both fields, particular technologies  are refined over time, and new technologies may be created with potentially  completely different tradeoffs.
in both fields, particular technologies are refined over time, and new technologies may be created with potentially completely different tradeoffs.
it would be  highly tedious to try them all out by hand; but a quasistatic compiler would  not be deterred by impatience.
note the total number of permutations is actually far greater than the three which happen to be shown: the three clauses or'ed together can be arranged 6 different ways; plus, each of the and clauses contains two sub-clauses and'ed together, which can also be permuted --- for a total of 24 possible versions.
so if the particular quicksort implementation beats the merge sort  implementation on both randomized and on already-sorted inputs, what accounts  for the nearly an order of magnitude difference in eqntott performance?
it's less tedious and less error-prone to let the clever compiler  manage program versions than to do so by hand.
several other possible transformations to improve  eqntott performance,  which might benefit from quasistatic constructs, were not fully explored for  lack of time.
if the system qsort() had been written with a qif statement to quasistatically select between a quicksort implementation or a merge sort implementation, it would not be necessary to go to this kind of effort, nor necessary to speculate about whether typical user files provided as input to eqntott tend to elicit o(n ) behavior from the quicksort used; whether or not quicksort often behaved poorly or not on user inputs would be directly observed and taken into account.
table: merge sort and median-of-3  quicksort on arrays of integers.
(times  were quite consistent for runs which used the same sort and had the same  sortedness of input, differing only on the random seed.)
in particular, every comparison routine defined in eqntott may take variable amounts of time to execute.
note  that careless use of quasistatic constructs in tight inner loops resulted in spectacular profiling overhead, far greater than even that for pixie .