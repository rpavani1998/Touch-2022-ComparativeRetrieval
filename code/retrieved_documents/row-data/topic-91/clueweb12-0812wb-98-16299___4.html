<!doctype html>
<meta charset="utf-8">
<title>mloss | Project details:Milk</title>
<body>
Login <br>
<br>

<ul> 
<li>About</li> 
<li>Software</li> 
<li>Forum</li> 
<li>Blog</li> 
<li>Workshop</li> 
<li>FAQ</li> </ul>  Project details for Milk <br>

<h2>Manage</h2> 
<dl> 
<dd> Project List </dd> </dl> 
<dl> 
<dd> Login  to submit a new project </dd> </dl> 
<h2>Details</h2> 
<dl> 
<dt> Version: </dt> 
<dd> 0.3.10 </dd> 
<dt> Submitter: </dt> 
<dd> luispedro </dd> 
<dt> Author(s): </dt> 
<dd> Luis Pedro Coelho </dd> 
<dt> Posted: </dt> 
<dd> 11 May 2011 </dd> 
<dt> Last Updated: </dt> 
<dd> 11 May 2011 </dd> 
<dt> Open Source License: </dt> 
<dd> mit </dd> 
<dt> Programming Language(s): </dt> 
<dd> python, c, c++ </dd> </dl> 
<dl> 
<dd> 
<h3> RSS Feed for &quot;Milk&quot;</h3> 
<h3> </h3> </dd> </dl> 
<dl> 
<dd> 
<h2>  Milk 0.3.10 </h2> 
<p> by luispedro - May 11, 2011, 04:18:53 CET [  ] </p> 
<p>  view (3 today),  download ( 0 today ), 1 subscription </p> 
<p> </p> Overall <br>
Features <br>
Usability <br>
Documentation <br>
(based 
on 2 votes) <br>
<br>
<br>
<br>
<br>
<br>

<dl> 
<dt> Description: </dt> 
<dd> 
<p>Milk is a machine learning toolkit in Python. </p> 
<p>Its focus is on supervised classification with several classifiers 
available: SVMs (based on libsvm), k-NN, random forests, decision trees. It 
also performs feature selection. These classifiers can be combined in many ways 
to form different classification systems. It works over many datatypes, with a 
preference for numpy arrays.</p> 
<p>For unsupervised learning, milk supports k-means clustering and affinity 
propagation.</p> </dd> </dl> <br>

<dl> 
<dt> Changes to previous version: </dt> 
<dd> 
<ul> 
<li>
<p>Added a new module: milk.ext.jugparallel to interface with jug 
(http://luispedro.org/software/jug). This makes it easy to parallelise things 
such as n-fold cross validation (each fold runs on its own processor) or 
multiple kmeans random starts.</p> </li> 
<li>
<p>Add some new functions: measures.curves.precision_recall, 
milk.unsupervised.kmeans.select_best.kmeans.</p> </li> 
<li>
<p>Fixed a tricky bug in SDA and a few minor issues elsewhere </p> </li> </ul> 
</dd> </dl> <br>

<dl> 
<dd> <b>BibTeX Entry:</b> Download </dd> 
<dd> <b>URL:</b> Project Homepage </dd> 
<dd> <b>Supported Operating Systems:</b> Agnostic </dd> 
<dd> <b>Data Formats:</b> None, Agnostic </dd> 
<dd> <b>Tags:</b> Python, Svm, Feature Selection, Kmeans, Decision Tree 
Learning, Random Forests, Supervised, Libsvm, Affinity Propagation, Nonnegative 
Matrix Factorization </dd> 
<dd> <b>Archive:</b> download here </dd> </dl> <br>

<dl> 
<dt> 
<h2>Other available revisons</h2> </dt> 
<dd> <b>Version</b> <b>Changelog</b> <b>Date</b> <br>
0.3.10 
<ul> 
<li>
<p>Added a new module: milk.ext.jugparallel to interface with jug 
(http://luispedro.org/software/jug). This makes it easy to parallelise things 
such as n-fold cross validation (each fold runs on its own processor) or 
multiple kmeans random starts.</p> </li> 
<li>
<p>Add some new functions: measures.curves.precision_recall, 
milk.unsupervised.kmeans.select_best.kmeans.</p> </li> 
<li>
<p>Fixed a tricky bug in SDA and a few minor issues elsewhere </p> </li> </ul> 
 May 11, 2011, 04:18:53 <br>
0.3.9 
<p>Speed improvements. Bug fixes. Added <code>folds</code> argument to 
nfoldcrossvalidation. Added<code>assign_centroids</code> function </p>  March 
18, 2011, 22:45:11 <br>
0.3.8 
<p>Fix compilation on Windows. </p>  February 12, 2011, 23:53:03 <br>
0.3.7 
<ul> 
<li> Logistic regression </li> 
<li> Source demos included (in source and documentation) </li> 
<li> Add cluster agreement metrics </li> 
<li> Fix nfoldcrossvalidation bug when using origins </li> </ul>  February 10, 
2011, 15:32:54 <br>
0.3.6 
<ul> 
<li> Unsupervised (1-class) kernel density modeling </li> 
<li> Fix for when SDA returns empty </li> 
<li> weights option to some learners </li> 
<li> stump learner </li> 
<li> Adaboost (result of above changes) </li> </ul>  December 20, 2010, 
19:04:15 <br>
0.3.5 
<ul> 
<li> fixes for 64-bit machines </li> </ul>  November 4, 2010, 05:25:35 <br>

0.3.4 
<ul> 
<li> Random forest learners </li> 
<li> Decision trees sped up 20x </li> 
<li> Much faster gridsearch (finds optimum without computing all folds) </li> 
</ul>  November 1, 2010, 02:01:11 <br>
0.3.1 
<ul> 
<li> fix sparse non-negative matrix factorisation </li> 
<li> mean grouped classifier </li> 
<li> update multi classifier to newer interface </li> 
<li> documentation &amp; testing fixes </li> </ul>  September 26, 2010, 
23:46:27 <br>
0.3 
<ul> 
<li> no scipy.weave dependency </li> 
<li> flatter namespace </li> 
<li> faster kmeans </li> 
<li> affinity propagation (borrowed from scikits-learn &amp; slightly improved 
to take less memory and time)</li> 
<li> pdist() </li> 
<li> more documentation </li> </ul>  September 24, 2010, 01:24:30 <br>
0.2 
<p>Cleaned up and tested code. Removed some dependencies. Better 
documentation. Changed the classification interface to separate model learning 
from model usage.</p>  May 21, 2010, 22:05:04 <br>
alpha-1 
<p>Improved Performance. Removed files from the distribution that were 
mistakenly included.</p>  December 17, 2009, 18:44:18 <br>
alpha-0 
<p>Initial Announcement on mloss.org. </p>  November 24, 2009, 00:16:42 <br>

<br> </dd> </dl> <br>

<h2>Comments</h2> 
<p> No one has posted any comments yet. Perhaps you'd like to be the first? 
</p> 
<h2>Leave a comment</h2> 
<p> You must be logged in to post comments. </p> <br>
<br>
</dd> </dl> <br>

<p>&copy; 2007-2012 Cheng Soon Ong, Soeren Sonnenburg, Mikio Braun | Impressum 
| Hosting graciously provided by theML Group of the TU Berlin | v0.1 | Thanks 
Max Planck Society for previously hosting the site. </p> 
</body>