<!doctype html>
<meta charset="utf-8">
<title>Bibliography generated from lcs.bib</title>
<body>

<dl> 
<dt> [1] </dt> 
<dd> Jose&nbsp;L. Aguilar and Mariela Cerrada. Reliability-Centered 
Maintenance Methodology-Based Fuzzy Classifier System Design for Fault 
Tolerance. InKoza et&nbsp;al. [529], page 621. One page paper. 
<p> </p> </dd> 
<dt> [2] </dt> 
<dd> Jose Aguilar and Mariela Cerrada. Fuzzy classifier system and genetic 
programming on system identification problems. In Lee Spector, Erik&nbsp;D. 
Goodman, Annie Wu, W.B. Langdon, Hans-Michael Voigt, Mitsuo Gen, Sandip Sen, 
Marco Dorigo, Shahram Pezeshk, Max&nbsp;H. Garzon, and Edmund Burke, editors,
Proceedings of the Genetic and Evolutionary Computation Conference (GECCO-2001)
, pages 1245-1251, San Francisco, California, USA, 7-11 July 2001. Morgan 
Kaufmann.
<p> </p> </dd> 
<dt> [3] </dt> 
<dd> J.&nbsp;Aguilar-Ruiz, J.&nbsp;Riquelme, and M.&nbsp;Toro. Evolutionary 
learning of hierarchical decision rules.IEEE Transactions on Systems, Man and 
Cybernetics, Part B, 33(2):324-331, 2003. 
<p> </p> </dd> 
<dt> [4] </dt> 
<dd> Manu Ahluwalia and Larry Bull. A Genetic Programming-based Classifier 
System. InBanzhaf et&nbsp;al. [32], pages 11-18. 
<blockquote> In this paper we present initial results from the use of Genetic 
Programming in Holland's learning Classifier System architecture. Rule are of 
the form condition(s)/action in which the conditions are represented as binary 
strings and the actions are represented by S-expressions. The basic Classifier 
System architecture used here in more analogous to Wilson's ZCS system than 
Holland's original formalism since no internal message list exists; 
stimulus-response rules are developed here. Using two well-known classification 
tasks it is shown that our approach can develop useful feature extractors for 
the K-nearest-neighbour algorithm. We also show that the use of niche-based 
evolutionary search can improve performance.</blockquote> 
<p> </p> </dd> 
<dt> [5] </dt> 
<dd> Sameer Alam, Kamran Shafi, Hussein&nbsp;A. Abbass, and Micheal Barlow. 
Evolving Air Traffic Scenarios for the Evaluation of Conflict Detection Models. 
In6th Eurocontrol Innovative Research Workshop, Eurocontrol Experimental 
Research Centre, France, Dec 4-6, 2007, 2007. 
<p> </p> </dd> 
<dt> [6] </dt> 
<dd> Sameer Alam, Kamran Shafi, Hussein&nbsp;A. Abbass, and Micheal Barlow. 
Forming an Intelligent Ensemble of Conflict Detection Algorithms in Free Flight 
by Data Mining the Scenario Space.Transportation Research Part-C: Emerging 
Technologies, 2009. In Press. 
<p> </p> </dd> 
<dt> [7] </dt> 
<dd> Rudolf&nbsp;F. Albrecht, Nigel&nbsp;C. Steele, and Colin&nbsp;R. Reeves, 
editors.Proceedings of the International Conference on Artificial Neural Nets 
and Genetic Algorithms. Spring-Verlag, 1993. 
<p> </p> </dd> 
<dt> [8] </dt> 
<dd> Peter&nbsp;J. Angeline, Zbyszek Michalewicz, Marc Schoenauer, Xin Yao, 
and Ali Zalzala, editors.Proceedings of the 1999 Congress on Evolutionary 
Computation CEC99, Washington (DC), 1999. IEEE Press. 
<p> </p> </dd> 
<dt> [9] </dt> 
<dd> Plamen Angelov. Evolving Rule-based Models. A tool for design of flexible 
adaptive systems, volume&nbsp;92 of Studies in fuzziness and soft computing. 
Springer-Verlag, 2002.
<p> </p> </dd> 
<dt> [10] </dt> 
<dd> G.&nbsp;Armano, M.&nbsp;Marchesi, and A.&nbsp;Murru. Nxcs: Hybrid 
approach to stock indexes forecasting. In Shu-Heng Chen, editor,Genetic 
Algorithms and Genetic Programming in Computational Finance, chapter&nbsp;6, 
pages 125-158. Kluwer, 2002.
<p> </p> </dd> 
<dt> [11] </dt> 
<dd> G.&nbsp;Armano, A.&nbsp;Murru, and F.&nbsp;Roli. Stock market prediction 
by a mixture of genetic-neural experts.International Journal of Pattern 
Recognition and Artificial Intelligence, 16(5):501-526, 2002. 
<p> </p> </dd> 
<dt> [12] </dt> 
<dd> G.&nbsp;Armano, M.&nbsp;Marchesi, and A.&nbsp;Murru. A hybrid 
genetic-neural architecture for stock indexes forecasting.To appear in the Int. 
Journal of Information Sciences, 2004. 
<p> </p> </dd> 
<dt> [13] </dt> 
<dd> W.&nbsp;Brian Arthur, John&nbsp;H. Holland, Blake LeBaron, Richard 
Palmer, and Paul Talyer. Asset Pricing Under Endogenous Expectations in an 
Artificial Stock Market. Technical report, Santa Fe Institute, 1996. This is 
the original version of LeBaron1999a.
<p> </p> </dd> 
<dt> [14] </dt> 
<dd> Jaume Bacardit and Josep&nbsp;M. Garrell. Evolution of adaptive 
discretization intervals for A rule-based genetic learning system. In 
W.&nbsp;B. Langdon, E.&nbsp;Cant&uacute;-Paz, K.&nbsp;Mathias, R.&nbsp;Roy, 
D.&nbsp;Davis, R.&nbsp;Poli, K.&nbsp;Balakrishnan, V.&nbsp;Honavar, 
G.&nbsp;Rudolph, J.&nbsp;Wegener, L.&nbsp;Bull, M.&nbsp;A. Potter, A.&nbsp;C. 
Schultz, J.&nbsp;F. Miller, E.&nbsp;Burke, and N.&nbsp;Jonoska, editors,GECCO 
2002: Proceedings of the Genetic and Evolutionary Computation Conference, page 
677. Morgan Kaufmann Publishers, 2002.
<p> </p> </dd> 
<dt> [15] </dt> 
<dd> Jaume Bacardit and Josep&nbsp;Maria Garrell. Evolving multiple 
discretizations with adaptive intervals for a Pittsburgh rule-based learning 
classifier system. In E.&nbsp;Cant&uacute;-Paz, J.&nbsp;A. Foster, K.&nbsp;Deb, 
D.&nbsp;Davis, R.&nbsp;Roy, U.-M. O'Reilly, H.-G. Beyer, R.&nbsp;Standish, 
G.&nbsp;Kendall, S.&nbsp;Wilson, M.&nbsp;Harman, J.&nbsp;Wegener, 
D.&nbsp;Dasgupta, M.&nbsp;A. Potter, A.&nbsp;C. Schultz, K.&nbsp;Dowsland, 
N.&nbsp;Jonoska, and J.&nbsp;Miller, editors,Genetic and Evolutionary 
Computation -- GECCO-2003, pages 1818-1831, Berlin, 2003. Springer-Verlag. 
<p> </p> </dd> 
<dt> [16] </dt> 
<dd> Jaume Bacardit and Josep&nbsp;Maria Garrell. Bloat control and 
generalization pressure using the minimum description length principle for a 
pittsburgh approach learning classifier system. In Tim Kovacs, Xavier 
LL&ograve;ra, Keiki Takadama, Pier&nbsp;Luca Lanzi, Wolfgang Stolzmann, and 
Stewart&nbsp;W. Wilson, editors,Learning Classifier Systems. International 
Workshops, IWLCS 2003-2005, Revised Selected Papers, volume 4399 of LNCS, pages 
59-79. Springer, 2007.
<p> </p> </dd> 
<dt> [17] </dt> 
<dd> Jaume Bacardit and Natalio Krasnogor. Empirical evaluation of ensemble 
techniques for a pittsburgh learning classifier system. In Jaume Bacardit, 
Ester Bernad&oacute;-Mansilla, Martin Butz, Tim Kovacs, Xavier Llor&agrave;, 
and Keiki Takadama, editors,Learning Classifier Systems. 10th and 11th 
International Workshops (2006-2007), volume 4998/2008 of Lecture Notes in 
Computer Science, pages 255-268. Springer, 2008. 
<blockquote> Ensemble techniques have proved to be very successful in boosting 
the performance of several types of machine learning methods. In this paper, we 
illustrate its usefulness in combination with GAssist, a Pittsburgh-style 
Learning Classifier System. Two types of ensembles are tested. First we 
evaluate an ensemble for consensus prediction. In this case several rule sets 
learnt using GAssist with different initial random seeds are combined using a 
flat voting scheme in a fashion similar to bagging. The second type of ensemble 
is intended to deal more efficiently with ordinal classification problems. That 
is, problems where the classes have some intrinsic order between them and, in 
case of misclassification, it is preferred to predict a class that is close to 
the correct one within the class intrinsic order. The ensemble for consensus 
prediction is evaluated using 25 datasets from the UCI repository. The 
hierarchical ensemble is evaluated using a Bioinformatics dataset. Both methods 
significantly improve the performance and behaviour of GAssist in all the 
tested domains.</blockquote> 
<p> </p> </dd> 
<dt> [18] </dt> 
<dd> Jaume Bacardit, David&nbsp;E. Goldberg, and Martin&nbsp;V. Butz. 
Improving the performance of a pittsburgh learning classifier system using a 
default rule. In Tim Kovacs, Xavier LL&ograve;ra, Keiki Takadama, 
Pier&nbsp;Luca Lanzi, Wolfgang Stolzmann, and Stewart&nbsp;W. Wilson, editors,
Learning Classifier Systems. International Workshops, IWLCS 2003-2005, Revised 
Selected Papers, volume 4399 of LNCS, pages 291-307. Springer, 2007. 
<p> </p> </dd> 
<dt> [19] </dt> 
<dd> J.&nbsp;Bacardit, M.&nbsp;Stout, J.D. Hirst, and N.&nbsp;Krasnogor. Data 
mining in proteomics with learning classifier systems. In L.&nbsp;Bull, 
E.&nbsp;Bernad&oacute; Mansilla, and J.&nbsp;Holmes, editors,Learning 
Classifier Systems in Data Mining, pages 17-46. Springer, 2008. 
<p> </p> </dd> 
<dt> [20] </dt> 
<dd> J.&nbsp;Bacardit, E.K. Burke, and N.&nbsp;Krasnogor. Improving the 
scalability of rule-based evolutionary learning.Memetic Computing, 1(1), to 
appear in 2009.
<p> </p> </dd> 
<dt> [21] </dt> 
<dd> Jaume Bacardit. Pittsburgh Genetic-Based Machine Learning in the Data 
Mining era: Representations, generalization, and run-time. PhD thesis, 
Universitat Ramon Llull, 2004.
<p> </p> </dd> 
<dt> [22] </dt> 
<dd> Thomas B&auml;ck, David&nbsp;B. Fogel, and Zbigniew Michalewicz, editors. 
Handbook of Evolutionary Computation. Institute of Physics Publishing and 
Oxford University Press, 1997. http://www.iop.org/Books/Catalogue/.
<p> </p> </dd> 
<dt> [23] </dt> 
<dd> Thomas B&auml;ck, Ulrich Hammel, and Hans-Paul Schwefel. Evolutionary 
computation: Comments on the history and current state.IEEE Transactions on 
Evolutionary Computation, 1(1):3-17, 1997. 
<blockquote> Evolutionary computation has started to receive significant 
attention during the last decade, although the origins can be traced back to 
the late 1950's. This article surveys the history as well as the current state 
of this rapidly growing field. We describe the purpose, the general structure, 
and the working principles of different approaches, including genetic 
algorithms (GA) [with links to genetic programming (GP) and classifier systems 
(CS)], evolution strategies (ES), and evolutionary programming (EP) by analysis 
and comparison of their most important constituents (i.e., representations, 
variation operators, reproduction, and selection mechanism). Finally, we give a 
brief overview on the manifold of application domains, although this 
necessarily must remain incomplete.</blockquote> 
<p> </p> </dd> 
<dt> [24] </dt> 
<dd> Thomas B&auml;ck, editor. Proceedings of the 7th International Conference 
on Genetic Algorithms (ICGA97). Morgan Kaufmann, 1997. 
<p> </p> </dd> 
<dt> [25] </dt> 
<dd> Jalal Baghdadchi. A Classifier Based Learning Model for Intelligent 
Agents. InWhitely et&nbsp;al. [878], page 870. One page poster paper. 
<blockquote> The objective of this study is to synthesize a learning model 
capable of successful and effective operation in hard-to-model environments. 
Here, we are presenting a structurally simple and functionally flexible model. 
The model follows the learning patterns experienced by the humans. The novelty 
of the adaptive model lies on the knowledge base, dual learning strategy, and 
flexible reasoning. The knowledge based is allowed to grow for as long as the 
agent lives. Learning is brought about by the interaction between two 
qualitatively different activities leaving long-term and short-term marks on 
the behavior of the agent.</blockquote> 
<p> </p> </dd> 
<dt> [26] </dt> 
<dd> Anthony&nbsp;J. Bagnall and G.&nbsp;D. Smith. Using an Adaptive Agent to 
Bid in a Simplified Model of the UK Market in Electricity. In Banzhaf 
et&nbsp;al. [32], page 774. One page poster paper. 
<blockquote> This work has no abstract. </blockquote> 
<p> </p> </dd> 
<dt> [27] </dt> 
<dd> Anthony&nbsp;J. Bagnall and G.&nbsp;D. Smith. An Adaptive Agent Model for 
Generator Company Bidding in the UK Power Pool. In Proceedings of Artificial 
Evolution, 4th European Conference (AE'99), volume 1829 of Lecture Notes in 
Computer Science, pages 191-203. Springer, 2000. 
<blockquote> This paper describes an autonomous adaptive agent model of the UK 
market in electricity, where the agents represent electricity generating 
companies. We briefly describe the UK market in electricity generation, then 
detail the simplifications we have made. Our current model consists of a single 
adaptive agent bidding against several nonadaptive agents. The adaptive agent 
uses a hierarchical agent structure with two Learning Classifier Systems to 
evolve market bidding rules to meet two objectives. We detail how the agent 
interacts with its environment, the particular problems this environment 
presents to the agent and the agent and classifier architectures we used in our 
experiments. We present the results and conclude that using our structure can 
improve performance.</blockquote> 
<p> </p> </dd> 
<dt> [28] </dt> 
<dd> A.J. Bagnall and Z.V. Zatuchna. On the classification of maze problems. 
In L.&nbsp;Bull and T.&nbsp;Kovacs, editors,Applications of Learning Classifier 
Systems, pages 307-316. Springer, 2005. 
<p> </p> </dd> 
<dt> [29] </dt> 
<dd> Anthony&nbsp;J. Bagnall. A Multi-Adaptive Agent Model of Generator 
Bidding in the UK Market in Electricity. In Whitely et&nbsp;al. [878], pages 
605-612.
<blockquote> A model of the UK market in electricity combining key factors 
influencing generator bidding is proposed and a hierarchical multi-objective 
adaptive agent architecture using case based reasoning and learning classifier 
systems is described. Experimentation shows that the adaptive agents learn 
bidding strategies that have been observed in the real world, and that in some 
market scenarios the agents appear to be learning the benefits of cooperating 
to receive increased long term rewards. The potential of the adaptive agent 
model is illustrated by experimentation with an alternative market structure.
</blockquote> 
<p> </p> </dd> 
<dt> [30] </dt> 
<dd> N.&nbsp;R. Ball. Towards the Development of Cognitive Maps in Classifier 
Systems. InAlbrecht et&nbsp;al. [7], pages 712-718. 
<blockquote> Classifier systems are well tested vehicles for implementing 
genetic algorithms in machine learning environments. This paper presents a 
novel system architecture that transforms a classifier system's knowledge 
representation from message-based structures to self-organizing neural 
networks. These networks have been integrated with a classifier system to 
produce a Hybrid Learning System (HLS) that exhibits adaptive behaviour when 
driven by low level environmental feedback. Problems are represented within HLS 
as objects characterized by environmental features. Objects controlled by the 
system have preset goals set against a subset of their features and the system 
has to achieve these goals by developing a behavioural repertoire that 
efficiently explores and exploits the problem environment. Three types of 
knowledge structures evolve during this adaptive process: a cognitive map of 
useful regularities within the environment (encoded in a self-organizing 
network); classifier behaviour calibrated against feature states and targets 
(encoded in a set of self-organizing feature maps); a population of complex 
behaviours (evolved from a gene pool supplied as part of the initial problem 
specification).</blockquote> 
<p> </p> </dd> 
<dt> [31] </dt> 
<dd> Sanghamitra Bandyopadhyay and Sankar&nbsp;K. Pal. Classification and 
Learning Using Genetic Algorithms. Applications in Bioinformatics and Web 
Intelligence. Natural Computing Series. Springer, 2007. 
<p> </p> </dd> 
<dt> [32] </dt> 
<dd> Wolfgang Banzhaf, Jason Daida, Agoston&nbsp;E. Eiben, Max&nbsp;H. Garzon, 
Vasant Honavar, Mark Jakiela, and Robert&nbsp;E. Smith, editors.Proceedings of 
the Genetic and Evolutionary Computation Conference (GECCO-99). Morgan 
Kaufmann, 1999.
<p> </p> </dd> 
<dt> [33] </dt> 
<dd> Flavio Baronti, Alessandro Passaro, and Antonina Starita. Post-processing 
clustering to decrease variability in xcs induced rulesets. In Tim Kovacs, 
Xavier LL&ograve;ra, Keiki Takadama, Pier&nbsp;Luca Lanzi, Wolfgang Stolzmann, 
and Stewart&nbsp;W. Wilson, editors,Learning Classifier Systems. International 
Workshops, IWLCS 2003-2005, Revised Selected Papers, volume 4399 of LNCS, pages 
80-92. Springer, 2007.
<p> </p> </dd> 
<dt> [34] </dt> 
<dd> Alwyn Barry. The Emergence of High Level Structure in Classifier Systems 
- A Proposal.Irish Journal of Psychology, 14(3):480-498, 1993. 
<p> </p> </dd> 
<dt> [35] </dt> 
<dd> Alwyn Barry. Hierarchy Formulation Within Classifiers System -- A Review. 
InGoodman et&nbsp;al. [379], pages 195-211. 
<blockquote> Whilst the development of Learning Classifier Systems has 
produced excellent results in some fields of application, it has been widely 
noted that problems emerge when seeking to establish higher levels of knowledge 
(see Barry (1993) for relevant review). Tsotsos (1995) suggests that research 
into the operation of the Visual Cortex shows a hierarchical decomposition of 
processing more structured than a simple Subsumption Architecture arrangement. 
Whilst the LCS can provide both memory and planning by the use of tags an rule 
chains, it provides a flat rule space. Various approached have been taken to 
introducing structure to the LCS. We examine these approaches and identify 
three major lines of research: multiple interacting LCS, Single LCS with a 
structured population; and Structured Encoding of Rules. We illustrate that the 
first two of these areas have been interpreted quite differently, and seek to 
draw out common findings from the different approaches. We round off our 
examination of the area by a more detailed look at the work of Dorigo and 
Schnepf (1992), using a Hybrid Classifier System to examine the performance 
claims of Dorigo and Schnepf's architecture.</blockquote> 
<p> </p> </dd> 
<dt> [36] </dt> 
<dd> Alwyn Barry. Aliasing in XCS and the Consecutive State Problem: 1 -- 
Effects. InBanzhaf et&nbsp;al. [32], pages 19-26. 
<blockquote> Whilst XCS (Wilson, 1998) has been shown to be more robust and 
reliable than previous LCS implementations (Kovacs, 1996, 1997), Lanzi(1997) 
identified a potential problem in the application of XCS to certain simple 
multi-step non Markovian environments. The 'Aliasing Problem' occurs when the 
environment provides the same message for two states in environmental positions 
that generate different constant payoffs. This prevents classifiers forming a 
correct payoff prediction for that message. This paper introduces a sub-class 
of the aliasing problem termed the 'Consecutive StateProblem' and uses the 
subclass to identify the effects of consecutive state aliasing on the learning 
of the State * Action * Payoff mapping within XCS. It is shown that aliasing 
states can prevent the formation of classifiers covering preceding states due 
to the trade-off of accuracy for match set occupancy made by the classifiers 
covering the aliasing states. This can be prevented by identifying a condition 
encoding which makes such match set ' piracy' improbable. However, under 
conditions of intense competition for population space where the classifier 
covering the aliased states cannot gain additional match set occupancy these 
classifiers will not be maintained within the population. Barry (1999) uses 
these findings to identify a solution to the Consecutive State Problem which is 
less heavyweight than the more general solution proposed by Lanzi (1997, 1998).
</blockquote> 
<p> </p> </dd> 
<dt> [37] </dt> 
<dd> Alwyn Barry. Aliasing in XCS and the Consecutive State Problem: 2 -- 
Solutions. InBanzhaf et&nbsp;al. [32], pages 27-34. 
<blockquote> The 'Aliasing Problem' within XCS (Wilson,1995, 1998), first 
identified by Lanzi (1997), does not only appear whenever the aliased states 
occur in separate environmental locations but also when they occur 
consecutively (Barry,1999). Lanzi (1997, 1998) introduced a mechanism that 
could solve the Aliasing Problem through the use of memory mechanisms within 
XCS (Wilson, 1995; Cliff and Ross,1994). Whilst this mechanism is a solution to 
the general problem of aliasing, it is a heavyweight solution. By limiting the 
scope of a solution to the Consecutive State Problem, which is shown to be a 
sub-problem of the Aliasing Problem, a simpler solution is proposed, and is 
shown to adequately address this problem. The application of a potential 
solution utilising explicit action duration identification is discussed and 
shown to be inadequate both as a solution to the Consecutive State Problem and 
for more general use within XCS.</blockquote> 
<p> </p> </dd> 
<dt> [38] </dt> 
<dd> Alwyn Barry. Specifying Action Persistence within XCS. In Whitely 
et&nbsp;al. [878], pages 50-57. 
<blockquote> In investigating the Consecutive State Problem within XCS (Barry, 
1999) it was suggested that a possible solution lay in allowing the XCS to 
persist with a single action over the aliased states. It was shown that this 
technique was sufficient to overcome the Consecutive State Problem as long as 
mechanisms were also provided which prevented the persistent application of 
'Null Actions'. An alternative solution based on the work of Cobb and 
Grefenstette (1991) was discussed which sought to extend the action of each 
classifier so that each classifier could specify the duration that the action 
should be applied for. It was noted that this was an inadequate solution for 
the Consecutive State Problem because XCS would still explore the possibility 
of an action which persisted into but not beyond the aliased states. This work 
now applies these ideas to a number of non-aliased multiple step environments. 
It demonstrates that, given a suitable exploration strategy, action persistence 
can be utilised within XCS to enable the selection of a pathway to a reward 
state which entails the minimum number of different actions. It is also shown 
that a modification to the learning mechanism restores the ability of XCS to 
select the pathway to a reward state with the minimum number of steps whilst 
minimising the number of actions used.</blockquote> 
<p> </p> </dd> 
<dt> [39] </dt> 
<dd> Alwyn Barry. XCS Performance and Population Structure within 
Multiple-Step Environments. PhD thesis, Queens University Belfast, 2000. 
<blockquote> Within Michigan-style Learning Classifier Systems based upon 
Holland's model (Holland et al 1986) support for learning in delayed-reward 
multiple-step environments was through the co-operation of classifiers within 
rule-chains. Despite the successful use of this LCS model in direct-reward 
environments (Wilson, 1985, 1987; Parodi and Bonelli, 1990; Holmes, 1997; 
Dorigo andColombetti, 1994), the application of LCS to delayed reward Markovian 
environments has been problematic. There is now a persuasive body of evidence 
that suggests that the use of strength as a fitness metric for the Genetic 
Algorithm (Kovacs and Kerber, 2000; Kovacs, 2000a), the use of rule-chains to 
establish multiple-step policies (Riolo, 1987b, 1989a; Forrest and Miller, 
1990; Compiani et al, 1990), and the lack of mechanisms to encourage the 
development of co-operative populations (Booker, 1988; Smith, 1991; Smith and 
Golberg, 1991) all contribute to its inability within these environments. XCS 
(Wilson, 1995, 1998) presents solutions to each of these issues and initial 
results have shown the considerable promise of the approach (Kovacs, 1996, 
1997; Lanzi, 1999c; Saxon and Barry, 1999a). In this work it is shown that 
whilst the XCS action-chaining mechanisms are effective for short 
action-chains, the combination of the use of discounted payoff and 
generalisation prevents XCS from learning optimal solutions in environments 
requiring even moderately sized action chains. In response it is hypothesised 
that the structuring of the solution, possibly hierarchically, can be used to 
reduce the required action chain length. A framework for hierarchical LCS 
research is proposed using a review of previous LCS hierarchical or structured 
approaches (Barry, 1993, 1996), and this work is compared to developments 
within the Reinforcement Learning community. Within a hierarchical solution 
low-level action chains may suffer when re-used if different payments are given 
to the action chains. An investigation into the Aliasing Problem (Lanzi, 1998a) 
reveals a subset of the problem, termed the Consecutive State Problem (Barry, 
1999a), that will admit to a simple solution, which is empirically demonstrated 
(Barry, 1999b). It is shown that XCS is also able to learn the optimal state * 
action * duration * payoffmapping when a mechanism providing persistent actions 
is added (Barry, 2000), and that although this cannot be used as a solution to 
the aliasing problem it does provide a means of increasing the range of action 
chains. Two forms of preidentified hierarchical structures are introduced and 
it is shown that these allow multiple XCS instances to learn a hierarchical 
model that can be applied to operate successfully within environments requiring 
long action chains.</blockquote> 
<p> </p> </dd> 
<dt> [40] </dt> 
<dd> Dr.&nbsp;Alwyn Barry. A hierarchical xcs for long path environments. In 
Lee Spector, Erik&nbsp;D. Goodman, Annie Wu, W.B. Langdon, Hans-Michael Voigt, 
Mitsuo Gen, Sandip Sen, Marco Dorigo, Shahram Pezeshk, Max&nbsp;H. Garzon, and 
Edmund Burke, editors,Proceedings of the Genetic and Evolutionary Computation 
Conference (GECCO-2001), pages 913-920, San Francisco, California, USA, 7-11 
July 2001. Morgan Kaufmann.
<p> </p> </dd> 
<dt> [41] </dt> 
<dd> Alwyn&nbsp;M. Barry. The stability of long action chains in xcs. Journal 
of Soft Computing, 6(3-4):183-199, 2002. 
<p> </p> </dd> 
<dt> [42] </dt> 
<dd> Alwyn Barry. Limits in long path learning with XCS. In 
E.&nbsp;Cant&uacute;-Paz, J.&nbsp;A. Foster, K.&nbsp;Deb, D.&nbsp;Davis, 
R.&nbsp;Roy, U.-M. O'Reilly, H.-G. Beyer, R.&nbsp;Standish, G.&nbsp;Kendall, 
S.&nbsp;Wilson, M.&nbsp;Harman, J.&nbsp;Wegener, D.&nbsp;Dasgupta, M.&nbsp;A. 
Potter, A.&nbsp;C. Schultz, K.&nbsp;Dowsland, N.&nbsp;Jonoska, and 
J.&nbsp;Miller, editors,Genetic and Evolutionary Computation -- GECCO-2003, 
volume 2724 ofLNCS, pages 1832-1843. Springer-Verlag, 2003. 
<p> </p> </dd> 
<dt> [43] </dt> 
<dd> Richard&nbsp;J. Bauer. Genetic Algorithms and Investment Strategies. 
Wiley Finance Editions. John Wiley &amp; Sons, 1994.
<p> </p> </dd> 
<dt> [44] </dt> 
<dd> Eric Baum and Igor Durdanovic. An Evolutionary Post Production System. In 
Proceedings of the International Workshop on Learning Classifier Systems 
(IWLCS-2000), in the Joint Workshops of SAB 2000 and PPSN 2000 [487]. Extended 
abstract.
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [45] </dt> 
<dd> Eric Baum and Igor Durdanovic. An Artificial Economy of Post Production 
Systems. InLanzi et&nbsp;al. [546], pages 3-20. 
<p> </p> </dd> 
<dt> [46] </dt> 
<dd> Eric Baum. Towards a model of intelligence as an economy of agents. 
Machine Learning, 35(2):155-185, 1999. 
<blockquote> A market-based algorithm is presented which autonomously 
apportions complex tasks to multiple cooperating agents giving each agent the 
motivation of improving performance of the whole system. A specific model, 
called &Acirc;&#147;The Hayek Machine&Acirc;&#148; is proposed and tested on a 
simulated Blocks World (BW) planning problem. Hayek learns to solve more 
complex BW problems than any previous learning algorithm. Given intermediate 
reward and simple features, it has learned to efficiently solve arbitrary BW 
problems. The Hayek Machine can also be seen as a model of evolutionary 
economics.</blockquote> 
<p> </p> </dd> 
<dt> [47] </dt> 
<dd> Richard&nbsp;K. Belew and Stephanie Forrest. Learning and Programming in 
Classifier Systems.Machine Learning, 3:193-223, 1988. 
<blockquote> Both symbolic and subsymbolic models contribute important 
insights to our understanding of intelligent systems. Classifier systems are 
low-level learning systems that are also capable of supporting representations 
at the symbolic level. In this paper, we explore in detail the issues 
surrounding the integration of programmed and learned knowledge in 
classifier-system representations, including comprehensibility, ease of 
expression, explanation predictability, robustness, redundancy, stability, and 
the use of analogical representations. We also examine how these issues speak 
to the debate between symbolic and subsymbolic paradigms. We discuss several 
dimensions for examining the tradeoffs between programmed and learned 
representations, and we propose an optimization model for constructing hybrid 
systems that combine positive aspects of each paradigm.</blockquote> 
<p> </p> </dd> 
<dt> [48] </dt> 
<dd> Richard&nbsp;K. Belew and Michael Gherrity. Back Propagation for the 
Classifier System. InSchaffer [718], pages 275-281. 
<blockquote> Connectionist networks and the Classifier System (CFS) provide 
two important examples of massively parallel knowledge representation systems 
for which successful learning algorithms have been developed. We present a 
construction that shows how the behavior of a large class of connectionist 
networks can be reproduced in a CFS. We then use this construction derive a 
version of the Rumelhart et al.'s back-propagation algorithm for the CFS, and 
conclude with remarks about critical differences between connectionist networks 
and the CFS that this analysis highlights.</blockquote> 
<p> </p> </dd> 
<dt> [49] </dt> 
<dd> L.&nbsp;Beltrametti, R.&nbsp;Fiorentini, L.&nbsp;Marengo, and 
R.&nbsp;Tamborini. A learning-to-forecast experiment on the foreign exchange 
market with a classifier system.Journal of Economic Dynamics and Control, 
21(8):1543-1575, 1997.
<blockquote> This paper reports on an experiment of learning and forecasting 
on the foreign exchange market by means of an Artificial Intelligence 
methodology (a 'Classifier System') which simulates learning and adaptation in 
complex and changing environments. The experiment has been run for two 
different exchange rates, the US dollar-D mark rate and the US dollar-yen rate, 
representative of two possibly different market environments. A fictitious 
''artificial agent'' is first trained on a monthly data base from 1973 to 1990, 
and then tested out-of-sample from 1990 to 1992. Its forecasting performance is 
then compared with the performance of decision rules which follow the 
prescription of various economic theories on exchange rate behaviour, and the 
performance of forecasts given by VAR estimations of the exchange-rate's 
determinants.</blockquote> 
<p> </p> </dd> 
<dt> [50] </dt> 
<dd> E.&nbsp;Bernad&oacute;, X., Llor&agrave;, and J.M. Garrell. XCS and GALE: 
a Comparative Study of Two Learning Classifier Systems with Six Other Learning 
Algorithms on Classification Tasks. InProceedings of the 4th International 
Workshop on Learning Classifier Systems (IWLCS-2001), pages 337-341, 2001. 
Short version published in Genetic and Evolutionary Compution Conference 
(GECCO2001).
<p> </p> </dd> 
<dt> [51] </dt> 
<dd> Ester Bernad&oacute;, Xavier Llor&agrave;, and Josep&nbsp;M. Garrell. XCS 
and GALE: A Comparative Study of Two Learning Classifier Systems on Data 
Mining. InLanzi et&nbsp;al. [546], pages 115-132. 
<p> </p> </dd> 
<dt> [52] </dt> 
<dd> Ester Bernad&oacute;-Mansilla and Josep&nbsp;M. Garrell-Guiu. 
Accuracy-Based Learning Classifier Systems: Models, Analysis and Applications 
to Classification Tasks.Evolutionary Computation, 11(3):209-238, 2003. 
<p> </p> </dd> 
<dt> [53] </dt> 
<dd> Ester Bernad&oacute;-Mansilla and T.K. Ho. Domain of competence of XCS 
classifier system in complexity measurement space.IEEE Trans. Evolutionary 
Computation, 9(1):82-104, 2005. 
<p> </p> </dd> 
<dt> [54] </dt> 
<dd> Hugues Bersini and Francisco&nbsp;J. Varela. Hints for Adaptive Problem 
Solving Gleaned From Immune Networks. InSchwefel and M&auml;nner [728], pages 
343-354.
<p> </p> </dd> 
<dt> [55] </dt> 
<dd> Janine Beunings, Ludwig B&ouml;lkow, Bernd Heydemann, Biruta Kresling, 
Claus-Peter Lieckfeld, Claus Mattheck, Werner Nachtigall, Josef Reichholf, 
Bertram&nbsp;J. Schmidt, Veronika Straa&szlig;, and Reinhard Witt.Bionik: Natur 
als Vorbild. WWF Dokumentationen. PRO FUTURA Verlag, 1993. 
<p> </p> </dd> 
<dt> [56] </dt> 
<dd> J.&nbsp;Biondi. Robustness and evolution in an adaptive system 
application on classification task. InAlbrecht et&nbsp;al. [7], pages 463-470. 
<blockquote> In this paper, we proposed an approach to a single-step 
Classifier System, in which the useful population is built by progressively 
specializing classifiers. It has been applied to a classification task in a 
medical domain. To permit the system to explore alternatives without making 
decisions earlier in learning stages, all the classifiers that might be 
selected are triggered and receive the resulting reward corresponding to their 
action. The payoff function involves the classifier's performance, its 
specificity and the system's performance (its robustness). Genetic operators 
are activated with a probability which depends on the system's robustness. 
During the test stages, no further learning takes place and the system's 
performance is measured by the percentage of correct classification made on the 
second set of examples. When the measure of performance is the highest, the 
population is stabilized and contains the correct classifiers (the payoff 
function and genetic operators have no more effect on classifiers). This 
approach achieves convergency more quickly and makes it possible to have a 
final accurate population without over-specializing.</blockquote> 
<p> </p> </dd> 
<dt> [57] </dt> 
<dd> Andrea Bonarini and Filippo Basso. Learning to compose fuzzy behaviors 
for autonomous agents.Int. Journal of Approximate Reasoning, 17(4):409-432, 
1997.
<p> </p> </dd> 
<dt> [58] </dt> 
<dd> Andrea Bonarini, Marco Dorigo, V.&nbsp;Maniezzo, and D.&nbsp;Sorrenti. 
AutonoMouse: An Experiment in Grounded Behaviors. InProceedings of GAA91 -- 
Second Italian Workshop on Machine Learning, Bari, Italy, 1991. 
<p> </p> </dd> 
<dt> [59] </dt> 
<dd> Andrea Bonarini, Claudio Bonacina, and Matteo Matteucci. Fuzzy and crisp 
representation of real-valued input for learning classifier systems. In Wu [923]
, pages 228-235.
<blockquote> We discuss some issues concerning the application of learning 
classifier systems to real-valued applications. In particular, we focus on the 
possibility of classifying data by crisp and fuzzy intervals, showing the 
effect of their granularity on the learning performance. We introduce the 
concept of sensorial cluster and we discuss the difference between cluster 
aliasing and perceptual aliasing. We show the impact of different choices on 
the performance of both crisp and fuzzy learning classifier systems applied to 
a mobile, autonomous, robotic agent.</blockquote> 
<p> </p> </dd> 
<dt> [60] </dt> 
<dd> Andrea Bonarini, Claudio Bonacina, and Matteo Matteucci. Fuzzy and Crisp 
Representations of Real-valued Input for Learning Classifier Systems. InLanzi 
et&nbsp;al. [544], pages 107-124. 
<blockquote> We discuss some issues concerning the application of learning 
classifier systems to real-valued applications. In particular, we focus on the 
possibility of classifying data by crisp and fuzzy intervals, showing the 
effect of their granularity on the learning performance. We introduce the 
concept of sensorial cluster and we discuss the difference between cluster 
aliasing and perceptual aliasing. We show the impact of different choices on 
the performance of both crisp and fuzzy learning classifier systems applied to 
a mobile, autonomous, robotic agent.</blockquote> 
<p> </p> </dd> 
<dt> [61] </dt> 
<dd> Andrea Bonarini. ELF: Learning Incomplete Fuzzy Rule Sets for an 
Autonomous Robot. In Hans-J&uuml;rgen Zimmermann, editor,First European 
Congress on Fuzzy and Intelligent Technologies -- EUFIT'93, volume&nbsp;1, 
pages 69-75, Aachen, D, September 1993. Verlag der Augustinus Buchhandlung.
<p> </p> </dd> 
<dt> [62] </dt> 
<dd> Andrea Bonarini. Evolutionary Learning of General Fuzzy Rules with Biased 
Evaluation Functions: Competition and Cooperation.Proc. 1st IEEE Conf. on 
Evolutionary Computation, pages 51-56, 1994. 
<p> </p> </dd> 
<dt> [63] </dt> 
<dd> Andrea Bonarini. Learning Behaviors Represented as Fuzzy Logic 
Controllers. In Hans-J&uuml;rgen Zimmermann, editor,Second European Congress on 
Intelligent Techniques and Soft Computing - EUFIT'94, volume&nbsp;2, pages 
710-715, Aachen, D, 1994. Verlag der Augustinus Buchhandlung.
<p> </p> </dd> 
<dt> [64] </dt> 
<dd> Andrea Bonarini. Extending Q-learning to Fuzzy Classifier Systems. In 
Marco Gori and Giovanni Soda, editors,Proceedings of the Italian Association 
for Artificial Intelligence on Topics in Artificial Intelligence, volume 992 of 
LNAI, pages 25-36, Berlin, 1995. Springer. 
<p> </p> </dd> 
<dt> [65] </dt> 
<dd> Andrea Bonarini. Delayed Reinforcement, Fuzzy Q-Learning and Fuzzy Logic 
Controllers. InHerrera and Verdegay [423], pages 447-466. 
<blockquote> In this paper, we discuss situations arising with reinforcement 
learning algorithms, when the reinforcement is delayed. The decision to 
consider delayed reinforcement is typical in many applications, and we discuss 
some motivations for it. Then, we summarize Q-Learning, a popular algorithm to 
deal with delayed reinforcement, and its recent extensions to use it to learn 
fuzzy logic structures (Fuzzy Q-Learning). Moreover, we present how a 
reinforcement learning algorithm we have developed in the past (ELF - 
Evolutionary Learning of Fuzzy rules) implements an extension of the popular 
Q-Learning algorithm for the distribution of delayed reinforcement when the 
controller to be learnt is a Fuzzy Logic Controller (FLC). Finally, we present 
some examples of the application of ELF to learning FLCs that implement 
behaviors for an autonomous agent.</blockquote> 
<p> </p> </dd> 
<dt> [66] </dt> 
<dd> Andrea Bonarini. Delayed Reinforcement, Fuzzy Q-Learning and Fuzzy Logic 
Controllers. In F.&nbsp;Herrera and J.&nbsp;L. Verdegay, editors,Genetic 
Algorithms and Soft Computing, (Studies in Fuzziness, 8), pages 447-466, 
Berlin, D, 1996. Physica-Verlag.
<p> </p> </dd> 
<dt> [67] </dt> 
<dd> Andrea Bonarini. Evolutionary Learning of Fuzzy rules: competition and 
cooperation. In W.&nbsp;Pedrycz, editor, Fuzzy Modelling: Paradigms and Practice
, pages 265-284. Norwell, MA: Kluwer Academic Press, 1996. 
ftp://ftp.elet.polimi.it/pub/Andrea.Bonarini/ELF/ELF-Pedrycz.ps.gz.
<blockquote> We discuss the problem of learning fuzzy rules using Evolutionary 
Learning techniques, such as Genetic Algorithms and Learning Classifier 
Systems. We present ELF, a system able to evolve a population of fuzzy rules to 
obtain a sub-optimal Fuzzy Logic Controller. ELF tackles some of the problems 
typical of the Evolutionary Learning approach: competition and cooperation 
between fuzzy rules, evolution of general fuzzy rules, imperfect reinforcement 
programs, fast evolution for real-time applications, dynamic evolution of the 
focus of the search. We also present some of the results obtained from the 
application of ELF to the development of Fuzzy Logic Controllers for autonomous 
agents and for the classical cart-pole problem.</blockquote> 
<p> </p> </dd> 
<dt> [68] </dt> 
<dd> Andrea Bonarini. Anytime learning and adaptation of fuzzy logic behaviors.
Adaptive Behavior, 5(3-4):281-315, 1997. 
<p> </p> </dd> 
<dt> [69] </dt> 
<dd> Andrea Bonarini. Reinforcement Distribution to Fuzzy Classifiers. In 
Proceedings of the IEEE World Congress on Computational Intelligence (WCCI) -- 
Evolutionary Computation, pages 51-56. IEEE Computer Press, 1998. 
<p> </p> </dd> 
<dt> [70] </dt> 
<dd> Andrea Bonarini. Comparing reinforcement learning algorithms applied to 
crisp and fuzzy learning classifier systems. InBanzhaf et&nbsp;al. [32], pages 
52-59.
<blockquote> We have implemented a tool to compare different modules of 
Reinforcement Learning algorithms applied to Learning Classifier Systems (LCS). 
We focus on three main classes of modules: credit assignment modules, 
exploration policies, and evolutionary strategies. For each class we have 
implemented many of the proposals we can find in the literature and also some 
new algorithms that we have designed. In this paper, we present the results of 
the application of our tool to both fuzzy and crisp LCSs that learn behaviors 
for simulated autonomous agents. Fuzzy LCSs can be considered a successful 
approach to cope with real-valued input and output in a real environment. A lot 
of investigations can be done with this tool in this experimental setting. This 
paper is focused on the comparison among different credit assignment algorithms 
and on their performance in learning both crisp and fuzzy models. Our 
experiments show that the more complex credit assignment algorithms (such as, 
for instance, the TD(lambda) generally have better performance than the more 
basic (such as Q-learning or Bucket Brigade) also when applied to LCSs. 
Moreover, fuzzy LCSs seem to require a larger computational effort, but also 
show more robustness.</blockquote> 
<p> </p> </dd> 
<dt> [71] </dt> 
<dd> Andrea Bonarini. An Introduction to Learning Fuzzy Classifier Systems. In 
Lanzi et&nbsp;al. [544], pages 83-104. 
<blockquote> We present a class of Learning Classifier Systems that learn 
fuzzy rule-based models, instead of interval-based or Boolean models. We 
discuss some motivations to consider Learning Fuzzy Classifier Systems (LFCS) 
as a promising approach to learn mappings from real-valued input to real-valued 
output, basing on data interpretation implemented by fuzzy sets. We describe 
some of the approaches explicitly or implicitly referring to this research 
area, presented in literature since the beginning of the last decade. We also 
show how the general LFCS model can be considered as a framework for a wide 
range of systems, each implementing in a different way the modules composing 
the basic architecture. We also mention some of the applications of LFCS 
presented in literature, which show the potentialities of this type of systems. 
Finally, we introduce a general methodology to extend reinforcement 
distribution algorithms usually not designed to learn fuzzy models. This opens 
new application possibilities.</blockquote> 
<p> </p> </dd> 
<dt> [72] </dt> 
<dd> Pierre Bonelli and Alexandre Parodi. An Efficient Classifier System and 
its Experimental Comparison with two Representative learning methods on three 
medical domains. InBooker and Belew [74], pages 288-295. 
<blockquote> In this paper, we describe a Classifier System, Newboole, and we 
present its experimental comparison with two widely used learning algorithms, 
CN2 (logic reduction system) and Back Propagation (neural net), on three 
medical domains. The experimental results, obtained in the context of learning 
from preclassified examples, demonstrate two main points: firstly, that all 
three systems perform very closely on the induction tasks with a slight 
advantage for the Back Propagation algorithm. Secondly, that a Classifier 
System can provide comprehensive solutions in the form of a reasonable number 
of ``symbolic'' decision rules, which is not the case using Back Propagation.
</blockquote> 
<p> </p> </dd> 
<dt> [73] </dt> 
<dd> Pierre Bonelli, Alexandre Parodi, Sandip Sen, and Stewart&nbsp;W. Wilson. 
NEWBOOLE: A Fast GBML System. InInternational Conference on Machine Learning, 
pages 153-159, San Mateo, California, 1990. Morgan Kaufmann.
<blockquote> Genetics based machine learning systems are considered by a 
majority of machine learners as slow rate learning systems. In this paper, we 
propose an improvement of Wilson's classifier system BOOLE that show how 
Genetics based machine learning systems learning rates can be greatly improved. 
This modification consists in a change of the reinforcement component. We then 
compare the respective performances of this modified BOOLE, called NEWBOOLE, 
and a neural net using back propagation on a difficult boolean learning task, 
the multiplexer function. The results of this comparison show that NEWBOOLE 
obtains significantly faster learning rates.</blockquote> 
<p> </p> </dd> 
<dt> [74] </dt> 
<dd> Lashon&nbsp;B. Booker and Richard&nbsp;K. Belew, editors. Proceedings of 
the 4th International Conference on Genetic Algorithms (ICGA91). Morgan 
Kaufmann, July 1991.
<p> </p> </dd> 
<dt> [75] </dt> 
<dd> Lashon&nbsp;B. Booker, David&nbsp;E. Goldberg, and John&nbsp;H. Holland. 
Classifier Systems and Genetic Algorithms.Artificial Intelligence, 40:235-282, 
1989.
<blockquote> Classifier systems are massively parallel, message-passing, 
rule-based systems that learn through credit assignment (the bucket brigade 
algorithm) and rule discovery (the genetic algorithm). They typically operate 
in environments that exhibit one or more of the following characteristics: (1) 
perpetually novel events accompanied by large amounts of noisy or irrelevant 
data; (2) continual, often real-time requirements for action; (3) implicitly or 
inexactly defined goals; and (4) sparse payoff or reinforcement obtainable only 
through long action sequences. Classifier systems are designed to absorb new 
information continuously from such environments, devising sets of competing 
hypotheses (expressed as rules) without disturbing significantly capabilities 
already acquired. This paper reviews the definition, theory, and extant 
applications of classifier systems, comparing them with other machine learning 
techniques, and closing with a discussion of advantages, problems, and possible 
extensions of classifier systems.</blockquote> 
<p> </p> </dd> 
<dt> [76] </dt> 
<dd> Lashon&nbsp;B. Booker, Rick&nbsp;L. Riolo, and John&nbsp;H. Holland. 
Learning and Representation in Classifier Systems. In Vassant Honavar and 
Leonard Uhr, editors,Artificial Intelligence and Neural Networks, pages 
581-613. Academic Press, 1994.
<p> </p> </dd> 
<dt> [77] </dt> 
<dd> Lashon&nbsp;B. Booker. Intelligent Behavior as an Adaptation to the Task 
Environment. PhD thesis, The University of Michigan, 1982. 
<p> </p> </dd> 
<dt> [78] </dt> 
<dd> Lashon&nbsp;B. Booker. Improving the performance of genetic algorithms in 
classifier systems. InGrefenstette [389], pages 80-92. 
<blockquote> Classifier systems must continuously infer useful categories and 
other generalizations in the form of classifier taxa from the steady stream of 
messages received and transmitted. This paper describes ways to use the genetic 
algorithm more effectively in discovering such patterns. Two issues are 
addressed. First, a flexible criterion is advocated for deciding when a message 
matches a classifier taxon. This is shown to improve performance over a wide 
range of categorization problems. Second, a restricted mating policy and 
crowding algorithm are introduced. These modifications lead to the growth and 
dynamic management of subpopulations correlated with the various pattern 
categories in the environment.</blockquote> 
<p> </p> </dd> 
<dt> [79] </dt> 
<dd> Lashon&nbsp;B. Booker. Classifier Systems that Learn Internal World 
Models.Machine Learning, 3:161-192, 1988. 
<blockquote> Most classifier systems learn a collection of stimulus-response 
rules, each of which directly acts on the problem-solving environment and 
accrues strength proportional to the overt reward expected from the behavioral 
sequences in which the rule participates. GOFER is an example of a classifier 
system that builds an internal model of its environment, using rules to 
represent objects, goals, and relationships. The model is used to direct 
behavior, and learning is triggered whenever the model proves to be an 
inadequate basis for generating behavior in a given situation. This means that 
overt external rewards are not necessarily the only or the most useful source 
of feedback for inductive change. GOFER is tested in a simple two-dimensional 
world where it learns to locate food and avoid noxious stimulation.</blockquote>
<p> </p> </dd> 
<dt> [80] </dt> 
<dd> Lashon&nbsp;B. Booker. Triggered rule discovery in classifier systems. In 
Schaffer [718], pages 265-274. 
<blockquote> Recent work by Quinlan (1988) and Grefenstette (1988) has raised 
doubts about the ability of classifier systems to learn concepts or long 
temporal sequences of rules efficiently. This paper shows how the use of 
learning triggers can greatly increase the performance of a classifier system 
to the point that it compares much more favorably with other learning systems. 
We introduce a new classifier system called Gofer-1 that demonstrates how to 
trigger rule discovery in an effective manner.</blockquote> 
<p> </p> </dd> 
<dt> [81] </dt> 
<dd> Lashon&nbsp;B. Booker. Instinct as an Inductive Bias for Learning 
Behavioral Sequences. InMeyer and Wilson [613], pages 230-237. 
<p> </p> </dd> 
<dt> [82] </dt> 
<dd> Lashon&nbsp;B. Booker. Representing Attribute-Based Concepts in a 
Classifier System. InRawlins [674], pages 115-127. 
<blockquote> Legitimate concerns have been raised about the expressive 
adequacy of the classifier language. This paper shows that many of those 
concerns stem from the inadequacies of the binary encodings typically used with 
classifier systems, not the classifier language per se. In particular, we 
describe some straightforward binary encodings for attribute-based instance 
spaces. These encodings give classifier systems the ability to represent 
ordinal and nominal attributes as expressively as most symbolic machine 
learning systems, without sacrificing the building blocks required by the 
genetic algorithm.</blockquote> 
<p> </p> </dd> 
<dt> [83] </dt> 
<dd> Lashon&nbsp;B. Booker. Viewing Classifier Systems as an Integrated 
Architecture. InCollected Abstracts for the First International Workshop on 
Learning Classifier System (IWLCS-92) [486]. October 6-8, NASA Johnson Space 
Center, Houston, Texas.
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [84] </dt> 
<dd> Lashon&nbsp;B. Booker. Do We Really Need to Estimate Rule Utilities in 
Classifier Systems?. In Wu [923], pages 236-241. 
<blockquote> Classifier systems have traditionally used explicit measures of 
utility (strength, predicted payoff, accuracy, etc.) to quantify the 
performance and fitness of classifier rules. Much of the effort in designing 
and implementing these systems has focused on getting these utilities 
``right''. One alternative worth exploring is the idea of using endogenous 
fitness; that is, reinforcing successful performance with ``resources'' that 
rules need in order to reproduce. Under this regime, the best rules are those 
that accumulate the most resources over their lifetime and, consequently, have 
the most offspring. This paper describes a classifier system designed along 
these lines. Rules have no associated utility measure, just a resource 
reservoir. When enough resources have been accumulated, the rule reproduces and 
the reservoir is reduced. Preliminary tests of this system on the multiplexor 
problem show that it performs as well as utility based classifier systems such 
as XCS.</blockquote> 
<p> </p> </dd> 
<dt> [85] </dt> 
<dd> Lashon&nbsp;B. Booker. Classifier systems, endogenous fitness, and 
delayed reward: A preliminary investigation. In Proceedings of the 
International Workshop on Learning Classifier Systems (IWLCS-2000), in the 
Joint Workshops of SAB 2000 and PPSN 2000 [487]. Extended abstract. 
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [86] </dt> 
<dd> Lashon&nbsp;B. Booker. Do We Really Need to Estimate Rule Utilities in 
Classifier Systems? InLanzi et&nbsp;al. [544], pages 125-142. 
<blockquote> Classifier systems have traditionally used explicit measures of 
utility (strength, predicted payoff, accuracy, etc.) to quantify the 
performance and fitness of classifier rules. Much of the effort in designing 
and implementing these systems has focused on getting these utilities 
``right''. One alternative worth exploring is the idea of using endogenous 
fitness; that is, reinforcing successful performance with ``resources'' that 
rules need in order to reproduce. Under this regime, the best rules are those 
that accumulate the most resources over their lifetime and, consequently, have 
the most offspring. This paper describes a classifier system designed along 
these lines. Rules have no associated utility measure. Instead, each rule has 
one or more reservoirs that can be used to store resources. When enough 
resources have been accumulated, a rule utilizes some of its resources to 
reproduce and the reservoir level is reduced accordingly. Preliminary tests of 
this system on the multiplexor problem show that it performs as well as 
utility-based classifier systems such as XCS.</blockquote> 
<p> </p> </dd> 
<dt> [87] </dt> 
<dd> Lashon&nbsp;B. Booker. Classifier systems, endogenous fitness, and 
delayed rewards: A preliminary investigation. In Lee Spector, Erik&nbsp;D. 
Goodman, Annie Wu, W.B. Langdon, Hans-Michael Voigt, Mitsuo Gen, Sandip Sen, 
Marco Dorigo, Shahram Pezeshk, Max&nbsp;H. Garzon, and Edmund Burke, editors,
Proceedings of the Genetic and Evolutionary Computation Conference (GECCO-2001)
, pages 921-926, San Francisco, California, USA, 7-11 July 2001.
<blockquote> Previous work has shown the potential advantages of using 
endogenous fitness schemes in classifier systems. The basic idea behind 
endogenous fitness is to reinforce successful system performance with 
``resources'' that rules need in order to reproduce. Instead of storing 
explicit quantitative estimates of performance, each rule has one or more 
reservoirs that are used to store resources. When enough resources have been 
accumulated, a rule utilizes some of its resources to reproduce and the 
reservoir level is reduced accordingly. This paper extends this concept to 
accommodate environments having delayed rewards. Reinforcement learning 
techniques for solving average-reward Markovian decision processes are combined 
with a simple endogenous fitness scheme in a classifier system. We describe 
initial tests of this approach on state space search problems used in previous 
classifier system studies.</blockquote> 
<p> </p> </dd> 
<dt> [88] </dt> 
<dd> Lashon&nbsp;B. Booker. A new approach to encoding actions in classifier 
systems. 2001.
<blockquote> The classifier system framework is a general-purpose approach to 
learning and representation designed to exhibit non-brittle behavior in 
complex, continually varying environments. Broadly speaking, classifier systems 
are expected to avoid brittle behavior because they implement processes that 
build and refine models of the environment. One of the most important of these 
processes is categorization. As Holland [5] has pointed out (p. 598) 
&quot;Categorization is the system's major weapon for combating the 
enviironment's perpetual novelty. The system must readily generate categories 
for input messages, and it must be able to generate categories relevant to its 
internal processes&quot;. Research in classifier systems has focused almost 
exclusively on finding generalizations for input messages. However, 
generalizations of actions will also be required in order to build effective 
models of the environment. This paper introduces a new encoding for actions in 
classifier rules that lends itself to representing abstract actions.
</blockquote> 
<p> </p> </dd> 
<dt> [89] </dt> 
<dd> Lashon&nbsp;B. Booker. Adaptive value function approximations in 
classifier systems. InGECCO '05: Proceedings of the 2005 workshops on Genetic 
and evolutionary computation, pages 90-91. ACM, 2005. 
<p> </p> </dd> 
<dt> [90] </dt> 
<dd> Lashon&nbsp;B. Booker. Approximating value functions in classifier 
systems. In L.&nbsp;Bull and T.&nbsp;Kovacs, editors,Foundations of Learning 
Classifier Systems, volume 183/2005 of Studies in Fuzziness and Soft Computing, 
pages 45-61. Springer, 2005.
<blockquote> While there has been some attention given recently to the issues 
of function approximation using learning classifier systems (e.g. [13, 3]), few 
studies have looked at the quality of the value function approximation computed 
by a learning classifier system when it solves a reinforcement learning problem 
[1, 8]. By contrast, considerable attention has been paid to this issue in the 
reinforcement learning literature [12]. One of the fundamental assumptions 
underlying algorithms for solving reinforcement learning problems is that 
states and state-action pairs have well-defined values that can be computed and 
used to help determine an optimal policy. The quality of those approximations 
is a critical factor in determining the success of many algorithms in solving 
reinforcement learning problems.</blockquote> 
<p> </p> </dd> 
<dt> [91] </dt> 
<dd> Lashon&nbsp;B. Booker. Adaptive value function approximations in 
classifier systems. In Tim Kovacs, Xavier LL&ograve;ra, Keiki Takadama, 
Pier&nbsp;Luca Lanzi, Wolfgang Stolzmann, and Stewart&nbsp;W. Wilson, editors,
Learning Classifier Systems. International Workshops, IWLCS 2003-2005, Revised 
Selected Papers, volume 4399 of LNCS, pages 219-238. Springer, 2007. 
<p> </p> </dd> 
<dt> [92] </dt> 
<dd> Gavin Brown, Tim Kovacs, and James Marshall. UCSpv: Principled Voting in 
UCS Rule Populations. In Hod&nbsp;Lipson et&nbsp;al., editor,GECCO'07: the 
Genetic and Evolutionary Computation Conference, pages 1774-1781. ACM, 2007. 
<p> </p> </dd> 
<dt> [93] </dt> 
<dd> Will Browne, Karen Holford, Carolynne Moore, and John Bullock. The 
implementation of a learning classifier system for parameter identification by 
signal processing of data from steel strip downcoilers. In A.&nbsp;T. Augousti, 
editor,Software in Measurement Conference, number 96-147. IEE Computer and 
Control Division, 1996.
<blockquote> The aim of this project is to improve the quality and consistency 
of coiling in a steel hot strip mill. Signal processing will be used to gather 
information on the parameter characteristics of the mill downcoilers as an aid 
to operator and engineering decision making. The Artificial Intelligence (AI) 
paradigm of Learning Classifier Systems (LCS) is proposed for the signal 
processing.</blockquote> 
<p> </p> </dd> 
<dt> [94] </dt> 
<dd> Will Browne, Karen Holford, Carolynne Moore, and John Bullock. A 
Practical Application of a Learning Classifier System for Downcoiler Decision 
Support in a Steel Hot Strip Mill.Ironmaking and Steelmaking, 25(1):33-41, 
1997. Engineering Doctorate Seminar '97. Swansea, Wales, Sept. 2nd, 1997.
<blockquote> The aim of this project is to improve the quality and consistency 
of coiling in a hot strip mill at British Steel Strip Products, Integrated 
Works. The Artificial Intelligence paradigm of Learning Classifier Systems is 
proposed for the processing of plant data. The stochastic computational 
technique of LCS will produce off-line rules to aid operator and engineering 
decision making. These rules link the plant inputs (plant condition, strip 
properties and associated variables) to coil outputs (presentation - including 
telescoping and pinching) in a form that is capable of being verified and 
validated. This is central to the initial operation, where on-line data will 
produce off-line rules that are critically evaluated by a human operator before 
implementation. Improvements to a basic LCS, that allow operation on industrial 
data, are detailed. Initial experimental results show that the technique of LCS 
has the potential to become a very useful tool for processing industrial data. 
Improvements in availability, coil presentation and ultimately customer 
satisfaction will result in a cost benefit to British Steel Plc.</blockquote> 
<p> </p> </dd> 
<dt> [95] </dt> 
<dd> Will Browne, Karen Holford, Carolynne Moore, and John Bullock. A 
Practical Application of a Learning Classifier System in a Steel Hot Strip 
Mill. InSmith et&nbsp;al. [770], pages 611-614. 
<blockquote> The aim of this project is to improve the quality and consistency 
of coiling in a steel hot strip mill at British Steel Strip Products, 
Integrated Works. The artificial intelligence paradigm of learning classifier 
systems (LCS) is proposed for the processing of plant data. Improvements to a 
basic LCS, that allow operation on industrial data, are detailed. Initial 
experimental results show that the technique of LCS has the potential to become 
a very useful for processing industrial data. The stochastic computational 
technique will produce off-line rules to aid operator and engineering decision 
making. Improvements in availability, coil presentation and ultimately customer 
satisfaction will result in cost benefits to British Steel Plc.</blockquote> 
<p> </p> </dd> 
<dt> [96] </dt> 
<dd> Will Browne, Karen Holford, and Carolynne Moore. An Industry-Based 
Development of the Learning Classifier System Technique. In I.&nbsp;C. Parmee, 
editor,Adaptive Computing in Design and Manufacture (ACDM 2000), pages 199-210. 
Springer-Verlag, 1999.
<blockquote> This paper describes the development of an Industrial Learning 
Classifier System for application in the steel industry. The real domain 
problem was the prediction and diagnosis of product quality issues in a Steel 
Hot Strip Mill. The properties of the data from this environment include 
multi-modality (much parameter interaction), poor separation between fault 
levels and high dimensionality (many parameters). The method to develop the 
Learning Classifier System technique, based on deterministic simulated data, is 
presented. The advances made in the technique that assist in its functionality 
in this type of industrial environments are given. The novel methods developed 
are core to the Learning Classifier System technique and are not 'fixes' for 
given problems. They address the fitness measure, encoding alphabet, population 
scope, phases of training, genetic operators, life limits and removal of 
taxation schemes. These improvements allow the industrial LCS to function 
correctly in the simulated domain. Encouraging results from diagnosis of real 
data are presented; however, further work is needed for greater accuracy and to 
allow the prediction function to be used on-line. Learning Classifier Systems 
represent a potentially useful tool that combines the transparency of symbolic 
approaches (such as Decision Trees) with the learning ability of connectionist 
approaches (such as Artificial Neural Networks) to machine learning.
</blockquote> 
<p> </p> </dd> 
<dt> [97] </dt> 
<dd> Will Browne, Karen Holford, Carolynne Moore, and John Bullock. An 
Industrial Learning Classifier System: The Importance of Pre-Processing Real 
Data and Choice of Alphabet.Engineering Applications of Artificial Intelligence
, 13(1):25-36, 2000.
<blockquote> Learning Classifier Systems (LCS) have received considerable 
attention in the research community, yet few have been applied in practice. 
This paper describes the development of a LCS for monitoring data produced by a 
hot strip mill at British Steel Strip Products. The problems associated with 
applying a theoretical technique in a practical environment are discussed with 
particular attention being given to the pre processing of voluminous real data. 
The appropriate choice of alphabet for the LCS is also discussed, with a 
comparison of two alphabets, namely the ternary alphabet and the real numbered 
approach, being included.</blockquote> 
<p> </p> </dd> 
<dt> [98] </dt> 
<dd> Will Browne. The Development of an Industrial Learning Classifier System 
for Application to a Steel Hot Strip Mill. PhD thesis, University of Wales, 
Cardiff, 1999.
<blockquote> The search for continual improvement in industry has identified 
the resource of plant data. Learning Classifier Systems (LCSs) were anticipated 
to be capable of exploiting plant data for cost benefit. The initial LCS 
performed poorly on simulated data as complex domains caused greedy and 
unstable performance. The aim of the project was to develop the LCS technique 
into a robust tool for application to industry. The utilisation of performance 
methods where appropriate, was achieved by splitting the LCS rule-base into the 
three training phases. Another advance was to separate the fitness measure into 
component functions, thus enabling optimal control of the LCS. Combining rule 
accuracy with the degree of domain match allowed the rule discovery to evenly 
search all niches of the rule base, whilst still exerting a generalisation 
pressure. Motivated by experiments with real data a morphing genetic operator 
to improve search rates, an evaluation limit to enable graceful improvements of 
hierarchies and a child limit to prevent convergence to a sub-optimum 
performance level were created. Implementing a real numbered alphabet 
simplified rule interpretation, automatically adjusted condition ranges to 
avoid aliasing and formed correct rule boundaries. Further simplification of 
the internal parameters removed all taxation, which greatly simplified the use 
of the industrial LCS. Optimum prediction and correct diagnosis of the complex 
simulated data was achieved. The real data sets from British Steel governed 
plant conditions and output quality. Diagnosis of the input-output 
relationships that could assist operators, engineers and managers was possible 
and contained encouraging results. However, inadequacies in data quality and 
the technique allowed only 80 prediction, which was insufficient confidence for 
plant predictive use. Although the LCS technique is still not fully developed, 
the effective learning, transparency and co-operation in rules has many 
potential benefits for industry.</blockquote> 
<p> </p> </dd> 
<dt> [99] </dt> 
<dd> Larry Bull and Terence&nbsp;C. Fogarty. Coevolving Communicating 
Classifier Systems for Tracking. InAlbrecht et&nbsp;al. [7], pages 522-527. 
<blockquote> In this paper we suggest a general approach to using the genetic 
algorithm (GA)[1] to evolve complex control systems. It has been shown [2] that 
although the GA may be used to evolve simple controllers, it is not able to 
cope with the evolution of controllers for more complex problems. We present an 
architecture of co-evolving communicating classifier systems [3] as a general 
solution to this, where the only restriction is that each classifier system is 
responsible for one simple behaviour. Thus the ecology of sub-problems evolves 
its own organisational structure at the same time its constituents evolve their 
solutions. Whether this structure ends up as a democratic soup, a hierarchy, or 
something in between, is determined by co-evolution rather than prescribed a 
priori by a creator. We use the trail following ``tracker task'' to compare the 
performance of a single classifier, responsible for the control of the whole 
system, evolved for this task with the performance of a co-evolved controller 
using our approach. The resulting interactions of the classifier system are 
also examined.</blockquote> 
<p> </p> </dd> 
<dt> [100] </dt> 
<dd> Larry Bull and Terence&nbsp;C. Fogarty. Evolving Cooperative 
Communicating Classifier Systems. In A.&nbsp;V. Sebald and L.&nbsp;J. Fogel, 
editors,Proceedings of the Third Annual Conference on Evolutionary Programming, 
pages 308-315, 1994.
<p> </p> </dd> 
<dt> [101] </dt> 
<dd> Larry Bull and Terence&nbsp;C. Fogarty. Parallel Evolution of 
Communicating Classifier Systems. InProceedings of the 1994 IEEE Conference on 
Evolutionary Computing, pages 680-685. IEEE, 1994. 
<p> </p> </dd> 
<dt> [102] </dt> 
<dd> Larry Bull and Terence&nbsp;C. Fogarty. Evolutionary Computing in 
Cooperative Multi-Agent Systems. In Sandip Sen, editor,Proceedings of the 1996 
AAAI Symposium on Adaptation, Coevolution and Learning in Multi-Agent Systems, 
pages 22-27. AAAI, 1996.
<p> </p> </dd> 
<dt> [103] </dt> 
<dd> Larry Bull and Terence&nbsp;C. Fogarty. Evolutionary Computing in 
Multi-Agent Environments: Speciation and Symbiogenesis. In H-M. Voigt, 
W.&nbsp;Ebeling, I.&nbsp;Rechenberg, and H.-P. Schwefel, editors,Parallel 
Problem Solving from Nature -- PPSN IV, pages 12-21. Springer-Verlag, 1996. 
<p> </p> </dd> 
<dt> [104] </dt> 
<dd> Larry Bull and O.&nbsp;Holland. Internal and External Representations: A 
Comparison in Evolving the Ability to Count. InProceedings of the First Annual 
Society for the Study of Artificial Intelligence and Simulated Behaviour 
Robotics Workshop, pages 11-14, 1994. 
<p> </p> </dd> 
<dt> [105] </dt> 
<dd> Larry Bull and Jacob Hurst. Self-Adaptive Mutation in ZCS Controllers. In 
Proceedings of the EvoNet Workshops - EvoRob 2000, pages 339-346. Springer, 
2000.
<p> </p> </dd> 
<dt> [106] </dt> 
<dd> Larry Bull and Jacob Hurst. ZCS redux. Evolutionary Computation, 
10(2):185-205, 2002.
<p> </p> </dd> 
<dt> [107] </dt> 
<dd> Larry Bull and Tim Kovacs, editors. Foundations of Learning Classifier 
Systems, volume 183 of Studies in Fuzziness and Soft Computing. Springer, 2005. 
<p> </p> </dd> 
<dt> [108] </dt> 
<dd> Larry Bull and Toby O'Hara. Accuracy-based neuro and neuro-fuzzy 
classifier systems. In W.&nbsp;B. Langdon, E.&nbsp;Cant&uacute;-Paz, 
K.&nbsp;Mathias, R.&nbsp;Roy, D.&nbsp;Davis, R.&nbsp;Poli, 
K.&nbsp;Balakrishnan, V.&nbsp;Honavar, G.&nbsp;Rudolph, J.&nbsp;Wegener, 
L.&nbsp;Bull, M.&nbsp;A. Potter, A.&nbsp;C. Schultz, J.&nbsp;F. Miller, 
E.&nbsp;Burke, and N.&nbsp;Jonoska, editors,GECCO 2002: Proceedings of the 
Genetic and Evolutionary Computation Conference, pages 905-911. Morgan Kaufmann 
Publishers, 9-13 July 2002.
<p> </p> </dd> 
<dt> [109] </dt> 
<dd> L.&nbsp;Bull and R.&nbsp;Preen. On dynamical genetic programming: Random 
boolean networks in learning classifier systems. InTo appear in Proceedings of 
the EvoNet Workshops: EuroGP. Springer, 2009. 
<p> </p> </dd> 
<dt> [110] </dt> 
<dd> Larry Bull and Matt Studley. Consideration of multiple objectives in 
neural learning classifier systems. In H.-P.&nbsp;Schwefel J.-J. Merelo 
Guerv&oacute;s, P. Adamidis, H.-G. Beyer, J.-L. 
Fern&aacute;ndez-Villaca&ntilde;as, editor,Parallel Problem Solving from Nature 
- PPSN VII, 7th International Conference, Granada, Spain, September 7-11, 2002. 
Proceedings, number 2439 in Lecture Notes in Computer Science, LNCS, page 549 
ff. Springer-Verlag, 2002.
<p> </p> </dd> 
<dt> [111] </dt> 
<dd> Larry Bull, Terence&nbsp;C. Fogarty, S.&nbsp;Mikami, and J.&nbsp;G. 
Thomas. Adaptive Gait Acquisition using Multi-agent Learning for Wall Climbing 
Robots. InAutomation and Robotics in Construction XII, pages 80-86, 1995. 
<p> </p> </dd> 
<dt> [112] </dt> 
<dd> Larry Bull, Terence&nbsp;C. Fogarty, and M.&nbsp;Snaith. Evolution in 
Multi-agent Systems: Evolving Communicating Classifier Systems for Gait in a 
Quadrupedal Robot. InEshelman [298], pages 382-388. 
<p> </p> </dd> 
<dt> [113] </dt> 
<dd> Larry Bull, Jacob Hurst, and Andy Tomlinson. Mutation in Classifier 
System Controllers. Inet&nbsp;al. [299], pages 460-467. 
<blockquote> The use and benefits of self-adaptive mutation operators are 
well-known within evolutionary computing. In this paper we examine the use of 
self-adaptive mutation in Michigan-style Classifier Systems with the aim of 
improving their performance as controllers for autonomous mobile robots. 
Initially, we implement the operator in the ZCS classifier and examine its 
performance in two ``animat'' environments. It is shown that, although no 
significant increase in performance is seen over results presented in the 
literature using a fixed rate of mutation, the operator adapts to approximately 
this rate regardless of the initial range. The same operator is then 
implemented in the more sophisticated XCS classifier, with its performance 
examined on another animat task. Again it is shown that no real improvements in 
performance are obtained over previous results with a fixed mutation rate, but 
that the operator adapts to a suitable rate.</blockquote> 
<p> </p> </dd> 
<dt> [114] </dt> 
<dd> Larry Bull, Pier&nbsp;Luca Lanzi, and Wolfgang&nbsp;Stolzmann (guest 
editors). Journal of soft computing, special issue on learning classifier 
systems, 6(3-4), 2002.
<p> </p> </dd> 
<dt> [115] </dt> 
<dd> Larry Bull, Dave Wyatt, and Ian Parmee. Towards the use of XCS in 
interactive evolutionary design. In W.&nbsp;B. Langdon, 
E.&nbsp;Cant&uacute;-Paz, K.&nbsp;Mathias, R.&nbsp;Roy, D.&nbsp;Davis, 
R.&nbsp;Poli, K.&nbsp;Balakrishnan, V.&nbsp;Honavar, G.&nbsp;Rudolph, 
J.&nbsp;Wegener, L.&nbsp;Bull, M.&nbsp;A. Potter, A.&nbsp;C. Schultz, 
J.&nbsp;F. Miller, E.&nbsp;Burke, and N.&nbsp;Jonoska, editors,GECCO 2002: 
Proceedings of the Genetic and Evolutionary Computation Conference, page 951. 
Morgan Kaufmann Publishers, 2002.
<p> </p> </dd> 
<dt> [116] </dt> 
<dd> L.&nbsp;Bull, P.L. Lanzi, and T.&nbsp;O'Hara. Anticipation mappings for 
learning classifier systems. InProceedings of the 2007 congress on evolutionary 
computation (CEC2007), pages 2133-214. IEEE, 2007. 
<p> </p> </dd> 
<dt> [117] </dt> 
<dd> L.&nbsp;Bull, M.&nbsp;Studley, T.&nbsp;Bagnall, and I.&nbsp;Whittley. On 
the use of rule-sharing in learning classifier system ensembles.IEEE Trans. 
Evolutionary Computation, 11:496-502, 2007. 
<p> </p> </dd> 
<dt> [118] </dt> 
<dd> Larry Bull. Artificial Symbiology: evolution in cooperative multi-agent 
environments. PhD thesis, University of the West of England, 1995. 
<blockquote> Nature is full of examples of both inter and intra species; from 
the workings of ant colonies to the cleaning symbiosis seen between the 
Pederson shrimp and the fish of the Bahamas. The fields of Artificial 
Intelligence and Artificial Life have consequently focused on these phenomenon 
as a means of dealing with complex systems in which agents must cooperate to 
achieve certain goals. In this thesis we examine the performance of the Genetic 
Algorithm when applied to systems of this type. That is, we examine the use of 
Evolutionary Computing techniques within cooperative multiagent environments. 
In the process we investigate some aspects of the natural phenomenon of 
symbiosis on which we base many elements of the work, in particular conditions 
under which various aspects of symbiotic associations occur. In extending the 
Genetic Algorithm to cooperative multiagent environments we introduce two 
macro-level operators (megamutations) to allow for greater integration between 
agents; the forming of hereditary endo-symbiosis and the horizontal transfer 
genes between such symbionts. Our results indicate that hereditary 
endo-symbiosis will form between agents evolving from within a window of the 
chaotic region of their attribute space and that gene transfer will occur from 
within a larger overlapping window. These operators are used within a generic 
rule-based framework, a simplified version of Pittsburgh-style Classifier 
Systems, which we alter to allow for direct systemic communication to evolve 
between the thus represented agents. We find that uninterpreted communication 
protocols will emerge between such agents using our framework. This work 
therefore contributes to the implementation of the Genetic Algorithm within 
complex systems.</blockquote> 
<p> </p> </dd> 
<dt> [119] </dt> 
<dd> Larry Bull. On ZCS in Multi-agent Environments. In A.&nbsp;E. Eiben, 
T.&nbsp;Baeck, M.&nbsp;Schoenauer, and H.-P. Schwefel, editors,Proceedings 
Parallel Problem Solving From Nature (PPSN-V), volume 1498 of Lecture Notes in 
Computer Science, pages 471-480. Springer-Verlag, 1998. 
<blockquote> This paper examines the performance of the ZCS Michigan-style 
classifier system in multi-agent environments. Using an abstract multi-agent 
model the effects of varying aspects of the performance, reinforcement and 
discovery components are examined. It is shown that small modifications to the 
basic ZCS architecture can improve its performance in environments with 
significant inter-agent dependence. Further, it is suggested that classifier 
systems have characteristics which make them more suitable to such 
non-stationary problem domains in comparison to other forms of reinforcement 
learning. Results from initial use of ZCS as an adaptive economic trading agent 
within an artificial double-auction market are then presented, with the 
findings from the abstract model shown to improve the efficiency of the traders 
and hence the overall market.</blockquote> 
<p> </p> </dd> 
<dt> [120] </dt> 
<dd> Larry Bull. On Evolving Social Systems. Computational and Mathematical 
Organization Theory, 5(3):281-298, 1999. 
<p> </p> </dd> 
<dt> [121] </dt> 
<dd> Larry Bull. On using ZCS in a Simulated Continuous Double-Auction Market. 
InBanzhaf et&nbsp;al. [32], pages 83-90. 
<blockquote> This paper presents results from on-going investigations into the 
performance of the Michigan-style classifier system in a complex multi-agent 
environment. Using a simplified model of a continuous double-auction market 
place the use of ZCS as an adaptive economic trading agent is examined. It is 
shown that a number of small changes to the basic system greatly improves its 
performance, resulting in improvements in the overall efficiency of the market. 
It is also shown that the role of the rule-discovery component of the 
classifier system is particularly critical in such a closely-coupled 
multi-agent environment.</blockquote> 
<p> </p> </dd> 
<dt> [122] </dt> 
<dd> Larry Bull. Simple markov models of the genetic algorithm in classifier 
systems: Accuracy-based fitness. InProceedings of the International Workshop on 
Learning Classifier Systems (IWLCS-2000), in the Joint Workshops of SAB 2000 
and PPSN 2000 [487]. Extended abstract. 
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [123] </dt> 
<dd> Larry Bull. Simple markov models of the genetic algorithm in classifier 
systems: Multi-step tasks. InProceedings of the International Workshop on 
Learning Classifier Systems (IWLCS-2000), in the Joint Workshops of SAB 2000 
and PPSN 2000 [487]. Extended abstract. 
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [124] </dt> 
<dd> Larry Bull. Lookahead And Latent Learning In ZCS. In W.&nbsp;B. Langdon, 
E.&nbsp;Cant&uacute;-Paz, K.&nbsp;Mathias, R.&nbsp;Roy, D.&nbsp;Davis, 
R.&nbsp;Poli, K.&nbsp;Balakrishnan, V.&nbsp;Honavar, G.&nbsp;Rudolph, 
J.&nbsp;Wegener, L.&nbsp;Bull, M.&nbsp;A. Potter, A.&nbsp;C. Schultz, 
J.&nbsp;F. Miller, E.&nbsp;Burke, and N.&nbsp;Jonoska, editors,GECCO 2002: 
Proceedings of the Genetic and Evolutionary Computation Conference, pages 
897-904, New York, 9-13 July 2002. Morgan Kaufmann Publishers.
<p> </p> </dd> 
<dt> [125] </dt> 
<dd> Larry Bull. On accuracy-based fitness. Journal of Soft Computing, 
6(3-4):154-161, 2002.
<p> </p> </dd> 
<dt> [126] </dt> 
<dd> Larry Bull, editor. Applications of Learning Classifier Systems. 
Springer, 2004.
<p> </p> </dd> 
<dt> [127] </dt> 
<dd> Larry Bull. A simple payoff-based learning classifier system. In 
Xin&nbsp;Yao et&nbsp;al., editor,Parallel Problem Solving from Nature - PPSN 
VIII, pages 1032-1041. Springer Verlag, 2004. 
<p> </p> </dd> 
<dt> [128] </dt> 
<dd> Larry Bull. Two Simple Learning Classifier Systems. In Larry Bull and Tim 
Kovacs, editors,Foundations of Learning Classifier Systems, number 183 in 
Studies in Fuzziness and Soft Computing, pages 63-90. Springer-Verlag, 2005.
<p> </p> </dd> 
<dt> [129] </dt> 
<dd> Larry Bull. On lookahead and latent learning in simple lcs. In Jaume 
Bacardit, Ester Bernad&oacute;-Mansilla, Martin Butz, Tim Kovacs, Xavier 
Llor&agrave;, and Keiki Takadama, editors,Learning Classifier Systems. 10th and 
11th International Workshops (2006-2007), volume 4998/2008 of Lecture Notes in 
Computer Science, pages 154-168. Springer, 2008. 
<blockquote> Learning Classifier Systems use evolutionary algorithms to 
facilitate rule- discovery, where rule fitness is traditionally payoff based 
and assigned under a sharing scheme. Most current research has shifted to the 
use of an accuracy-based scheme where fitness is based on a rule&rsquo;s 
ability to predict the expected payoff from its use. Learning Classifier 
Systems that build anticipations of the expected states following their actions 
are also a focus of current research. This paper presents a simple but 
effective learning classifier system of this last type, using payoff-based 
fitness, with the aim of enabling the exploration of their basic principles, 
i.e., in isolation from the many other mechanisms they usually contain. The 
system is described and modelled, before being implemented. Comparisons to an 
equivalent accuracy-based system show similar performance. The use of 
self-adaptive mutation in such systems in general is then considered.
</blockquote> 
<p> </p> </dd> 
<dt> [130] </dt> 
<dd> L.&nbsp;Bull. On dynamical genetic programming: Simple boolean networks 
in learning classifier systems.To appear in International Journal of Parallel, 
Emergent and Distributed Systems, 2009. 
<p> </p> </dd> 
<dt> [131] </dt> 
<dd> Martin&nbsp;V. Butz and David&nbsp;E. Goldberg. Bounding the population 
size in XCS to ensure reproductive opportunities. In E.&nbsp;Cant&uacute;-Paz, 
J.&nbsp;A. Foster, K.&nbsp;Deb, D.&nbsp;Davis, R.&nbsp;Roy, U.-M. O'Reilly, 
H.-G. Beyer, R.&nbsp;Standish, G.&nbsp;Kendall, S.&nbsp;Wilson, M.&nbsp;Harman, 
J.&nbsp;Wegener, D.&nbsp;Dasgupta, M.&nbsp;A. Potter, A.&nbsp;C. Schultz, 
K.&nbsp;Dowsland, N.&nbsp;Jonoska, and J.&nbsp;Miller, editors,Genetic and 
Evolutionary Computation -- GECCO-2003, volume 2724 of LNCS, pages 1844-1856. 
Springer-Verlag, 2003.
<p> </p> </dd> 
<dt> [132] </dt> 
<dd> Martin&nbsp;V. Butz and Martin Pelikan. Analyzing the evolutionary 
pressures in xcs. In Lee Spector, Erik&nbsp;D. Goodman, Annie Wu, W.B. Langdon, 
Hans-Michael Voigt, Mitsuo Gen, Sandip Sen, Marco Dorigo, Shahram Pezeshk, 
Max&nbsp;H. Garzon, and Edmund Burke, editors,Proceedings of the Genetic and 
Evolutionary Computation Conference (GECCO-2001), pages 935-942, San Francisco, 
California, USA, 7-11 July 2001. Morgan Kaufmann.
<p> </p> </dd> 
<dt> [133] </dt> 
<dd> M.V. Butz and M.&nbsp;Pelikan. Studying XCS/BOA learning in boolean 
functions: structure encoding and random boolean functions. In 
M.&nbsp;Cattolico et&nbsp;al., editor,Genetic and evolutionary computation 
conference, GECCO 2006, pages 1449-1456. ACM, 2006. 
<p> </p> </dd> 
<dt> [134] </dt> 
<dd> Martin Butz and Wolfgang Stolzmann. Action-Planning in Anticipatory 
Classifier Systems. In Wu [923], pages 242-249. 
<blockquote> Learning consists in the acquisition of knowledge. In 
Reinforcement Learning this is knowledge about how to reach a maximum of 
environmental reward. We are interested in the acquisition of knowledge that 
consists in having expectations of behavioral consequences. Behavioral 
consequences depend on the current situation, so it is necessary to learn in 
which situation S which behavior/reaction R leads to which behavioral 
consequences C. In other words, SRC units are learned. It was the psychologist 
Edward Tolman (1932) who firstly stated that animals learn SRC units. Seward 
(1949) proved that rats are able to learn in the absence of reward and 
confirmed Tolman's assumption. Learning in the absence of reinforcement is 
called `latent learning' and cannot be explained by usual reinforcement 
learning techniques. In the field of Learning Classifier Systems (LCS) latent 
learning is realized in Riolo's CFSC2 (Riolo, 1991) and Stolzmann's ACS 
(Stolzmann, 1997, 1998). Both authors prove the performance of their learning 
algorithms with a simulation of Seward's experiment. This experiment consists 
in a learning phase without any reward followed by a test phase where the rats 
have to use the knowledge they acquired during the learning phase to do 
action-planning. Action-planning and latent learning occur at different times. 
This paper focuses on the integration of action-planning and latent learning in 
ACS. Using an example about learning of the hand-eye co-ordination of a robot 
arm in conjunction with a camera it will be shown, that a combination of 
action-planning and latent learning in ACS induces a substantial reduction of 
the number of trials which are required to learn a complete model of a 
prototypically environment.</blockquote> 
<p> </p> </dd> 
<dt> [135] </dt> 
<dd> Martin&nbsp;V. Butz and Stewart&nbsp;W. Wilson. An Algorithmic 
Description of XCS. Technical Report 2000017, Illinois Genetic Algorithms 
Laboratory, 2000.
<blockquote> A concise description of the XCS classifier system's parameters, 
structures, and algorithms is presented as an aid to research. The algorithms 
are written in modularly structured pseudo code with accompanying explanations.
</blockquote> 
<p> </p> </dd> 
<dt> [136] </dt> 
<dd> Martin&nbsp;V. Butz and Stewart&nbsp;W. Wilson. An Algorithmic 
Description of XCS. InLanzi et&nbsp;al. [545], pages 253-272. 
<p> </p> </dd> 
<dt> [137] </dt> 
<dd> Martin&nbsp;V. Butz and Stewart&nbsp;W. Wilson. An algorithmic 
description of xcs.Journal of Soft Computing, 6(3-4):144-153, 2002. 
<p> </p> </dd> 
<dt> [138] </dt> 
<dd> Martin Butz, David&nbsp;E. Goldberg, and Wolfgang Stolzmann. New 
challenges for an ACS: Hard problems and possible solutions. Technical Report 
99019, University of Illinois at Urbana-Champaign, Urbana, IL, October 1999.
<blockquote> An Anticipatory Classifier System (ACS) is a learning mechanism 
based on learning classifier systems and the cognitive model of ``Anticipatory 
Behavioral Control''. By comparing perceived consequences with its own 
expectations (anticipations), an ACS is able to learn in multi-step 
environments. To date, the ACS has proven its abilities in various problems of 
that kind. It is able to learn latently (i.e. to learn without getting any 
reward) and it is able to distinguish between non-Markov states. Additionally, 
an ACS is capable of incrementally building a cognitive map that can be used to 
do action-planning. Although the ACS has proven to scale up in suitable 
environments, it depends on certain environmental properties. It believes 
itself to be the only agent that can change the perceptions received from an 
environment. Any environmental change is considered and believed to be caused 
by the executed actions. The ACS learns from the changes by using fixed 
mechanisms. This paper reveals the properties of an environment that the 
current ACS assumes to be given. By investigating the problems of the current 
ACS when violating these properties we believe that this investigation will 
immediately serve for a better understanding of the ACS and lead to many ideas 
to improve the current ACS. We will propose some ideas and discuss the 
important ones in more detail.</blockquote> 
<p> </p> </dd> 
<dt> [139] </dt> 
<dd> Martin Butz, David&nbsp;E. Goldberg, and Wolfgang Stolzmann. The 
anticipatory classifier system and genetic generalization. Technical Report 
2000032, Illinois Genetic Algorithms Laboratory, 2000.
<blockquote> The anticipatory classifier system (ACS) combines the learning 
classifier system framework with the learning theory of anticipatory behavioral 
control. The result is an evolutionary system that builds an environmental 
model and further applies reinforcement learning techniques to form an optimal 
behavioral policy in the model. After providing some background as well as 
outlining the objectives of the system, we explain in detail all involved 
current processes. Furthermore, we analyze the deficiency of 
over-specialization in the anticipatory learning process (ALP), the main 
learning mechanism in the ACS. Consequently, we introduce a genetic algorithm 
(GA) to the ACS that is meant for generalization of over-specialized 
classifiers. We show that it is possible to form a symbiosis between a directed 
specialization and a genetic generalization mechanism achieving a learning 
mechanism that evolves a complete, accurate, and compact description of a 
perceived environment. Results in three different environmental settings 
confirm the usefulness of the genetic algorithm in the ACS. Finally, we discuss 
future research directions with the ACS and anticipatory systems in general.
</blockquote> 
<p> </p> </dd> 
<dt> [140] </dt> 
<dd> Martin&nbsp;V. Butz, David&nbsp;E. Goldberg, and Wolfgang Stolzmann. 
Introducing a Genetic Generalization Pressure to the Anticipatory Classifier 
System -- Part 1: Theoretical Approach. InWhitely et&nbsp;al. [878], pages 
34-41. Also Technical Report 2000005 of the Illinois Genetic Algorithms 
Laboratory.
<blockquote> The Anticipatory Classifier System (ACS) is a learning classifier 
system that is based on the cognitive mechanism of anticipatory behavioral 
control. Besides the common reward learning, the ACS is able to learn latently 
(i.e. to learn in an environment without getting any reward) which is not 
possible with reinforcement learning techniques. Furthermore, it forms a 
complete internal representation of the environment and thus it is able to use 
cognitive processes such as reasoning and planning. Latest research observed 
that the ACS is not generating accurate, maximally general rules reliably (i.e. 
rules which are accurate and also as general as possible), but it is sometimes 
generating over-specialized rules. This paper shows how a genetic algorithm can 
be used to overcome this present pressure of over-specification in the ACS 
mechanism with a genetic generalization pressure. The ACS works then as a 
hybrid which learns latently, forms a cognitive map, and evolves accurate, 
maximally general rules.</blockquote> 
<p> </p> </dd> 
<dt> [141] </dt> 
<dd> Martin&nbsp;V. Butz, David&nbsp;E. Goldberg, and Wolfgang Stolzmann. 
Introducing a Genetic Generalization Pressure to the Anticipatory Classifier 
System -- Part 2: Performance Analysis. InWhitely et&nbsp;al. [878], pages 
42-49. Also Technical Report 2000006 of the Illinois Genetic Algorithms 
Laboratory.
<blockquote> The Anticipatory Classifier System (ACS) is able to form a 
complete internal representation of an environment. Unlike most other 
classifier system and reinforcement learning approaches, it is able to learn 
latently (i.e. to learn in an environment without getting any reward) and to 
form an internal model of the perceived environment. After the observation that 
the model is not necessarily maximally general a genetic generalization 
pressure was introduced to the ACS. This paper focuses on the different 
mechanisms in the anticipatory learning process, which resembles the 
specification pressure, and in the genetic algorithm, which realizes the 
genetic generalization pressure. The capability of generating maximally general 
rules and evolving a completely converged population is investigated in detail. 
Furthermore, the paper approaches a first comparison with the XCS classifier 
system in different mazes and the multiplexer problem.</blockquote> 
<p> </p> </dd> 
<dt> [142] </dt> 
<dd> Martin&nbsp;V. Butz, David&nbsp;E. Goldberg, and Wolfgang Stolzmann. 
Investigating Generalization in the Anticipatory Classifier System. In
Proceedings of Parallel Problem Solving from Nature (PPSN VI), 2000. Also 
technical report 2000014 of the Illinois Genetic Algorithms Laboratory.
<blockquote> Recently, a genetic algorithm (GA) was introduced to the 
Anticipatory Classifier System (ACS) which surmounted the occasional problem of 
over-specification of rules. This paper investigates the resulting 
generalization capabilities further by monitoring in detail the performance of 
the ACS in the highly challenging multiplexer task. Moreover, by comparing the 
ACS to the XCS in this task it is shown that the ACS generates accurate, 
maximally general rules and its population converges to those rules. Besides 
the observed ability of latent learning and the formation of an internal 
environmental representation, this ability of generalization adds a new 
advantage to the ACS in comparison with similar approaches.</blockquote> 
<p> </p> </dd> 
<dt> [143] </dt> 
<dd> Martin&nbsp;V. Butz, David&nbsp;E. Goldberg, and Wolfgang Stolzmann. 
Probability-enhanced predictions in the anticipatory classifier system. In
Proceedings of the International Workshop on Learning Classifier Systems 
(IWLCS-2000), in the Joint Workshops of SAB 2000 and PPSN 2000 [487]. Extended 
abstract.
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [144] </dt> 
<dd> Martin&nbsp;V. Butz, Tim Kovacs, Pier&nbsp;Luca Lanzi, and 
Stewart&nbsp;W. Wilson. How XCS Evolves Accurate Classifiers. In Lee Spector, 
Erik&nbsp;D. Goodman, Annie Wu, W.&nbsp;B. Langdon, Hans-Michael Voigt, Mitsuo 
Gen, Sandip Sen, Marco Dorigo, Shahram Pezeshk, Max&nbsp;H Garzon, and Edmund 
Burke, editors,GECCO-2001: Proceedings of the Genetic and Evolutionary 
Computation Conference, pages 927-934. Morgan Kaufmann, 2001. 
<p> </p> </dd> 
<dt> [145] </dt> 
<dd> Martin&nbsp;V. Butz, Kumara Sastry, and David&nbsp;E. Goldberg. 
Tournament selection: Stable fitness pressure in XCS. In 
E.&nbsp;Cant&uacute;-Paz, J.&nbsp;A. Foster, K.&nbsp;Deb, D.&nbsp;Davis, 
R.&nbsp;Roy, U.-M. O'Reilly, H.-G. Beyer, R.&nbsp;Standish, G.&nbsp;Kendall, 
S.&nbsp;Wilson, M.&nbsp;Harman, J.&nbsp;Wegener, D.&nbsp;Dasgupta, M.&nbsp;A. 
Potter, A.&nbsp;C. Schultz, K.&nbsp;Dowsland, N.&nbsp;Jonoska, and 
J.&nbsp;Miller, editors,Genetic and Evolutionary Computation -- GECCO-2003, 
volume 2724 ofLNCS, pages 1857-1869. Springer-Verlag, 2003. 
<p> </p> </dd> 
<dt> [146] </dt> 
<dd> Martin Butz, Tim Kovacs, Pier&nbsp;Luca Lanzi, and Stewart&nbsp;W. 
Wilson. Toward a theory of generalization and learning in xcs.IEEE Transactions 
on Evolutionary Computation, 8(1):8-46, 2004. 
<blockquote> Takes initial steps toward a theory of generalization and 
learning in the learning classifier system XCS. We start from Wilson's 
generalization hypothesis, which states that XCS has an intrinsic tendency to 
evolve accurate, maximally general classifiers. We analyze the different 
evolutionary pressures in XCS and derive a simple equation that supports the 
hypothesis theoretically. The equation is tested with a number of experiments 
that confirm the model of generalization pressure that we provide. Then, we 
focus on the conditions, termed &quot;challenges,&quot; that must be satisfied 
for the existence of effective fitness or accuracy pressure in XCS. We derive 
two equations that suggest how to set the population size and the covering 
probability so as to ensure the development of fitness pressure. We argue that 
when the challenges are met, XCS is able to evolve problem solutions reliably. 
When the challenges are not met, a problem may provide intrinsic fitness 
guidance or the reward may be biased in such a way that the problem will still 
be solved. The equations and the influence of intrinsic fitness guidance and 
biased reward are tested on large Boolean multiplexer problems. The paper is a 
contribution to understanding how XCS functions and lays the foundation for 
research on XCS's learning complexity.</blockquote> 
<p> </p> </dd> 
<dt> [147] </dt> 
<dd> M.V. Butz, D.E. Goldberg, and P.L. Lanzi. Bounding learning time in XCS. 
InGenetic and evolutionary computation (GECCO 2004), volume 3103/2004 of LNCS, 
pages 739-750. Springer, 2004.
<blockquote> It has been shown empirically that the XCS classifier system 
solves typical classification problems in a machine learning competitive way. 
However, until now, no learning time estimate has been derived analytically for 
the system. This paper introduces a time estimate that bounds the learning time 
of XCS until maximally accurate classifiers are found. We assume a domino 
convergence model in which each attribute is successively specialized to the 
correct value. It is shown that learning time in XCS scales polynomially in 
problem length and problem complexity and thus in a machine learning 
competitive way.</blockquote> 
<p> </p> </dd> 
<dt> [148] </dt> 
<dd> M.V. Butz, D.E. Goldberg, and P.L. Lanzi. Computational complexity of the 
XCS classifier system. In Larry Bull and Tim Kovacs, editors,Foundations of 
Learning Classifier Systems, number 183 in Studies in Fuzziness and Soft 
Computing, pages 91-126. Springer-Verlag, 2005.
<p> </p> </dd> 
<dt> [149] </dt> 
<dd> M.V. Butz, D.E. Goldberg, and P.L. Lanzi. Gradient descent methods in 
learning classifier systems: improving XCS performance in multistep problems.
IEEE Trans. Evolutionary Computation, 9(5):452-473, 2005. 
<p> </p> </dd> 
<dt> [150] </dt> 
<dd> M.V. Butz, M.&nbsp;Pelikan, X.&nbsp;Llor&agrave;, and D.E. Goldberg. 
Extracted global structure makes local building block processing effective in 
XCS. In H.G. Beyer and U.M. O'Reilly, editors,Genetic and evolutionary 
computation conference, GECCO 2005, pages 655-662. ACM, 2005. 
<p> </p> </dd> 
<dt> [151] </dt> 
<dd> M.V. Butz, P.L. Lanzi, and S.W. Wilson. Hyper-ellipsoidal conditions in 
xcs: rotation, linear approximation, and solution structure. In 
M.&nbsp;Cattolico, editor,Proc. genetic and evolutionary computation conference 
(GECCO 2006), pages 1457-1464. ACM, 2006. 
<p> </p> </dd> 
<dt> [152] </dt> 
<dd> M.V. Butz, M.&nbsp;Pelikan, X.&nbsp;Llor&agrave;, and D.E. Goldberg. 
Automated global structure extraction for effective local building block 
processing in XCS.Evolutionary Computation, 14(3):345-380, 2006. 
<p> </p> </dd> 
<dt> [153] </dt> 
<dd> Martin&nbsp;V. Butz, David&nbsp;E. Goldberg, and Pier&nbsp;Luca Lanzi. 
Effect of pure error-based fitness in xcs. In Tim Kovacs, Xavier LL&ograve;ra, 
Keiki Takadama, Pier&nbsp;Luca Lanzi, Wolfgang Stolzmann, and Stewart&nbsp;W. 
Wilson, editors,Learning Classifier Systems. International Workshops, IWLCS 
2003-2005, Revised Selected Papers, volume 4399 of LNCS, pages 104-114. 
Springer, 2007.
<p> </p> </dd> 
<dt> [154] </dt> 
<dd> M.V. Butz, D.E. Goldberg, P.L. Lanzi, and K.&nbsp;Sastry. Problem 
solution sustenance in XCS: Markov chain analysis of niche support 
distributions and the impact on computational complexity.Genetic Programming 
and Evolvable Machines, 8(1):5-37, 2007. 
<p> </p> </dd> 
<dt> [155] </dt> 
<dd> Martin&nbsp;V. Butz, Pier&nbsp;Luca Lanzi, Xavier Llor&aacute;, and 
Daniele Loiacono. An Analysis of Matching in Learning Classifier Systems. In
Proceedings of the 10th annual conference on Genetic and evolutionary 
computation, pages 1349-1356. ACM, 2008. 
<blockquote> We investigate rule matching in learning classifier systems for 
problems involving binary and real inputs. We consider three rule encodings: 
the widely used character-based encoding, a specificity-based encoding, and a 
binary encoding used in Alecsys. We compare the performance of the three 
algorithms both on matching alone and on typical test problems. The results on 
matching alone show that the population generality influences the performance 
of the matching algorithms based on string representations in different ways. 
Character-based encoding becomes slower and slower as generality increases, 
specificity-based encoding becomes faster and faster as generality increases. 
The results on typical test problems show that the specificity-based 
representation can halve the time required for matching but also that binary 
encoding is about ten times faster on the most difficult problems. Moreover, we 
extend specificity-based encoding to real-inputs and propose an algorithm that 
can halve the time require for matching real inputs using an interval-based 
representation.</blockquote> 
<p> </p> </dd> 
<dt> [156] </dt> 
<dd> M.V. Butz, P.L. Lanzi, and S.W. Wilson. Function approximation with xcs: 
Hyperellipsoidal conditions, recursive least squares, and compaction.IEEE 
Trans. Evolutionary Computation, 12(3):355-376, 2008. 
<p> </p> </dd> 
<dt> [157] </dt> 
<dd> M.V. Butz, P.&nbsp;Stalph, and P.L. Lanzi. Self-adaptive mutation in 
xcsf. InGECCO '08: Proceedings of the 10th annual conference on Genetic and 
evolutionary computation, pages 1365-1372. ACM, 2008. 
<blockquote> Recent advances in XCS technology have shown that self-adaptive 
mutation can be highly useful to speed-up the evolutionary progress in XCS. 
Moreover, recent publications have shown that XCS can also be successfully 
applied to challenging real-valued domains including datamining, function 
approximation, and clustering. In this paper, we combine these two advances and 
investigate self-adaptive mutation in the XCS system for function approximation 
with hyperellipsoidal condition structures, referred to as XCSF in this paper. 
It has been shown that XCSF solves function approximation problems with an 
accuracy, noise robustness, and generalization capability comparable to other 
statistical machine learning techniques and that XCSF outperforms simple 
clustering techniques to which linear approximations are added. This paper 
shows that the right type of self-adaptive mutation can further improve XCSF's 
performance solving problems more parameter independent and more reliably. We 
analyze various types of self-adaptive mutation and show that XCSF with 
self-adaptive mutation ranges,differentiated for the separate classifier 
condition values, yields most robust performance results. Future work may 
further investigate the properties of the self-adaptive values and may 
integrate advanced self-adaptation techniques.</blockquote> 
<p> </p> </dd> 
<dt> [158] </dt> 
<dd> Martin&nbsp;V. Butz. An Implementation of the XCS classifier system in C. 
Technical Report 99021, The Illinois Genetic Algorithms Laboratory, 1999.
<blockquote> The XCS classifier system was developed by Wilson (1995). The 
learning mechanism is based on the accuracy of its reward prediction. This 
method leads to the formation of accurate most general classifiers. This paper 
explains how to download, compile and use the XCS code version 1.0 written in 
ANSI C. It discusses how to select various parameter settings, how to add and 
remove certain procedures in the XCS, how to apply the XCS in the multiplexer 
environment and diverse woods environments, and how to add code to apply the 
XCS in other environments. The code provides the mechanisms introduced by 
Wilson (1995) and the enhancements published by Wilson (1998).</blockquote> 
<p> </p> </dd> 
<dt> [159] </dt> 
<dd> Martin&nbsp;V. Butz. XCSJava 1.0: An Implementation of the XCS classifier 
system in Java . Technical Report 2000027, Illinois Genetic Algorithms 
Laboratory, 2000.
<blockquote> The XCSJava 1.0 implementation of the XCS classifier system in 
Java is freely available from the IlliGAL anonymous ftp-site. The 
implementation covers the basic features of the XCS classifier system and 
provides a multiplexer and maze environment for testing purposes. This paper 
explains how to download, compile, and run the code. Moreover, it explains the 
object oriented approach in the implementation and the possible parameter 
manipulation as well as the environmental interface to hook in other test 
environments. Additionally to the source code, an executable package of the 
version as well as an XCSJava 1.0 API documentation is provided.</blockquote> 
<p> </p> </dd> 
<dt> [160] </dt> 
<dd> Martin&nbsp;V. Butz. An Algorithmic Description of ACS2. In Lanzi 
et&nbsp;al. [546], pages 211-229. 
<p> </p> </dd> 
<dt> [161] </dt> 
<dd> Martin&nbsp;V. Butz. Anticipatory learning classifier systems. Kluwer 
Academic Publishers, 2002.
<p> </p> </dd> 
<dt> [162] </dt> 
<dd> Martin&nbsp;V. Butz. Biasing Exploration in an Anticipatory Learning 
Classifier System. InLanzi et&nbsp;al. [546], pages 3-22. 
<p> </p> </dd> 
<dt> [163] </dt> 
<dd> M.V. Butz. Kernel-based, ellipsoidal conditions in the real-valued xcs 
classifier system. In H.G.&nbsp;Beyer et&nbsp;al., editor,Proc. genetic and 
evolutionary computation conference (GECCO 2005), pages 1835-1842. ACM, 2005. 
<p> </p> </dd> 
<dt> [164] </dt> 
<dd> M.V. Butz. Rule-Based Evolutionary Online Learning Systems: A Principled 
Approach to LCS Analysis and Design. Studies in Fuzziness and Soft Computing. 
Springer-Verlag, 2006.
<blockquote> This book offers a comprehensive introduction to learning 
classifier systems (LCS) &acirc;&#128;&#147; or more generally, rule-based 
evolutionary online learning systems. LCSs learn interactively 
&acirc;&#128;&#147; much like a neural network &acirc;&#128;&#147; but with an 
increased adaptivity and flexibility. This book provides the necessary 
background knowledge on problem types, genetic algorithms, and reinforcement 
learning as well as a principled, modular analysis approach to understand, 
analyze, and design LCSs. The analysis is exemplarily carried through on the 
XCS classifier system &acirc;&#128;&#147; the currently most prominent system 
in LCS research. Several enhancements are introduced to XCS and evaluated. An 
application suite is provided including classification, reinforcement learning 
and data-mining problems. Reconsidering John Holland&rsquo;s original vision, 
the book finally discusses the current potentials of LCSs for successful 
applications in cognitive science and related areas.</blockquote> 
<p> </p> </dd> 
<dt> [165] </dt> 
<dd> Alessio Camilli and Roberto&nbsp;Di Meglio. Sistemi a classificatori su 
architetture a parallelismo massiccio. Technical report, Univ. Delgi Studi di 
Pisa, 1989.
<p> </p> </dd> 
<dt> [166] </dt> 
<dd> Alessio Camilli, Roberto&nbsp;Di Meglio, F.&nbsp;Baiardi, 
M.&nbsp;Vanneschi, D.&nbsp;Montanari, and R.&nbsp;Serra. Classifier System 
Parallelization on MIMD Architectures. Technical Report 3/17, CNR, 1990.
<p> </p> </dd> 
<dt> [167] </dt> 
<dd> Alessio Camilli. Classifier systems in massively parallel architectures. 
Master's thesis, University of Pisa, 1990. (In Italian).
<p> </p> </dd> 
<dt> [168] </dt> 
<dd> Y.&nbsp;J. Cao, N.&nbsp;Ireson, Larry Bull, and R.&nbsp;Miles. Design of 
a Traffic Junction Controller using a Classifier System and Fuzzy Logic. In 
Bernd Reusch, editor,Proceedings of the Sixth International Conference on 
Computational Intelligence, Theory and Applications (6th Fuzzy Days), volume 
1625 ofLNCS, pages 342-353. Springer-Verlag, 1999. 
<p> </p> </dd> 
<dt> [169] </dt> 
<dd> Y.&nbsp;J. Cao, N.&nbsp;Ireson, L.&nbsp;Bull, and R.&nbsp;Miles. 
Distributed Learning Control of Traffic Signals. InProceedings of the EvoNet 
Workshops - EvoSCONDI 2000, pages 117-126. Springer, 2000. 
<p> </p> </dd> 
<dt> [170] </dt> 
<dd> Y.&nbsp;J. Cao, N.&nbsp;Ireson, L.&nbsp;Bull, and R.&nbsp;Miles. An 
evolutionary intelligent agents approach to traffic signal control.
International Journal of Knowledge-based Intelligent Engineering Systems, 
5(4):279-289, 2001.
<p> </p> </dd> 
<dt> [171] </dt> 
<dd> A.&nbsp;Carbonaro, G.&nbsp;Casadei, and A.&nbsp;Palareti. Genetic 
Algorithms and Classifier Systems in Simulating a Cooperative Behavior. In
Albrecht et&nbsp;al. [7], pages 479-483. 
<blockquote> Genetic Algorithms and Classifier Systems are often used in 
biologic-like and evolutionary behaviors' simulations. The basic example is 
Wood7 Wilson's world. In this environment it is interesting to study some 
problems: Can evolve the cooperative behaviors of organisms present in the 
world? How and when do the behaviors evolve? Some preliminary results show the 
conditions under that cooperative behavior rules are developing rapidly. 
Particularly we have pointed out the likely of following observations: a. The 
cooperative behavior develops more easily if the initial population starts from 
the same point. b. It exists some thresholds under that the cooperative 
behavior can't evolve; these thresholds depend to the population size.
</blockquote> 
<p> </p> </dd> 
<dt> [172] </dt> 
<dd> Brian Carse and Terence&nbsp;C. Fogarty. A delayed-action classifier 
system for learning in temporal environments. InProceedings of the 1st IEEE 
Conference on Evolutionary Computation, volume&nbsp;2, pages 670-673, 1994. 
<p> </p> </dd> 
<dt> [173] </dt> 
<dd> Brian Carse and Terence&nbsp;C. Fogarty. A Fuzzy Classifier System Using 
the Pittsburgh Approach. InDavidor and Schwefel [228], pages 260-269. 
<blockquote> This paper describes a fuzzy classifier system using the 
Pittsburgh model. In this model genetic operations and fitness assignment apply 
to complete rule-sets, rather than to individual rules, thus overcoming the 
problem of conflicting individual and collective interests of classifiers. The 
fuzzy classifier system presented here dynamically adjusts both membership 
functions and fuzzy relations. A modified crossover operator for particular use 
in Pittsburgh-syle fuzzy classifier systems, with variable length rule-sets, is 
introduced and evaluated. Experimental results of the new system, which appear 
encouraging, are presented and discussed.</blockquote> 
<p> </p> </dd> 
<dt> [174] </dt> 
<dd> Brian Carse and A.&nbsp;G. Pipe. A Framework For Evolving Fuzzy 
Classifier Systems Using Genetic Programming. In14th Int. Conf. of Florida 
Artificial Intelligence Research Society FLAIRS-2001, pages 465-469. AAAI 
Press, 2001.
<p> </p> </dd> 
<dt> [175] </dt> 
<dd> Brian Carse and A.&nbsp;G. Pipe. X-FCS: a fuzzy classifier systems using 
accuracy based fitness -- first results. InProcs. Int. Conf. In Fuzzy Logic and 
Technology, EUSFLAT, pages 195-198, 2001. 
<p> </p> </dd> 
<dt> [176] </dt> 
<dd> Brian Carse, Terence&nbsp;C. Fogarty, and A.&nbsp;Munro. Distributed 
Adaptive Routing Control in Communications Networks using a Temporal Fuzzy 
Classifier System. InProceedings of the Fifth IEEE Conference on Fuzzy Systems, 
pages 2203-2207. IEEE, 1996.
<p> </p> </dd> 
<dt> [177] </dt> 
<dd> Brian Carse, Terence&nbsp;C. Fogarty, and A.&nbsp;Munro. Evolutionary 
Learning of Controllers using Temporal Fuzzy Classifier Systems. In I.&nbsp;C. 
Parmee, editor,Proceedings of the Second Conference on Adaptive Computing in 
Engineering Design and Control, pages 174-180, 1996. 
<p> </p> </dd> 
<dt> [178] </dt> 
<dd> Brian Carse, Terence&nbsp;C. Fogarty, and A.&nbsp;Munro. Evolving fuzzy 
rule based controllers using genetic algorithms.International Journal for Fuzzy 
Sets and Systems, 80:273-293, 1996. 
<p> </p> </dd> 
<dt> [179] </dt> 
<dd> Brian Carse, Terence&nbsp;C. Fogarty, and A.&nbsp;Munro. The Temporal 
Fuzzy Classifier System and its Application to Distributed Control in a 
Homogeneous Multi-Agent ecology. InGoodman et&nbsp;al. [379], pages 76-86. 
<blockquote> A fuzzy classifier system is described which explicitly 
represents time in the classifier syntax by augmenting individual classifiers 
with temporal tags. This feature allows the learning algorithm - in this case 
the genetic algorithm - to explore and exploit temporal features of the 
environment in which the classifier system might be expected to operate. The 
proposed temporal fuzzy classifier system is applied to a multi-agent 
distributed control task - adaptive distributed rooting in packet-switched 
communications networks.</blockquote> 
<p> </p> </dd> 
<dt> [180] </dt> 
<dd> Brian Carse, Terence&nbsp;C. Fogarty, and Alistair Munro. Evolving 
Temporal Fuzzy Rule-Bases for Distributed Routing Control in Telecommunication 
Networks. InHerrera and Verdegay [423], pages 467-488. 
<blockquote> Distributed routing control in telecommunication networks is a 
challenging problem. A networked assembly of geographically dispersed routing 
controllers are required to route traffic across the network in such a way so 
as to avoid congestion. Measured state information for each controller is 
delayed and necessarily available only on occasion. Interactions between 
routing controllers are highly non-linear and instability is a serious problem. 
A hybrid technique for distributing routing is proposed based on a synthesis of 
shortest-path routing, machine learning and fuzzy control. An architecture is 
described for a novel temporal fuzzy classifier system which forms the basis 
for each routing controller. Experimental results are presented which compare 
the new technique with two extant routing methods -- non-adaptive shortest-hop 
routing and adaptive shortest-path routing.</blockquote> 
<p> </p> </dd> 
<dt> [181] </dt> 
<dd> Brian Carse, Terence&nbsp;C. Fogarty, and Alistair Munro. Artificial 
evolution of fuzzy rule bases which represent time: A temporal fuzzy classifier 
system.International Journal of Intelligent Systems, 13(issue 10-11):905-927, 
1998.
<p> </p> </dd> 
<dt> [182] </dt> 
<dd> Brian Carse. Learning Anticipatory Behaviour Using a Delayed Action 
Classifier System. InFogarty [324], pages 210-223. 
<blockquote> To manifest anticipatory behaviour that goes beyond simple 
stimulus-response, classifier systems must evolve internal reasoning processes 
based on couplings via internal messages. A major challenge that has been 
encountered in engendering internal reasoning processes in classifier systems 
has been the discovery and maintenance of long classifier chains. This paper 
proposes a modified version of the traditional classifier system, called the 
delayed action classifier system (DACS), devised specifically for learning of 
anticipatory or predictive behaviour. DACS operates by delaying the action 
(i.e. posting of messages) of appropriately tagged, matched classifiers by a 
number of execution cycles which is encoded on the classifier. Since classifier 
delays are encoded on the classifier genome, a GA is able to explore 
simultaneously the spaces of actions and delays. Results of experiments 
comparing DACS to a traditional classifier system in terms of the dynamics of 
classifier reinforcement and system performance using the bucket brigade are 
presented and examined. Experiments comparing DACS with a traditional 
classifier system, which appear encouraging, for a simple prediction problem 
are described and considered. Areas for further work using the delayed-action 
classifier notion are suggested and briefly discussed.</blockquote> 
<p> </p> </dd> 
<dt> [183] </dt> 
<dd> G.&nbsp;Casadei, A.&nbsp;Palareti, and G.&nbsp;Proli. Classifier System 
in Traffic Management. InAlbrecht et&nbsp;al. [7], pages 620-627. 
<blockquote> The systems of controlling and improving traffic movement have 
been studied for several years now. The usefulness of these systems is that 
they can modify and change the lights signals of traffic lights. It is not 
enough to intervene when the situation has reached a critical point such as a 
traffic jam. The system has to work out how the traffic will flow. The ideal 
solution would be a system that works out and foresees the situation on the 
roads based on a model of motorists' behaviour. This research shows how to best 
utilise the classifier systems so that it would be possible to create a model 
that is similar to that of the real world.</blockquote> 
<p> </p> </dd> 
<dt> [184] </dt> 
<dd> J.&nbsp;Casillas, B.&nbsp;Carse, and L.&nbsp;Bull. Fuzzy-XCS: a michigan 
genetic fuzzy system.IEEE Trans. Fuzzy Systems, 15:536-550, 2007. 
<p> </p> </dd> 
<dt> [185] </dt> 
<dd> Proceedings of the 2000 Congress on Evolutionary Computation (CEC00). 
IEEE Press, 2000.
<p> </p> </dd> 
<dt> [186] </dt> 
<dd> Proceedings of the 2001 Congress on Evolutionary Computation (CEC01). 
IEEE Press, 2001.
<p> </p> </dd> 
<dt> [187] </dt> 
<dd> Keith&nbsp;W. Chalk and George&nbsp;D. Smith. The Co-evolution of 
Classifier Systems in a Competitive Environment. Poster presented at AISB94. 
Authors were from the University of East Anglia, U.K.
<p> </p> </dd> 
<dt> [188] </dt> 
<dd> Keith Chalk and George&nbsp;D. Smith. Multi-Agent Classifier Systems and 
the Iterated Prisoner's Dilemma. InSmith et&nbsp;al. [770], pages 615-618. 
<blockquote> This paper describes experiments using multiple classifier system 
(CS) agents to play the iterated prisoner's dilemma (IPD) under various 
conditions. Our main interest is in how, and under what circumstances, 
cooperation is most likely to emerge through competition between these agents. 
Experiments are conducted with agents playing fixed strategies and other agents 
individually and in tournaments, with differing CS parameters. Performance 
improves when reward is stored and averaged over longer periods, and when a 
genetic algorithm (GA) is used more frequently. Increasing the memory of the 
system improves performance to a point, but long memories proved difficult to 
reinforce fully and performed less well.</blockquote> 
<p> </p> </dd> 
<dt> [189] </dt> 
<dd> Sin&nbsp;Man Cheang, Kin&nbsp;Hong Lee, and Kwong&nbsp;Sak Leung. Data 
classification using genetic parallel programming. In E.&nbsp;Cant&uacute;-Paz, 
J.&nbsp;A. Foster, K.&nbsp;Deb, D.&nbsp;Davis, R.&nbsp;Roy, U.-M. O'Reilly, 
H.-G. Beyer, R.&nbsp;Standish, G.&nbsp;Kendall, S.&nbsp;Wilson, M.&nbsp;Harman, 
J.&nbsp;Wegener, D.&nbsp;Dasgupta, M.&nbsp;A. Potter, A.&nbsp;C. Schultz, 
K.&nbsp;Dowsland, N.&nbsp;Jonoska, and J.&nbsp;Miller, editors,Genetic and 
Evolutionary Computation -- GECCO-2003, volume 2724 of LNCS, pages 1918-1919. 
Springer-Verlag, 2003.
<blockquote> A novel Linear Genetic Programming (LGP) paradigm called Genetic 
Parallel Programming (GPP) has been proposed to evolve parallel programs based 
on a Multi-ALU Processor. It is found that GPP can evolve parallel programs for 
Data Classification problems. In this paper, five binary-class UCI Machine 
Learning Repository databases are used to test the effectiveness of the 
proposed GPP-classifier. The main advantages of employing GPP for data 
classification are: 1) speeding up evolutionary process by parallel hardware 
fitness evaluation; and 2) discovering parallel algorithms automatically. 
Experimental results show that the GPP-classifier evolves simple classification 
programs with good generalization performance. The accuracies of these evolved 
classifiers are comparable to other existing classification algorithms.
</blockquote> 
<p> </p> </dd> 
<dt> [190] </dt> 
<dd> A.&nbsp;P. Chen and Y.&nbsp;H. Chang. Using extended classifier system to 
forecast S&amp;P futures based on contrary sentiment indicators.Evolutionary 
Computation, 3:2084-2090, 2005. 
<p> </p> </dd> 
<dt> [191] </dt> 
<dd> Hung-Ming Chen and Shinn-Ying Ho. Designing an optimal evolutionary fuzzy 
decision tree for data mining. In Lee Spector, Erik&nbsp;D. Goodman, Annie Wu, 
W.B. Langdon, Hans-Michael Voigt, Mitsuo Gen, Sandip Sen, Marco Dorigo, Shahram 
Pezeshk, Max&nbsp;H. Garzon, and Edmund Burke, editors,Proceedings of the 
Genetic and Evolutionary Computation Conference (GECCO-2001), pages 943-950, 
San Francisco, California, USA, 7-11 July 2001. Morgan Kaufmann.
<p> </p> </dd> 
<dt> [192] </dt> 
<dd> C.C. Chen and C.C. Wong. Self-generating rule-mapping fuzzy controller 
design using a genetic algorithm.IEE Proc. Control Theory Appl., 
149(2):143-148, 2002.
<p> </p> </dd> 
<dt> [193] </dt> 
<dd> An&nbsp;Pin Chen, Yi-Chang Chen, and Wen-Chuan Tseng. Applying Extending 
Classifier System to Develop an Option-Operation Suggestion Model of Intraday 
Trading -- An Example of Taiwan Index Option. InKnowledge-Based Intelligent 
Information and Engineering Systems, 9th International Conference (KES 2005), 
volume 3681 ofLecture Notes in Computer Science, pages 27-33. Springer, 2005. 
<p> </p> </dd> 
<dt> [194] </dt> 
<dd> Tung&nbsp;Wan Cheng, Wen&nbsp;Chih Tsai, and An&nbsp;Pin Chen. Strategy 
of futures trading mechanism using extended classifier system. InIntelligent 
Systems, 2004. Proceedings. 2004 2nd International IEEE Conference, 
volume&nbsp;2, pages 503-507, 2004.
<blockquote> Nowadays, many artificial intelligent trading models divided the 
process in three separate subprocesses: trading, validation and application, 
but these models cannot meet the request of today's trading environment. A new 
online learning algorithm, extended classifier system (XCS) is used in futures 
extended classifier trading mechanism (FXCTM) to satisfy traders' requirement. 
This paper verifies that FXCTM provides a very good forecast ability in future 
market trading performance. Also, this paper discusses about how the population 
set of XCS affects the result of the model. Finally, the simulation results 
show that this model could get an obvious profit from futures market.
</blockquote> 
<p> </p> </dd> 
<dt> [195] </dt> 
<dd> Pawel Cichosz and Jan&nbsp;J. Mulawka. GBQL: A novel genetics-based 
reinforcement learning architecture. InProceedings of the Third European 
Congress on Intelligent Techniques and Soft Computing (EUFIT'95), 1995. 
<blockquote> This research attempts to integrate the existing ideas in two 
fields: reinforcement learning algorithms based on the methods of temporal 
differences (TD), in particular Q-learning, and genetics-based machine 
learning, in particular classifier systems (CS). Close relations between the 
bucket brigade credit assignment algorithm used in classifier systems and TD 
methods, several widely realized drawbacks of CS, and good theoretical 
properties of TD, gave the initial motivation for developing a learning 
architecture that would combine TD-based temporal credit assignment algorithms 
with genetics-based adaptive knowledge representation. This paper presents a 
simple instantiation of this idea, called GBQL (Genetics-Based Q-Learning). 
This learning architecture may be expected to be a promising alternative for 
stimulus-response classifier systems on one hand, and for the implementations 
of Q-learning using other knowledge representation methods (e.g., connectionist 
networks) on the other hand.</blockquote> 
<p> </p> </dd> 
<dt> [196] </dt> 
<dd> Pawel Cichosz and Jan&nbsp;J. Mulawka. Faster temporal credit assignment 
in learning classifier systems. InProceedings of the First Polish Conference on 
Evolutionary Algorithms (KAE-96), 1996. 
<blockquote> Classifier systems are genetics-based learning systems using the 
paradigm of reinforcement learning. In the most challenging case of delayed 
reinforcement, it involves a difficult temporal credit assignment problem. 
Standard classifier systems solve this problem using the bucket brigade 
algorithm. In this paper we show how to make the temporal credit assignment 
process faster by augmenting this algorithm by some refinements borrowed from a 
related field of reinforcement learning algorithms based on the methods of 
temporal differences (TD). These algorithms usually converge significantly 
faster if they are used in combination with TD(lambda). As a natural 
consequence of the easily noticeable similarity between the bucket brigade and 
TD(0), the BB(lambda) algorithm is derived, using the standard technique of 
eligibility traces. The TTD(lambda,m) procedure, which eliminates eligibility 
traces and implements an approximation of TD(lambda) in a computationally 
efficient way, has also been ported to the context of classifier systems, 
yielding the TBB(lambda,m) algorithm. The two resulting novel algorithms 
provide promising and, strangely enough, completely unexplored so far 
possibilities of making learning classifier systems learn faster under the 
conditions of reinforcement delay.</blockquote> 
<p> </p> </dd> 
<dt> [197] </dt> 
<dd> Pawel Cichosz. Reinforcement learning algorithms based on the methods of 
temporal differences. Master's thesis, Institute of Computer Science, Warsaw 
University of Technology, 1994.
<blockquote> The reinforcement learning paradigm differs significantly from 
the traditional supervised learning paradigm. An agent in each particular input 
situation must generate an action. Then it receives a reinforcement value from 
the environment, providing a measure of the agent's performance. The task for 
the agent is to maximize the reinforcement values it receives in long term. 
Reinforcement learning agents are adaptive, reactive, and self-improving. To 
formulate a particular task as a reinforcement learning task one just has to 
design an appropriate reinforcement function, specifying the goal of the task. 
This makes the paradigm widely applicable, especially in such domains as game 
playing, automatic control, and robotics. The reinforcement value received by 
the agent at a particular time step may reflect the positive or negative 
consequences of actions taken several steps before. In order to deal with such 
delayed reinforcement one needs some algorithms for temporal credit assignment. 
This thesis concentrates on a class of algorithms based on Sutton's temporal 
differences (TD) methods. The AHC and Q-learning algorithms are well known 
instances of this class. The TTD procedure is proposed for the efficient and 
general implementation of this class of algorithms, as an alternative to the 
traditional so called eligibility traces implementation, which is found to 
suffer from both inefficiency and lack of generality. Important practical 
issues in using these algorithms are discussed. The problem of learning with 
multidimensional actions is addressed and a simple way to generalize 
appropriately TD-based algorithms is presented. It is argued that existing 
one-dimensional algorithms are hardly applicable to tasks with vector actions 
and that the proposed extensions, despite their simplicity, constitute a 
promising approach to this problem, though they require further work. A novel 
genetics-based reinforcement learning architecture is introduced. It combines 
Q-learning with genetics-based knowledge representation and rule discovery 
mechanisms. For the class of learning problems considered in this thesis, it 
can be a promising alternative to Holland's classifier systems with the bucket 
brigade temporal credit assignment algorithm. For all described algorithms 
experimental results are presented, illustrating their performance. Several 
important open problems in reinforcement learning are identified and directions 
for future research are outlined.</blockquote> 
<p> </p> </dd> 
<dt> [198] </dt> 
<dd> Pawel Cichosz. Reinforcement Learning by Truncating Temporal Differences. 
PhD thesis, Department of Electronics and Information Technology, Warsaw 
University of Technology, 1997.
<blockquote> The paradigm of reinforcement learning provides an appealing 
framework for developing intelligent adaptive systems. The learner interacts 
with a possibly unknown and stochastic environment by observing its states and 
performing actions. It receives scalar reinforcement, or reward values, which 
provide a relative measure of the quality of the executed actions. The 
learner's task is to identify an optimal decision policy, i.e., a state-action 
mapping that leads to the maximization of the rewards it receives in the long 
term. Reinforcement values may be sparse and delayed with respect to the 
actions which contributed to them. A common approach to learning from delayed 
rewards is to use TD(lambda) methods for predicting future rewards in each 
state. Q-learning is currently the most popular and best theoretically 
understood TD-based reinforcement learning algorithm, but a variety of other 
related algorithms can be used. There have been a few impressive practical 
applications of reinforcement learning, but the existing algorithms still 
suffer from important deficiencies. This thesis examines possible ways of 
overcoming some of them, and thus making it easier to develop successful 
intelligent systems based on the reinforcement learning paradigm. Probably the 
most painful problem to be addressed is the relatively slow convergence of 
reinforcement learning algorithms. Although using TD(lambda&gt;0) is known to 
usually give a considerable learning speedup, in practice TD(0) is still often 
used, because positive lambda increases the computational expense enormously, 
particularly for realistic tasks, with large state spaces. This is because 
TD(lambda) is implemented using eligibility traces, maintained and updated at 
each time step for all states. In this thesis the effects of the eligibility 
traces implementation are analyzed and an alternative implementation is 
derived, called the TTD procedure, which closely approximates TD(lambda) in a 
computationally efficient way, so that one can use lambda&gt;0 at essentially 
the same cost as TD(0). This novel technique is theoretically shown to be 
approximately equivalent to, and empirically demonstrated to perform at least 
as well as eligibility traces, while it gives impressive computational savings. 
This is the major contribution of the dissertation around which the remaining 
contributions are concentrated. The theoretical analysis of TTD leads to a 
number of additional interesting results. The proposed technique is shown to be 
covered by the existing TD(lambda) convergence theory, by proving its 
error-reduction property. It is extended to variable lambda, to allow one to 
select lambda values adaptively, which has been suggested by some prior work. 
Reinforcement learning speedup techniques proposed by other authors, based on 
experience replay, are shown to be equivalent to special variable lambda forms 
of TTD. A TTD analog is derived for replacing eligibility traces, recently 
proposed by other authors and argued to have some important advantages over 
traditional, accumulating eligibility traces. Finally, a version of TTD is 
presented for average-reward reinforcement learning, alternative to the 
standard discounted-reward framework, adopted by this work. To apply 
reinforcement learning algorithms to tasks with large, especially continuous 
state spaces, it is usually necessary to combine them with learning function 
approximators to generalize over the state space. For a particular, but widely 
used class of function approximators, known as parameter-estimation methods, 
TTD is rederived in a gradient form and shown to be equivalent to the 
corresponding version of eligibility traces. Empirical results are presented 
for the combination of TTD and CMAC, a function approximator particularly well 
suited to reinforcement learning, which show that it learns successfully and 
requires much less computation than eligibility traces.</blockquote> 
<p> </p> </dd> 
<dt> [199] </dt> 
<dd> Dave Cliff and Seth&nbsp;G. Bullock. Adding `Foveal Vision' to Wilson's 
Animat.Adaptive Behavior, 2(1):47-70, 1993. 
<blockquote> Different animals employ different strategies for sampling 
sensory data. The strategies are often closely constrained by environmental 
considerations, such as the animal's ecological niche. In animals that can see, 
differences in sampling strategy manifest themselves as differences in field of 
view and in spatially variant sampling (so-called ``foveal'' vision). In 
analysing adaptive behaviour in animals, or attempting to design autonomous 
robots, mechanisms for exploring variations in sensory sampling strategy will 
be required. This paper describes our work exploring a minimal system for 
investigating the effects of variations in patterns of sensory sampling. We 
have re-implemented Wilson's (1986) animat, and then experimented with altering 
its sensory sampling pattern (i.e. its sensory field). Empirical results are 
presented which demonstrate that alterations in the sensory field pattern can 
have a significant effect on the animat's observable behaviour (and hence also 
on the internal mechanisms which generate the behaviours). Analysis of our 
results involves characterising the interaction between the animat's sensory 
field and the environment within which the animat resides. We found that the 
animat's observed behaviour can, at least in part, be explained as a result of 
the animat cautiously moving in a manner which maximises the generation of new 
information from the environment over time. The paper concludes with a 
discussion of the generality of the results, and reflections on the prospects 
for further work.</blockquote> 
<p> </p> </dd> 
<dt> [200] </dt> 
<dd> Dave Cliff and Susi Ross. Adding Temporary Memory to ZCS. Adaptive 
Behavior, 3(2):101-150, 1994. Also technical report: 
ftp://ftp.cogs.susx.ac.uk/pub/reports/csrp/csrp347.ps.Z.
<blockquote> In a recent paper, Wilson (1994b) described a `zeroth-level' 
classifier system (ZCS). ZCS employs a reinforcement learning technique 
comparable to Q-Learning (Watkins, 1989). This paper presents results from the 
first reconstruction of ZCS. Having replicated Wilson's results, we extend ZCS 
in a manner suggested by Wilson: the original formulation of ZCS has no memory 
mechanisms, but Wilson (1994b) suggested how internal `temporary memory' 
registers could be added. We show results from adding one-bit and two-bit 
memory registers to ZCS. Our results demonstrate that ZCS can efficiently 
exploit memory facilities in non-Markov environments. We also show that the 
memoryless ZCS can converge on near-optimal stochastic solutions in non-Markov 
environments. Following the discussion of adding memory, we present results 
from trials using ZCS in Markov environments requiring increasingly long chains 
of actions before reward is received. Our results indicate that inaccurate 
over-general classifiers can interact with the classifier-generation mechanisms 
to cause catastrophic breakdowns in overall system performance. Basing 
classifier fitness on accuracy may alleviate this problem. We conclude that the 
memory mechanism in its current form is unlikely to scale well for situations 
requiring large amounts of temporary memory. Nevertheless, the ability to find 
stochastic solutions when there is insufficient memory might offset this 
problem to some extent.</blockquote> 
<p> </p> </dd> 
<dt> [201] </dt> 
<dd> Dave Cliff and Susi Ross. Adding Temporary Memory to ZCS. Technical 
Report CSRP347, School of Cognitive and Computing Sciences, University of 
Sussex, 1995. ftp://ftp.cogs.susx.ac.uk/pub/reports/csrp/csrp347.ps.Z.
<p> </p> </dd> 
<dt> [202] </dt> 
<dd> Dave Cliff, Philip Husbands, Jean-Arcady Meyer, and Stewart&nbsp;W. 
Wilson, editors.From Animals to Animats 3. Proceedings of the Third 
International Conference on Simulation of Adaptive Behavior (SAB94). A Bradford 
Book. MIT Press, 1994.
<p> </p> </dd> 
<dt> [203] </dt> 
<dd> H.&nbsp;G. Cobb and John&nbsp;J. Grefenstette. Learning the persistence 
of actions in reactive control rules. InProceedings 8th International Machine 
Learning Workshop, pages 293-297. Morgan Kaufmann, 1991. 
<blockquote> This paper explores the effect of explicitly searching for the 
persistence of each decision in a time-dependent sequential decision task. In 
prior studies, Grefenstette, et al, show the effectiveness of SAMUEL, a genetic 
algorithm-based system, in solving a simulation problem where an agent learn 
show to evade a predator that is in pursuit. In their work, an agent applies a 
control action at each time step. This paper examines a reformulation of the 
problem: the agent learns not only the level of response of a control action, 
but also how long to apply that control action. By examining this problem, the 
work shows that it is appropriate to choose a representation of the state space 
that compresses time information when solving a time-dependent sequential 
decision problem. By compressing time information, critical events in the 
decision sequence become apparent.</blockquote> 
<p> </p> </dd> 
<dt> [204] </dt> 
<dd> Philippe Collard and Cathy Escazut. Relational Schemata: A Way to Improve 
the Expressiveness of Classifiers. InEshelman [298], pages 397-404. 
<p> </p> </dd> 
<dt> [205] </dt> 
<dd> Marco Colombetti and Marco Dorigo. Learning to Control an Autonomous 
Robot by Distributed Genetic Algorithms. InRoitblat and Wilson [700], pages 
305-312.
<p> </p> </dd> 
<dt> [206] </dt> 
<dd> Marco Colombetti and Marco Dorigo. Robot Shaping: Developing Situated 
Agents through Learning. Technical Report TR-92-040, International Computer 
Science Institute, Berkeley, CA, 1993.
<blockquote> Learning plays a vital role in the development of situated 
agents. In this paper, we explore the use of reinforcement learning to 
&quot;shape&quot; a robot to perform a predefined target behavior. We connect 
both simulated and real robots to Alecsys, a parallel implementation of a 
learning classifier system with an extended genetic algorithm. After 
classifying different kinds of Animat-like behaviors, we explore the effects on 
learning of different types of agent's architecture (monolithic, flat and 
hierarchical) and of training strategies. In particular, hierarchical 
architecture requires the agent to learn how to coordinate basic learned 
responses. We show that the best results are achieved when both the agent's 
architecture and the training strategy match the structure of the behavior 
pattern to be learned. We report the results of a number of experiments carried 
out both in simulated and in real environments, and show that the results of 
simulations carry smoothly to real robots. While most of our experiments deal 
with simple reactive behavior, in one of them we demonstrate the use of a 
simple and general memory mechanism. As a whole, our experimental activity 
demonstrates that classifier systems with genetic algorithms can be practically 
employed to develop autonomous agents.</blockquote> 
<p> </p> </dd> 
<dt> [207] </dt> 
<dd> Marco Colombetti and Marco Dorigo. Training Agents to Perform Sequential 
Behavior. Technical Report TR-93-023, International Computer Science Institute, 
Berkeley, CA, September 1993.
<blockquote> This paper is concerned with training an agent to perform 
sequential behavior. In previous work we have been applying reinforcement 
learning techniques to control a reactive robot. Obviously, a pure reactive 
system is limited in the kind of interactions it can learn. In particular, it 
can only learn what we call pseudo-sequences, that is sequences of actions in 
which the transition signal is generated by the appearance of a sensorial 
stimulus. We discuss the difference between pseudo-sequences and proper 
sequences, and the implication that these differences have on training 
procedures. A result of our research is that, in case of proper sequences, for 
learning to be successful the agent must have some kind of memory; moreover it 
is often necessary to let the trainer and the learner communicate. We study 
therefore the influence of communication on the learning process. First we 
consider trainer-to-learner communication introducing the concept of 
reinforcement sensor, which let the learning robot explicitly know whether the 
last reinforcement was a reward or a punishment; we also show how the use of 
this sensor induces the creation of a set of error recovery rules. Then we 
introduce learner-to-trainer communication, which is used to disambiguate 
indeterminate training situations, that is situations in which observation 
alone of the learner behavior does not provide the trainer with enough 
information to decide if the learner is performing a right or a wrong move. All 
the design choices we make are discussed and compared by means of experiments 
in a simulated world.</blockquote> 
<p> </p> </dd> 
<dt> [208] </dt> 
<dd> Marco Colombetti and Marco Dorigo. Training agents to perform sequential 
behavior. Adaptive Behavior, 2(3):247-275, 1994. 
ftp://iridia.ulb.ac.be/pub/dorigo/journals/IJ.06-ADAP94.ps.gz.
<blockquote> This paper is concerned with training an agent to perform 
sequential behavior. In previous work we have been applying reinforcement 
learning techniques to control a reactive agent. Obviously, a pure reactive 
system is limited in the kind of interactions it can learn. In particular, it 
can learn what we call pseudo-sequences, that is sequences of actions in which 
each action is selected on the basis of current sensory stimuli; on the 
contrary, it cannot learn proper sequences, in which actions have to be 
selected also on the basis of some internal state. Moreover, it is a result of 
our research that effective learning of proper sequences is improved by letting 
the agent and the trainer communicate. First we consider trainer-to-agent 
communication, introducing the concept of reinforcement sensor, which lets the 
learning robot explicitly know whether the last reinforcement was a reward or a 
punishment; we also show how the use of this sensor makes error recovery rules 
emerge. Then we introduce agent-to-trainer communication, which is used to 
disambiguate ambiguous training situations, that is situations in which the 
observation of the agent's behavior does not provide the trainer with enough 
information to decide whether the agent's move is right or wrong. We also show 
an alternative solution of the problem of ambiguous situations, which involves 
learning to coordinate behavior in a simpler, unambiguous setting, and then 
transferring what has been learnt to a more complex situation. All the design 
choices we make are discussed and compared by means of experiments in a 
simulated world.</blockquote> 
<p> </p> </dd> 
<dt> [209] </dt> 
<dd> Marco Colombetti and Marco Dorigo. Verso un'ingegneria del comportamento. 
Rivista di Automatica, Elettronica e Informatica, 83(10), 1996. In Italian. 
<p> </p> </dd> 
<dt> [210] </dt> 
<dd> Marco Colombetti and Marco Dorigo. Evolutionary Computation in Behavior 
Engineering. InEvolutionary Computation: Theory and Applications, 
chapter&nbsp;2, pages 37-80. World Scientific Publishing Co.: Singapore, 1999. 
Also Technical Report. TR/IRIDIA/1996-1, IRIDIA, Universit&eacute; Libre de 
Bruxelles.
<p> </p> </dd> 
<dt> [211] </dt> 
<dd> Marco Colombetti, Marco Dorigo, and G.&nbsp;Borghi. Behavior Analysis and 
Training: A Methodology for Behavior Engineering.IEEE Transactions on Systems, 
Man and Cybernetics, 26(6):365-380, 1996. 
<p> </p> </dd> 
<dt> [212] </dt> 
<dd> Marco Colombetti, Marco Dorigo, and G.&nbsp;Borghi. Robot shaping: The 
HAMSTER Experiment. In M.&nbsp;Jamshidi et&nbsp;al., editor,Proceedings of 
ISRAM'96, Sixth International Symposium on Robotics and Manufacturing, May 
28-30, Montpellier, France, 1996. 
<p> </p> </dd> 
<dt> [213] </dt> 
<dd> M.&nbsp;Compiani, D.&nbsp;Montanari, R.&nbsp;Serra, and P.&nbsp;Simonini. 
Asymptotic dynamics of classifier systems. InSchaffer [718], pages 298-303. 
<blockquote> Classifier systems are discussed as high-dimensional dynamical 
systems. Their learning abilities and long term behavior are analyzed in a 
letter prediction task domain. We find that the system can develop different 
types of solutions, sometimes heavily relying on its dynamical properties. A 
taxonomy of the system solutions is outlined, and some problems due to the 
activity of the genetic operators are discussed, as well as ways to solve or 
alleviate them.</blockquote> 
<p> </p> </dd> 
<dt> [214] </dt> 
<dd> M.&nbsp;Compiani, D.&nbsp;Montanari, R.&nbsp;Serra, and G.&nbsp;Valastro. 
Classifier systems and neural networks. InParallel Architectures and Neural 
Networks-First Italian Workshop, pages 105-118. World Scientific, Teaneck, NJ, 
1989.
<p> </p> </dd> 
<dt> [215] </dt> 
<dd> M.&nbsp;Compiani, D.&nbsp;Montanari, R.&nbsp;Serra, and P.&nbsp;Simonini. 
Learning and Bucket Brigade Dynamics in Classifier Systems. InSpecial issue of 
Physica D (Vol. 42) [292], pages 202-212. 
<blockquote> Classifier systems are rule-based adaptive systems whose learning 
capabilities emerge from processes of selection and competition within a 
population of rules (classifiers). These processes are ruled by the values of 
numerical variables which measure the fitness of each rule. The system's 
adaptivity is ensured by a fitness reallocation mechanism (the bucket brigade 
algorithm) and by genetic algorithms which are responsible for the internal 
dynamics of the system. In this paper we discuss classifier systems as 
dynamical systems, the main focus being on the asymptotic dynamics due to the 
bucket brigade abstracting from the action of the genetics. This topic is 
discussed with reference to a specific task domain, in which the system is used 
as a detector of statistical properties of periodic or fluctuating external 
environments. We also describe a major consequence of the genetics on the 
bucket brigade dynamics, namely the proliferation of individual rules into 
subpopulations of equivalent classifiers: we then show that this can eventually 
lead to undesired stochastic behavior or to the destabilizatiion of correct 
solutions devised by the system.</blockquote> 
<p> </p> </dd> 
<dt> [216] </dt> 
<dd> Clare&nbsp;Bates Congdon. Classification of epidemiological data: A 
comparison of genetic algorithm and decision tree approaches. InProceedings of 
the 2000 Congress on Evolutionary Computation (CEC00) [185], pages 442-449. 
<blockquote> This paper describes an application of genetic algorithms (GA's) 
to classify epidemiological data, which is often challenging to classify due to 
noise and other factors. For such complex data (that requires a large number of 
very specific rules to achieve a high accuracy), smaller rule sets, composed of 
more general rules, may be preferable, even if they are less accurate. The GA 
presented here allows the user to encourage smaller rule sets by setting a 
parameter. The rule sets found are also compared to those created by standard 
decision-tree algorithms. The results illustrate tradeoffs involving the number 
of rules, descriptive accuracy, predictive accuracy, and accuracy in describing 
and predicting positive examples across different rule sets.</blockquote> 
<p> </p> </dd> 
<dt> [217] </dt> 
<dd> A.L. Corcoran and S.&nbsp;Sen. Using real-valued genetic algorithms to 
evolve rule sets for classification. InProceedings of the IEEE Conference on 
Evolutionary Computation, pages 120-124. IEEE Press, 1994. 
<p> </p> </dd> 
<dt> [218] </dt> 
<dd> O.&nbsp;Cord&oacute;n, F.&nbsp;Herrera, E.&nbsp;Herrera-Viedma, and 
M.&nbsp;Lozano.Genetic Algorithms and Fuzzy Logic in Control Processes. 
Technical Report DECSAI-95109, University of Granada, Granada, Spain, 1995.
<blockquote> In this paper we describe the genetic algorithms and fuzzy logic, 
focusing them as tools to model control processes and to design intelligent and 
automatic control systems. We describe the application of genetic algorithms to 
design fuzzy logic controllers, as well as the learning classifier systems and 
their development in a fuzzy environment, the fuzzy learning classifier systems.
</blockquote> 
<p> </p> </dd> 
<dt> [219] </dt> 
<dd> Oscar Cord&oacute;n, Francisco Herrera, Frank Hoffmann, and Luis 
Magdalena.Genetic Fuzzy Systems. World Scientific, 2001. 
<blockquote> In recent years, a great number of publications have explored the 
use of genetic algorithms as a tool for designing fuzzy systems. Genetic Fuzzy 
Systems explores and discusses this symbiosis of evolutionary computation and 
fuzzy logic. The book summarizes and analyzes the novel field of genetic fuzzy 
systems, paying special attention to genetic algorithms that adapt and learn 
the knowledge base of a fuzzy-rule-based system. It introduces the general 
concepts, foundations and design principles of genetic fuzzy systems and covers 
the topic of genetic tuning of fuzzy systems. It also introduces the systems: 
the Michigan, Pittsburgh and Iterative-learning methods. Finally, it explores 
hybrid genetic fuzzy systems such as genetic fuzzy clustering or genetic 
neuro-fuzzy systems and describes a number of applications from different 
areas. Genetic Fuzzy System represents a comprehensive treatise on the design 
of the fuzzy-rule-based systems using genetic algorithms, both from a 
theoretical and a practical perspective. It is a valuable compendium for 
scientists and engineers concerned with research and applications in the domain 
of fuzzy systems and genetic algorithms.</blockquote> 
<p> </p> </dd> 
<dt> [220] </dt> 
<dd> H.&nbsp;Brown Cribbs III and Robert&nbsp;E. Smith. Classifier System 
Renaissance: New Analogies, New Directions. InKoza et&nbsp;al. [527], pages 
547-552.
<blockquote> Learning classifier systems (LCSs) have existed for nearly twenty 
years (Holland &amp; Reitman, 1978). Research efforts in reinforcement learning 
(RL), evolutionary computation (EC), and neural networks have enhanced the 
original LCS paradigm. New thoughts from these areas have created a 
``renaissance'' period for the LCS. This paper highlights some key LCS 
advancements and the fields that inspired them. One inspiration, from neural 
networks, is examined for a novel LCS approach to autonomous mobile robots. A 
simple, LCS-controlled robot simulation is presented. This simulation shows the 
potential benefits of combined biological paradigms and the hybridization of 
ideas in the LCS. Future directions for LCS reseach are discussed.</blockquote> 
<p> </p> </dd> 
<dt> [221] </dt> 
<dd> Henry&nbsp;Brown Cribbs III and Robert&nbsp;E. Smith. What Can I do with 
a Learning Classifier System? In C.&nbsp;Karr and L.&nbsp;M. Freeman, editors,
Industrial Applications of Genetic Algorithms, pages 299-320. CRC Press, 1998. 
<blockquote> The learning classifier system (LCS) is an application of the 
genetic algorithm to machine learning. Artificial neural networks (ANNs) 
perform mappings of input vectors to outputs much the same way a LCS does. This 
chapter introduces the LCS paradigm and provides literature references for 
future investigation. Through the use of LCS principles, an ANN becomes a 
variable structure production system, capable of making complex input-output 
mappnigs that are similar to a LCS. The evolutionary process of a single ANN 
facilitates a broad understanding of how evolution may help rule-based (or 
neuron-based) systems. An evolutionary approach to ANN structure is reviewed. 
Its similarities to the LCS are discussed. A simple extension to Smith and 
Cribbs' (1994) and Cribbs' (1995) work in an ANN and LCS analogy is presented. 
The experiment presented removes the nonlinerarity of the ANN's output layer to 
assess the nonlinear effects of the GA's partitioning within the hidden layer. 
The results indicate that GA-induced nonlinearity actively participates in the 
solution of a difficult Boolean problem -- the six multiplexor problem.
</blockquote> 
<p> </p> </dd> 
<dt> [222] </dt> 
<dd> Walling Cyre. Learning grammars with a modified classifier system. In 
David&nbsp;B. Fogel, Mohamed&nbsp;A. El-Sharkawi, Xin Yao, Garry Greenwood, 
Hitoshi Iba, Paul Marrow, and Mark Shackleton, editors,Proceedings of the 2002 
Congress on Evolutionary Computation CEC2002, pages 1366-1371. IEEE Press, 2002.
<p> </p> </dd> 
<dt> [223] </dt> 
<dd> Hai&nbsp;H. Dam, Kamran Shafi, and Hussein&nbsp;A. Abbass. Can 
Evolutionary Computation Handle Large Datasets? A Study into Network Intrusion 
Detection. InProceedings of the 18th Australian Joint Conference on Artificial 
Intelligence, Lecture Notes in Computer Science (LNCS), 3809, pages 1092-1095. 
Springer, Heidelberg, 2005.
<p> </p> </dd> 
<dt> [224] </dt> 
<dd> H.H. Dam, H.A. Abbass, and C.&nbsp;Lokan. DXCS: an XCS system for 
distributed data mining. In H.G. Beyer and U.M. O'Reilly, editors,Genetic and 
evolutionary computation conference, GECCO 2005, pages 1883-1890, 2005. 
<p> </p> </dd> 
<dt> [225] </dt> 
<dd> Hai&nbsp;Huong Dam, Hussein&nbsp;A. Abbass, Chris Lokan, and Xin Yao. 
Neural-based learning classifier systems.IEEE Trans. Knowl. Data Eng., 
20(1):26-39, 2008.
<p> </p> </dd> 
<dt> [226] </dt> 
<dd> Martin Danek and Robert&nbsp;E. Smith. XCS applied to mapping FPGA 
architectures. In W.&nbsp;B. Langdon, E.&nbsp;Cant&uacute;-Paz, 
K.&nbsp;Mathias, R.&nbsp;Roy, D.&nbsp;Davis, R.&nbsp;Poli, 
K.&nbsp;Balakrishnan, V.&nbsp;Honavar, G.&nbsp;Rudolph, J.&nbsp;Wegener, 
L.&nbsp;Bull, M.&nbsp;A. Potter, A.&nbsp;C. Schultz, J.&nbsp;F. Miller, 
E.&nbsp;Burke, and N.&nbsp;Jonoska, editors,GECCO 2002: Proceedings of the 
Genetic and Evolutionary Computation Conference, pages 912-919. Morgan Kaufmann 
Publishers, 2002.
<p> </p> </dd> 
<dt> [227] </dt> 
<dd> Dipankar Dasgupta and Fabio&nbsp;A. Gonzalez. Evolving complex fuzzy 
classifier rules using a linear tree genetic representation. In Lee Spector, 
Erik&nbsp;D. Goodman, Annie Wu, W.B. Langdon, Hans-Michael Voigt, Mitsuo Gen, 
Sandip Sen, Marco Dorigo, Shahram Pezeshk, Max&nbsp;H. Garzon, and Edmund 
Burke, editors,Proceedings of the Genetic and Evolutionary Computation 
Conference (GECCO-2001), pages 299-305, San Francisco, California, USA, 7-11 
July 2001. Morgan Kaufmann.
<p> </p> </dd> 
<dt> [228] </dt> 
<dd> Y.&nbsp;Davidor and H.-P. Schwefel, editors. Parallel Problem Solving 
From Nature -- PPSN III, volume 866 of Lecture Notes in Computer Science, 
Berlin, 1994. Springer Verlag.
<p> </p> </dd> 
<dt> [229] </dt> 
<dd> Lawrence Davis and David Orvosh. The Mating Pool: A Testbed for 
Experiments in the Evolution of Symbol Systems. InEshelman [298], pages 405-412.
<p> </p> </dd> 
<dt> [230] </dt> 
<dd> Lawrence Davis and D.&nbsp;K. Young. Classifier Systems with Hamming 
Weights. InProceedings of the Fifth International Conference on Machine Learning
, pages 162-173. Morgan Kaufmann, 1988.
<p> </p> </dd> 
<dt> [231] </dt> 
<dd> Lawrence Davis, Stewart&nbsp;W. Wilson, and David Orvosh. Temporary 
Memory for Examples can Speed Learning in a Simple Adaptive System. InRoitblat 
and Wilson [700], pages 313-320. 
<p> </p> </dd> 
<dt> [232] </dt> 
<dd> Lawrence Davis, Chunsheng Fu, and Stewart&nbsp;W. Wilson. An incremental 
multiplexer problem and its uses in classifier system research. InLanzi 
et&nbsp;al. [546], pages 23-31. 
<p> </p> </dd> 
<dt> [233] </dt> 
<dd> Lawrence Davis. Mapping Classifier Systems into Neural Networks. In 
Proceedings of the Workshop on Neural Information Processing Systems 1, pages 
49-56, 1988.
<p> </p> </dd> 
<dt> [234] </dt> 
<dd> Lawrence Davis, editor. Genetic Algorithms and Simulated Annealing, 
Research Notes in Artificial Intelligence. Pitman Publishing: London, 1989.
<p> </p> </dd> 
<dt> [235] </dt> 
<dd> Lawrence Davis. Mapping Neural Networks into Classifier Systems. In 
Schaffer [718], pages 375-378. 
<blockquote> Neural networks are machine learning systems based on simple, 
localized responses to external stimuli. They can respond to the same stimuli 
that classifier systems respond to, and they alter their internal structure on 
the basis of reinforcement from an external source. The learning techniques 
used by researchers in the neural network field have traditionally been quite 
different from those used by genetic algorithm researchers, however. The 
tension between these similarities and differences have led researchers to 
wonder what the formal relationship between the two systems is. This is one of 
two papers showing that there is a sense in which these two types of machine 
learning systems are equivalent. In a companion paper, it is shown that any 
classifier system may be transformed into a neural network that is isomorphic 
in function. In this paper, it is shown that any neural network can be 
transformed into a classifier system that is isomorphic in function, although 
several modifications must be made to standard classifier system practice for 
this transformation to work. The present paper also considers a different 
transformation procedure described by Belew and Gherrity that accomplishes this 
task in a different way. The paper concludes with a discussion of these 
transformation procedures and their import.</blockquote> 
<p> </p> </dd> 
<dt> [236] </dt> 
<dd> Lawrence Davis. Covering and Memory in Classifier Systems. In Collected 
Abstracts for the First International Workshop on Learning Classifier System 
(IWLCS-92) [486]. October 6-8, NASA Johnson Space Center, Houston, Texas. 
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [237] </dt> 
<dd> Lawrence Davis. A formal relationship between ant colony optimizers and 
classifier systems. In Tim Kovacs, Xavier LL&ograve;ra, Keiki Takadama, 
Pier&nbsp;Luca Lanzi, Wolfgang Stolzmann, and Stewart&nbsp;W. Wilson, editors,
Learning Classifier Systems. International Workshops, IWLCS 2003-2005, Revised 
Selected Papers, volume 4399 of LNCS, pages 258-269. Springer, 2007. 
<p> </p> </dd> 
<dt> [238] </dt> 
<dd> Devon Dawson and Benjoe Juliano. Modifying xcs for size-constrained 
systems.International Journal on Neural and Mass-Parallel Computing and 
Information Systems, 2003. 
<p> </p> </dd> 
<dt> [239] </dt> 
<dd> Devon Dawson. Improving extended classifier system performance in 
resource-constrained configurations. Master's thesis, California State 
University, Chico, 2002.
<p> </p> </dd> 
<dt> [240] </dt> 
<dd> Devon Dawson. Improving performance in size-constrained extended 
classifier systems. In E.&nbsp;Cant&uacute;-Paz, J.&nbsp;A. Foster, 
K.&nbsp;Deb, D.&nbsp;Davis, R.&nbsp;Roy, U.-M. O'Reilly, H.-G. Beyer, 
R.&nbsp;Standish, G.&nbsp;Kendall, S.&nbsp;Wilson, M.&nbsp;Harman, 
J.&nbsp;Wegener, D.&nbsp;Dasgupta, M.&nbsp;A. Potter, A.&nbsp;C. Schultz, 
K.&nbsp;Dowsland, N.&nbsp;Jonoska, and J.&nbsp;Miller, editors,Genetic and 
Evolutionary Computation -- GECCO-2003, pages 1870-1881, Berlin, 2003. 
Springer-Verlag.
<p> </p> </dd> 
<dt> [241] </dt> 
<dd> Bart de Boer. Classifier Systems: a useful approach to machine learning?. 
Master's thesis, Leiden University, 1994. 
ftp://ftp.wi.leidenuniv.nl/pub/CS/MScTheses/deboer.94.ps.gz.
<blockquote> Classifier systems are sub-symbolic or dynamic approaches to 
machine learning. These systems have been studied rather extensively. In this 
thesis some theoretical results about the long-term behaviour and the 
computational abilities of classifier systems are derived. Then some 
experiments are undertaken. The first experiment entails the implementation of 
a simple logic function, a multiplexer in a simple classifier system. It is 
shown that this task can be learned very well. The second task that is taught 
to the system is a mushroom-classification problem that has been researched 
with other learning systems. It is shown that this task can be learned. The 
last problem is the parity problem. First it is shown that this problem does 
not scale linearly with its number of bits in a straightforward classifier 
system. An attempt is made to solve it with a multilayer classifier-system, but 
this is found to be almost impossible. Explanations are given of why this 
should be the case. Then some thought is given to analogies between classifier 
systems and neural networks. It is indicated that there are mappings between 
certain classifier systems and certain neural networks. It is suggested that 
this is a main concern for future classifier systems research.</blockquote> 
<p> </p> </dd> 
<dt> [242] </dt> 
<dd> Kenneth&nbsp;A. De&nbsp;Jong, William&nbsp;M. Spears, and Dianna&nbsp;F. 
Gordon. Using Genetic Algorithms for Concept Learning.Machine Learning, 
3:161-188, 13.
<blockquote> In this article, we explore the use of genetic algorithms (GAs) 
as a key element in the design and implementation of robust concept learning 
systems. We describe and evaluate a GA-based system called GABIL that 
continually learns and refines concept classification rules from its 
interaction with the environment. The use of GAs is motivated by recent studies 
showing the effects of various forms of bias built into different concept 
learning systems, resulting in systems that perform well on certain concept 
classes (generally, those well matched to the biases) and poorly on others. By 
incorporating a GA as the underlying adaptive search mechanism, we are able to 
construct a concept learning system that has a simple, unified architecture 
with several important features. First, the system is surprisingly robust even 
with minimal bias. Second, the system can be easily extended to incorporate 
traditional forms of bias found in other concept learning systems. Finally, the 
architecture of the system encourages explicit representation of such biases 
and, as a result, provides for an important additional feature: the ability to 
dynamically adjust system bias. The viability of this approach is illustrated 
by comparing the performance of GABIL with that of four other more traditional 
concept learners (AQ14, C4.5, ID5R, and IACL) on a variety of target concepts. 
We conclude with some observations about the merits of this approach and about 
possible extensions.</blockquote> 
<p> </p> </dd> 
<dt> [243] </dt> 
<dd> Kenneth&nbsp;A. De&nbsp;Jong. Learning with Genetic Algorithms: An 
Overview.Machine Learning, 3:121-138, 1988. 
<blockquote> Genetic algorithms represent a class of adaptive search 
techniques that have been intensively studied in recent years. Much of the 
interest in genetic algorithms is due to the fact that they provide a set of 
efficient domain-independent search heuristics which are a significant 
improvement over traditional ``weak methods'' without the need for 
incorporating highly domain-specific knowledge. There is now considerable 
evidence that genetic algorithms are useful for global function optimization 
and NP-hard problems. Recently, there has been a good deal of interest in using 
genetic algorithms for machine learning problems. This paper provides a brief 
overview of how one might use genetic algorithms as a key element in learning 
systems.</blockquote> 
<p> </p> </dd> 
<dt> [244] </dt> 
<dd> Michael de la Maza. A SEAGUL Visits the Race Track. In Schaffer [718], 
pages 208-212.
<blockquote> SEAGUL (Sensitive Evolutionary Adaptable Genetic Unique Learner) 
is a genetic algorithm that creates production rules that pick the winners of 
horse races. SEAGUL uses data from the Daily Racing Form, a newspaper that is 
found at all race tracks and is available to the general public, to generate 
these rules. SEAGUL deviates from orthodox genetic algorithms in several areas. 
It has a pre-defined procedure for generating the initial population, it 
creates inviolable components that cannot be modified through mutation, it does 
not use the bucket brigade algorithm, and it optimizes its rule set by 
analyzing variables individually and then collectively.</blockquote> 
<p> </p> </dd> 
<dt> [245] </dt> 
<dd> K.&nbsp;Deb and W.M. Spears. In: T. back and d.b. fogel and t. 
michalewicz (eds). evolutionary computation 2: Advanced algorithms and 
operators, 93-100. institute of physics publishing, 2000.
<p> </p> </dd> 
<dt> [246] </dt> 
<dd> Daniel Derrig and James Johannes. Deleting End-of-Sequence Classifiers. 
In John&nbsp;R. Koza, editor,Late Breaking Papers at the Genetic Programming 
1998 Conference, University of Wisconsin, Madison, Wisconsin, USA, July 1998. 
Stanford University Bookstore.
<p> </p> </dd> 
<dt> [247] </dt> 
<dd> Daniel Derrig and James&nbsp;D. Johannes. Hierarchical Exemplar Based 
Credit Allocation for Genetic Classifier Systems. InKoza et&nbsp;al. [529], 
pages 622-628.
<p> </p> </dd> 
<dt> [248] </dt> 
<dd> L.&nbsp;Desjarlais and Stephanie Forrest. Linked learning in classifier 
systems: A control architecture for mobile robots. InCollected Abstracts for 
the First International Workshop on Learning Classifier System (IWLCS-92) [486]
. October 6-8, NASA Johnson Space Center, Houston, Texas.
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [249] </dt> 
<dd> John&nbsp;C. Determan and James&nbsp;A. Foster. A genetic algorithm for 
expert system rule generation. In Lee Spector, Erik&nbsp;D. Goodman, Annie Wu, 
W.B. Langdon, Hans-Michael Voigt, Mitsuo Gen, Sandip Sen, Marco Dorigo, Shahram 
Pezeshk, Max&nbsp;H. Garzon, and Edmund Burke, editors,Proceedings of the 
Genetic and Evolutionary Computation Conference (GECCO-2001), page 757, San 
Francisco, California, USA, 7-11 July 2001. Morgan Kaufmann.
<p> </p> </dd> 
<dt> [250] </dt> 
<dd> P.&nbsp;Devine, R.&nbsp;Paton, and M.&nbsp;Amos. Adaptation of 
Evolutionary Agents in Computational Ecologies. InBCEC-97, Sweden, 1997. 
<p> </p> </dd> 
<dt> [251] </dt> 
<dd> Federico Divina and Elena Marchiori. Evolutionary concept learning. In 
W.&nbsp;B. Langdon, E.&nbsp;Cant&uacute;-Paz, K.&nbsp;Mathias, R.&nbsp;Roy, 
D.&nbsp;Davis, R.&nbsp;Poli, K.&nbsp;Balakrishnan, V.&nbsp;Honavar, 
G.&nbsp;Rudolph, J.&nbsp;Wegener, L.&nbsp;Bull, M.&nbsp;A. Potter, A.&nbsp;C. 
Schultz, J.&nbsp;F. Miller, E.&nbsp;Burke, and N.&nbsp;Jonoska, editors,GECCO 
2002: Proceedings of the Genetic and Evolutionary Computation Conference, pages 
343-350, New York, 9-13 July 2002. Morgan Kaufmann Publishers.
<p> </p> </dd> 
<dt> [252] </dt> 
<dd> F.&nbsp;Divina, M.&nbsp;Keijzer, and E.&nbsp;Marchiori. A method for 
handling numerical attributes in ga-based inductive concept learners. In
Proceedings of the Genetic and Evolutionary Computation Conference (GECCO-2003)
, pages 898-908. Springer-Verlag, 2003.
<p> </p> </dd> 
<dt> [253] </dt> 
<dd> Phillip&nbsp;William Dixon, David&nbsp;W. Corne, and Martin&nbsp;John 
Oates. A preliminary investigation of modified xcs as a generic data mining 
tool. InLanzi et&nbsp;al. [546], pages 133-150. 
<p> </p> </dd> 
<dt> [254] </dt> 
<dd> P.W. Dixon, D.&nbsp;Corne, and M.J. Oates. A ruleset reduction algorithm 
for the XCS learning classifier system. In P.L. Lanzi, W.&nbsp;Stolzmann, and 
S.W. Wilson, editors,Learning classifier systems, 5th international workshop 
(IWLCS 2002), volume 2661 of LNCS, pages 20-29. Springer, 2002. 
<p> </p> </dd> 
<dt> [255] </dt> 
<dd> Jean-Yves Donnart and Jean-Arcady Meyer. A hierarchical classifier system 
implementing a motivationally autonomous animat. In Cliff et&nbsp;al. [202], 
pages 144-153.
<blockquote> This work describes a control architecture based on a 
hierarchical classifier system. This architecture, which uses both reactive and 
planning rules, implements a motivationally autonomous animat that chooses the 
actions it will perform according to the expected consequences of the 
alternatives. The adaptive faculties of this animat are illustrated through 
various examples.</blockquote> 
<p> </p> </dd> 
<dt> [256] </dt> 
<dd> Jean-Yves Donnart and Jean-Arcady Meyer. Hierarchical-map Building and 
Self-positioning with MonaLysa. Adaptive Behavior, 5(1):29-74, 1996. 
<blockquote> This paper describes how an animat endowed with the MonaLysa 
control architecture can build a cognitive map that merges into a hierarchical 
framework not only topological links between landmarks, but also higher-level 
structures, control information, and metric distances and orientations. The 
paper also describes how the animat can use such a map to locate itself, even 
if it is endowed with noisy dead-reckoning capacities. MonaLysa's mapping and 
self-positioning capacities are illustrated by results obtained in three 
different environments and four noise-level conditions. These capacities appear 
to be gracefully degraded when the environment grows more challenging and when 
the noise level increases. In the discussion, the current approach is compared 
to others with similar objectives, and directions for future work are outlined.
</blockquote> 
<p> </p> </dd> 
<dt> [257] </dt> 
<dd> Jean-Yves Donnart and Jean-Arcady Meyer. Learning Reactive and Planning 
Rules in a Motivationally Autonomous Animat. IEEE Transactions on Systems, Man 
and Cybernetics - Part B: Cybernetics, 26(3):381-395, 1996. 
<blockquote> This work describes a control architecture based on a 
hierarchical classifier system. This system, which learns both reactive and 
planning rules, implements a motivationally autonomous animat that chooses the 
actions it performs according to its perception of the external environment, to 
its physiological or internal state, to the consequences of its current 
behavior, and to the expected consequences of its future behavior. The adaptive 
faculties of this architecture are illustrated within the context of a 
navigation task, through various experiments with a simulated and a real robot.
</blockquote> 
<p> </p> </dd> 
<dt> [258] </dt> 
<dd> Jean-Yves Donnart and Jean-Arcady Meyer. Spatial Exploration, Map 
Learning, and Self-Positioning with MonaLysa. In Maes et&nbsp;al. [595], pages 
204-213.
<blockquote> This paper describes how the MonaLysa control architecture 
implements a route-following navigation strategy. Two procedures that allow map 
building and self-positioning are described, and experimental results are 
provided that demonstrate that such procedures are robust with respect to 
noise. This approach is compared to others with similar objectives, and 
directions for future work are outlined.</blockquote> 
<p> </p> </dd> 
<dt> [259] </dt> 
<dd> Jean-Yves Donnart. Cognitive Architecture and Adaptive Properties of an 
Motivationally Autonomous Animat. PhD thesis, Universit&eacute; Pierre et Marie 
Curie. Paris, France, 1998.
<blockquote> This thesis is centered on MonaLysa, the control architecture of 
a motivationally autonomous animat. This architecture implements a motivational 
system that selects the actions and goals of an artificial agent, according to 
its internal state, the stimuli from the environment, and its evaluation of the 
long term consequences of its behavioral choices. This architecture is based on 
an original hierarchical classifier system, that efficiently learns several 
action plans and builds an internal representation of the animat's environment. 
The functionalities of MonaLysa are illustrated within the context of the 
navigation of a simulated animat and of a real robot. In the first part of this 
work, the animat has to reach a goal and to avoid the obstacles it encounters 
on its way. We demonstrate that MonaLysa can efficiently learn a general 
reactive behaviour, notably because it can dynamically change its current goal 
when the animat encounters an obstacle. Moreover, MonaLysa exploits its 
interactions with the environment to learn alternative plans and to deduce an 
optimal path towards its goal; it is also able to modify the organization of 
its plans so as to adapt to environmental changes. In the second part of this 
work, the animat has to explore its environment, when various amounts of noise 
are added to the normal functioning of its odometric sensors. In this context, 
MonaLysa is able to learn a reliable spatial representation of its environment, 
while maintaining a correct estimate of its position. This spatial 
representation is very robust with respect to noise and can adapt to any 
environment. The generality of the approach presented herein opens the way to 
many applications, which are outlined at the end of this work.</blockquote> 
<p> </p> </dd> 
<dt> [260] </dt> 
<dd> Marco Dorigo and Hugues Bersini. A Comparison of Q-Learning and 
Classifier Systems. InCliff et&nbsp;al. [202], pages 248-255. 
<blockquote> Reinforcement Learning is a class of problems in which an 
autonomous agent acting in a given environment improves its behavior by 
progressively maximizing a function calculated just on the basis of a 
succession of scalar responses received from the environment. Q-learning and 
classifier systems (CS) are two methods among the most used to solve 
reinforcement learning problems. Notwithstanding their popularity and their 
shared goal, they have been in the past often considered as two different 
models. In this paper we first show that the classifier system, when restricted 
to a sharp simplification called discounted max very simple classifier system 
(DMAX-VSCS), boils down to tabular Q-learning. It follows that DMAX-VSCS 
converges to the optimal policy as proved by Watkins &amp; Dayan (1992), and 
that it can draw profit from the results of experimental and theoretical works 
dedicated to improve Q-learning and to facilitate its use in concrete 
applications. In the second part of the paper, we show that three of the 
restrictions we need to impose to the CS for deriving its equivalence with 
Q-learning, that is, no internal states, no don't care symbols, and no 
structural changes, turn out so essential as to be recently rediscovered and 
reprogrammed by Q-learning adepts. Eventually, we sketch further similarities 
among ongoing work within both research contexts. The main contribution of the 
paper is therefore to make explicit the strong similarities existing between 
Q-learning and classifier systems, and to show that experience gained with 
research within one domain can be useful to direct future research in the other 
one.</blockquote> 
<p> </p> </dd> 
<dt> [261] </dt> 
<dd> Marco Dorigo and Marco Colombetti. Robot shaping: Developing autonomous 
agents through learning. Artificial Intelligence, 2:321-370, 1994. 
ftp://iridia.ulb.ac.be/pub/dorigo/journals/IJ.05-AIJ94.ps.gz.
<blockquote> Learning plays a vital role in the development of situated 
agents. In this paper, we explore the use of reinforcement learning to shape a 
robot to perform a predefined target behavior. We connect both simulated and 
real robots to ALECSYS, a parallel implementation of a learning classifier 
system with an extended genetic algorithm. After classifying different kinds of 
Animat-like behaviors, we explore the effects on learning of different types of 
agent's architecture (monolithic, flat and hierarchical) and of training 
strategies. In particular, hierarchical architecture requires the agent to 
learn how to coordinate basic learned responses. We show that the best results 
are achieved when both the agent's architecture and the training strategy match 
the structure of the behavior pattern to be learned. We report the results of a 
number of experiments carried out both in simulated and in real environments, 
and show that the results of simulations carry smoothly to real robots. While 
most of our experiments deal with simple reactive behavior, in one of them we 
demonstrate the use of a simple and general memory mechanism. As a whole, our 
experimental activity demonstrates that classifier systems with genetic 
algorithms can be practically employed to develop autonomous agents.
</blockquote> 
<p> </p> </dd> 
<dt> [262] </dt> 
<dd> Marco Dorigo and Marco Colombetti. The Role of the Trainer in 
Reinforcement Learning. In S.&nbsp;Mahadevan et&nbsp;al., editor,Proceedings of 
MLC-COLT '94 Workshop on Robot Learning, July 10th, New Brunswick, NJ, pages 
37-45, 1994.
<p> </p> </dd> 
<dt> [263] </dt> 
<dd> Marco Dorigo and Marco Colombetti. Pr&eacute;cis of Robot Shaping: An 
Experiment in Behavior Engineering.Special Issue on Complete Agent Learning in 
Complex Environments, Adaptive Behavior, 5(3-4):391-405, 1997. 
<p> </p> </dd> 
<dt> [264] </dt> 
<dd> Marco Dorigo and Marco Colombetti. Reply to Dario Floreano's 
``Engineering Adaptive Behavior''.Special Issue on Complete Agent Learning in 
Complex Environments, Adaptive Behavior, 5(3-4):417-420, 1997. 
<p> </p> </dd> 
<dt> [265] </dt> 
<dd> Marco Dorigo and Marco Colombetti. Robot Shaping: An Experiment in 
Behavior Engineering. MIT Press/Bradford Books, 1998. 
<p> </p> </dd> 
<dt> [266] </dt> 
<dd> Marco Dorigo and V.&nbsp;Maniezzo. Parallel Genetic Algorithms: 
Introduction and Overview of Current Research. In J.&nbsp;Stenders, editor,
Parallel Genetic Algorithms: Theory and Applications, Amsterdam, 1992. IOS 
Press.
<p> </p> </dd> 
<dt> [267] </dt> 
<dd> Marco Dorigo and U.&nbsp;Schnepf. Organisation of Robot Behaviour Through 
Genetic Learning Processes. InProceedings of ICAR'91 -- Fifth IEEE 
International Conference on Advanced Robotics, Pisa, Italy, pages 1456-1460. 
IEEE Press, 1991.
<p> </p> </dd> 
<dt> [268] </dt> 
<dd> Marco Dorigo and U.&nbsp;Schnepf. Genetics-based Machine Learning and 
Behaviour Based Robotics: A New Synthesis. IEEE Transactions on Systems, Man 
and Cybernetics, 23(1):141-154, 1993. 
<blockquote> Intelligent robots should be able to use sensor information to 
learn how to behave in a changing environment. As environmental complexity 
grows, the learning task becomes more and more difficult. We face this problem 
using an architecture based on learning classifier systems and on the 
structural properties of animal behavioural organization, as proposed by 
ethologists. After a description of the learning technique used and of the 
organizational structure proposed, we present experiments that show how 
behaviour acquisition can be achieved. Our simulated robot learns to follow a 
light and to avoid hot dangerous objects. While these two simple behavioural 
patterns are independently learnt, coordination is attained by means of a 
learning coordination mechanism. Again this capacity is demonstrated by 
performing a number of experiments</blockquote> 
<p> </p> </dd> 
<dt> [269] </dt> 
<dd> Marco Dorigo and E.&nbsp;Sirtori. A Parallel Environment for Learning 
Systems. InProceedings of GAA91 -- Second Italian Workshop on Machine Learning, 
Bari, Italy, 1991. 
<p> </p> </dd> 
<dt> [270] </dt> 
<dd> Marco Dorigo and Enrico Sirtori. Alecsys: A Parallel Laboratory for 
Learning Classifier Systems. InBooker and Belew [74], pages 296-302. 
<blockquote> A major problem with learning systems is how to tackle real world 
problems. A distinctive characteristic of many real world problems is that they 
present a complexity that cannot be ``user-defined'', and which is generally 
orders of magnitude higher than in toy systems. The use of more powerful, 
parallel machines, is a way to attack this problem from two sides: through an 
increase in the performance of standard algorithms, and by design of a new 
structural organization of the learning system -- organization that should 
allow a better control on the environmental complexity. In order to explore 
these potentialities we have built a tool, ALECSYS, that can be used to 
implement parallel learning classifier systems in a modular fashion. In ALECSYS 
parallelism is used both to increase the system performance, by what we call 
low-level parallelization, and to allow the use of many different learning 
classifier systems simultaneously, by what we call high-level parallelization. 
In the paper we first present the system organization and the algorithms used, 
then we report some simulation results and finally we give some hints for 
further work.</blockquote> 
<p> </p> </dd> 
<dt> [271] </dt> 
<dd> Marco Dorigo, V.&nbsp;Maniezzo, and D.&nbsp;Montanari. Classifier-based 
robot control systems. InIFAC/IFIP/IMACS International Symposium on Artificial 
Intelligence in Real-Time Control, pages 591-598, Delft, Netherlands, 1992. 
<p> </p> </dd> 
<dt> [272] </dt> 
<dd> Marco Dorigo, Mukesh&nbsp;J. Patel, and Marco Colombetti. The effect of 
Sensory Information on Reinforcement Learning by a Robot Arm. In 
M.&nbsp;Jamshidi et&nbsp;al., editor,Proceedings of ISRAM'94, Fifth 
International Symposium on Robotics and Manufacturing, August 14-18, Maui, HI, 
pages 83-88. ASME Press, 1994.
<p> </p> </dd> 
<dt> [273] </dt> 
<dd> Marco Dorigo. Message-Based Bucket Brigade: An Algorithm for the 
Apportionment of Credit Problem. In Y.&nbsp;Kodratoff, editor,Proceedings of 
European Working Session on Learning '91, Porto, Portugal, number 482 in 
Lecture notes in Artificial Intelligence, pages 235-244. Springer-Verlag, 1991.
<p> </p> </dd> 
<dt> [274] </dt> 
<dd> Marco Dorigo. New perspectives about default hierarchies formation in 
learning classifier systems. In E.&nbsp;Ardizzone, E.&nbsp;Gaglio, and 
S.&nbsp;Sorbello, editors,Proceedings of the 2nd Congress of the Italian 
Association for Artificial Intelligence (AI*IA) on Trends in Artificial 
Intelligence, volume 549 of LNAI, pages 218-227, Palermo, Italy, October 1991. 
Springer Verlag.
<blockquote> A major problem with learning systems is how to tackle real world 
problems. A distinctive characteristic of many real world problems is that they 
present a complexity that cannot be user-defined, and which is generally orders 
of magnitude higher than in toy systems. The use of more powerful, parallel 
machines, is a way to attack this problem from two sides: through an increase 
in the performance of standard algorithms, and by design of a new structural 
organization of the learning system - organization that should allow a better 
control on the environmental complexity. In order to explore these 
potentialities we have built a tool, ALECSYS, that can be used to implement 
parallel learning classifier systems in a modular fashion. In ALECSYS 
parallelism is used both to increase the system performance, by what we call 
low-level parallelization, and to allow the use of many different learning 
classifier systems simultaneously, by what we call high-level parallelization. 
In the paper we first present the system organization and the algorithms used, 
then we report some simulation results and finally we give some hints for 
further work.</blockquote> 
<p> </p> </dd> 
<dt> [275] </dt> 
<dd> Marco Dorigo. Using Transputers to Increase Speed and Flexibility of 
Genetic-based Machine Learning Systems.Microprocessing and Microprogramming, 
34:147-152, 1991.
<p> </p> </dd> 
<dt> [276] </dt> 
<dd> Marco Dorigo. Alecsys and the AutonoMouse: Learning to Control a Real 
Robot by Distributed Classifier Systems. Technical Report 92-011, Politecnico 
di Milano, 1992.
<p> </p> </dd> 
<dt> [277] </dt> 
<dd> Marco Dorigo. Optimization, Learning and Natural Algorithms. PhD thesis, 
Politecnico di Milano, Italy, 1992. (In Italian).
<p> </p> </dd> 
<dt> [278] </dt> 
<dd> Marco Dorigo. Genetic and Non-Genetic Operators in ALECSYS. Evolutionary 
Computation, 1(2):151-164, 1993. Also Technical Report TR-92-075 International 
Computer Science Institute.
<blockquote> It is well known that standard learning classifier systems, when 
applied to many different domains, exhibit a number of problems: payoff 
oscillation, difficulty in regulating interplay between the reward system and 
the background genetic algorithm (GA), rule chains' instability, default 
hierarchies' instability, among others. ALECSYS is a parallel version of a 
standard learning classifier system (CS) and, as such, suffers from these same 
problems. In this paper we propose some innovative solutions to some of these 
problems. We introduce the following original features. Mutespec is a new 
genetic operator used to specialize potentially useful classifiers. Energy is a 
quantity introduced to measure global convergence to apply the genetic 
algorithm only when the system is close to a steady state. Dynamic adjustment 
of the classifiers set cardinality speeds up the performance phase of the 
algorithm. We present simulation results of experiments run in a simulated 
two-dimensional world in which a simple agent learns to follow a light source.
</blockquote> 
<p> </p> </dd> 
<dt> [279] </dt> 
<dd> Marco Dorigo. Gli Algoritmi Genetici, i Sistemi a Classificatori e il 
Problema dell'Animat.Sistemi Intelligenti, 3(93):401-434, 1993. In Italian. 
<p> </p> </dd> 
<dt> [280] </dt> 
<dd> Marco Dorigo. Alecsys and the AutonoMouse: Learning to Control a Real 
Robot by Distributed Classifier Systems. Machine Learning, 19:209-240, 1995. 
<blockquote> In this article we investigate the feasibility of using learning 
classifier systems as a tool for building adaptive control systems for real 
robots. Their use on real robots imposes efficiency constraints which are 
addressed by three main tools: parallelism, distributed architecture, and 
training. Parallelism is useful to speed up computation and to increase the 
flexibility of the learning system design. Distributed architecture helps in 
making it possible to decompose the overall task into a set of simpler learning 
tasks. Finally, training provides guidance to the system while learning, 
shortening the number of cycles required to learn. These tools and the issues 
they raise are first studied in simulation, and then the experience gained with 
simulations is used to implement the learning system on the real robot. Results 
have shown that with this approach it is possible to let the AutonoMouse, a 
small real robot, learn to approach a light source under a number of different 
noise and lesion conditions.</blockquote> 
<p> </p> </dd> 
<dt> [281] </dt> 
<dd> Marco Dorigo. The Robot Shaping Approach to Behavior Engineering. 
Th&eacute;se d'Agr&eacute;gation de l'Enseignement Sup&eacute;rieur, 
Facult&eacute; des Sciences Appliqu&eacute;es, Universit&eacute; Libre de 
Bruxelles, pp.176, 1995.
<p> </p> </dd> 
<dt> [282] </dt> 
<dd> J.&nbsp;Drugowitsch and A.&nbsp;Barry. XCS with eligibility traces. In 
H.G. Beyer and U.M. O'Reilly, editors,Genetic and evolutionary computation 
conference, GECCO 2005, pages 1851-1858. ACM, 2005. 
<p> </p> </dd> 
<dt> [283] </dt> 
<dd> Jan Drugowitsch and Alwyn Barry. A Formal Framework and Extensions for 
Function Approximation in Learning Classifier Systems.Machine Learning, 
70(1):45-88, 2007.
<blockquote> Learning Classifier Systems (LCS) consist of the three 
components: function approximation, reinforcement learning, and classifier 
replacement. In this paper we formalize the function approximation part, by 
providing a clear problem definition, a formalization of the LCS function 
approximation architecture, and a definition of the function approximation aim. 
Additionally, we provide definitions of optimality and what conditions need to 
be fulfilled for a classifier to be optimal. As a demonstration of the 
usefulness of the framework, we derive commonly used algorithmic approaches 
that aim at reaching optimality from first principles, and introduce a new 
Kalman filter-based method that outperforms all currently implemented methods, 
in addition to providing further insight into the probabilistic basis of the 
localized model that a classifier provides. A global function approximation in 
LCS is achieved by combining the classifier's localized model, for which we 
provide a simplified approach when compared to current LCS, based on the 
Maximum Likelihood of a combination of all classifiers. The formalizations in 
this paper act as the foundation of a currently actively developed formal 
framework that includes all three LCS components, promising a better formal 
understanding of current LCS and the development of better LCS algorithms.
</blockquote> 
<p> </p> </dd> 
<dt> [284] </dt> 
<dd> Jan Drugowitsch and Alwyn&nbsp;M. Barry. A principled foundation for lcs. 
In Jaume Bacardit, Ester Bernad&oacute;-Mansilla, Martin Butz, Tim Kovacs, 
Xavier Llor&agrave;, and Keiki Takadama, editors,Learning Classifier Systems. 
10th and 11th International Workshops (2006-2007), volume 4998/2008 of Lecture 
Notes in Computer Science, pages 77-95. Springer, 2008. 
<blockquote> In this paper we promote a new methodology for designing LCS that 
is based on first identifying their underlying model and then using standard 
machine learning methods to train this model. This leads to a clear 
identification of the LCS model and makes explicit the assumptions made about 
the data, as well as promises advances in the theoretical understanding of LCS 
through transferring the understanding of the applied machine learning methods 
to LCS. Additionally, it allows us, for the first time, to give a formal and 
general, that is, representation-independent, definition of the optimal set of 
classifiers that LCS aim at finding. To demonstrate the feasibility of the 
proposed methodology we design a Bayesian LCS model by borrowing concepts from 
the related Mixtures-of-Experts model. The quality of a set of classifiers and 
consequently also the optimal set of classifiers is defined by the application 
of Bayesian model selection, which turns finding this set into a principled 
optimisation task. Using a simple Pittsburgh-style LCS, a set of preliminary 
experiments demonstrate the feasibility of this approach.</blockquote> 
<p> </p> </dd> 
<dt> [285] </dt> 
<dd> Jan Drugowitsch. Design and Analysis of Learning Classifier Systems: A 
Probabilistic Approach. Springer, 2008. 
<blockquote> This book provides a comprehensive introduction to the design and 
analysis of Learning Classifier Systems (LCS) from the perspective of machine 
learning. LCS are a family of methods for handling unsupervised learning, 
supervised learning and sequential decision tasks by decomposing larger problem 
spaces into easy-to-handle subproblems. Contrary to commonly approaching their 
design and analysis from the viewpoint of evolutionary computation, this book 
instead promotes a probabilistic model-based approach, based on their defining 
question &quot;What is an LCS supposed to learn?&quot;. Systematically 
following this approach, it is shown how generic machine learning methods can 
be applied to design LCS algorithms from the first principles of their 
underlying probabilistic model, which is in this book -- for illustrative 
purposes -- closely related to the currently prominent XCS classifier system. 
The approach is holistic in the sense that the uniform goal-driven design 
metaphor essentially covers all aspects of LCS and puts them on a solid 
foundation, in addition to enabling the transfer of the theoretical foundation 
of the various applied machine learning methods onto LCS. Thus, it not only 
advances the analysis of existing LCS but also puts forward the design of new 
LCS within that same framework.</blockquote> 
<p> </p> </dd> 
<dt> [286] </dt> 
<dd> Barry&nbsp;B. Druhan and Robert&nbsp;C. Mathews. THIYOS: A Classifier 
System Model of Implicit Knowledge in Artificial Grammars. InProc. Ann. Cog. 
Sci. Soc., 1989. 
<p> </p> </dd> 
<dt> [287] </dt> 
<dd> D.&nbsp;Dumitrescu, B.&nbsp;Lazzerini, L.&nbsp;C. Jain, and 
A.&nbsp;Dumitrescu.Evolutionary Computation. CRC Press International, 2000. 
<p> </p> </dd> 
<dt> [288] </dt> 
<dd> Daniel Eckert and Johann Mitl&ouml;hner. Modelling individual and 
endogenous learning in games: the relevance of classifier systems. InComplex 
Modelling for Socio-Economic Systems, SASA, Vienna, 1997. 
<p> </p> </dd> 
<dt> [289] </dt> 
<dd> Daniel Eckert, Johann Mitl&ouml;hner, and Makus Moschner. Evolutionary 
stability issues and adaptive learning in classifier systems. In OR'97 
Conference on Operations Research, Vienna, 1997. 
<blockquote> This work has no abstract. </blockquote> 
<p> </p> </dd> 
<dt> [290] </dt> 
<dd> Narayanan Edakunni, Tim Kovacs, Gavin Brown, and James Marshall. Modeling 
UCS as a mixture of experts. In Proceedings of the 2009 Genetic and 
Evolutionary Computation Conference (GECCO'09). ACM, 2009. 
<blockquote> We present a probabilistic formulation of UCS (a sUpervised 
Classifier System). UCS is shown to be a special case of mixture of experts 
where the experts are learned independently and later combined during 
prediction. In this work, we develop the links between the constituent 
components of UCS and a mixture of experts, thus lending UCS a strong 
analytical background. We find during our analysis that mixture of experts is a 
more generic formulation of UCS and possesses more generalization capability 
and flexibility than UCS, which is also verified using empirical evaluations. 
This is the first time that a simple probabilistic model has been proposed for 
UCS and we believe that this work will form a useful tool to analyse Learning 
Classifier Systems and gain useful insights into their working.</blockquote> 
<p> </p> </dd> 
<dt> [291] </dt> 
<dd> A.&nbsp;E. Eiben and J.&nbsp;E. Smith. Introduction to evolutionary 
computation. Natural computing series. Springer-Verlag, 2003. 
<p> </p> </dd> 
<dt> [292] </dt> 
<dd> Emergent Computation. Proceedings of the Ninth Annual International 
Conference of the Center for Nonlinear Studies on Self-organizing, Collective, 
and Cooperative Phenomena in Natural and Artificial Computing Networks. A 
special issue of Physica D. Stephanie Forrest (Ed.), 1990.
<p> </p> </dd> 
<dt> [293] </dt> 
<dd> G.&nbsp;Enee and C.&nbsp;Escazut. Classifier systems evolving multi-agent 
system with distributed elitism. InAngeline et&nbsp;al. [8], pages 1740-1745. 
<p> </p> </dd> 
<dt> [294] </dt> 
<dd> G.&nbsp;Enee and C.&nbsp;Escazut. A minimal model of communication for a 
multi-agent classifier system. InLanzi et&nbsp;al. [546], pages 32-42. 
<p> </p> </dd> 
<dt> [295] </dt> 
<dd> Cathy Escazut and Philippe Collard. Learning Disjunctive Normal Forms in 
a Dual Classifier System. In Nada Lavrac and Stefan Wrobel, editors,Proceedings 
of the 8th European Conference on Machine Learning, volume 912 of LNAI, pages 
271-274. Springer, 1995.
<p> </p> </dd> 
<dt> [296] </dt> 
<dd> Cathy Escazut and Terence&nbsp;C. Fogarty. Coevolving Classifier Systems 
to Control Traffic Signals. In John&nbsp;R. Koza, editor,Late Breaking Papers 
at the 1997 Genetic Programming Conference, Stanford University, CA, USA, July 
1997. Stanford Bookstore.
<p> </p> </dd> 
<dt> [297] </dt> 
<dd> Cathy Escazut, Philippe Collard, and Jean-Louis Cavarero. Dynamic 
Management of the Specificity in Classifier Systems. InAlbrecht et&nbsp;al. [7]
, pages 484-491.
<blockquote> The estimation of the rule usefulness in a classifier system is 
faced to the credit-apportionment problem. Usually, the apportioning of payoffs 
process is performed by the bucket brigade algorithm. However, some works have 
shown that this algorithm presents some difficulties. Generally, the condition 
part of a rule is defined on an alphabet containing a ``don't care'' symbol. 
That is why a same rule can be fired in different contexts. In such conditions, 
it is impossible to use too generalized classifiers because of the incoherence 
of the strength management. The solution we propose here, can solve the 
problem: general classifiers belonging to a success-ending sequence are 
dynamically specialized. In order not to store all the sequence actions, the 
Bucket Brigade algorithm is applied to the new-created rule specificity. So, 
the closer a classifier is from the end of the solution sequence, the more 
specific it is. This new algorithm is presented here and applied to an 
autonomous moving robot which must learn how to move in an environment with 
obstacles.</blockquote> 
<p> </p> </dd> 
<dt> [298] </dt> 
<dd> Larry&nbsp;J. Eshelman, editor. Proceedings of the 6th International 
Conference on Genetic Algorithms (ICGA95). Morgan Kaufmann Publishers, 1995. 
<p> </p> </dd> 
<dt> [299] </dt> 
<dd> J.&nbsp;A.&nbsp;Meyer et&nbsp;al., editor. From Animals to Animats 6: 
Proceedings of the Sixth International Conference on Simulation of Adaptive 
Behavior, 2000. 
<p> </p> </dd> 
<dt> [300] </dt> 
<dd> Andrew Fairley and Derek&nbsp;F. Yates. Improving Simple Classifier 
Systems to alleviate the problems of Duplication, Subsumption and Equivalence 
of Rules. InAlbrecht et&nbsp;al. [7], pages 408-416. 
<blockquote> For new, potentially improved rules that is, the search performed 
by a classifier system's genetic algorithm is guided by the relative strength 
of the rules in the extant rule base. This paper identifies three general types 
of rule whose presence in a plan can affect the relative strength of rules in a 
rule base and thereby provide the potential to compromise the effectiveness of 
the genetic algorithm. The nature and extent of relative strength distortion is 
investigated and a method to combat the distortion which involves adaptation of 
the standard bucket brigade, is proposed.</blockquote> 
<p> </p> </dd> 
<dt> [301] </dt> 
<dd> Andrew Fairley and Derek&nbsp;F. Yates. Inductive Operators and Rule 
Repair in a Hybrid Genetic Learning System: Some Initial Results. InFogarty 
[324], pages 166-179. 
<blockquote> Symbolic knowledge representation schemes have been suggested as 
one way to improve the performance of classifier systems in the context of 
complex, real-world problems. The main reason for this is that unlike the 
traditional binary string representation, high-level languages facilitate the 
exploitation of problem specific knowledge. However, the two principle genetic 
operators, crossover and mutation, are, in their basic form, ineffective with 
regard to discovering useful rules in such representations. Moreover, the 
operators do not take into account any environmental cues which may benefit the 
rule discovery process. A further source of inefficiency in classifier systems 
concerns their capacity for forgetting valuable experience by deleting 
previously useful rules. In this paper, solutions to both these problems are 
addressed. First, in respect of the suitability of crossover and mutation, a 
new set of operators, specifically tailored for a high level language, are 
proposed. Moreover, to alleviate the problem of forgetfulness, an approach 
based on the way some enzyme systems facilitate the repair of genes in 
biological systems, is investigated.</blockquote> 
<p> </p> </dd> 
<dt> [302] </dt> 
<dd> I.&nbsp;De Falco, A.&nbsp;Iazzetta, E.&nbsp;Tarantino, and A.&nbsp;Della 
Cioppa. An evolutionary system for automatic explicit rule extraction. In
Proceedings of the 2000 Congress on Evolutionary Computation (CEC00) [185], 
pages 450-457.
<blockquote> The search for novel and useful patterns within large databases, 
known as data mining, has become of great importance owing to the 
ever-increasing amounts of data collected by large organizations. In particular 
the emphasis is devoted to heuristic search methods able to discover patterns 
that are hard or impossible to detect using standard query mechanisms and 
classicial statistical techniques. In this paper an evolutionary system capable 
of extracting explicit classification rules is presented. The results are 
compared with those obtained by other approaches.</blockquote> 
<p> </p> </dd> 
<dt> [303] </dt> 
<dd> William&nbsp;Joseph Falke II and Peter Ross. Dynamic strategies in a 
real-time strategy game. In E.&nbsp;Cant&uacute;-Paz, J.&nbsp;A. Foster, 
K.&nbsp;Deb, D.&nbsp;Davis, R.&nbsp;Roy, U.-M. O'Reilly, H.-G. Beyer, 
R.&nbsp;Standish, G.&nbsp;Kendall, S.&nbsp;Wilson, M.&nbsp;Harman, 
J.&nbsp;Wegener, D.&nbsp;Dasgupta, M.&nbsp;A. Potter, A.&nbsp;C. Schultz, 
K.&nbsp;Dowsland, N.&nbsp;Jonoska, and J.&nbsp;Miller, editors,Genetic and 
Evolutionary Computation -- GECCO-2003, LNCS, pages 1920-1921. Springer-Verlag, 
2003.
<p> </p> </dd> 
<dt> [304] </dt> 
<dd> J.&nbsp;Doyne Farmer, N.&nbsp;H. Packard, and A.&nbsp;S. Perelson. The 
Immune System, Adaptation &amp; Learning.Physica D, 22:187-204, 1986. 
<p> </p> </dd> 
<dt> [305] </dt> 
<dd> J.&nbsp;Doyne Farmer. A Rosetta Stone for Connectionism. In Special issue 
of Physica D (Vol. 42) [292], pages 153-187. 
<blockquote> The term connectionism is usually applied to neural networks. 
There are, however, many other models that are mathematically similar, 
including classifier systems, immune networks, autocatalytic chemical reaction 
networks, and others. In view of this similarity, it is appropriate to broaden 
the term connectionism. I define a connectionist model as a dynamical system 
with two properties: (1) The interactions between the variables at any given 
time are explicitly constrained to a finite list of connections. (2) The 
connections are fluid, in that their strength and/or pattern of connectivity 
can change with time. This paper reviews the four examples listed above and 
maps them into a common mathematical framework, discussing their similarities 
and differences. It also suggests new applications of connectionist models, and 
poses some problems to be addressed in an eventual theory of connectionist 
systems.</blockquote> 
<p> </p> </dd> 
<dt> [306] </dt> 
<dd> Francine Federman and Susan&nbsp;Fife Dorchak. Information Theory and 
NEXTPITCH: A Learning Classifier System. InB&auml;ck [24], pages 442-449. 
<blockquote> NEXTPITCH, a learning classifier system using genetic algorithms, 
inductively learns to predict the next note in a childhood melody. Just as a 
listener develops expectations of what is to follow based on what has been 
heard, NEXTPITCH models human music learning by developing the rules that 
represent actual pitch transitions in the melody. This paper introduces our 
representation of music and our description of classifier formats. Our results 
are correlated by analysis of variance statistical routines. Information theory 
is used to partition melodies into classes so that we may examine the 
applicability of the results from one set of melodies to another.</blockquote> 
<p> </p> </dd> 
<dt> [307] </dt> 
<dd> Francine Federman and Susan&nbsp;Fife Dorchak. Representation of Music in 
a Learning Classifier System. In Rad and Skowron, editors,Foundations of 
Intelligent Systems: Proceedings 10th International Symposium (ISMIS'97). 
Springer-Verlag: Heidelberg, 1997.
<p> </p> </dd> 
<dt> [308] </dt> 
<dd> Francine Federman and Susan&nbsp;Fife Dorchak. A Study of Classifier 
Length and Population Size. InKoza et&nbsp;al. [529], pages 629-634. 
<p> </p> </dd> 
<dt> [309] </dt> 
<dd> Francine Federman, Gayle Sparkman, and Stephanie Watt. Representation of 
Music in a Learning Classifier System Utilizing Bach Chorales. InBanzhaf 
et&nbsp;al. [32], page 785. One page poster paper. 
<blockquote> This paper addresses the question of the impact of the 
representation of a domain on the performance in a learning classifier system. 
NEXTPITCH, a learning classifier system using genetic algorithms, inductively 
learns to predict the next note of a Bach chorale. This paper presents an 
analyses of different representations of specific features of Western tonal 
music. Our results are correlated by analyses of variance statistical routines.
</blockquote> 
<p> </p> </dd> 
<dt> [310] </dt> 
<dd> Francine Federman. NEXTNOTE: A Learning Classifier System. In 
Annie&nbsp;S. Wu, editor,Proceedings of the Genetic and Evolutionary 
Computation Conference Workshop Program, pages 136-138, 2000. 
<blockquote> NEXTPITCH, a learning classifier system (LCS) using genetic 
algorithms, inductively learns to predict the next note in a melody. This paper 
addresses the issues of (1) the impact of the representation of a domain on the 
performance of an LCS and (2) the classification of the input to an LCS in 
order to determine performance.</blockquote> 
<p> </p> </dd> 
<dt> [311] </dt> 
<dd> Thomas Fent. Applications of Learning Classifier Systems for Simulating 
Learning Organizations, volume&nbsp;10 of Fortschrittsberichte Simulation. 
ARGESIM / ASIM-Verlag, Wien, September 2001.
<blockquote> In the field of mathematical modelling of economic phenomena 
analytical models, assuming the existence of a stable equilibrium, are very 
popular. It is often expected, that the quantities defining the state of the 
system gradually approach to the equilibrium, and remain there in the 
following. Moreover, it is often assumed, that the interacting individuals 
behave perfectly rational --- i.e they always take those decisions, that 
maximize their utility. Such approaches, however, have only limited suitability 
for modelling economic systems subject to a permanent and succesively 
accelerated change. Moreover, they are only partially capable to describe 
individuals that do not only possess intelligence but also emotions. Therefore, 
the theory of<em>complex adaptive systems</em> applies computer simulations 
whose implementations does not necessaryly depend on the existence of 
equilibria or perfectly ratinal agents. At the beginning of this thesis the 
necessity and the practicality of the employment of<em>complex adaptive systems
</em> for describing recent economic happenings is discussed. Then methods that 
are qualified to implement such systems --- in particular classifier systems 
and genetic algorithms --- are being explained. In the following some examples 
are provided to illustrate possibilities and also restrictions of the usage of 
such procedures. Based on this elaborations two comprehensive economic models 
are formulated. The first model is about the problem of communication within a 
firm developing a new product. In big enterprises it is often a big challenge 
to establish an effective and efficient flow of information. Moreover, in 
distributed decision making processes conflicting objectives may occur. Many 
different groups of employees are cooperating in the process of designing a new 
product. The tasks reqired to successfully introduce a new product involve 
employees from market research, engineering, scheduling, maintenance, and many 
others. These people may possess different viewpoints and different technical 
languages. To solve this problem citep *hauser suggested a communication scheme 
called<em>``House of Quality''</em>. This thesis introduces a simulation based 
on the<em>``House of Quality''</em>, which was implemented in MATLAB. The 
decision makers are implemented as classifier systems, and apply genetic 
algorithms to learn a meaningful solution. To evaluate the rules generated by 
this adaptive learning process, the obtained results are compared with the 
results gained by full enumeration. It turns out that the genetic algorithms 
indeed create pretty good decision rules. These rules illustrate how the 
responsible individuals should react to the encountered situations. The second 
model examines a heterogenous market of goods that can be substituted for each 
other. The task of the learning agents is to place there products in the market 
such that the number of customers who buy their products is maximized. Four 
classes of different agents occur in this market. Two of these groups contain 
learning agents. The first group observes the positions (= the needs) of the 
customers directly. The second group observes the positions of the suppliers 
and their profits. The decisions for the next planning period are based on 
these observations. Additionally, there is a group of suppliers placing their 
products according to a<em>``random walk''</em>, and another supplier who 
always takes over the position of the most successful seller of the previous 
period. To compare these strategies three different behaviour patterns of the 
demand side are taken into consideration: i) static, ii) cyclic, and iii) 
random walk. To allow accurate conclusions about the relation between customer 
behaviour and the success of a certain selling strategy, all the customers 
exhibit the same behaviour pattern within one particular simulation. It turned 
out, that in the cases i) and iii) the strategy of imitating the most 
successful seller is optimal --- under the assumption, that only one supplier 
follows that strategy. If the customers behave according to ii), on the other 
hand, the agents observing the customers directly are the winners.</blockquote> 
<p> </p> </dd> 
<dt> [312] </dt> 
<dd> Rhonda Ficek. Genetic Algorithms. Technical Report NDSU-CS-TR-90-51, 
North Dakota State University. Computer Science and Operations Research, 1997.
<blockquote> Genetic algorithms are generating a great deal of interest today. 
They take their inspiration from the ways plants and animals evolve. Developed 
by John Holland, genetic algorithms use the ideas and language of genetics -- 
genes, chromosomes, mutations, etc. Holland's unique method for performing 
adaptive searches has received a great deal of attention, and numerous 
applications which make use of genetic algorithms have been developed. The 
algorithm behind evolution solves the problem of producing species able to 
thrive in particular environments. This same genetic algorithm can solve many 
other kinds of problems as well. It forms the basis of an emerging field of 
computer programming that could challenge expert systems. Research is under way 
on adapting the genetic algorithm to such applications as running pump stations 
on oil pipelines, eliminating distortion from x-ray images, and designing 
very-large-scale integrated (VLSI) computer chips. This paper begins with an 
overview of genetic algorithms, followed by a summary of the history of their 
development. The next three sections of the paper discuss the major areas of 
genetic algorithm research: applications of genetic algorithms, theoretical 
work, and classifier systems. Next, genetic algorithms are compared to other 
related methods, and their strengths are discussed. The final section discusses 
the future of genetic algorithms.</blockquote> 
<p> </p> </dd> 
<dt> [313] </dt> 
<dd> M.&nbsp;V. Fidelis, H.&nbsp;S. Lopes, and A.&nbsp;A. Freitas. Discovering 
comprehensible classification rules with a genetic algorithm. InProceedings of 
the 2000 Congress on Evolutionary Computation (CEC00) [185], pages 805-810. 
<p> </p> </dd> 
<dt> [314] </dt> 
<dd> Gary&nbsp;William Flake. The Computational Beauty of Nature. MIT Press, 
1998. (Contains a chapter on ZCS).
<p> </p> </dd> 
<dt> [315] </dt> 
<dd> Peter Fletcher. Simulating the use of `fiat money' in a simple commodity 
economy. Master's thesis, Schools of Psychology and Computer Science, 
University of Birmingham, 1996.
<blockquote> This project simulates a simple commodity economy in which 
artificially intelligent adaptive agents learn to trade with one another. Two 
versions of the economy are studied in detail. The first consists of three 
types of agent and three types of commodity, and the second version includes 
the addition of `fiat money'. The agents make decisions using a classifier 
system, capable of being rewarded and punished according to the relative 
success of the economic strategies generated. The economic environment that the 
agents inhabit is taken from Marimon et al(1989) but a different classifier 
system is used, to investigate whether an alternative implementation affects 
the results of the simulation. The results were not fully replicated, and the 
differences between the two implementations are analysed, giving rise to novel 
observations about the environment and the original research.</blockquote> 
<p> </p> </dd> 
<dt> [316] </dt> 
<dd> Terence&nbsp;C. Fogarty and Luis&nbsp;Miramontes Hercog. Social 
simulation using a multi-agent model based on classifier systems: The emergence 
of switching agents in the dual pub problem. In Erik&nbsp;D. Goodman, editor,
2001 Genetic and Evolutionary Computation Conference Late Breaking Papers, 
pages 87-94, 2001.
<p> </p> </dd> 
<dt> [317] </dt> 
<dd> Terence&nbsp;C. Fogarty, Brian Carse, and Larry Bull. Classifier Systems 
-- recent research.AISB Quarterly, 89:48-54, 1994. 
<blockquote> We consider; the role of selectionist reinforcement learning in 
classifier systems; the fuzzy matching and activation of rules, and the 
evolution of communication within and between classifier systems.</blockquote> 
<p> </p> </dd> 
<dt> [318] </dt> 
<dd> Terence&nbsp;C. Fogarty, Larry Bull, and Brian Carse. Evolving 
Multi-Agent Systems. In J.&nbsp;Periaux and G.&nbsp;Winter, editors,Genetic 
Algorithms in Engineering and Computer Science, pages 3-22. John Wiley &amp; 
Sons, 1995.
<p> </p> </dd> 
<dt> [319] </dt> 
<dd> Terence&nbsp;C. Fogarty, Brian Carse, and Larry Bull. Classifier Systems: 
selectionist reinforcement learning, fuzzy rules and communication. Presented 
at the First International Workshop on Biologically Inspired Evolutionary 
Systems, Tokyo, 1995.
<p> </p> </dd> 
<dt> [320] </dt> 
<dd> Terence&nbsp;C. Fogarty, N.&nbsp;S. Ireson, and Larry Bull. Genetic-based 
Machine Learning -- Applications in Industry and Commerce. In Vic 
Rayward-Smith, editor,Applications of Modern Heuristic Methods, pages 91-110. 
Alfred Waller Ltd, 1995.
<blockquote> This paper describes how genetic algorithms are being used to 
engineer control and classification systems for industrial and commercial 
applications. Using multiple burner combustion control and credit risk 
assessment as examples it illustrates how expert human knowledge can be 
complemented by searching large amounts of data using genetic algorithms in 
knowledge-based machine learning systems. It goes on to discuss recent research 
on parallel and distributed genetic algorithms aimed at tackling large complex 
problems.</blockquote> 
<p> </p> </dd> 
<dt> [321] </dt> 
<dd> Terence&nbsp;C. Fogarty, Brian Carse, and A.&nbsp;Munro. Artificial 
evolution of fuzzy rule bases which represent time: A temporal fuzzy classifier 
system.International Journal of Intelligent Systems, 13(10-11):906-927, 1998. 
<p> </p> </dd> 
<dt> [322] </dt> 
<dd> T.C. Fogarty. An incremental genetic algorithm for real-time learning. In 
Proc. Sixth Int. Workshop on Machine Learning, pages 416-419, 1989. 
<p> </p> </dd> 
<dt> [323] </dt> 
<dd> Terence&nbsp;C. Fogarty. Co-evolving Co-operative Populations of Rules in 
Learning Control Systems. InEvolutionary Computing, AISB Workshop Selected 
Papers [324], pages 195-209. 
<blockquote> It is shown how co-evolving populations of individual rules can 
outperform evolving a population of complete sets of rules with the genetic 
algorithm in learning classifier systems. A rule-based control system is 
presented which uses only the genetic algorithm for learning individual control 
rules with immediate reinforcement after the firing of each rule. How this has 
been used for an industrial control problem is described as an example of its 
operation. The refinement of the system to deal with delayed reward is 
presented and its operation on the cart-pole balancing problem described. A 
comparison is made of the performance of the refined system using only 
selection and mutation to learn individual rules with that of the genetic 
algorithm to learn a complete set of rules. A comparison is also made of the 
performance of the refined system using only selection to learn individual 
rules with that of the bucket-brigade and other reinforcement algorithms on the 
same task.</blockquote> 
<p> </p> </dd> 
<dt> [324] </dt> 
<dd> Terence&nbsp;C. Fogarty, editor. Evolutionary Computing, AISB Workshop 
Selected Papers, number 865 in Lecture Notes in Computer Science. 
Springer-Verlag, 1994.
<p> </p> </dd> 
<dt> [325] </dt> 
<dd> Terence&nbsp;C. Fogarty. Learning new rules and adapting old ones with 
the genetic algorithm. In G.&nbsp;Rzevski, editor,Artificial Intelligence in 
Manufacturing, pages 275-290. Springer-Verlag, 1994. 
<p> </p> </dd> 
<dt> [326] </dt> 
<dd> Terence&nbsp;C. Fogarty. Optimising Individual Control Rules and Multiple 
Communicating Rule-based Control Systems with Parallel Distributed Genetic 
Algorithms.IEE Journal of Control Theory and Applications, 142(3):211-215, 1995.
<p> </p> </dd> 
<dt> [327] </dt> 
<dd> Terence&nbsp;C. Fogarty. Genetic algorithms for the optimization of 
combustion in multiple-burner furnaces and boiler plants. In Thomas B&auml;ck, 
David&nbsp;B. Fogel, and Zbigniew Michalewicz, editors,Handbook of Evolutionary 
Computation, pages G3.2:1-G3.2:7. IOP Publishing Ltd and Oxford University 
Press, 1997.
<p> </p> </dd> 
<dt> [328] </dt> 
<dd> David&nbsp;B. Fogel. Evolutionary Computation. The Fossil Record. 
Selected Readings on the History of Evolutionary Computation, chapter 16: 
Classifier Systems. IEEE Press, 1998. This is a reprint of (Holland and 
Reitman, 1978), with an added introduction by Fogel.
<p> </p> </dd> 
<dt> [329] </dt> 
<dd> Stephanie Forrest and John&nbsp;H. Miller. Emergent behavior in 
classifier systems. InSpecial issue of Physica D (Vol. 42) [292], pages 213-217.
<blockquote> The paper presents examples of emergent behavior in classifier 
systems, focusing on symbolic reasoning and learning. These behaviors are 
related to global dynamical properties such as state cycles, basins of 
attraction, and phase transitions. A mapping is defined between classifier 
systems and an equivalent dynamical system (Boolean networks). The mapping 
provides a way to understand and predict emergent classifier system behaviors 
by observing the dynamical behavior of the Boolean networks. The paper reports 
initial results and discusses the implications of this approach for classifier 
systems.</blockquote> 
<p> </p> </dd> 
<dt> [330] </dt> 
<dd> Stephanie Forrest, Robert&nbsp;E. Smith, and A.&nbsp;Perelson. 
Maintaining diversity with a genetic algorithm. InCollected Abstracts for the 
First International Workshop on Learning Classifier System (IWLCS-92) [486]. 
October 6-8, NASA Johnson Space Center, Houston, Texas.
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [331] </dt> 
<dd> Stephanie Forrest. A study of parallelism in the classifier system and 
its application to classification in KL-ONE semantic networks. PhD thesis, 
University of Michigan, Ann Arbor, MI, 1985.
<p> </p> </dd> 
<dt> [332] </dt> 
<dd> Stephanie Forrest. Implementing semantic network structures using the 
classifier system. InGrefenstette [389], pages 24-44. 
<p> </p> </dd> 
<dt> [333] </dt> 
<dd> Stephanie Forrest. The Classifier System: A Computational Model that 
Supports Machine Intelligence. InInternational Conference on Parallel Processing
, pages 711-716, Los Alamitos, Ca., USA, August 1986. IEEE Computer Society 
Press.
<p> </p> </dd> 
<dt> [334] </dt> 
<dd> Stephanie Forrest. Parallelism and Programming in Classifier Systems. 
Pittman, London, 1991.
<p> </p> </dd> 
<dt> [335] </dt> 
<dd> Stephanie Forrest, editor. Proceedings of the 5th International 
Conference on Genetic Algorithms (ICGA93). Morgan Kaufmann, 1993. 
<p> </p> </dd> 
<dt> [336] </dt> 
<dd> Richard Forsyth. Machine Learning: Applications in expert systems and 
information retrival, chapter Evolutionary Learning Strategies, pages 78-95. 
Ellis Horwood Limited, 1986.
<p> </p> </dd> 
<dt> [337] </dt> 
<dd> Peter&nbsp;W. Frey and David&nbsp;J. Slate. Letter Recognition Using 
Holland-Style Adaptive Classifiers.Machine Learning, 6:161-182, 1991. 
<blockquote> Machine rule induction was examined on a difficult categorization 
problem by applying a Holland-style classifier system to a complex letter 
recognition task. A set of 20,000 unique letter images was generated by 
randomly distorting pixel images of the 26 uppercase letters from 20 different 
commercial fonts. The parent fonts represented a full range of character types 
including script, italic, serif, and Gothic. The features of each of the 20,000 
characters were summarized in terms of 16 primitive numerical attributes. Our 
research focused on machine induction techniques for generating IF-THEN 
classifiers in which the IF part was a list of values for each of the 16 
attributes and the THEN part was the correct category, i.e., one of the 26 
letters of the alphabet. We examined the effects of different procedures for 
encoding attributes, deriving new rules, and apportioning credit among the 
rules. Binary and Gray-code attribute encodings that required exact matches for 
rule activation were compared with integer representations that employed fuzzy 
matching for rule activation. Random and genetic methods for rule creation were 
compared with instance-based generalization. The strength/specificity method 
for credit apportionment was compared with a procedure we call 
``accuracy/utility.''</blockquote> 
<p> </p> </dd> 
<dt> [338] </dt> 
<dd> Chunsheng Fu and Lawrence Davis. A modified classifier system compaction 
algorithm. In W.&nbsp;B. Langdon, E.&nbsp;Cant&uacute;-Paz, K.&nbsp;Mathias, 
R.&nbsp;Roy, D.&nbsp;Davis, R.&nbsp;Poli, K.&nbsp;Balakrishnan, 
V.&nbsp;Honavar, G.&nbsp;Rudolph, J.&nbsp;Wegener, L.&nbsp;Bull, M.&nbsp;A. 
Potter, A.&nbsp;C. Schultz, J.&nbsp;F. Miller, E.&nbsp;Burke, and 
N.&nbsp;Jonoska, editors,GECCO 2002: Proceedings of the Genetic and 
Evolutionary Computation Conference, pages 920-925. Morgan Kaufmann Publishers, 
2002.
<p> </p> </dd> 
<dt> [339] </dt> 
<dd> Chunsheng Fu, Stewart&nbsp;W. Wilson, and Lawrence Davis. Studies of the 
xcsi classifier system on a data mining problem. In Lee Spector, Erik&nbsp;D. 
Goodman, Annie Wu, W.B. Langdon, Hans-Michael Voigt, Mitsuo Gen, Sandip Sen, 
Marco Dorigo, Shahram Pezeshk, Max&nbsp;H. Garzon, and Edmund Burke, editors,
Proceedings of the Genetic and Evolutionary Computation Conference (GECCO-2001)
, page 985, San Francisco, California, USA, 7-11 July 2001. Morgan Kaufmann.
<p> </p> </dd> 
<dt> [340] </dt> 
<dd> Leeann&nbsp;L. Fu. The XCS Classifier System and Q-learning. In 
John&nbsp;R. Koza, editor,Late Breaking Papers at the Genetic Programming 1998 
Conference, University of Wisconsin, Madison, Wisconsin, USA, 1998. Stanford 
University Bookstore.
<p> </p> </dd> 
<dt> [341] </dt> 
<dd> Leeann&nbsp;L. Fu. What I have come to understand about classifier 
systems, 1998. Unpublished document. Dept. of Electrical Engineering and 
Computer Science. University of Michigan.
<blockquote> This document has no abstract. </blockquote> 
<p> </p> </dd> 
<dt> [342] </dt> 
<dd> Takeshi Furuhashi, Ken Nakaoka, Koji Morikawa, and Yoshiki Uchikawa. 
Controlling Excessive Fuzziness in a Fuzzy Classifier System. InForrest [335], 
pages 635-635.
<p> </p> </dd> 
<dt> [343] </dt> 
<dd> T.&nbsp;Furuhashi, K.&nbsp;Nakaoka, and Y.&nbsp;Uchikawa. An efficient 
finding of fuzzy rules using a new approach to genetic based machine learning. 
InProceedings Fourth IEEE International Conference on Fuzzy Systems, pages 
715-722. IEEE Computer Press, 1995.
<p> </p> </dd> 
<dt> [344] </dt> 
<dd> Takeshi Furuhashi, Ken Nakaoka, and Yoshiki Uchikawa. A Study on Fuzzy 
Classifier System for Finding Control Knowledge of Multi-Input Systems. In
Herrera and Verdegay [423], pages 489-502. 
<blockquote> This paper details our attempt to find control knowledge of 
multi-input systems using a Fuzzy Classifier System (FCS). Simulations are done 
to show that the FCS can find fuzzy rules for collision avoidance in steering a 
ship. This paper presents new payoffs and credits for building antecedent parts 
of fuzzy rules which have truth values larger than zero and for finding fuzzy 
control rules which achieve the collision avoidance steering. The results show 
that the FCS can discover fuzzy rules for the multi-input system.</blockquote> 
<p> </p> </dd> 
<dt> [345] </dt> 
<dd> Takeshi Furuhashi. A Proposal of Hierarchical Fuzzy Classifier Systems. In
Forrest [335]. 
<p> </p> </dd> 
<dt> [346] </dt> 
<dd> Michelle Galea and Qiang Shen. Evolutionary approaches to fuzzy rule 
induction. In Jonathan&nbsp;M. Rossiter and Trevor&nbsp;P. Martin, editors,
Proceedings of the 2003 UK Workshop on Computational Intelligence (UKCI-03), 
pages 205-216, 2003.
<p> </p> </dd> 
<dt> [347] </dt> 
<dd> Yang Gao, Joshua&nbsp;Zhexue Huang, Hongqiang Rong, and Da&nbsp;qian Gu. 
LCSE: Learning Classifier System Ensemble for Incremental Medical Instances. In 
Tim Kovacs, Xavier LL&ograve;ra, Keiki Takadama, Pier&nbsp;Luca Lanzi, Wolfgang 
Stolzmann, and Stewart&nbsp;W. Wilson, editors,Learning Classifier Systems. 
International Workshops, IWLCS 2003-2005, Revised Selected Papers, volume 4399 
ofLNCS, pages 93-103. Springer, 2007. 
<p> </p> </dd> 
<dt> [348] </dt> 
<dd> Santiago Garcia, Fermin Gonzalez, and Luciano Sanchez. Evolving Fuzzy 
Rule Based Classifiers with GA&Acirc;&shy;P: A Grammatical Approach. In 
Riccardo Poli, Peter Nordin, William&nbsp;B. Langdon, and Terence&nbsp;C. 
Fogarty, editors,Genetic Programming, Proceedings of EuroGP'99, volume 1598 of 
LNCS, pages 203-210, Goteborg, Sweden, May 1999. Springer-Verlag. 
<p> </p> </dd> 
<dt> [349] </dt> 
<dd> Chris Gathercole. A Classifier System Plays a Simple Board Game. Master's 
thesis, Department of AI, University of Edinburgh, U.K., 1993.
<blockquote> A description of the problems, successes and failures encountered 
whilst attempting to encourage a Classifier System to learn to play a simple 
board game well. Classifier Systems are a kind of free-for-all Production Rule 
System where the pattern-matching rules compete on the basis of their 
(modifiable) strength values, and the population of rules is altered by a 
Genetic Algorithm. They have shown promise in problems where there is very 
little specific, (i.e. useful) information available from the environment, and 
the internal adjustments proceed without explicit direction from the 
environment (or the programmer). In this thesis an attempt is made to `coerce' 
a variant of Goldberg's Simple Classifier System to `learn' how to play a 
simple board game (called Dodgems). Various options were tried , among them 
were: different internal representations, adding more powerful move operators, 
forcing every move to be valid, and others... The results, whilst not 
startling, do indicate increased performance with the use of the enhanced move 
operators over the initial representations. Larger population sizes appear to 
be beneficial. Also, there is a discussion of the problems involved in choosing 
the relevant data to study the internal workings of the Classifier System.
</blockquote> 
<p> </p> </dd> 
<dt> [350] </dt> 
<dd> Pierre Gerard and Olivier Sigaud. Combining Anticipation and Dynamic 
Programming in Classifier Systems. InProceedings of the International Workshop 
on Learning Classifier Systems (IWLCS-2000), in the Joint Workshops of SAB 2000 
and PPSN 2000 [487]. Extended abstract. 
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [351] </dt> 
<dd> Pierre Gerard and Olivier Sigaud. Adding a generalization mechanism to 
YACS. In Lee Spector, Erik&nbsp;D. Goodman, Annie Wu, W.B. Langdon, 
Hans-Michael Voigt, Mitsuo Gen, Sandip Sen, Marco Dorigo, Shahram Pezeshk, 
Max&nbsp;H. Garzon, and Edmund Burke, editors,Proceedings of the Genetic and 
Evolutionary Computation Conference (GECCO-2001), pages 951-957, San Francisco, 
California, USA, 7-11 July 2001. Morgan Kaufmann.
<p> </p> </dd> 
<dt> [352] </dt> 
<dd> Pierre Gerard and Olivier Sigaud. YACS: Combining dynamic programming 
with generalization in classifier systems. InAdvances in Classifier Systems, 
volume 1996 ofLNAI, pages 52-69. Springer-Verlag, 2001. 
<p> </p> </dd> 
<dt> [353] </dt> 
<dd> Pierre G&eacute;rard and Olivier Sigaud. Designing efficient exploration 
with MACS: Modules and function approximation. In E.&nbsp;Cant&uacute;-Paz, 
J.&nbsp;A. Foster, K.&nbsp;Deb, D.&nbsp;Davis, R.&nbsp;Roy, U.-M. O'Reilly, 
H.-G. Beyer, R.&nbsp;Standish, G.&nbsp;Kendall, S.&nbsp;Wilson, M.&nbsp;Harman, 
J.&nbsp;Wegener, D.&nbsp;Dasgupta, M.&nbsp;A. Potter, A.&nbsp;C. Schultz, 
K.&nbsp;Dowsland, N.&nbsp;Jonoska, and J.&nbsp;Miller, editors,Genetic and 
Evolutionary Computation -- GECCO-2003, volume 2724 of LNCS, pages 1882-1893. 
Springer-Verlag, 2003.
<blockquote> MACS (Modular Anticipatory Classifier System) is a new 
Anticipatory Classifier System. With respect to its predecessors, ACS, ACS2 and 
YACS, the latent learning process in MACS is able to take advantage of new 
regularities. Instead of anticipating all attributes of the perceived 
situations in the same classifier, MACS only anticipates one attribute per 
classifier. In this paper we describe how the model of the environment 
represented by the classifiers can be used to perform active exploration and 
how this exploration policy is aggregated with the exploitation policy. The 
architecture is validated experimentally. Then we draw more general principles 
from the architectural choices giving rise to MACS. We show that building a 
model of the environment can be seen as a function approximation problem which 
can be solved with Anticipatory Classifier Systems such as MACS, but also with 
accuracy-based systems like XCS or XCSF, organized into a Dyna architecture.
</blockquote> 
<p> </p> </dd> 
<dt> [354] </dt> 
<dd> Pierre Gerard, Wolfgang Stolzmann, and Olivier Sigaud. YACS, a new 
learning classifier system using anticipation.Journal of Soft Computing, 
6(3-4):216-228, 2002.
<blockquote> A new and original trend in the learning classifier system (LCS) 
framework is focussed on latent learning. These new LCSs call upon classifiers 
with a (condition), an (action) and an (effect) part. In psychology, latent 
learning is defined as learning without getting any kind of reward. In the LCS 
framework, this process is in charge of discovering classifiers which are able 
to anticipate accurately the consequences of actions under some conditions. 
Accordingly, the latent learning process builds a model of the dynamics of the 
environment. This model can be used to improve the policy learning process. 
This paper describes YACS, a new LCS performing latent learning, and compares 
it with ACS.</blockquote> 
<p> </p> </dd> 
<dt> [355] </dt> 
<dd> Andreas Geyer-Schulz. Fuzzy Classifier Systems. In Robert Lowen and Marc 
Roubens, editors,Fuzzy Logic: State of the Art, Series D: System Theory, 
Knowledge Engineering and Problem Solving, pages 345-354, Dordrecht, 1993. 
Kluwer Academic Publishers.
<p> </p> </dd> 
<dt> [356] </dt> 
<dd> Andreas Geyer-Schulz. Fuzzy Rule-Based Expert Systems and Genetic Machine 
Learning. Physica Verlag, 1995. 
<p> </p> </dd> 
<dt> [357] </dt> 
<dd> Andreas Geyer-Schulz. Holland Classifier Systems. In Proceedings of the 
International Conference on APL (APL'95), volume&nbsp;25, pages 43-55, New 
York, NY, USA, June 1995. ACM Press.
<blockquote> A Holland classifier system is an adaptive, general purpose 
machine learning system which is designed to operate in noisy environments with 
infrequent and often incomplete feedback. Examples of such environments are 
financial markets, stock management systems, or chemical processes. In 
financial markets, a Holland classifier system would develop trading 
strategies, in a stock management system order heuristics, and in a chemical 
plant it would perform process control. In this paper we describe a Holland 
classifier system and present the implementation of its components, namely the 
production system, the bucket brigade algorithm, the genetic algorithm, and the 
cover detector, cover effector and triggered chaining operator. Finally, we 
illustrate the working of a Holland classifier system by learning to find a 
path with a high payoff in a simple finite state world.</blockquote> 
<p> </p> </dd> 
<dt> [358] </dt> 
<dd> Andreas Geyer-Schulz. Fuzzy Rule-Based Expert Systems and Genetic Machine 
Learning. Physica Verlag, 1997. 
<blockquote> This book integrates fuzzy rule-languages with genetic 
algorithms, genetic programming, and classifier systems with the goal of 
obtaining fuzzy rule-based expert systems with learning capabilities. The main 
topics are first introduced by solving small problems, then a prototype 
implementation of the algorithm is explained, and last but not least the 
theoretical foundations are given. The second edition takes into account the 
rapid progress in the application of fuzzy genetic algorithms with a survey of 
recent developments in the field. The chapter on genetic programming has been 
revised. An exact uniform initialization algorithm replaces the heuristic 
presented in the first edition. A new method of abstraction, compound 
derivations, is introduced.</blockquote> 
<p> </p> </dd> 
<dt> [359] </dt> 
<dd> Antonella Giani, Fabrizio Baiardi, and Antonina Starita. Q-Learning in 
Evolutionary Rule-Based Systems. InDavidor and Schwefel [228], pages 270-289. 
<blockquote> PANIC (Parallelism And Neural networks in Classifier systems), an 
Evolutionary Rule Based System (ERBS) to evolve behavioral strategies codified 
by sets of rules, is presented. PANIC assigns credit to the rules through a new 
mechanism, Q-Credit Assignment (QCA), based on Q-learning. By taking into 
account the context where a rule is applied, QCA is more accurate than 
classical methods when a single rule can fire in different situations. QCA is 
implemented through a multi-layer feed-forward neural network.</blockquote> 
<p> </p> </dd> 
<dt> [360] </dt> 
<dd> Antonella Giani, Fabrizio Baiardi, and Antonina Starita. PANIC: A 
parallel evolutionary rule based system. In John&nbsp;R. McDonnell, 
Robert&nbsp;G. Reynolds, and David&nbsp;B. Fogel, editors,Evolutionary 
Programming IV. Proceedings of the Fourth Annual Conference on Evolutionary 
Programming, pages 753-771, 1995. 
<blockquote> PANIC (Parallelism And Neural networks In Classifier Systems) is 
a parallel system to evolve behavioral strategies codified by sets of rules. It 
integrates several adaptive techniques and computational paradigms, such as 
genetic algorithms, neural networks, temporal difference methods and classifier 
systems, to define a powerful and robust learning system. To allocate credit to 
rules, we propose a new mechanism, Q-Credit Assignment (QCA), based on the 
temporal difference method Q-learning. To overcome the sharing rule problem, 
posed by traditional credit assignment strategies in rule based systems, QCA 
evaluates a rule depending on the context where it is applied. The mechanism is 
implemented through a multi-layer, feed-forward neural network. To overcome the 
heavy computational load of this approach, a decentralized and asynchronous 
parallel model of the genetic algorithm for massive parallel architecture has 
been devised.</blockquote> 
<p> </p> </dd> 
<dt> [361] </dt> 
<dd> Antonella Giani, A.&nbsp;Sticca, F.&nbsp;Baiardi, and A.&nbsp;Starita. 
Q-learning and Redundancy Reduction in Classifier Systems with Internal State. 
In Claire N&eacute;dellec and C&eacute;line Rouveirol, editors,Proceedings of 
the 10th European Conference on Machine Learning (ECML-98), volume 1398 of LNAI
, pages 364-369. Springer, 1998.
<p> </p> </dd> 
<dt> [362] </dt> 
<dd> Antonella Giani. A Study of Parallel Cooperative Classifier Systems. In 
John&nbsp;R. Koza, editor,Late Breaking Papers at the Genetic Programming 1998 
Conference, University of Wisconsin, Madison, Wisconsin, USA, July 1998. 
Stanford University Bookstore.
<p> </p> </dd> 
<dt> [363] </dt> 
<dd> A.&nbsp;H. Gilbert, Frances Bell, and Christine&nbsp;L. Valenzuela. 
Adaptive Learning of Process Control and Profit Optimisation using a Classifier 
System.Evolutionary Computation, 3(2):177-198, 1995. 
<blockquote> A Classifier System is used to learn control and profit 
optimisation of a batch chemical reaction. Ability to learn different market 
conditions and changes to reaction parameters is demonstrated. The Profit 
Sharing algorithm is used for Apportionment of Credit. The greater 
effectiveness of the use of the genetic algorithm over Apportionment of Credit 
alone or the random replacement of low strength rules is also shown. The 
Classifier System is unusual in having more than one action per rule.
</blockquote> 
<p> </p> </dd> 
<dt> [364] </dt> 
<dd> Attilio Giordana and G.&nbsp;Lo Bello. Learning classification programs: 
The genetic algorithm approach. In A.&nbsp;E. Eiben and Z.&nbsp;Michalewicz, 
editors,Evolutionary Computation, pages 163-177. IOS Press, 1999. 
<blockquote> Genetic Algorithms have been proposed by many authors for Machine 
Learning tasks. In fact, they are appealing for several different reasons, such 
as the flexibility, the great exploration power, and the possibility of 
exploiting parallel processing. Nevertheless, it is still controversial whether 
the genetic approach can really provide effective solutions to learning tasks, 
in comparison to other algorithms based on classical search strategies. In this 
paper we try to clarify this point and we overview the work done with respect 
to the task of learning classification programs from examples. The state of the 
art emerging from our analysis suggests that the genetic approach can be a 
valuable alternative to classical approaches, even if further investigation is 
necessary in order to come to a final conclusion.</blockquote> 
<p> </p> </dd> 
<dt> [365] </dt> 
<dd> Attilio Giordana and Filippo Neri. Search-Intensive Concept Induction. 
Evolutionary Computation, 3:375-416, 1995. 
<blockquote> This paper describes REGAL, a distributed genetic algorithm-based 
system, designed for learning First Order Logic concept descriptions from 
examples. The system is a hybrid between the Pittsburgh and the Michigan 
approaches, as the population constitutes a redundant set of partial concept 
descriptions, each evolved separately. In order to increase effectiveness, 
REGAL is specifically tailored to the concept learning task; hence, REGAL is 
task-dependent, but, on the other hand, domain-independent. The system proved 
to be particularly robust with respect to parameter setting across a variety of 
different application domains. REGAL is based on a selection operator, called 
Universal Suffrage operator, provably allowing the population to asymptotically 
converge, in average, to an equilibrium state, in which several species 
coexist. The system is presented both in a serial and in a parallel version, 
and a new distributed computational model is proposed and discussed. The system 
has been tested on a simple artificial domain, for the sake of illustration, 
and on several complex real-world and artificial domains, in order to show its 
power, and to analyze its behavior under various conditions. The results 
obtained so far suggest that genetic search may be a valuable alternative to 
logic-based approaches to learning concepts, when no (or little) a priori 
knowledge is available and a very large hypothesis space has to be explored.
</blockquote> 
<p> </p> </dd> 
<dt> [366] </dt> 
<dd> Attilio Giordana and L.&nbsp;Saitta. REGAL: An Integrated System for 
Learning Relations Using Genetic Algorithms. InProc. 2nd International Workshop 
on Multistrategy Learning, pages 234-249, 1993. 
<p> </p> </dd> 
<dt> [367] </dt> 
<dd> Attilio Giordana and L.&nbsp;Saitta. Learning disjunctive concepts by 
means of genetic algorithms. InProc. Int. Conf. on Machine Learning, pages 
96-104, 1994.
<p> </p> </dd> 
<dt> [368] </dt> 
<dd> R.&nbsp;Giraldez, J.&nbsp;Aguilar-Ruiz, and J.&nbsp;Riquelme. Natural 
coding: A more efficient representation for evolutionary learning. In
Proceedings of the Genetic and Evolutionary Computation Conference (GECCO-2003)
, pages 979-990. Springer-Verlag, 2003.
<p> </p> </dd> 
<dt> [369] </dt> 
<dd> R.&nbsp;Giraldez, J.&nbsp;Aguilar-Ruiz, and J.&nbsp;Riquelme. 
Knowledge-based fast evaluation for evolutionary learning.IEEE Transactions on 
Systems, Man and Cybernetics, Part C: Applications and Reviews, 35(2):254-261, 
2005.
<blockquote> The increasing amount of information available is encouraging the 
search for efficient techniques to improve the data mining methods, especially 
those which consume great computational resources, such as evolutionary 
computation. Efficacy and efficiency are two critical aspects for 
knowledge-based techniques. The incorporation of knowledge into evolutionary 
algorithms (EAs) should provide either better solutions (efficacy) or the 
equivalent solutions in shorter time (efficiency), regarding the same 
evolutionary algorithm without incorporating such knowledge. In this paper, we 
categorize and summarize some of the incorporation of knowledge techniques for 
evolutionary algorithms and present a novel data structure, called efficient 
evaluation structure (EES), which helps the evolutionary algorithm to provide 
decision rules using less computational resources. The EES-based EA is tested 
and compared to another EA system and the experimental results show the quality 
of our approach, reducing the computational cost about 50%, maintaining the 
global accuracy of the final set of decision rules.</blockquote> 
<p> </p> </dd> 
<dt> [370] </dt> 
<dd> David&nbsp;E. Goldberg, Jeffrey Horn, and Kalyanmoy Deb. What Makes a 
Problem Hard for a Classifier System?. In Collected Abstracts for the First 
International Workshop on Learning Classifier System (IWLCS-92) [486]. (Also 
technical report 92007 Illinois Genetic Algorithms Laboratory, University of 
Illinois at Urbana-Champaign). Available from ENCORE 
(ftp://ftp.krl.caltech.edu/pub/EC/Welcome.html) in the section on Classifier 
Systems.
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [371] </dt> 
<dd> David&nbsp;E. Goldberg. Computer-Aided Gas Pipeline Operation using 
Genetic Algorithms and Rule Learning. PhD thesis, The University of Michigan, 
1983.
<p> </p> </dd> 
<dt> [372] </dt> 
<dd> David&nbsp;E. Goldberg. Dynamic System Control using Rule Learning and 
Genetic Algorithms. InProceedings of the 9th International Joint Conference on 
Artificial Intelligence (IJCAI-85), pages 588-592. Morgan Kaufmann, 1985. 
<p> </p> </dd> 
<dt> [373] </dt> 
<dd> David&nbsp;E. Goldberg. Genetic algorithms and rules learning in dynamic 
system control. InGrefenstette [389], pages 8-15. 
<p> </p> </dd> 
<dt> [374] </dt> 
<dd> David&nbsp;E. Goldberg. Genetic Algorithms in Search, Optimization, and 
Machine Learning. Addison-Wesley, Reading, Mass., 1989. 
<p> </p> </dd> 
<dt> [375] </dt> 
<dd> David&nbsp;E. Goldberg. Probability Matching, the Magnitude of 
Reinforcement, and Classifier System Bidding.Machine Learning, 5:407-425, 1990. 
(Also TCGA tech report 88002, U. of Alabama).
<blockquote> This paper juxtaposes the probability matching paradox of 
decision theory and the magnitude of reinforcement problem of animal learning 
theory to show that simple classifier system bidding structures are unable to 
match the range of behaviors required in the deterministic and probabilistic 
problems faced by real cognitive systems. The inclusion of a variance-sensitive 
bidding (VSB) mechanism is suggested, analyzed, and simulated to enable good 
bidding performance over a wide range of nonstationary probabilistic and 
deterministic environments.</blockquote> 
<p> </p> </dd> 
<dt> [376] </dt> 
<dd> David&nbsp;E. Goldberg. Some Reflections on Learning Classifier Systems. 
Technical Report 2000009, Illinois Genetic Algorithms Laboratory, University of 
Illinois at Urbana-Champaign, 2000. This appeared as part of Holland2000a.
<blockquote> This work has no abstract </blockquote> 
<p> </p> </dd> 
<dt> [377] </dt> 
<dd> S.&nbsp;Y. Goldsmith. Steady state analysis of a simple classifier system
. PhD thesis, University of New Mexico, Albuquerque, USA, 1989.
<p> </p> </dd> 
<dt> [378] </dt> 
<dd> M.&nbsp;Goodloe and S.&nbsp;J. Graves. Improving performance of an 
electric power expert system with genetic algorithms. InProceedings of the 1st 
International Conference on the Applications of Artificial Intelligence and 
Expert Systems (IEA/AIE-88), pages 298-305. ACM Press, 1988. 
<blockquote> Nickel cadmium batteries are an important source of power for 
aerospace applications. One such application is being developed at the Marshall 
Space Flight Center (MSFC) for use with the Hubble Space Telescope. A battery 
testbed has been built at MSFC to aid in that development. In addition, the 
Nickel Cadmium Battery Expert System (NICBES) was developed by Martin Marietta 
Corporation to assist NASA engineers in battery management. This paper 
describes an extension to NICBES which will make it more effective as a battery 
management tool. The extension involves the incorporation of classifier system 
machine learning techniques into a subsystem of NICBES. The principal reason 
for suggesting this extension is the nature of battery management itself. There 
is still much which is unknown about these batteries and the factors affecting 
their performance [2]. Hence, battery management might be said to be as much an 
art as a science and relies heavily on the expertise of the battery manager. 
NICBES is an attempt to incorporate that battery expertise into an expert 
system. One difficulty, however, is that battery behavior is likely to change 
over time in unforseen ways. This detracts from the usefulness of the expert 
system. Consequently, the battery manager who is using NICBES as a tool would 
be required to make changes to the expert system in order to accomodate the 
changed parameters of battery behavior. This should be the function of the 
knowledge engineer, however, not the battery expert. This is an example of the 
familiar problem of knowledge acquisition in knowledge engineering. The 
solution presented here is to use machine learning techniques to help overcome 
the knowledge acquisition problem. The expert system then interacts at a high 
level with the battery manager and undertakes adaptation on itself in order to 
determine new rules conforming to the changed parameters of the power system. 
The basic principles of learning classifier systems based on genetic algorithms 
will be presented first. Next, a brief description of NICBES will be given, 
particularly the advice subsystem to which the learning component will be 
added. A discussion of specific techniques by which machine learning can be 
incorporated into this particular rule-based expert system will follow. This 
discussion will come under the headings of the bit-string representation of 
rules, the initial rule population, an evaluation function for this system, and 
the genetic operators. Finally, some comments will be made concerning the 
implementation of a user interface for a system such as this.</blockquote> 
<p> </p> </dd> 
<dt> [379] </dt> 
<dd> E.&nbsp;G. Goodman, V.&nbsp;L. Uskov, and W.&nbsp;F. Punch, editors. 
Proceedings of the First International Conference on Evolutionary Algorithms 
and their Application EVCA'96, Moscow, 1996. The Presidium of the Russian 
Academy of Sciences.
<p> </p> </dd> 
<dt> [380] </dt> 
<dd> D.P. Greene and S.F. Smith. A genetic system for learning models of 
consumer choice. InProceedings of the Second International Conference on 
Genetic Algorithms and their Applications, pages 217-223. Morgan Kaufmann, 1987.
<p> </p> </dd> 
<dt> [381] </dt> 
<dd> David&nbsp;Perry Greene and Stephen&nbsp;F. Smith. Competition-based 
induction of decision models from examples.Machine Learning, 13:229-257, 1993. 
<blockquote> Symbolic induction is a promising approach to constructing 
decision models by extracting regularities from a data set of examples. The 
predominant type of model is a classification rule (or set of rules) that maps 
a set of relevant environmental features into specific categories or values. 
Classifying loan risk based on borrower profiles, consumer choice from purchase 
data, or supply levels based on operating conditions are all examples of this 
type of model-building task. Although current inductive approaches, such as ID3 
and CN2, perform well on certain problems, their potential is limited by the 
incremental nature of their search. Genetic algorithms (GA) have shown great 
promise on complex search domains, and hence suggest a means for overcoming 
these limitations. However, effective use of genetic search in this context 
requires a framework that promotes the funamental model-building objectives of 
predictive accuracy and model simplicity. In this article we describe COGIN, a 
GA-based inductive system that exploits the conventions of induction from 
examples to provide this framework. The novelty of COGIN lies in its use of 
training set coverage to simultaneously promote competition in various 
classification niches within the model and constrain overall model complexity. 
Experimental comparisons with NewID and CN2 provide evidence of the 
effectiveness of the COGIN framework and the viability of the GA approach.
</blockquote> 
<p> </p> </dd> 
<dt> [382] </dt> 
<dd> David&nbsp;Perry Greene and Stephen&nbsp;F. Smith. Using Coverage as a 
Model Building Constraint in Learning Classifier Systems.Evolutionary 
Computation, 2(1):67-91, 1994. 
<blockquote> Promoting and maintaining diversity is a critical requirement of 
search in learning classifier systems (LCSs). What is required of the genetic 
algorithm (GA) in an LCS context is not convergence to a single global maximum, 
as in the standard optimization framework, but instead the generation of 
individuals (i.e., rules) that collectively cover the overall problem space. 
COGIN (COverage-based Genetic INduction) is a system designed to exploit 
genetic recombination for the purpose of constructing rule-based classification 
models from examples. The distinguishing characteristic of COGIN is its use of 
coverage of training set examples as an explicit constraint on the search, 
which acts to promote appropriate diversity in the population of rules over 
time. By treating training examples as limited resources, COGIN creates an 
ecological model that simultaneously accommodates a dynamic range of niches 
while encouraging superior individuals within a niche, leading to concise and 
accurate decision models. Previous experimental studies with COGIN have 
demonstrated its performance advantages over several well-known symbolic 
induction approaches. In this paper, we examine the effects of two 
modifications to the original system configuration, each designed to inject 
additional diversity into the search: increasing the carrying capacity of 
training set examples (i.e., increasing coverage redundancy) and increasing the 
level of disruption in the recombination operator used to generate new rules. 
Experimental results are given that show both types of modifications to yield 
substantial improvements to previously published results.</blockquote> 
<p> </p> </dd> 
<dt> [383] </dt> 
<dd> D.P. Greene. Automated knowledge acquisition: Overcoming the expert 
systems bottleneck. InProceedings of the Seventh International Conference on 
Information Systems, pages 107-117. Lawrence Erlbaum, 1987. 
<p> </p> </dd> 
<dt> [384] </dt> 
<dd> D.P. Greene. Inductive knowledge acquisition using genetic adaptive search
. PhD thesis, The Graduate School of Industrial Administration, Carnegie Mellon 
University, 1992.
<p> </p> </dd> 
<dt> [385] </dt> 
<dd> A.&nbsp;Greenyer. The use of a learning classifier system JXCS. In 
P.&nbsp;van&nbsp;der Putten and M.&nbsp;van Someren, editors,CoIL Challenge 
2000: The Insurance Company Case. Leiden Institute of Advanced Computer 
Science, June 2000. Technical report 2000-09.
<p> </p> </dd> 
<dt> [386] </dt> 
<dd> John&nbsp;J. Grefenstette and H.&nbsp;G. Cobb. User's guide for SAMUEL, 
Version 1.3. Technical Report NRL Memorandum Report 6820, Naval Research 
Laboratory, 1991.
<p> </p> </dd> 
<dt> [387] </dt> 
<dd> John&nbsp;J. Grefenstette and Alan&nbsp;C. Schultz. An evolutionary 
approach to learning in robots. In Machine Learning Workshop on Robot Learning, 
New Brunswick, NJ, 1994. http://www.ib3.gmu.edu/gref/.
<blockquote> Evolutionary learning methods have been found to be useful in 
several areas in the development of intelligent robots. In the approach 
described here, evolutionary algorithms are used to explore alternative robot 
behaviors within a simulation model as a way of reducing the overall knowledge 
engineering effort. This paper presents some initial results of applying the 
SAMUEL genetic learning system to a collision avoidance and navigation task for 
mobile robots.</blockquote> 
<p> </p> </dd> 
<dt> [388] </dt> 
<dd> John&nbsp;J. Grefenstette, C.&nbsp;L. Ramsey, and Alan&nbsp;C. Schultz. 
Learning Sequential Decision Rules using Simulation Models and Competition. 
Machine Learning, 5(4):355-381, 1990. 
http://www.ib3.gmu.edu/gref/publications.html.
<blockquote> The problem of learning decision rules for sequential tasks is 
addressed, focusing on the problem of learning tactical decision rules from a 
simple flight simulator. The learning method relies on the notion of 
competition and employs genetic algorithms to search the space of decision 
policies. Several experiments are presented that address issues arising from 
differences between the simulation model on which learning occurs and the 
target environment on which the decision rules are ultimately tested.
</blockquote> 
<p> </p> </dd> 
<dt> [389] </dt> 
<dd> John&nbsp;J. Grefenstette, editor. Proceedings of the 1st International 
Conference on Genetic Algorithms and their Applications (ICGA85). Lawrence 
Erlbaum Associates: Pittsburgh, PA, July 1985.
<p> </p> </dd> 
<dt> [390] </dt> 
<dd> John&nbsp;J. Grefenstette. Multilevel Credit Assignment in a Genetic 
Learning System. InProceedings of the 2nd International Conference on Genetic 
Algorithms (ICGA87) [391], pages 202-207. 
<blockquote> Genetic algorithms assign credit to building blocks based on the 
performance of the knowledge structures in which they occur. If the knowledge 
structures are rules sets, then the bucket brigade algorithm provides a means 
of performing additional credit assignment at the level of individual rules. 
This paper explores one possibility for using the fine-grained feedback 
provided by the bucket brigade in genetic learning systems that manipulate sets 
of rules.</blockquote> 
<p> </p> </dd> 
<dt> [391] </dt> 
<dd> John&nbsp;J. Grefenstette, editor. Proceedings of the 2nd International 
Conference on Genetic Algorithms (ICGA87), Cambridge, MA, July 1987. Lawrence 
Erlbaum Associates.
<p> </p> </dd> 
<dt> [392] </dt> 
<dd> John&nbsp;J. Grefenstette. Credit Assignment in Rule Discovery Systems 
Based on Genetic Algorithms.Machine Learning, 3:225-245, 1988. 
<blockquote> In rule discovery systems, learning often proceeds by first 
assessing the quality of the system's current rules and then modifying rules 
based on that assessment. This paper addresses the credit assignment problem 
that arises when long sequences of rules fire between successive external 
rewards. The focus is on the kinds of rule assessment schemes which have been 
proposed for rule discovery systems that use genetic algorithms as the primary 
rule modification strategy. Two distinct approaches to rule learning with 
genetic algorithms have been previously reported, each approach offering a 
useful solution to a different level of the credit assignment problem. We 
describe a system, called RUDI, that exploits both approaches. We present 
analytic and experimental results that support the hypothesis that multiple 
levels of credit assignment can improve the performance of rule learning 
systems based on genetic algorithms.</blockquote> 
<p> </p> </dd> 
<dt> [393] </dt> 
<dd> John&nbsp;J. Grefenstette. A System for Learning Control Strategies with 
Genetic Algorithms. InSchaffer [718], pages 183-190. 
<blockquote> A system called SAMUEL is described for learning rules to control 
a process, given only a weak model of the process consisting of a set of 
sensors, a set of control variables, and feedback mechanism that provides 
intermittent performance measurements. This paper focuses on features that 
distinguish SAMUEL from previous systems for learning rules with genetic 
algorithms. In particular, a restricted high level rule language is used, and 
genetic operators suitable for the language are presented. An empirical study 
shows that SAMUEL can learn rules to control a challenging dynamic process.
</blockquote> 
<p> </p> </dd> 
<dt> [394] </dt> 
<dd> John&nbsp;J. Grefenstette. Lamarckian Learning in Multi-Agent Environments
. InBooker and Belew [74], pages 303-310. 
http://www.ib3.gmu.edu/gref/publications.html.
<blockquote> Genetic algorithms gain much of their power from mechanisms 
derived from the field of population genetics. However, it is possible, and in 
some cases desirable, to augment the standard mechanisms with additional 
features not available in biological systems. In this paper, we examine the use 
of Lamarckian learning operators in the SAMUEL architecture. The use of the 
operators is illustrated on three tasks in multi-agent environments.
</blockquote> 
<p> </p> </dd> 
<dt> [395] </dt> 
<dd> John&nbsp;J. Grefenstette. Learning decision strategies with genetic 
algorithms. In Proc. Intl. Workshop on Analogical and Inductive Inference, 
volume 642 ofLecture Notes in Artificial Intelligence, pages 35-50. 
Springer-Verlag, 1992. http://www.ib3.gmu.edu/gref/.
<blockquote> Machine learning offers the possibility of designing intelligent 
systems that refine and improve their initial knowledge through their own 
experience. This article focuses on the problem of learning sequential decision 
rules for multi-agent environments. We describe the SAMUEL learning system that 
uses genetic algorithms and other competition based techniques to learn 
decision strategies for autonomous agents. One of the main themes in this 
research is that the learning system should be able to take advantage of 
existing knowledge where available. This article describes some of the 
mechanisms for expressing existing knowledge in SAMUEL, and explores some of 
the issues in selecting constraints for the learning system.</blockquote> 
<p> </p> </dd> 
<dt> [396] </dt> 
<dd> John&nbsp;J. Grefenstette. The Evolution of Strategies for Multi-agent 
Environments. Adaptive Behavior, 1:65-89, 1992. http://www.ib3.gmu.edu/gref/. 
<blockquote> SAMUEL is an experimental learning system that uses genetic 
algorithms and other learning methods to evolve reactive decision rules from 
simulations of multi-agent environments. The basic approach is to explore a 
range of behavior within a simulation model, using feedback to adapt its 
decision strategies over time. One of the main themes in this research is that 
the learning system should be able to take advantage of existing knowledge 
where available. This has led to the adoption of rule representations that ease 
the expression existing knowledge. A second theme is that adaptation can be 
driven by competition among knowledge structures. Competition is applied at two 
levels in SAMUEL. Within a strategy composed of decision rules, rules compete 
with one another to influence the behavior of the system. At a higher level of 
granularity, entire strategies compete with one another, driven by a genetic 
algorithm. This article focuses on recent elaborations of the agent model of 
SAMUEL that are specifically designed to respond to multiple external agents. 
Experimental results are presented that illustrate the behavior of SAMUEL on 
two multi-agent predator-prey tasks.</blockquote> 
<p> </p> </dd> 
<dt> [397] </dt> 
<dd> John&nbsp;J. Grefenstette. Using a genetic algorithm to learn behaviors 
for autonomous vehicles. In Proceedings American Institute of Aeronautics and 
Astronautics Guidance, Navigation and Control Conference, pages 739-749. AIAA, 
1992. http://www.ib3.gmu.edu/gref/.
<blockquote> Truly autonomous vehicles will require both projective planning 
and reactive components in order to perform robustly. Projective components are 
needed for long-term planning and replanning where explicit reasoning about 
future states is required. Reactive components allow the system to always have 
some action available in real-time, and themselves can exhibit robust behavior, 
but lack the ability to explicitly reason about future states over a long time 
period. This work addresses the problem of creating reactive components for 
autonomous vehicles. Creating reactive behaviors (stimulus-response rules) is 
generally difficult, requiring the acquisition of much knowledge from domain 
experts, a problem referred to as the knowledge acquisition bottleneck. SAMUEL 
is a system that learns reactive behaviors for autonomous agents. SAMUEL learns 
these behaviors under simulation, automating the process of creating 
stimulus-response rules and therefore reducing the bottleneck. The learning 
algorithm was designed to learn useful behaviors from simulations of limited 
fidelity. Current work is investigating how well behaviors learned under 
simulation environments work in real world environments. In this paper, we 
describe SAMUEL, and describe behaviors that have been learned for simulated 
autonomous aircraft, autonomous underwater vehicles, and robots. These 
behaviors include dog fighting, missile evasion, tracking, navigation, and 
obstacle avoidance.</blockquote> 
<p> </p> </dd> 
<dt> [398] </dt> 
<dd> John&nbsp;J. Grefenstette. Evolutionary Algorithms in Robotics. In 
M.&nbsp;Jamshedi and C.&nbsp;Nguyen, editors,Robotics and Manufacturing: Recent 
Trends in Research, Education and Applications, v5. Proc. Fifth Intl. Symposium 
on Robotics and Manufacturing, ISRAM 94, pages 65-72. ASME Press: New York, 
1994. http://www.ib3.gmu.edu/gref/.
<blockquote> Evolutionary algorithms incorporate principles from biological 
population genetics to perform search, optimization, and learning. This article 
discusses issues arising in the application of evolutionary algorithms to 
problems in robotics.</blockquote> 
<p> </p> </dd> 
<dt> [399] </dt> 
<dd> T.&nbsp;Nakashima H.&nbsp;Ishibuchi and T.&nbsp;Kuroda. A fuzzy 
genetics-based machine learning method for designing linguistic classification 
systems with high comprehensibility. InProceedings 6th Int. Conf. on Neural 
Information Processing, volume&nbsp;2, pages 597-602, 1999. 
<p> </p> </dd> 
<dt> [400] </dt> 
<dd> T.&nbsp;Nakashima H.&nbsp;Ishibuchi and T.&nbsp;Kuroda. A hybrid fuzzy 
gbml algorithm for designing compact fuzzy rule-based classification systems. In
Proc. 9th IEEE Int. Conf. on Fuzzy Systems (FUZZ IEEE 2000), volume&nbsp;2, 
pages 706-711, 2000.
<p> </p> </dd> 
<dt> [401] </dt> 
<dd> T.&nbsp;Nakashima H.&nbsp;Ishibuchi and T.&nbsp;Murata. 
Genetic-algorithm-based approaches to the design of fuzzy systems for 
multi-dimensional pattern classification problems. InProc. 1996 IEEE Int. conf 
on Evolutionary Computation, pages 229-234, 1996. 
<p> </p> </dd> 
<dt> [402] </dt> 
<dd> T.&nbsp;Nakashima H.&nbsp;Ishibuchi and T.&nbsp;Murata. Performance 
evaluation of fuzzy classifier systems for multidimensional pattern 
classification problems.IEEE Transactions on Systems, Man and Cybernetics, Part 
B, 29(5):601-618, 1999. 
<p> </p> </dd> 
<dt> [403] </dt> 
<dd> Chris&nbsp;Lokan Hai H.&nbsp;Dam, Hussein A.&nbsp;Abbass. Bcs: Bayesain 
learning classifier system. Technical Report TR-ALAR-200604005, Artificial Life 
and Adaptive Robotics Laboratory, UNSW, 2006.
<p> </p> </dd> 
<dt> [404] </dt> 
<dd> Ali Hamzeh and Adel Rahmani. A fuzzy system to control exploration rate 
in xcs. In Tim Kovacs, Xavier LL&ograve;ra, Keiki Takadama, Pier&nbsp;Luca 
Lanzi, Wolfgang Stolzmann, and Stewart&nbsp;W. Wilson, editors,Learning 
Classifier Systems. International Workshops, IWLCS 2003-2005, Revised Selected 
Papers, volume 4399 of LNCS, pages 115-127. Springer, 2007. 
<p> </p> </dd> 
<dt> [405] </dt> 
<dd> Hisashi Handa, Takashi Noda, Tadataka Konishi, Osamu Katai, and Mitsuru 
Baba. Coevolutionary fuzzy classifier system for autonomous mobile robots. In
Takadama [815]. 
<p> </p> </dd> 
<dt> [406] </dt> 
<dd> Greg Harrison. Genetically programmed learning classifier system for 
complex adaptive system processing with agent-based architecture. US Patent 
6,741,974, 2004.
<p> </p> </dd> 
<dt> [407] </dt> 
<dd> Adrian Hartley. Genetics Based Machine Learning as a Model of Perceptual 
Category Learning in Humans. Master's thesis, University of Birmingham, 1998. 
ftp://ftp.cs.bham.ac.uk/pub/authors/T.Kovacs/index.html.
<blockquote> The ability to recognize quickly and accurately what they 
encounter is a fundamental ability of normal intelligent human behaviour. How 
people perform the task of learning the categories that objects in the world 
fit into is still an unanswered question. However, in this thesis I follow up 
an idea that Holland et al. (1986) proposed and present genetic based machine 
learning as a model of perceptual category learning. Genetics based machine 
learning has a certain amount of popularity within computer science yet the 
ideas have been slow to cross the boundaries of disciplines. The main drive of 
this research is to adopt the theoretical position of Holland et al. (1986) and 
see if realistically genetic based machine learning can be used as a model of 
learning in humans. Within Psychology the domain of category learning has grown 
as an area of interest, for categorization is considered basic to all our 
intellectual abilities (Estes 1994). Categorization ``is the process of 
assigning objects (of whatever kind) to categories (which are collections of 
objects which are grouped together for some purpose)'' (Lamberts 1997). There 
is a bench mark set of results within perceptual category learning from Shepard 
et al (1961). These tasks have a well defined difficulty ordering and serve as 
a starting point for any model of perceptual category learning. In psychology 
neural networks are often used for cognitive modelling. However Sen (1996) used 
a simple classifier system (Newboole) to model the classic Shepard et al. 
(1961) tasks. I will begin with a replication of this study and then move on to 
use another more advanced classifier system (XCS: Wilson 1995) to see if this 
provides a better model of perceptual category learning. Also, I introduce a 
category switch task that has not previously been evaluated with these systems. 
Results show that although simple classifier systems can capture qualitatively 
results from humans, they fail to show elegant solutions to problems and are 
limited in the tasks they can model. XCS can solve a greater variety of 
problems as it can handle multi step problems as well as single step, also it 
models both the Shepard and the switch problems. XCS develops a covering map of 
knowledge giving the system much more complete knowledge of the classification 
problem compared to simpler systems. XCS learns not only what is a correct 
classification but also what is an incorrect classification. Also due to the 
derivation of a covering map of knowledge XCS finds simple elegant solutions to 
problems. Some classifier systems (XCS) may offer a realistic alternative to 
neural networks in cognitive modelling.</blockquote> 
<p> </p> </dd> 
<dt> [408] </dt> 
<dd> Adrian Hartley. Accuracy-based fitness allows similar performance to 
humans in static and dynamic classification environments. In Banzhaf et&nbsp;al.
[32], pages 266-273. 
<blockquote> Traditionally within classifier systems the ability of a 
classifier to obtain reward (as measured by its strength) indicates the fitness 
of the classifier within the rule population. However, Wilson (1995) proposed a 
new approach to fitness in terms of a classifier's prediction accuracy. This 
paper presents experiments with two different classifier systems: Newboole 
(Bonelli et al. 1990) and XCS (Wilson 1995). Both systems demonstrate 
qualitative matches to data from perceptual category learning in humans. 
However, the different methods of fitness evaluation of classifiers alter the 
knowledge the systems learn and maintain. When fitness is based upon strength 
(Newboole) the system acquires knowledge to solve the classification problem. 
But when fitness is based on accuracy (XCS) the system acquires a more complete 
knowledge of the problem space. Further experiments show that the optimal 
covering map (Kovacs 1997) of knowledge that emerges in XCS allows the system 
to compensate rapidly in a dynamic classification environment. This is also 
more similar to human performance on comparable tasks.</blockquote> 
<p> </p> </dd> 
<dt> [409] </dt> 
<dd> U.&nbsp;Hartmann. Efficient Parallel Learning in Classifier Systems. In 
Albrecht et&nbsp;al. [7], pages 515-521. 
<blockquote> Classifier systems are simple production systems working on 
binary messages of fixed length. Genetic algorithms are employed in classifier 
systems in order to discover new classifiers. We use methods of the 
computational complexity theory in order to analyse the inherent difficulty of 
learning in classifier systems. Hence our results do not depend on special 
(possibly genetic) learning algorithms. The paper formalises this rule 
discovery or learning problem for classifier systems which has been proved to 
be hard in general. It will be proved that restrictions on two distinct 
learning problems lead to problems in NC, i.e. problems which are efficiently 
solvable in parallel.</blockquote> 
<p> </p> </dd> 
<dt> [410] </dt> 
<dd> U.&nbsp;Hartmann. On the Complexity of Learning in Classifier Systems. In 
Davidor and Schwefel [228], pages 280-289. Republished in: ECAI 94. 11th 
European Conference on Artificial Intelligence. A Cohn (Ed.), pp.438-442, 1994. 
John Wiley and Sons.
<blockquote> Genetic algorithms are employed in classifier systems in order to 
discover new classifiers. The paper formalises this rule discovery or learning 
problem for classifier systems and uses methods of computational complexity 
theory to analyse its inherent difficulty. It is proved that two distinct 
learning problems are NP-complete, i.e. not likely to be solvable efficiently. 
The practical relevance of these theoretical results is briefly discussed.
</blockquote> 
<p> </p> </dd> 
<dt> [411] </dt> 
<dd> Marianne Haslev. A Classifier System for the Production by Computer of 
Past Tense Verb-Forms. Presented at a Genetic Algorithms Workshop at the 
Rowland Institute, Cambridge MA, Nov 1986, 1986.
<p> </p> </dd> 
<dt> [412] </dt> 
<dd> Mozart Hasse and Aurora&nbsp;R. Pozo. Using Phenotypic Sharing in a 
Classifier Tool. InWhitely et&nbsp;al. [878], page 392. One page poster paper. 
<blockquote> This paper describes a classifier tool that uses a genetic 
algorithm to make rule induction. The genetic algorithm uses the Michigan 
approach, is domain independent and is able to process continuous and discrete 
attributes. Some optimizations include the use of phenotypic sharing (with 
linear complexity) to direct the search. The results of accuracy are compared 
with other 33 algorithms in 32 datasets. The difference of accuracy is not 
statistically significant at the 10% level when compared with the best of the 
other 33 algorithms. The implementation allows the configuration of many 
parameters, and intends to be improved with the inclusion of new operators.
</blockquote> 
<p> </p> </dd> 
<dt> [413] </dt> 
<dd> Akira Hayashi and Nobuo Suematsu. Viewing Classifier Systems as Model 
Free Learning in POMDPs. In Advances in Neural Information Processing Systems 
(NIPS) 11, pages 989-995, 1999. 
<blockquote> Classifier systems are now viewed disappointing because of their 
problems such as the rule strength vs rule set performance problem and the 
credit assignment problem. In order to solve the problems, we have developed a 
hybrid classifier system: GLS (Generalization Learning System). In designing 
GLS, we view CSs as model free learning in POMDPs and take a hybrid approach to 
finding the best generalization, given the total number of rules. GLS uses the 
policy improvement procedure by Jaakkola et al. for an locally optimal 
stochastic policy when a set of rule conditions is given. GLS uses GA to search 
for the best set of rule conditions.</blockquote> 
<p> </p> </dd> 
<dt> [414] </dt> 
<dd> J&ouml;rg Heitk&ouml;tter and David Beasley. The Hitch-Hiker's Guide to 
Evolutionary Computation (FAQ for comp.ai.genetic). Accessed 28/2/09. 
http://www.aip.de/~ast/EvolCompFAQ/, 2001.
<p> </p> </dd> 
<dt> [415] </dt> 
<dd> J.&nbsp;Hekanaho. Symbiosis in multimodal concept learning. In Proc. 1995 
Int. Conf. on Machine Learning (ML'95), pages 278-285, 1995. 
<p> </p> </dd> 
<dt> [416] </dt> 
<dd> Luis&nbsp;Miramontes Hercog and Terence&nbsp;C. Fogarty. XCS-based 
inductive intelligent multi-agent system. InLate Breaking Papers at the 2000 
Genetic and Evolutionary Computation Conference (GECCO-2000), pages 125-132, 
2000.
<blockquote> Induction is tested in a population of XCS-based agents, tested 
in the frame of the ``El Farol'' bar problem. Two reward schemes are used, 
selfish and co-operative, being the latter the best for the purposes of the 
experiment.</blockquote> 
<p> </p> </dd> 
<dt> [417] </dt> 
<dd> Luis&nbsp;Miramontes Hercog and Terence&nbsp;C. Fogarty. XCS-based 
Inductive Multi-Agent System. InProceedings of the International Workshop on 
Learning Classifier Systems (IWLCS-2000), in the Joint Workshops of SAB 2000 
and PPSN 2000 [487]. Extended abstract. 
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [418] </dt> 
<dd> Luis&nbsp;Miramontes Hercog and Terence&nbsp;C. Fogarty. Analysis of 
inductive intelligence in xcs-based multi-agent system (maxcs). In J.Periaux, 
P.&nbsp;Joly, and E.&nbsp;Onate, editors,Innovative Tools for Scientific 
Computation in Aeronautical Engineering, pages 351-366. CIMNE, Barcelona, 2001. 
ISBN: 84-90025-78-X.
<p> </p> </dd> 
<dt> [419] </dt> 
<dd> Luis&nbsp;Miramontes Hercog and Terence&nbsp;C. Fogarty. Co-evolutionary 
classifier systems for multi-agent simulation. In David&nbsp;B. Fogel, 
Mohamed&nbsp;A. El-Sharkawi, Xin Yao, Garry Greenwood, Hitoshi Iba, Paul 
Marrow, and Mark Shackleton, editors,Proceedings of the 2002 Congress on 
Evolutionary Computation CEC2002, pages 1798-1803. IEEE Press, 2002. 
<p> </p> </dd> 
<dt> [420] </dt> 
<dd> Luis&nbsp;Miramontes Hercog and Terence&nbsp;C. Fogarty. Social 
simulation using a Multi-Agent Model based on Classifier Systems: The Emergence 
of Vacillating Behaviour in the ``El Farol'' Bar Problem. InLanzi et&nbsp;al. 
[546], pages 88-111. 
<p> </p> </dd> 
<dt> [421] </dt> 
<dd> Luis&nbsp;Miramontes Hercog. Hand-eye coordination: An evolutionary 
approach. Master's thesis, Department of Artificial Intelligence. University of 
Edinburgh, 1998.
<blockquote> The coordination between the sensor and motor systems is an 
essential feature in autonomous intelligent systems. This thesis investigates 
the evolutionary approach to sensorimotor control using learning classifier 
systems. A simple classifier system is used to solve the problem of 
coordinating a pair of eyes and an arm in order to catch an object. First, an 
analysis of the previous approaches based on neural networks is done. Then a 
review of what a simple classifier system is, as well as the specific 
implementation of the simple classifier system to solve this problem. 
Afterwards an analysis of the results is presented. Finally a review of the 
advantages and disadvantages of this approach comparing it with previous ones 
is offered. Results have shown that classifier systems are a promising tool, 
which solve this sensorimotor coordination problem, further work needs to be 
done to determine the limitations of this approach.</blockquote> 
<p> </p> </dd> 
<dt> [422] </dt> 
<dd> Luis&nbsp;Miramontes Hercog. Evolutionary algorithms and collective 
learning for traffic demand policy management. Technical report, South Bank 
University, 2003.
<p> </p> </dd> 
<dt> [423] </dt> 
<dd> F.&nbsp;Herrera and J.&nbsp;L. Verdegay, editors. Genetic Algorithms and 
Soft Computing, (Studies in Fuzziness, 8). Physica-Verlag, Berlin, 1996. 
<p> </p> </dd> 
<dt> [424] </dt> 
<dd> E.&nbsp;Herrera-Viedma. Sistemas Clasificadores de Aprendizaje. 
Aproximaciones Difusas. Technical Report DECSAI-95132, Dept. of Computer 
Science and A.I., University of Granada, 1995.
<blockquote> La Inteligencia Artificial tiene planteado el reto de lograr 
crear sistemas computacionales que desarrollen una conducta similar a la 
conducta humana. Esto no es tarea facil y es el quebradero de cabeza de muchos 
investigadores. En el presente trabajo hemos intentado estudiar algunas de las 
aportaciones que se estan haciendo desde el campo de los Algoritmos Geneticos y 
su integracion con tecnicas basadas en Conjuntos Fuzzy. Concretamente, 
analizaremos uno de los paradigmas de aprendizaje de los AGs, Los Sistemas 
Clasificadores, y algunas de sus aproximaciones fuzzy, varios modelos de 
Sistemas Clasificadores Fuzzy. Es importante destacar que estos sistemas son de 
especial interes por la implicaciones que pueden tener en el desarrollo de 
sistema de control de aprendizaje autonomos y adaptativos que pueden actuar de 
forma ``inteligente'', de modo similar a los seres humanos.</blockquote> 
<p> </p> </dd> 
<dt> [425] </dt> 
<dd> Tetsuya Higuchi and Bernard Manderick. Hardware realizations of 
evolutionary algorithms. In Thomas B&auml;ck, David&nbsp;B. Fogel, and Zbigniew 
Michalewicz, editors,Handbook of Evolutionary Computation, pages E2.3:1-G2.3:8. 
IOP Publishing Ltd and Oxford University Press, 1997.
<p> </p> </dd> 
<dt> [426] </dt> 
<dd> M.&nbsp;R. Hilliard, G.&nbsp;E. Liepins, Mark Palmer, Michael Morrow, and 
Jon Richardson. A classifier based system for discovering scheduling 
heuristics. InGrefenstette [391], pages 231-235. 
<p> </p> </dd> 
<dt> [427] </dt> 
<dd> M.&nbsp;R. Hilliard, G.&nbsp;E. Liepins, and M.&nbsp;Palmer. Machine 
learning applications to job shop scheduling. InProc. AAAI-SIGMAN Workshop on 
Production Planning and Scheduling, 1988. 
<p> </p> </dd> 
<dt> [428] </dt> 
<dd> John&nbsp;H. Holland and Arthur&nbsp;W. Burks. Adaptive Computing System 
Capable of Learning and Discovery. Patent 4697242 United States 29 Sept., 1987. 
<p> </p> </dd> 
<dt> [429] </dt> 
<dd> John&nbsp;H. Holland and J.&nbsp;S. Reitman. Cognitive systems based on 
adaptive algorithms. In D.&nbsp;A. Waterman and F.&nbsp;Hayes-Roth, editors,
Pattern-directed Inference Systems. New York: Academic Press, 1978. Reprinted 
in: Evolutionary Computation. The Fossil Record. David B. Fogel (Ed.) IEEE 
Press, 1998. ISBN: 0-7803-3481-7.
<blockquote> The type of cognitive system (CS) studied here has four basic 
parts: (1) a set of interacting elementary productions, called classifiers, (2) 
a performance algorithm that directs the action of the system in the 
environment, (3) a simple learning algorithm that keeps a record of each 
classifier's success in bringing about rewards, and (4) a more complex learning 
algorithm, called the genetic algorithm, that modifies the set of classifiers 
so that variants of good classifiers persist and new, potentially better ones 
are created in a provably efficient manner. Two ``proof-of-principle'' 
experiments are reported. One experiment shows CS's performance in a maze when 
it has only the ability to adjust the predictions about ensuing rewards of 
classifiers (similar to adjusting the ``weight'' of a classifier) vs. when the 
power of the genetic algorithm is added. Criterion was achieved an order of 
magnitude more rapidly when the genetic algorithm was operative. A second 
experiment examines transfer of learning. Placed in a more difficult maze, CS 
with experience in the simpler maze reaches criterion an order of magnitude 
more rapidly than CS without prior experience.</blockquote> 
<p> </p> </dd> 
<dt> [430] </dt> 
<dd> John&nbsp;H. Holland, Keith&nbsp;J. Holyoak, Richard&nbsp;E. Nisbett, and 
P.&nbsp;R. Thagard.Induction: Processes of Inference, Learning, and Discovery. 
MIT Press, Cambridge, 1986.
<p> </p> </dd> 
<dt> [431] </dt> 
<dd> John&nbsp;H. Holland, Keith&nbsp;J. Holyoak, Richard&nbsp;E. Nisbett, and 
Paul&nbsp;R. Thagard. Classifier Systems, Q-Morphisms, and Induction. InDavis 
[234], pages 116-128. 
<p> </p> </dd> 
<dt> [432] </dt> 
<dd> John&nbsp;H. Holland, Lashon&nbsp;B. Booker, Marco Colombetti, Marco 
Dorigo, David&nbsp;E. Goldberg, Stephanie Forrest, Rick&nbsp;L. Riolo, 
Robert&nbsp;E. Smith, Pier&nbsp;Luca Lanzi, Wolfgang Stolzmann, and 
Stewart&nbsp;W. Wilson. What is a Learning Classifier System? InLanzi 
et&nbsp;al. [544], pages 3-32. 
<blockquote> We asked ``What is a Learning Classifier System'' to some of the 
best-known researchers in the field. These are their answers.</blockquote> 
<p> </p> </dd> 
<dt> [433] </dt> 
<dd> John&nbsp;H. Holland. Processing and processors for schemata. In 
E.&nbsp;L. Jacks, editor,Associative Information Processing, pages 127-146. New 
York: American Elsevier, 1971.
<p> </p> </dd> 
<dt> [434] </dt> 
<dd> John&nbsp;H. Holland. Adaptation in Natural and Artificial Systems. 
University of Michigan Press, Ann Arbor, 1975. Republished by the MIT press, 
1992.
<p> </p> </dd> 
<dt> [435] </dt> 
<dd> John&nbsp;H. Holland. Adaptation. In R.&nbsp;Rosen and F.&nbsp;M. Snell, 
editors,Progress in Theoretical Biology. New York: Plenum, 1976. 
<p> </p> </dd> 
<dt> [436] </dt> 
<dd> John&nbsp;H. Holland. Adaptive algorithms for discovering and using 
general patterns in growing knowledge bases.International Journal of Policy 
Analysis and Information Systems, 4(3):245-268, 1980. 
<p> </p> </dd> 
<dt> [437] </dt> 
<dd> John&nbsp;H. Holland. Genetic Algorithms and Adaptation. Technical 
Report&nbsp;34, University of Michigan. Department of Computer and 
Communication Sciences, Ann Arbor, 1981.
<p> </p> </dd> 
<dt> [438] </dt> 
<dd> John&nbsp;H. Holland. Escaping brittleness. In Proceedings Second 
International Workshop on Machine Learning, pages 92-95, 1983. 
<blockquote> Expert systems are powerful when working within the 
domain-specific boundaries of the initial design. It is widely agreed that the 
usefulness of such systems would be greatly enhanced if they could be made more 
versatile or less brittle - tolerant of changes in the domain and underlying 
model. This paper suggests 7 criteria for escaping brittleness (combination, 
parallelism, declarative and procedural information, categorization, synchronic 
and diachronic pointing, gracefulness and confirmation) and gives an example of 
a class of general purpose systems, classifier systems, that attempt to meet 
these criteria.</blockquote> 
<p> </p> </dd> 
<dt> [439] </dt> 
<dd> John&nbsp;H. Holland. Properties of the bucket brigade. In Grefenstette 
[389], pages 1-7. 
<blockquote> This paper does not have an absract. </blockquote> 
<p> </p> </dd> 
<dt> [440] </dt> 
<dd> John&nbsp;H. Holland. A Mathematical Framework for Studying Learning in a 
Classifier System. In Doyne Farmer, Alan Lapedes, Norman Packard, and Burton 
Wendroff, editors,Evolution, Games and Learning: Models for Adaptation in 
Machines and Nature, pages 307-317, Amsterdam, 1986. North-Holland. 
<p> </p> </dd> 
<dt> [441] </dt> 
<dd> John&nbsp;H. Holland. A Mathematical Framework for Studying Learning in 
Classifier Systems.Physica D, 22:307-317, 1986. 
<blockquote> Massively parallel, rule-based systems offer both a practical and 
a theoretical tool for understanding systems that act usefully in complex 
environments [see, for example, refs 1-4]. However, these systems pose a number 
of problems of a high order of difficulty -- problems that can be broadly 
characterized as problems in nonlinear dynamics. The difficulties stem from the 
fact that the systems are designed to act in environments with complex 
transition functions -- environments that, in all circumstances of interest, 
are far from equilibrium. Interactions with the environment thus face the 
systems with perpetual novelty, and the usual simplifications involving fixed 
points, limit cycles, etc,. just do not apply. Learning procedures (adaptive 
algorithms) offer a way of combating these difficulties, but an understanding 
of the possibilities is not a simple matter. The key question is easy enough to 
state informally: What kinds of environmental regularity can be exploited by 
learning? However, if answers that are both useful and widely applicable are to 
be forthcoming, the question must be reformulated in a way that gives it 
precision without losing generality. The usual tool for this task is a 
mathematical framework that suitably encompasses the subject. It is the purpose 
of this paper to explore a framework that gives a precise definition to the 
notion of an environmental regularity and then treats learning procedures as 
procedures for revising rules in response to detected environmental 
regularities. In this context, procedures for revising rules become more than a 
convenience, they take a central place in the design. Whether carried out by a 
human or a machine, rule revision requires the solution of two broad problems. 
First, one must rate rules as to their usefulness to the system as a whole -- 
the apportionment of credit problem. Then one must devise new rules that serve 
the system better than the least useful of the rules already in place -- the 
rule discovery problem. Though these two problems are sometimes treated 
separately, they are closely interrelated. A machine learning approach is used 
here to illustrate the interaction of apportionment of credit and rule 
discovery algorithms, and then the overall system is abstracted and translated 
to the mathematical framework. To give the framework a concrete subject matter, 
section 1 introduces a particular class of highly parallel, rule-based systems 
called classifier systems. The next section....</blockquote> 
<p> </p> </dd> 
<dt> [442] </dt> 
<dd> John&nbsp;H. Holland. Escaping Brittleness: The Possibilities of 
General-Purpose Learning Algorithms Applied to Parallel Rule-Based Systems. In 
Mitchell, Michalski, and Carbonell, editors,Machine Learning, an Artificial 
Intelligence Approach. Volume II, chapter&nbsp;20, pages 593-623. Morgan 
Kaufmann, 1986.
<blockquote> Message-passing, rule-based production systems in which many 
rules are active simultaneously offer attractive possibilities for the 
exploitation of general-purpose machine learning algorithms. In such systems 
each rule can be looked upon as a tentative hypothesis about some aspect of the 
task environment, competing against other plausible hypotheses being 
entertained at the same time. In this context there are two major tasks for 
machine learning algorithms: (1) apportionment of credit and (2) rule 
discovery. The apportionment-of-credit algorithm(s) must assign ``strength'' to 
rules on the basis of their observed usefulness to the system. The problem is 
complicated by the difficulty of determining which of a cluster of rules active 
in an early, ``stage-setting'' capacity has contributed to a later useful 
outcome (e.g., rules controlling early moves that make possible later a triple 
jump in checkers). If strengths can be assigned appropriately, then they can be 
used to determine a rule's ability to win against competing rules, and they can 
be used to determine the rule's likelihood of being used as a ``parent'' for 
new rules. Surprisingly, for credit apportionment algorithms of the 
bucket-brigade variety, one can prove fixed-point theorems that provide some 
guarantees of an appropriate apportionment. The task of rule discovery depends 
critically upon the discovery of good ``building blocks'' for generating 
plausible rules (hypotheses). A parallel system designed with machine learning 
in mind must permit a constant flux of new rules to be tested and exploited or 
discarded. Moreover this flux must not disturb the system's behavior in task 
environments for which it has well-practiced, effective procedures. Genetic 
algorithms, using the strengths as ``fitnesses'', offer subtle ways of 
discovering good building blocks, and there are new versions of theorems from 
mathematical genetics that enable us to understand this discovery process.
</blockquote> 
<p> </p> </dd> 
<dt> [443] </dt> 
<dd> John&nbsp;H. Holland. Genetic Algorithms and Classifier Systems: 
Foundations and Future Directions. InGrefenstette [391], pages 82-89. 
<blockquote> Theoretical questions about classifier systems, with rare 
exceptions, apply equally to other adaptive nonlinear networks (ANNs) such as 
the connectionist models of cognitive psychology, the immune system, economic 
systems, ecologies and genetic systems. This paper discusses pervasive 
properties of ANNs and the kinds of mathematics relevant to questions about 
these properties. It discusses relevant functional extensions of the basic 
classifier system and extensions of the extant mathematical theory. An appendix 
briefly reviews some of the key theorems about classifier systems.</blockquote> 
<p> </p> </dd> 
<dt> [444] </dt> 
<dd> John&nbsp;H. Holland. Concerning the Emergence of Tag-Mediated Lookahead 
in Classifier Systems. InSpecial issue of Physica D (Vol. 42) [292], pages 
188-201.
<blockquote> This paper, after a general introduction to the area, discusses 
the architecture and learning algorithms that permit automatic parallel, 
distributed lookahead to emerge in classifier systems. Simple additions to a 
``standard'' classifier system suffice, principally a new register called the 
virtual strength register, and a provision to use the bucket brigade 
credit-assignment algorithm in ``virtual'' mode to modify values in this 
register. With these additions, current actions are decided on the basis of 
expected values associated with the ``lookahead cones'' of possible 
alternatives.</blockquote> 
<p> </p> </dd> 
<dt> [445] </dt> 
<dd> John&nbsp;H. Holmes, Dennis&nbsp;R. Durbin, and Flaura&nbsp;K. Winston. A 
New Bootstrapping Method to Improve Classification Performance in Learning 
Classifier Systems. InProceedings of Parallel Problem Solving from Nature (PPSN 
VI), 2000. 
<blockquote> A new technique for improving the classification performance of 
learning classifier systems (LCS) was developed and applied to a real-world 
data mining problem. EpiCS, a stimulus-response LCS, was adapted to perform 
prevalence-based bootstrapping, wherein data from training and testing sets 
were sampled according to the prevalence of the individual classes, rather than 
randomly using the class distribution inherent in the data. Prevalence-based 
bootstrapping was shown to improve classification performance significantly on 
training and testing (p&lt;0.0001). Furthermore, this procedure was shown to 
enhance EpiCS's classification performance on testing compared to C4.5 when 
similar bootstrapping procedures were applied to the latter.</blockquote> 
<p> </p> </dd> 
<dt> [446] </dt> 
<dd> John&nbsp;H. Holmes, Dennis&nbsp;R. Durbin, and Flaura&nbsp;K. Winston. 
The learning classifier system: an evolutionary computation approach to 
knowledge discovery in epidemiologic surveillance.Artificial Intelligence In 
Medicine, 19(1):53-74, 2000. 
<blockquote> The learning classifier system (LCS) integrates a rule-based 
system with reinforcement learning and genetic algorithm-based rule discovery. 
This investigation reports on the design, implementation, and evaluation of 
EpiCS, a LCS adapted for knowledge discovery in epidemiologic surveillance. 
Using data from a large, national child automobile passenger protection 
program, EpiCS was compared with C4.5 and logistic regression to evaluate its 
ability to induce rules from data that could be used to classify cases and to 
derive estimates of outcome risk, respectively. The rules induced by EpiCS were 
less parsimonious than those induced by C4.5, but were potentially more useful 
to investigators in hypothesis generation. Classification performance of C4.5 
was superior to that of EpiCS (P&lt;0.05). However, risk estimates derived by 
EpiCS were significantly more accurate than those derived by logistic 
regression (P&lt;0.05).</blockquote> 
<p> </p> </dd> 
<dt> [447] </dt> 
<dd> John&nbsp;H. Holmes, Jennifer&nbsp;A. Sager, and Warren&nbsp;B. Bilker. 
Three methods for covering missing input data in xcs. InLearning Classifier 
Systems, volume 4399 of LNAI, pages 181-192. Springer, 2007. 
<p> </p> </dd> 
<dt> [448] </dt> 
<dd> John&nbsp;H. Holmes, Jennifer&nbsp;A. Sager, and Warren&nbsp;B. Bilker. 
Three methods for covering missing input data in xcs. In Tim Kovacs, Xavier 
LL&ograve;ra, Keiki Takadama, Pier&nbsp;Luca Lanzi, Wolfgang Stolzmann, and 
Stewart&nbsp;W. Wilson, editors,Learning Classifier Systems. International 
Workshops, IWLCS 2003-2005, Revised Selected Papers, volume 4399 of LNCS, pages 
181-192. Springer, 2007.
<blockquote> Missing data pose a potential threat to learning and 
classification in that they may compromise the ability of a system to develop 
robust, generalized models of the environment in which they operate. This 
investigation reports on the effects of three approaches to covering these data 
using an XCS-style learning classifier system. Using fabricated datasets 
representing a wide range of missing value densities, it was found that missing 
data do not appear to adversely affect LCS learning and classification 
performance. Furthermore, three types of missing value covering were found to 
exhibit similar efficiency on these data, with respect to convergence rate and 
classification accuracy.</blockquote> 
<p> </p> </dd> 
<dt> [449] </dt> 
<dd> John&nbsp;H. Holmes. Evolution-Assisted Discovery of Sentinel Features in 
Epidemiologic Surveillance. PhD thesis, Drexel University, 1996. 
http://cceb.med.upenn.edu/holmes/disstxt.ps.gz.
<blockquote> The use of a genetics-based classifier system (CS) in generating 
epidemiologic hypotheses was investigated. In addition, epidemiologic 
analytical techniques were used to evaluate the performance of a CS in this 
problem domain. Five component studies were implemented, using epidemiologic 
surveillance data over a range of prevalences. The evaluation study 
investigated the use of the area under the receiver operating characteristic 
curve (*) as an alternative to crude accuracy (CA) during the training period. 
The classification study examined the ability of the CS to classify 
unencountered patients. The reproducibility study demonstrated the stochastic 
processes underlying CS performance during training and testing. The 
payoff-penalty parameterization study investigated the effects of differential 
penalty for false negative and false positive decisions on learning rate and 
classification ability. The risk assessment study examined the ability of a CS 
to derive estimates of risk for purposes of classification. At 50% prevalence, 
* was identical to CA over the entire training period; with decreasing 
prevalence, CA increasingly overestimated the learning rate, while * provided 
more accurate depictions of this measure. Across all four prevalences 
investigated, the CS was able to classify unseen patients well, with *s ranging 
from 0.95 at 50% prevalence to 0.78 at 10%. The classifier populations after 
training indicated considerable generalization; decision rules were discernible 
on visual examination. When trained and tested using 1,000 different data sets 
drawn from the same pool, the CS was fairly consistent in terms of learning 
rate and classification ability, although with sufficient variation to warrant 
investigating the use of bootstrapping techniques. Biasing the ratio of false 
positive to false negative (FP:FN) decisions affected the learning rate 
relative to prevalence. Learning rate was most enhanced at 25% and 10% 
prevalence by a FP:FN ratio of 4:1 and 10:1, respectively. Across all four 
prevalences, the CS was able to produce risk estimates that consistently 
outperformed decision rules derived using logistic regression. The CS was shown 
to be a useful adjunct to hypothesis generation during epidemiologic 
surveillance.</blockquote> 
<p> </p> </dd> 
<dt> [450] </dt> 
<dd> John&nbsp;H. Holmes. A genetics-based machine learning approach to 
knowledge discovery in clinical data.Journal of the American Medical 
Informatics Association Supplement, 1996. 
<p> </p> </dd> 
<dt> [451] </dt> 
<dd> John&nbsp;H. Holmes. Discovering Risk of Disease with a Learning 
Classifier System. In B&auml;ck [24]. 
http://cceb.med.upenn.edu/holmes/icga97.ps.gz.
<blockquote> A learning classifier system, EpiCS, was used to derive a 
continuous measure of disease risk in a series of 250 individuals. Using the 
area under the receiver-operating characteristic curve, this measure was 
compared with the risk estimate derived for the same individuals by logistic 
regression. Over 20 training-testing trials, risk estimates derived by EpiCS 
were consistently more accurate (mean area=0.97, SD=0.01) than that derived by 
logistic regression (mean area=0.89, SD=0.02). The areas for the trials with 
minimum and maximum classification performance on testing were significantly 
greater (p=0.019 and p&lt;0.001, respectively) than the area for the logistic 
regression curve. This investigation demonstrated the ability of a learning 
classifier system to produce output that is clinically meaningful in diagnostic 
classification.</blockquote> 
<p> </p> </dd> 
<dt> [452] </dt> 
<dd> John&nbsp;H. Holmes. Differential negative reinforcement improves 
classifier system learning rate in two-class problems with unequal base rates. 
InKoza et&nbsp;al. [529], pages 635-642. 
http://cceb.med.upenn.edu/holmes/gp98.ps.gz.
<blockquote> The effect of biasing negative reinforcement levels on learning 
rate and classification accuracy in a learning classifier system (LCS) was 
investigated. Simulation data at five prevalences (base rates) were used to 
train and test the LCS. Erroneous decisions made by the LCS during training 
were punished differentially according to type: false positive (FP) or false 
negative (FN), across a range of four FP:FN ratios. Training performance was 
assessed by learning rate, determined from the number of iterations required to 
reach 95% of the maximum area under the receiver operating characteristic (ROC) 
curve obtained during learning. Learning rates were compared across the three 
biased ratios with those obtained at the unbiased ratio. Classification 
performance of the LCS at testing was evaluated by means of the area under the 
ROC curve. During learning, differences were found between the biased and 
unbiased penalty schemes, but only at unequal base rates. A linear relationship 
between bias level and base rate was suggested. With unequal base rates, 
biasing the FP:FN ratio improved the learning rate. Little effect was observed 
on testing the LCS with novel cases.</blockquote> 
<p> </p> </dd> 
<dt> [453] </dt> 
<dd> John&nbsp;H. Holmes. Evaluating Learning Classifier System Performance In 
Two-Choice Decision Tasks: An LCS Metric Toolkit. InBanzhaf et&nbsp;al. [32], 
page 789. One page poster paper.
<blockquote> A ``metric toolkit'' to evaluate learning classifier system 
performance is proposed. The metrics are shown to be superior to crude accuracy 
in evaluating classification performance, especially for data with unequal 
numbers of positive and negative cases. In addition, these metrics provide 
information to the researcher that is not available from crude accuracy. When 
used appropriately, these metrics provide accurate depictions of learning 
classifier system performance during training and testing in supervised 
learning environments.</blockquote> 
<p> </p> </dd> 
<dt> [454] </dt> 
<dd> John&nbsp;H. Holmes. Quantitative Methods for Evaluating Learning 
Classifier System Performance in Forced Two-Choice Decision Tasks. In Wu [923], 
pages 250-257.
<blockquote> Applying a learning classifier system to two-class decision 
problems requires a special approach to performance evaluation. This paper 
presents a suite of quantitative tools that addresses the evaluation 
requirements of two-class problems. These metrics, borrowed from the domain of 
medical decision making, are proposed as adjuncts to commonly used evaluation 
methods such as crude accuracy (``percent correct''). They include sensitivity, 
specificity, area under the receiver operating characteristic curve, and 
predictive value. These metrics are shown to be superior to crude accuracy in 
evaluating learning classifier system performance, especially when applied to 
data with unequal numbers of positive and negative cases. In addition, these 
metrics provide information to the researcher that is not available from crude 
accuracy. When used appropriately, these metrics provide accurate depictions of 
learning classifier system performance during training and testing in 
supervised learning environments.</blockquote> 
<p> </p> </dd> 
<dt> [455] </dt> 
<dd> John&nbsp;H. Holmes. Applying a Learning Classifier System to Mining 
Explanatory and Predictive Models from a Large Database. InProceedings of the 
International Workshop on Learning Classifier Systems (IWLCS-2000), in the 
Joint Workshops of SAB 2000 and PPSN 2000 [487]. Extended abstract. 
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [456] </dt> 
<dd> John&nbsp;H. Holmes. Learning Classifier Systems Applied to Knowledge 
Discovery in Clinical Research Databases. InLanzi et&nbsp;al. [544], pages 
243-261.
<blockquote> A stimulus-response learning classifier system (LCS), EpiCS, was 
developed from the BOOLE and NEWBOOLE models to address the needs of knowledge 
discovery in databases used in clinical research. Two specific needs were 
investigated: the derivation of accurate estimates of disease risk, and the 
ability to deal with rare clinical outcomes. EpiCS was shown to have excellent 
classification accuracy, compared to logistic regression, when using risk 
estimates as the primary means for classification. This was especially true in 
data with low disease prevalence. EpiCS was designed to accommodate 
differential negative reinforcement when false positive or false negative 
decisions were made by the system. This feature was investigated to determine 
its effect on learning rate and classification accuracy. Tested across a range 
of disease prevalences, the learning rate improved when erroneous decisions 
were differentially negatively reinforced. However, classification accuracy was 
not affected by differential negative reinforcement.</blockquote> 
<p> </p> </dd> 
<dt> [457] </dt> 
<dd> John&nbsp;H. Holmes. A representation for accuracy-based assessment of 
classifier system prediction performance. InLanzi et&nbsp;al. [546], pages 
43-56.
<p> </p> </dd> 
<dt> [458] </dt> 
<dd> Keith&nbsp;J. Holyoak, K.&nbsp;Koh, and Richard&nbsp;E. Nisbett. A Theory 
of Conditioning: Inductive Learning within Rule-Based Default Hierarchies.
Psych. Review, 96:315-340, 1990. 
<p> </p> </dd> 
<dt> [459] </dt> 
<dd> Jeffrey Horn and David&nbsp;E. Goldberg. Natural Niching for Cooperative 
Learning in Classifier Systems. InKoza et&nbsp;al. [527], pages 553-564. 
<p> </p> </dd> 
<dt> [460] </dt> 
<dd> Jeffrey Horn and David&nbsp;E. Goldberg. A Timing Analysis of Convergence 
to Fitness Sharing Equilibrium. In Parallel Problem Solving from Nature (PPSN), 
1998.
<blockquote> Fitness sharing has been shown to be an effective niching 
mechanism in genetic algorithms (GAs). Sharing allows GAs to maintain multiple, 
cooperating ``species'' in a single population for many generations under 
severe selective pressure. While recent studies have shown that the maintenance 
time for niching equilibrium is long, it has never been shown that the time it 
takes to reach equilibrium is sufficiently fast. While experiments indicate 
that selection under fitness sharing drives the population to equilibrium just 
as fast and as effectively as selection alone drives the simple GA to a uniform 
population, we can now show analytically that this is the case.</blockquote> 
<p> </p> </dd> 
<dt> [461] </dt> 
<dd> Jeffrey Horn and David&nbsp;E. Goldberg. Towards a Control Map for 
Niching. InFoundations of Genetic Algorithms (FOGA), pages 287-310, 1998. 
<blockquote> Niching can allow a diverse population to cooperatively represent 
a single, distributed solution to the problem at hand. Successful niching 
mechanisms must promote both cooperation (i.e., co- existence of separate 
``species'' for each desired niche), and competition (i.e., intensive search 
for the best species for each niche, and for the best niches). In this paper we 
seek the competitive- cooperative boundary in the space of possible niche 
relationships, that will allow us to successfully predict which pairs of 
interacting niches will survive under GA selection and which niche pairs will 
be resolved to yield a single winner. By combining extant models of niching 
equilibrium, niche maintenance, and convergence, we define the regions of 
cooperation and competition on a map of niching scenarios varying along the 
dimensions of niche overlap and relative niche fitness. We verify this 
predictive map of niching failure/success, and discuss its utility in allowing 
us to control for the competitive evolution of desired types of cooperation. 
Although our models are specific to the niching mechanism we call resource 
sharing, we believe the development of competitive-cooperative control maps is 
important for niching theory in general.</blockquote> 
<p> </p> </dd> 
<dt> [462] </dt> 
<dd> Jeffrey Horn, David&nbsp;E. Goldberg, and Kalyanmoy Deb. Implicit Niching 
in a Learning Classifier System: Nature's Way. Evolutionary Computation, 
2(1):37-66, 1994. Also IlliGAL Report No 94001, 1994.
<blockquote> We approach the difficult task of analyzing the complex behavior 
of even the simplest learning classifier system (LCS) by isolating one crucial 
subfunction in the LCS learning algorithm: covering through niching. The LCS 
must maintain a population of diverse rules that together solve a problem 
(e.g., classify examples). To maintain a diverse population while applying the 
GA's selection operator, the LCS must incorporate some kind of niching 
mechanism. The natural way to accomplish niching in an LCS is to force 
competing rules to share resources (i.e., rewards). This implicit LCS fitness 
sharing is similar to the explicit fitness sharing used in many niched GAs. 
Indeed, the LCS implicit sharing algorithm can he mapped onto explicit fitness 
sharing with a one-to-one correspondence between algorithm components. This 
mapping is important because several studies of explicit fitness sharing, and 
of niching in GAs generally, have produced key insights and analytical tools 
for understanding the interaction of the niching and selection forces. We can 
now bring those results to bear in understanding the fundamental type of 
cooperation (a.k.a. weak cooperation) that an LCS must promote.</blockquote> 
<p> </p> </dd> 
<dt> [463] </dt> 
<dd> Jeffrey Horn. The Nature of Niching: Genetic Algorithms and the Evolution 
of Optimal, Cooperative Populations. PhD thesis, University of Illinois at 
Urbana-Champaign (UMI Dissertation Service No. 9812622, 1997.
<p> </p> </dd> 
<dt> [464] </dt> 
<dd> D.&nbsp;Howard and L.&nbsp;Bull. On the effects of node duplication and 
connection-orientated constructivism in neural XCSF. In M.&nbsp;Keijzer 
et&nbsp;al., editor,GECCO-2008: Proceedings of the Genetic and Evolutionary 
Computation Conference, pages 1977-1984. ACM, 2008. 
<p> </p> </dd> 
<dt> [465] </dt> 
<dd> D.&nbsp;Howard, L.&nbsp;Bull, and P.L. Lanzi. Self-Adaptive 
Constructivism in Neural XCS and XCSF. In M.&nbsp;Keijzer et&nbsp;al., editor,
GECCO-2008: Proceedings of the Genetic and Evolutionary Computation Conference, 
pages 1389-1396. ACM, 2008.
<p> </p> </dd> 
<dt> [466] </dt> 
<dd> Dijia Huang. A framework for the credit-apportionment process in 
rule-based systems.IEEE Transactions on Systems, Man and Cybernetics, 1989. 
<p> </p> </dd> 
<dt> [467] </dt> 
<dd> Dijia Huang. Credit Apportionment in Rule-Based Systems: Problem Analysis 
and Algorithm Synthesis. PhD thesis, University of Michigan, 1989. 
<p> </p> </dd> 
<dt> [468] </dt> 
<dd> Dijia Huang. The Context-Array Bucket-Brigade Algorithm: An Enhanced 
Approach to Credit-Apportionment in Classifier Systems. InSchaffer [718], pages 
311-316.
<blockquote> The credit-apportionment problem in the classifier system refers 
to the problem of assigning credit or blame to each rule involved in achieving 
a certain goal. This paper presents an enhanced credit-apportionment algorithm: 
the context-array bucket-brigade algorithm for solving the credit apportionment 
problems in the classifier system. This algorithm separates the contexts (the 
circumstances in which rules can fire) into context subsets. Then it employs 
array-valued bids (strengths) to estimate rule usefulness at the context subset 
level. The essence of this algorithm is that (i) it improves 
credit-apportionment and (ii) it provides explicit information for rule 
discovery. Favorable results have been observed in the tests of two versions of 
the algorithm.</blockquote> 
<p> </p> </dd> 
<dt> [469] </dt> 
<dd> Jacob Hurst and Larry Bull. A Self-Adaptive Classifier System. In 
Proceedings of the International Workshop on Learning Classifier Systems 
(IWLCS-2000), in the Joint Workshops of SAB 2000 and PPSN 2000 [487]. Extended 
abstract.
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [470] </dt> 
<dd> Jacob Hurst and Larry Bull. A Self-Adaptive XCS. In Lanzi et&nbsp;al. 
[546], pages 57-73. 
<p> </p> </dd> 
<dt> [471] </dt> 
<dd> J.&nbsp;Hurst and L.&nbsp;Bull. Self-adaptation in classifier system 
controllers.Artificial Life and Robotics, 5(2):109-119, 2003. 
<p> </p> </dd> 
<dt> [472] </dt> 
<dd> J.&nbsp;Hurst and L.&nbsp;Bull. A self-adaptive neural learning 
classifier system with constructivism for mobile robot control. In X.&nbsp;Yao 
et&nbsp;al., editor,Parallel problem solving from nature (PPSN VIII), volume 
3242 ofLNCS, pages 942-951. Springer, 2004. 
<p> </p> </dd> 
<dt> [473] </dt> 
<dd> Francesc Xavier&nbsp;Llor&agrave; i&nbsp;F&agrave;brega and Josep 
Maria&nbsp;Garrell i&nbsp;Guiu. GENIFER: A Nearest Neighbour based Classifier 
System using GA. InBanzhaf et&nbsp;al. [32], page 797. One page poster paper 
appeared at GECCO. The full version is available at 
http://www.salleurl.edu/~xevil/Work/index.html.
<blockquote> This work has no abstract </blockquote> 
<p> </p> </dd> 
<dt> [474] </dt> 
<dd> Francesc Xavier&nbsp;Llor&agrave; i&nbsp;F&agrave;brega, Josep 
Maria&nbsp;Garrell i&nbsp;Guiu, and Ester&nbsp;Bernad&oacute; i&nbsp;Mansilla. 
A Classifier System based on Genetic Algorithm under the Pittsburgh approach 
for problems with real valued attributes. In Viceng Torra, editor,Proceedings 
of Artificial Intelligence Catalan Workshop (CCIA98), volume 14-15, pages 
85-93. ACIA Press, 1998. In Catalan 
http://www.salleurl.edu/~xevil/Work/index.html.
<p> </p> </dd> 
<dt> [475] </dt> 
<dd> Francesc Xavier&nbsp;Llor&agrave; i&nbsp;F&agrave;brega. Automatic 
Classification using genetic algorithms under a Pittsburgh approach. Master's 
thesis, Enginyeria La Salle - Ramon Llull University, 1998. 
http://www.salleurl.edu/~xevil/Work/index.html.
<blockquote> This master thesis explores the application of genetic algorithms 
as a supervised machine learning technique. It studies different 
classifications approaches (Michigan and Pittsburgh), and generates different 
individual codification and evaluation function alternatives. The 
classification centers its scope in problems described using real value 
attributes. All these approaches are modelled under a Pittsburgh philosophy. To 
validated them, and to analize they performance, they are applied to solve a 
real world problem: ``The automatic classification of mammary biopsy images''.
</blockquote> 
<p> </p> </dd> 
<dt> [476] </dt> 
<dd> Josep Maria&nbsp;Garrell i&nbsp;Guiu, Elisabet&nbsp;Golobardes 
i&nbsp;Rib&eacute;, Ester&nbsp;Bernad&oacute; i&nbsp;Mansilla, and Francesc 
Xavier&nbsp;Llor&agrave; i&nbsp;F&agrave;brega. Automatic Classification of 
mammary biopsy images with machine learning techniques. In E.&nbsp;Alpaydin, 
editor,Proceedings of Engineering of Intelligent Systems (EIS'98), 
volume&nbsp;3, pages 411-418. ICSC Academic Press, 1998. 
http://www.salleurl.edu/~xevil/Work/index.html.
<blockquote> This paper describes the application of Machine Learning (ML) 
techniques to a real world problem: the Automatic Diagnosis (classification) of 
Mammary Biopsy Images. The starting point consists of a set of data (solved 
cases) provided by the Signal Theory Research Group of our University [9]. The 
techniques applied are Genetic Algorithms (GA) and Case-Based Reasoning (CBR). 
The paper compares our results with previous ones obtained using Neural 
Networks (NN) [10]. The main goals are: to efficiently solve classification 
problems of such a type, to compare different alternatives for ML and to study 
hybrid systems. The paper also introduces the systems we developed for solving 
this kind of classification problems: GeB-CS (Genetic Based Classifier System) 
for a GA approach, and CaB-CS (Case-Based Classifier System) for a CBR approach.
</blockquote> 
<p> </p> </dd> 
<dt> [477] </dt> 
<dd> Josep Maria&nbsp;Garrell i&nbsp;Guiu, Elisabet&nbsp;Golobardes 
i&nbsp;Rib&eacute;, Ester&nbsp;Bernad&oacute; i&nbsp;Mansilla, and Francesc 
Xavier&nbsp;Llor&agrave; i&nbsp;F&agrave;brega.Automatic Diagnosis with Genetic 
Algorithms and Case-Based Reasoning. Artificial Intelligence in Engineering, 
13(4):367-372, 1999. (This is an expanded version of Guiu98a).
<p> </p> </dd> 
<dt> [478] </dt> 
<dd> H.&nbsp;Iba, H.&nbsp;de&nbsp;Garis, and T.&nbsp;Higuchi. Evolutionary 
Learning of Predatory Behaviors Based on Structured Classifiers. InRoitblat and 
Wilson [700], pages 356-363. 
<p> </p> </dd> 
<dt> [479] </dt> 
<dd> H.&nbsp;Inoue, K.&nbsp;Takadama, M.&nbsp;Okada, K.&nbsp;Shimohara, , and 
O.&nbsp;Katai. Agent architecture based on self-reflection learning classifier 
system. InThe 5th International Symposium on Artificial Life and Robotics 
(AROB'2000), pages 454-457, 2000. 
<p> </p> </dd> 
<dt> [480] </dt> 
<dd> H.&nbsp;Inoue, K.&nbsp;Takadama, and K.&nbsp;Shimohara. Inference of 
user's internal states and its agent's architecture. InThe 20th System 
Engineering Meeting of SICE (The Society of Instrument and Control Engineers), 
pages 55-60, 2000.
<p> </p> </dd> 
<dt> [481] </dt> 
<dd> Charalambos Ioannides and Will Browne. Investigating scaling of an 
abstracted lcs utilising ternary and s-expression alphabets. In Jaume Bacardit, 
Ester Bernad&oacute;-Mansilla, Martin Butz, Tim Kovacs, Xavier Llor&agrave;, 
and Keiki Takadama, editors,Learning Classifier Systems. 10th and 11th 
International Workshops (2006-2007), volume 4998/2008 of Lecture Notes in 
Computer Science, pages 46-56. Springer, 2008. 
<blockquote> Utilising the expressive power of S-Expressions in Learning 
Classifier Systems often prohibitively increases the search space due to 
increased flexibility of the encoding. This work shows that selection of 
appropriate S-Expression functions through domain knowledge improves scaling in 
problems, as expected. It is also known that simple alphabets perform well on 
relatively small sized problems in a domain, e.g. ternary alphabet in the 6, 11 
and 20 bit MUX domain. Once fit ternary rules have been formed it was 
investigated whether higher order learning was possible and whether this staged 
learning facilitated selection of appropriate functions in complex alphabets, 
e.g. selection of S-Expression functions. This novel methodology is shown to 
provide compact results (135-MUX) and exhibits potential for scaling well 
(1034-MUX), but is only a small step towards introducing abstraction to LCS.
</blockquote> 
<p> </p> </dd> 
<dt> [482] </dt> 
<dd> N.&nbsp;Ireson, Y.&nbsp;J. Cao, L.&nbsp;Bull, and R.&nbsp;Miles. A 
Communication Architecture for Multi-Agent Learning Systems. InProceedings of 
the EvoNet Workshops - EvoTel 2000, pages 255-266, 2000. 
<p> </p> </dd> 
<dt> [483] </dt> 
<dd> Hisao Ishibuchi and Tomoharu Nakashima. Linguistic Rule Extraction by 
Genetics-Based Machine Learning. InWhitely et&nbsp;al. [878], pages 195-202. 
<blockquote> This paper shows how linguistic classification knowledge can be 
extracted fro numerical data for pattern classification problems with many 
continuous attributes by genetic algorithms. Classification knowledge is 
extracted in the form of linguistic if-then rules. In this paper, emphasis is 
placed on the simplicity of the extracted knowledge. The simplicity is measured 
by two criteria: the number of extracted linguistic rules and the length of 
each rule (i.e, the number of antecedent conditions involved in each rule). The 
classification ability of extracted linguistic rules, which is measured by the 
classification rate on given training patterns, is also considered. Thus our 
task is formulated as a linguistic rule extraction problem with three 
objectives: to maximize the classification rate, to minimize the number of 
extracted rules, and to minimize the length of each rule. For tackling this 
problem, we propose a multi-objective genetics-based machine learning (GBML) 
algorithm, which is a hybrid algorithm of Michigan approach and Pittsburgh 
approach. Our hybrid algorithm is basically a Pittsburgh-style algorithm with 
variable string length. A Michigan-style algorithm is combined as a kind of 
mutation for partially modifying each string.</blockquote> 
<p> </p> </dd> 
<dt> [484] </dt> 
<dd> Hisao Ishibuchi and Takashi Yamamoto. Fuzzy rule selection by data mining 
criteria and genetic algorithms. In W.&nbsp;B. Langdon, 
E.&nbsp;Cant&uacute;-Paz, K.&nbsp;Mathias, R.&nbsp;Roy, D.&nbsp;Davis, 
R.&nbsp;Poli, K.&nbsp;Balakrishnan, V.&nbsp;Honavar, G.&nbsp;Rudolph, 
J.&nbsp;Wegener, L.&nbsp;Bull, M.&nbsp;A. Potter, A.&nbsp;C. Schultz, 
J.&nbsp;F. Miller, E.&nbsp;Burke, and N.&nbsp;Jonoska, editors,GECCO 2002: 
Proceedings of the Genetic and Evolutionary Computation Conference, pages 
399-406, New York, 9-13 July 2002. Morgan Kaufmann Publishers.
<p> </p> </dd> 
<dt> [485] </dt> 
<dd> Yasushi Ishikawa and Takao Terano. Co-evolution of multiagents via 
organizational-learning classifier system and its application to marketing 
simulation. InProc. 4th Pacific-Asia Conf. on Information Systems ( PACIS-2000)
, pages 1114-1127, 2000.
<p> </p> </dd> 
<dt> [486] </dt> 
<dd> Collected Abstracts for the First International Workshop on Learning 
Classifier System (IWLCS92), 1992. October 6-8, NASA Johnson Space Center, 
Houston, Texas.
<p> </p> </dd> 
<dt> [487] </dt> 
<dd> Proceedings of the International Workshop on Learning Classifier Systems 
(IWLCS-2000), in the Joint Workshops of SAB 2000 and PPSN 2000, 2000. Pier Luca 
Lanzi, Wolfgang Stolzmann and Stewart W. Wilson (workshop organisers).
<p> </p> </dd> 
<dt> [488] </dt> 
<dd> Jacob Hurst, Larry Bull and Chris Melhuish. TCS learning classifier 
system controller on a real robot. In H.-P.&nbsp;Schwefel J.-J. Merelo 
Guerv&oacute;s, P. Adamidis, H.-G. Beyer, J.-L. 
Fern&aacute;ndez-Villaca&ntilde;as, editor,Parallel Problem Solving from Nature 
- PPSN VII, 7th International Conference, Granada, Spain, September 7-11, 2002. 
Proceedings, number 2439 in Lecture Notes in Computer Science, LNCS, page 588 
ff. Springer-Verlag, 2002.
<p> </p> </dd> 
<dt> [489] </dt> 
<dd> C.Z. Janikow. Indictive learning of decision rules in attribute-based 
examples: a knowledge-intensive genetic algorithm approach. PhD thesis, 
University of North Carolina, 1991.
<p> </p> </dd> 
<dt> [490] </dt> 
<dd> C.Z. Janikow. A knowledge-intensive genetic algorithm for supervised 
learning.Machine Learning, 13:189-228, 1993. 
<p> </p> </dd> 
<dt> [491] </dt> 
<dd> Cezary&nbsp;Z. Janikow. Genetic information learning. In Thomas 
B&auml;ck, David&nbsp;B. Fogel, and Zbigniew Michalewicz, editors,Handbook of 
Evolutionary Computation, pages G2.3:1-G2.3:10. IOP Publishing Ltd and Oxford 
University Press, 1997.
<p> </p> </dd> 
<dt> [492] </dt> 
<dd> Kenneth A.&nbsp;De Jong and William&nbsp;M. Spears. Learning Concept 
Classification Rules using Genetic Algorithms. InProceedings of the Twelfth 
International Conference on Artificial Intelligence IJCAI-91, volume&nbsp;2, 
1991.
<p> </p> </dd> 
<dt> [493] </dt> 
<dd> K. Takadama, T. Terano, K. Shimohara, K. Hori and S.&nbsp;Nakasuka. 
Towards a multiagent design principle - analyzing an organizational-learning 
oriented classifier system. In V.&nbsp;Loia and S.&nbsp;Sessa, editors,Soft 
Computing Agents: New Trends for Designing Autonomous Systems, Series of 
Studies in Fuzziness and Soft Computing. Springer-Verlag, 2001.
<p> </p> </dd> 
<dt> [494] </dt> 
<dd> Daisuke Katagami and Seiji Yamada. Real robot learning with human 
teaching. InTakadama [815]. 
<p> </p> </dd> 
<dt> [495] </dt> 
<dd> Hiroharu Kawanaka, Tomohiro Yoshikawa, and Shinji Tsuruoka. A Study of 
Parallel GA Using DNA Coding Method for Acquisition of Fuzzy Control Rules. In
Late Breaking Papers at the 2000 Genetic and Evolutionary Computation 
Conference (GECCO-2000), pages 431-436, 2000. 
<blockquote> Fuzzy controls have been widely used in industry for its high 
degree of performance in human-computer interactions. DNA coding method, which 
is one of the coding methods in Genetic Algorithms, is based on biological DNA 
and a mechanism of development from the artificial DNA. This method has 
redundancy and overlapping of genes, and it is suitable for knowledge 
representation. In this paper, we propose the Parallel Genetic Algorithm using 
the DNA coding method. This paper applies this method to acquisition of fuzzy 
control rules with multiple input/output system for a mobile robot. This method 
can select input variables from many candidates and tune membership functions. 
The result of simulation shows that the robot can reach the goal quickly and 
efficiently. Effective fuzzy rules for the mobile robot are acquired by using 
this method while the length of the chromosomes in the population is 
automatically adjusted.</blockquote> 
<p> </p> </dd> 
<dt> [496] </dt> 
<dd> Yeong-Joon Kim and Christoph&nbsp;F. Eick. Multi-rule-set decision-making 
schemes for a genetic algorithm learning environment for classification tasks. 
In John&nbsp;R. McDonnell, Robert&nbsp;G. Reynolds, and David&nbsp;B. Fogel, 
editors,Evolutionary Programming IV. Proceedings of the Fourth Annual 
Conference on Evolutionary Programming, pages 773-788, 1995. 
<blockquote> Over the last three years, we developed an inductive learning 
environment called DELVAUX for classification tasks that learns 
PROSPECTOR-style, Bayesian rules from ests of examples, using a genetic 
algorithm to evolve a population consists of rule-sets. Several problems 
comlicate the search for the best rule-set. First, the search space that is 
explored by DELVAUX is enormously large, which makes it difficult to predict if 
a particular solution is a good solution. The second problem is the problem of 
convergence with outliers that perform well in training but not in testing. 
This paper describes efforts to alleviate these two problems centering on 
multi-rule-set learning techniques that learn multiple rule-sets and proposes 
several decision-making schemes that are employed by the multi-rule-set 
learning environment to derive a decision. Empirical results are presented that 
compare the single rule-set learning environment of DELVAUX with several 
multi-rule-set learning environments that use different decision-making 
schemes. Moreover, a more sophisticated fitness function for the multi-rule-set 
learning approach is introduced, and a genetic algorithm approach that finds 
the `best' multi-rule-set for a given set of rule-sets is discussed.
</blockquote> 
<p> </p> </dd> 
<dt> [497] </dt> 
<dd> Hiroaki Kitano, Stephen&nbsp;F. Smith, and Tetsuya Higuchi. GA-1: A 
Parallel Associative Memory Processor for Rule Learning with Genetic 
Algorithms. InBooker and Belew [74], pages 311-317. 
<blockquote> In this paper, we discuss the underlying hardware and supportable 
learning paradigms provided by the GA-1 system. GA-1 is a system currently 
under development which offers unique opportunities for research into 
large-scale rule learning with genetic algorithms (GAs). The base hardware is 
the IXM2 parallel associative memory machine which enables high performance 
processing by using 64 T800 transputers and associative memories providing 256K 
parallelism. Various population/subpopulation models, mating strategies, and 
generation models can be implemented to investigate architectures for high 
performance GA-based systems. Regardless of these options, however, GA-based 
rule learning takes maximum advantage of the hardware through extensive use of 
associative memory for bit-vector matching. Preliminary experiments indicate 
that GA-1 exhibits high execution speeds for such an approach.</blockquote> 
<p> </p> </dd> 
<dt> [498] </dt> 
<dd> Leslie Knight and Sandip Sen. PLEASE: A Prototype Learning System using 
Genetic Algorithms. InEshelman [298], pages 429-435. 
<p> </p> </dd> 
<dt> [499] </dt> 
<dd> Gabriella K&oacute;kai, Zolt&aacute;n T&oacute;th, and Szilvia Zvada. An 
experimental comparison of genetic and classical concept learning methods. In 
W.&nbsp;B. Langdon, E.&nbsp;Cant&uacute;-Paz, K.&nbsp;Mathias, R.&nbsp;Roy, 
D.&nbsp;Davis, R.&nbsp;Poli, K.&nbsp;Balakrishnan, V.&nbsp;Honavar, 
G.&nbsp;Rudolph, J.&nbsp;Wegener, L.&nbsp;Bull, M.&nbsp;A. Potter, A.&nbsp;C. 
Schultz, J.&nbsp;F. Miller, E.&nbsp;Burke, and N.&nbsp;Jonoska, editors,GECCO 
2002: Proceedings of the Genetic and Evolutionary Computation Conference, page 
952. Morgan Kaufmann Publishers, 2002.
<p> </p> </dd> 
<dt> [500] </dt> 
<dd> Kostyantyn Korovkin and Robert Richards. Visual Auction: A Classifier 
System Pedagogical and Researcher Tool. In Scott Brave and Annie&nbsp;S. Wu, 
editors,Late Breaking Papers at the 1999 Genetic and Evolutionary Computation 
Conference (GECCO-99), pages 159-163, 1999. 
<blockquote> This paper surveys the Visual Auction. The Visual Auction is a 
pedagogical and research tool, which provides a dynamic visual representation 
of the matching and auction process in a classifier system. The tool allows for 
the visual representation of both the matching process and the process of 
determining the winner of the auction. The tool can be used pedagogically, for 
it quickly demonstrates how antecedent matching occurs in a classifier system 
and shows how the matched classifiers compete to win the auction. As a research 
tool, it assists the researcher in implementing a classifier system by 
providing more in-depth knowledge of the auction process, thus providing 
insight into how parameter settings or bid equations could be modified to 
generate more efficient learning.</blockquote> 
<p> </p> </dd> 
<dt> [501] </dt> 
<dd> Tim Kovacs and Manfred Kerber. Some dimensions of problem complexity for 
XCS. In Annie&nbsp;S. Wu, editor,Proceedings of the 2000 Genetic and 
Evolutionary Computation Conference Workshop Program, pages 289-292, 2000. 
<blockquote> Despite two decades of work, learning classifier systems 
researchers have had relatively little to say on the subject of what makes a 
problem difficult for a classifier system. One focus of our work has been the 
issue of what makes a problem difficult for XCS -- Wilson's recent 
accuracy-based classifier system. This document outlines the approach taken, 
provides some initial results and outlines possible directions for future work.
</blockquote> 
<p> </p> </dd> 
<dt> [502] </dt> 
<dd> Tim Kovacs and Manfred Kerber. What makes a problem hard for XCS? In 
Proceedings of the International Workshop on Learning Classifier Systems 
(IWLCS-2000), in the Joint Workshops of SAB 2000 and PPSN 2000 [487]. Extended 
abstract.
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [503] </dt> 
<dd> Tim Kovacs and Manfred Kerber. What makes a problem hard for XCS? In 
Lanzi et&nbsp;al. [545], pages 80-99. 
<blockquote> Despite two decades of work learning classifier systems 
researchers have had relatively little to say on the subject of what makes a 
problem difficult for a classifier system. Wilson's accuracy-based XCS, a 
promising and increasingly popular classifier system, is, we feel, the natural 
first choice of classifier system with which to address this issue. To make the 
task more tractable we limit our considerations to a restricted, but very 
important, class of problems. Most significantly, we consider only single step 
reinforcement learning problems and the use of the standard binary/ternary 
classifier systems language. In addition to distinguishing several dimensions 
of problem complexity for XCS, we consider their interactions, identify 
bounding cases of difficulty, and consider complexity metrics for XCS. Based on 
these results we suggest a simple template for ternary single step test suites 
to more comprehensively evaluate classifier systems.</blockquote> 
<p> </p> </dd> 
<dt> [504] </dt> 
<dd> Tim Kovacs and Manfred Kerber. High classification accuracy does not 
imply effective genetic search. In K.&nbsp;Deb et&nbsp;al., editor,Proceedings 
of the 2004 Genetic and Evolutionary Computation Conference (GECCO), volume 
3102 ofLNCS, pages 785-796. Springer, 2004. 
<p> </p> </dd> 
<dt> [505] </dt> 
<dd> Tim Kovacs and Manfred Kerber. A study of structural and parametric 
learning in XCS.Evolutionary Computation, 14(1):1-19, 2006. 
<p> </p> </dd> 
<dt> [506] </dt> 
<dd> Tim Kovacs and Pier&nbsp;Luca Lanzi. A Learning Classifier Systems 
Bibliography. Technical Report 99.52, Dipartimento di Elettronica e 
Informazione, Politecnico di Milano, 1999.
<blockquote> We present a bibliography of all works we could find on Learning 
Classifier Systems (LCS) -- the genetics-based machine learning systems 
introduced by John Holland. With over 400 entries, this is at present the 
largest bibliography on classifier systems in existence. We include a list of 
LCS resources on the world wide web.</blockquote> 
<p> </p> </dd> 
<dt> [507] </dt> 
<dd> Tim Kovacs and Pier&nbsp;Luca Lanzi. A Learning Classifier Systems 
Bibliography. InLanzi et&nbsp;al. [544], pages 321-347. 
<blockquote> We present a bibliography of all works we could find on Learning 
Classifier Systems (LCS) -- the genetics-based machine learning systems 
introduced by John Holland. With over 400 entries, this is at present the 
largest bibliography on classifier systems in existence. We include a list of 
LCS resources on the world wide web.</blockquote> 
<p> </p> </dd> 
<dt> [508] </dt> 
<dd> Tim Kovacs and Pier&nbsp;Luca Lanzi. A Bigger Learning Classifier Systems 
Bibliography. InLanzi et&nbsp;al. [545], pages 213-249. 
<blockquote> With over 600 entries, this is by far the most comprehensive 
bibliography of the machine learning systems introduced by John Holland.
</blockquote> 
<p> </p> </dd> 
<dt> [509] </dt> 
<dd> Tim Kovacs. Evolving Optimal Populations with XCS Classifier Systems. 
Master's thesis, School of Computer Science, University of Birmingham, 
Birmingham, U.K., 1996. Also technical report CSR-96-17 and CSRP-96-17 
ftp://ftp.cs.bham.ac.uk/pub/tech-reports/1996/CSRP-96-17.ps.gz.
<blockquote> This work investigates some uses of self-monitoring in classifier 
systems (CS) using Wilson's recent XCS system as a framework. XCS is a 
significant advance in classifier systems technology which shifts the basis of 
fitness evaluation for the Genetic Algorithm (GA) from the strength of payoff 
prediction to the accuracy of payoff prediction. Initial work consisted of 
implementing an XCS system in Pop-11 and replicating published XCS multiplexer 
experiments from (Wilson 1995, 1996a). In subsequent original work, the XCS 
Optimality Hypothesis, which suggests that under certain conditions XCS systems 
can reliably evolve optimal populations (solutions), is proposed. An optimal 
population is one which accurately maps inputs to actions to reward predictions 
using the smallest possible set of classifiers. An optimal XCS population forms 
a complete mapping of the payoff environment in the reinforcement learning 
tradition, in contrast to traditional classifier systems which only seek to 
maximise classifier payoff (reward). The more complete payoff map allows XCS to 
deal with payoff landscapes with more than 1 niche (i.e. those with more than 2 
payoff levels) which traditional payoff-maximising CS find very difficult. This 
makes XCS much more suitable as the foundation of animat control systems than 
traditional CS. In support of the Optimality Hypothesis, techniques were 
developed which allow the system to highly reliably evolve optimal populations 
for logical multiplexer functions. A technique for auto-termination of learning 
was also developed to allow the system to recognise when an optimal population 
has been evolved. The self-monitoring mechanisms involved in this work are 
discussed in terms of the design space of adaptive systems.</blockquote> 
<p> </p> </dd> 
<dt> [510] </dt> 
<dd> Tim Kovacs. Steady State Deletion Techniques in a Classifier System. 
Unpublished document -- partially subsumed by Kovacs1999a `Deletion Schemes for 
Classifier Systems', 1997.
<blockquote> In a standard genetic algorithm a chromosome can be fully 
evaluated (assigned a fitness) immediately. In classifier systems, however, a 
chromosome can only be fully evaluated after many interactions with the 
environment, since a chromosome may generalise over many environmental states. 
In this work it is suggested that evolutionary systems which cannot fully 
evaluate candidate solutions immediately will benefit from protecting them from 
deletion until they have been well evaluated. A new technique which protects 
poorly evaluated chromosomes outperforms both techniques from (Wilson, 1995) on 
two types of boolean function and a delayed reward problem. Next a weeding 
operator which deletes low fitness rules is introduced and found to improve 
performance on one boolean function. Results indicate the XCS classifier system 
is able to learn boolean functions for which no (or few) useful generalisations 
can be made over the input string, despite its drive towards accurate 
generalisation.</blockquote> 
<p> </p> </dd> 
<dt> [511] </dt> 
<dd> Tim Kovacs. XCS Classifier System Reliably Evolves Accurate, Complete, 
and Minimal Representations for Boolean Functions.. In Roy, Chawdhry, and Pant, 
editors,Soft Computing in Engineering Design and Manufacturing, pages 59-68. 
Springer-Verlag, London, 1997. 
ftp://ftp.cs.bham.ac.uk/pub/authors/T.Kovacs/index.html.
<blockquote> Wilson's recent XCS classifier system forms complete mappings of 
the payoff environment in the reinforcement learning tradition thanks to its 
accuracy based fitness. According to Wilson's Generalization Hypothesis, XCS 
has a tendency towards generalization. With the XCS Optimality Hypothesis, I 
suggest that XCS systems can evolve optimal populations (representations); 
populations which accurately map all input/action pairs to payoff predictions 
using the smallest possible set of non-overlapping classifiers. The ability of 
XCS to evolve optimal populations for boolean multiplexer problems is 
demonstrated using condensation, a technique in which evolutionary search is 
suspended by setting the crossover and mutation rates to zero. Condensation is 
automatically triggered by self-monitoring of performance statistics, and the 
entire learning process is terminated by autotermination. Combined, these 
techniques allow a classifier system to evolve optimal representations of 
boolean functions without any form of supervision. A more complex but more 
robust and efficient technique for obtaining optimal populations called subset 
extraction is also presented and compared to condensation.</blockquote> 
<p> </p> </dd> 
<dt> [512] </dt> 
<dd> Tim Kovacs. XCS Classifier System Reliably Evolves Accurate, Complete, 
and Minimal Representations for Boolean Functions. Technical Report Version.. 
Technical Report CSRP-97-19, School of Computer Science, University of 
Birmingham, Birmingham, U.K., 1997. 
http://www.cs.bham.ac.uk/system/tech-reports/tr.html.
<blockquote> This paper extends the work presented in (Kovacs, 1996) on 
evolving optimal solutions to boolean reinforcement learning problems using 
Wilson's recent XCS classifier system. XCS forms complete mappings of the 
payoff environment in the reinforcement learning tradition thanks to its 
accuracy based fitness, which, according to Wilson's Generalization Hypothesis, 
also gives XCS a tendency towards accurate generalization. (Kovacs, 1996) 
introduced the XCS Optimality Hypothesis which suggests that XCS systems can 
evolve optimal populations (representations); populations which accurately map 
all input/action pairs to payoff predictions using the smallest possible set of 
non-overlapping classifiers. The ability of XCS to evolve optimal populations 
for boolean multiplexer problems was demonstrated in (Kovacs, 1996) using 
condensation, a technique in which evolutionary search is suspended by setting 
the crossover and mutation rates to zero. Condensation is automatically 
triggered by self-monitoring of performance statistics, and the entire learning 
process is terminated by autotermination. Combined, these techniques allow a 
classifier system to evolve optimal representations of boolean functions 
without any form of supervision. The present work shows how condensation can be 
greatly accelerated by truncating each action set around its most numerous 
member. Following this, a more complex but more robust and efficient technique 
for obtaining optimal populations called subset extraction is presented and 
compared to condensation.</blockquote> 
<p> </p> </dd> 
<dt> [513] </dt> 
<dd> Tim Kovacs. Deletion schemes for classifier systems. In Banzhaf 
et&nbsp;al. [32], pages 329-336. Also technical report CSRP-99-08, School of 
Computer Science, University of Birmingham.
<blockquote> The issue of deletion schemes for classifier systems has received 
little attention. In a standard genetic algorithm a chromosome can be evaluated 
(assigned a reasonable fitness) immediately. In classifier systems, however, a 
chromosome can only be fully evaluated after many interactions with the 
environment, since a chromosome may generalise over many environmental states. 
A new technique which protects poorly evaluated chromosomes outperforms both 
techniques from (Wilson, 1995) in two very different single step problems. 
Results indicate the XCS classifier system is able to learn single step 
problems for which no (or few) useful generalisations can be made over the 
input string, despite its drive towards accurate generalisation.</blockquote> 
<p> </p> </dd> 
<dt> [514] </dt> 
<dd> Tim Kovacs. Strength or accuracy? A comparison of two approaches to 
fitness calculation in learning classifier systems. In Wu [923], pages 258-265. 
<blockquote> Wilson's XCS is a clear departure from earlier classifier systems 
in the way it calculates the fitness of classifiers for use in the genetic 
algorithm. Despite the growing body of work on XCS and the advantages claimed 
for it, there has been no detailed comparison of XCS and traditional 
strength-based systems. We distinguish different definitions of overgenerality 
for strength and accuracy-based fitness and analyse some implications of the 
use of accuracy, including an advantage in exploration. We analyse the 
formation of strong overgenerals, a major problem for strength-based systems, 
and show that they require biased reward functions. We also show that all 
non-trivial multi step environments have biased reward functions and thus 
suffer from strong overgenerals. We conclude that strength-based systems are 
not suitable for multi step environments or indeed many single step 
environments.</blockquote> 
<p> </p> </dd> 
<dt> [515] </dt> 
<dd> Tim Kovacs. Strength or Accuracy? Fitness calculation in learning 
classifier systems. InLanzi et&nbsp;al. [544], pages 143-160. 
<blockquote> Wilson's XCS is a clear departure from earlier classifier systems 
in terms of the way it calculates the fitness of classifiers for use in the 
genetic algorithm. Despite the growing body of work on XCS and the advantages 
claimed for it there has been no detailed comparison of XCS and traditional 
strength-based systems. This work takes a step towards rectifying this 
situation by surveying a number of issues related to the change in fitness. I 
distinguish different definitions of overgenerality for strength and 
accuracy-based fitness and analyse some implications of the use of accuracy, 
including an apparent advantage in addressing the explore/exploit problem. I 
analyse the formation of strong overgenerals, a major problem for 
strength-based systems, and illustrate their dependence on biased reward 
functions. I consider motivations for biasing reward functions in single step 
environments, and show that non-trivial multi step environments have biased 
Q-functions. I conclude that XCS's accuracy-based fitness appears to have a 
number of significant advantages over traditional strength-based fitness.
</blockquote> 
<p> </p> </dd> 
<dt> [516] </dt> 
<dd> Tim Kovacs. Towards a theory of strong overgeneral classifiers. In Worthy 
Martin and William&nbsp;M. Spears, editors,Foundations of Genetic Algorithms 
(FOGA) Volume 6, pages 165-184. Morgan Kaufmann, 2000. Also technical report 
CSRP-00-20, School of Computer Science, University of Birmingham.
<blockquote> We analyse the concept of strong overgeneral rules, the Achilles' 
heel of traditional Michigan-style learning classifier systems, using both the 
traditional strength-based and newer accuracy-based approaches to rule fitness. 
We argue that different definitions of overgenerality are needed to match the 
goals of the two approaches, present minimal conditions and environments which 
will support strong overgeneral rules, demonstrate their dependence on the 
reward function, and give some indication of what kind of reward functions will 
avoid them. Finally, we distinguish fit overgeneral rules, show how strength 
and accuracy-based fitness differ in their response to fit overgenerals and 
conclude by considering possible extensions to this work.</blockquote> 
<p> </p> </dd> 
<dt> [517] </dt> 
<dd> Tim Kovacs. Trends in learning classifier systems publication. Technical 
Report CSRP-00-21, School of Computer Science, University of Birmingham, 2000.
<blockquote> Using data from the world's most comprehensive Learning 
Classifier Systems (LCS) bibliography, we examine trends in LCS publication and 
attempt to account for them. We find support for the notions of a classic 
period and an ongoing LCS renaissance, and find that Wilson's XCS has become a 
major focus of LCS research.</blockquote> 
<p> </p> </dd> 
<dt> [518] </dt> 
<dd> Tim Kovacs. What should a classifier system learn? In Proceedings of the 
2001 Congress on Evolutionary Computation (CEC01) [186], pages 775-782. 
<p> </p> </dd> 
<dt> [519] </dt> 
<dd> Tim Kovacs. A Comparison and Strength and Accuracy-based Fitness in 
Learning Classifier Systems. PhD thesis, University of Birmingham, 2002. 
<p> </p> </dd> 
<dt> [520] </dt> 
<dd> Tim Kovacs. Learning Classifier Systems Resources. Journal of Soft 
Computing, 6(3-4):240-243, 2002. 
<blockquote> This article lists currently available sources of information on 
classifier systems and classifier systems research, both on-line and in print. 
The need for new resources, and improvements to certain existing ones, are 
suggested.</blockquote> 
<p> </p> </dd> 
<dt> [521] </dt> 
<dd> Tim Kovacs. Performance and population state metrics for rule-based 
learning systems. In David&nbsp;B. Fogel, Mohamed&nbsp;A. El-Sharkawi, Xin Yao, 
Garry Greenwood, Hitoshi Iba, Paul Marrow, and Mark Shackleton, editors,
Proceedings of the 2002 Congress on Evolutionary Computation CEC2002, pages 
1781-1786. IEEE Press, 2002.
<p> </p> </dd> 
<dt> [522] </dt> 
<dd> Tim Kovacs. Two views of classifier systems. In Lanzi et&nbsp;al. [546], 
pages 74-87.
<blockquote> This work suggests two ways of looking at Michigan classifier 
systems; as Genetic Algorithm-based systems, and as Reinforcement 
Learning-based systems, and argues that the former is more suitable for 
traditional strength-based systems while the latter is more suitable for 
accuracy-based XCS. The dissociation of the Genetic Algorithm from policy 
determination in XCS is noted, and the two types of Michigan classifier system 
are contrasted with Pittsburgh systems.</blockquote> 
<p> </p> </dd> 
<dt> [523] </dt> 
<dd> Tim Kovacs. What should a classifier system learn and how should we 
measure it?Journal of Soft Computing, 6(3-4):171-182, 2002. 
<blockquote> We consider the issues of how a classifier system should learn to 
represent a Boolean function, and how we should measure its progress in doing 
so. We identify four properties which may be desirable of a representation; 
that it be complete, accurate, minimal and non-overlapping. We distinguish two 
categories of learning metric, introduce new metrics and evaluate them. We 
demonstrate the superiority of population state metrics over performance 
metrics in two situations, and in the process find evidence of XCS's strong 
bias against overlapping rules.</blockquote> 
<p> </p> </dd> 
<dt> [524] </dt> 
<dd> Tim Kovacs. Strength or Accuracy: Credit Assignment in Learning 
Classifier Systems. Springer, 2004. 
<p> </p> </dd> 
<dt> [525] </dt> 
<dd> Tim Kovacs. Genetics-based machine learning. In Grzegorz Rozenberg, 
Thomas B&auml;ck, and Joost Kok, editors,Handbook of Natural Computing: Theory, 
Experiments, and Applications. Springer Verlag, 2010. 
<p> </p> </dd> 
<dt> [526] </dt> 
<dd> Yuhsuke Koyama. The emergence of the cooperative behaviors in a small 
group. InTakadama [815]. 
<p> </p> </dd> 
<dt> [527] </dt> 
<dd> John&nbsp;R. Koza, David&nbsp;E. Goldberg, David&nbsp;B. Fogel, and 
Rick&nbsp;L. Riolo, editors.Genetic Programming 1996: Proceedings of the First 
Annual Conference, Stanford University, CA, USA, 1996. MIT Press. 
<p> </p> </dd> 
<dt> [528] </dt> 
<dd> John&nbsp;R. Koza, Kalyanmoy Deb, Marco Dorigo, David&nbsp;B. Fogel, 
Max&nbsp;H. Garzon, Hitoshi Iba, and Rick Riolo, editors.Genetic Programming 
1997: Proceedings of the Second Annual Conference. Morgan Kaufmann, 1997. 
<p> </p> </dd> 
<dt> [529] </dt> 
<dd> John&nbsp;R. Koza, Wolfgang Banzhaf, Kumar Chellapilla, Kalyanmoy Deb, 
Marco Dorigo, David&nbsp;B. Fogel, Max&nbsp;H. Garzon, David&nbsp;E. Goldberg, 
Hitoshi Iba, and Rick Riolo, editors.Genetic Programming 1998: Proceedings of 
the Third Annual Conference. Morgan Kaufmann, 1998. 
<p> </p> </dd> 
<dt> [530] </dt> 
<dd> Setsuya Kurahashi and Takao Terano. Technology extraction of expert 
operator skills from process time series data. In Jaume Bacardit, Ester 
Bernad&oacute;-Mansilla, Martin Butz, Tim Kovacs, Xavier Llor&agrave;, and 
Keiki Takadama, editors,Learning Classifier Systems. 10th and 11th 
International Workshops (2006-2007), volume 4998/2008 of Lecture Notes in 
Computer Science, pages 269-285. Springer, 2008. 
<blockquote> Continuation processes in chemical and/or biotechnical plants 
always generate a large amount of time series data. However, since conventional 
process models are described as a set of control models, it is difficult to 
explain complicated and active plant behaviors. To uncover complex plant 
behaviors, this paper proposes a new method of developing a process response 
model from continuous time-series data. The method consists of the following 
phases: (1) Reciprocal correlation analysis; (2) Process response model; (3) 
Extraction of control rules; (4) Extraction of a workflow; and (5) Detection of 
outliers. The main contribution of the research is to establish a method to 
mine a set of meaningful control rules from a Learning Classifier System using 
the Minimum Description Length criteria and Tabu search method. The proposed 
method has been applied to an actual process of a biochemical plant and has 
shown its validity and effectiveness.</blockquote> 
<p> </p> </dd> 
<dt> [531] </dt> 
<dd> Samuel Landau, S&eacute;bastien Picault, Oliver Sigaud, and Pierre 
G&eacute;rard. A comparison between ATNoSFERES and XCSM. In W.&nbsp;B. Langdon, 
E.&nbsp;Cant&uacute;-Paz, K.&nbsp;Mathias, R.&nbsp;Roy, D.&nbsp;Davis, 
R.&nbsp;Poli, K.&nbsp;Balakrishnan, V.&nbsp;Honavar, G.&nbsp;Rudolph, 
J.&nbsp;Wegener, L.&nbsp;Bull, M.&nbsp;A. Potter, A.&nbsp;C. Schultz, 
J.&nbsp;F. Miller, E.&nbsp;Burke, and N.&nbsp;Jonoska, editors,GECCO 2002: 
Proceedings of the Genetic and Evolutionary Computation Conference, pages 
926-933. Morgan Kaufmann Publishers, 2002.
<p> </p> </dd> 
<dt> [532] </dt> 
<dd> Samuel Landau, S&eacute;bastien Picault, Olivier Sigaud, and Pierre 
G&eacute;rard. Further Comparison between ATNoSFERES and XCSM. In Wolfgang 
Stolzmann, Pier&nbsp;Luca Lanzi, and Stewart&nbsp;W. Wilson, editors,IWLCS-02. 
Proceedings of the Fifth International Workshop on Learning Classifier Systems, 
LNAI. Springer, 2002.
<p> </p> </dd> 
<dt> [533] </dt> 
<dd> Samuel Landau, Olivier Sigaud, S&eacute;bastien Picault, and Pierre 
G&eacute;rard. An Experimental Comparison between ATNoSFERES and ACS. In 
Wolfgang Stolzmann, Pier&nbsp;Luca Lanzi, and Stewart&nbsp;W. Wilson, editors,
IWLCS-03. Proceedings of the Sixth International Workshop on Learning 
Classifier Systems, LNAI. Springer, 2003. 
<p> </p> </dd> 
<dt> [534] </dt> 
<dd> Samuel Landau, Olivier Sigaud, and Marc Schoenauer. ATNoSFERES revisited. 
InProceedings of the Genetic and Evolutionary Computation Conference GECCO-2005
, pages 1867-1874. ACM, 2005.
<blockquote> ATNoSFERES is a Pittsburgh style Learning Classifier System (LCS) 
in which the rules are represented as edges of an Augmented Transition Network. 
Genotypes are strings of tokens of a stack-based language, whose execution 
builds the labeled graph. The original ATNoSFERES, using a bitstring to 
represent the language tokens, has been favorably compared in previous work to 
several Michigan style LCSs architectures in the context of Non Markov 
problems. Several modifications of ATNoSFERES are proposed here: the most 
important one conceptually being a representational change: each token is now 
represented by an integer, hence the genotype is a string of integers; several 
other modifications of the underlying grammar language are also proposed. The 
resulting ATNoSFERES-II is validated on several standard animat Non Markov 
problems, on which it outperforms all previously published results in the LCS 
literature. The reasons for these improvement are carefully analyzed, and some 
assumptions are proposed on the underlying mechanisms in order to explain these 
good results.</blockquote> 
<p> </p> </dd> 
<dt> [535] </dt> 
<dd> Samuel Landau, Olivier Sigaud, S&eacute;bastien Picault, and Pierre 
G&eacute;rard. An experimental comparison between atnosferes and acs. In Tim 
Kovacs, Xavier LL&ograve;ra, Keiki Takadama, Pier&nbsp;Luca Lanzi, Wolfgang 
Stolzmann, and Stewart&nbsp;W. Wilson, editors,Learning Classifier Systems. 
International Workshops, IWLCS 2003-2005, Revised Selected Papers, volume 4399 
ofLNCS, pages 144-160. Springer, 2007. 
<p> </p> </dd> 
<dt> [536] </dt> 
<dd> Pier&nbsp;Luca Lanzi and Marco Colombetti. An Extension of XCS to 
Stochastic Environments. Technical Report 98.85, Dipartimento di Elettronica e 
Informazione - Politecnico di Milano, 1998.
<p> </p> </dd> 
<dt> [537] </dt> 
<dd> Pier&nbsp;Luca Lanzi and Marco Colombetti. An Extension to the XCS 
Classifier System for Stochastic Environments. InBanzhaf et&nbsp;al. [32], 
pages 353-360.
<blockquote> We analyze XCS learning capabilities in stochastic environments 
where the result of agent actions can be uncertain. We show that XCS can deal 
when degree of environmental uncertainty is limited. We analyze our 
experimental results and propose an extension to XCS, called XCS_mu, which can 
learn optimal solutions for higher degrees of uncertainty. We test XCS_mu when 
the uncertainty affects agent actions in the whole environment and when the 
uncertainty is limited to some areas. Finally, we show that XCS_mu is a proper 
extension of XCS in that it coincides with it when it is applied to 
deterministic environments.</blockquote> 
<p> </p> </dd> 
<dt> [538] </dt> 
<dd> P.L. Lanzi and D.&nbsp;Loiacono. Standard and averaging reinforcement 
learning in XCS. In M.&nbsp;Cattolico, editor,GECCO 2006: Proceedings of the 
8th annual conference on genetic and evolutionary computation, pages 1480-1496. 
ACM, 2006.
<p> </p> </dd> 
<dt> [539] </dt> 
<dd> P.L. Lanzi and D.&nbsp;Loiacono. Classifier systems that compute action 
mappings. In H.&nbsp;Lipson, editor,Genetic and Evolutionary Computation 
Conference, GECCO 2007, Proceedings, pages 1822-1829. ACM, 2007. 
<p> </p> </dd> 
<dt> [540] </dt> 
<dd> Pier&nbsp;Luca Lanzi and Rick&nbsp;L. Riolo. A Roadmap to the Last Decade 
of Learning Classifier System Research (from 1989 to 1999). InLanzi et&nbsp;al. 
[544], pages 33-62. 
<blockquote> In 1989 Wilson and Goldberg presented a critical review of the 
first ten years of learning classifier system research. With this paper we 
review the subsequent ten years of learning classifier systems research, 
discussing the main achievements and the major research directions pursued in 
those years.</blockquote> 
<p> </p> </dd> 
<dt> [541] </dt> 
<dd> Pier&nbsp;Luca Lanzi and Stewart&nbsp;W. Wilson. Optimal classifier 
system performance in non-Markov environments. Technical Report 99.36, 
Dipartimento di Elettronica e Informazione - Politecnico di Milano, 1999. Also 
IlliGAL technical report 99022, University of Illinois.
<blockquote> Wilson's (1994) bit-register memory scheme was incorporated into 
the XCS classifier system and investigated in a series of non-Markov 
environments. Two extensions to the scheme proved important for reaching 
optimal performance in the harder environments. The first was an exploration 
strategy in which exploration of external actions was probabilistic as in 
Markov environments, but internal ``actions'' (register settings) were selected 
deterministically. The second was use of a register having more bit-positions 
than were strictly necessary to resolve environmental aliasing. The origins and 
effects of the two extensions are discussed.</blockquote> 
<p> </p> </dd> 
<dt> [542] </dt> 
<dd> Pier&nbsp;Luca Lanzi and Stewart&nbsp;W. Wilson. Toward Optimal 
Classifier System Performance in Non-Markov Environments.Evolutionary 
Computation, 8(4):393-418, 2000. 
<blockquote> Wilson's (1994) bit-register memory scheme was incorporated into 
the XCS classifier system and investigated in a series of non-Markov 
environments. Two extensions to the scheme were important in obtaining 
near-optimal performance in the harder environments. The first was an 
exploration strategy in which exploration of external actions was probabilistic 
as in Markov environments, but internal ``actions'' (register settings) were 
selected deterministically. The second was use of a register having more 
bit-positions than were strictly necessary to resolve environmental aliasing. 
The origins and effects of the two extensions are discussed.</blockquote> 
<p> </p> </dd> 
<dt> [543] </dt> 
<dd> P.L. Lanzi and S.W. Wilson. Using convex hulls to represent classifier 
conditions. In M.&nbsp;Cattolico, editor,Proc. genetic and evolutionary 
computation conference (GECCO 2006), pages 1481-1488. ACM, 2006. 
<p> </p> </dd> 
<dt> [544] </dt> 
<dd> Pier&nbsp;Luca Lanzi, Wolfgang Stolzmann, and Stewart&nbsp;W. Wilson, 
editors.Learning Classifier Systems. From Foundations to Applications, volume 
1813 ofLNAI. Springer-Verlag, Berlin, 2000. 
<p> </p> </dd> 
<dt> [545] </dt> 
<dd> Pier&nbsp;Luca Lanzi, Wolfgang Stolzmann, and Stewart&nbsp;W. Wilson, 
editors.Advances in Learning Classifier Systems, volume 1996 of LNAI. 
Springer-Verlag, Berlin, 2001.
<p> </p> </dd> 
<dt> [546] </dt> 
<dd> Pier&nbsp;Luca Lanzi, Wolfgang Stolzmann, and Stewart&nbsp;W. Wilson, 
editors.Advances in Learning Classifier Systems, volume 2321 of LNAI. 
Springer-Verlag, Berlin, 2002.
<p> </p> </dd> 
<dt> [547] </dt> 
<dd> Pier&nbsp;Luca Lanzi, Daniele Loiacono, Stewart&nbsp;W. Wilson, and 
David&nbsp;E. Goldberg. Classifier prediction based on tile coding. InGenetic 
and Evolutionary Computation -- GECCO-2006, pages 1497-1504. ACM, 2006. 
<blockquote> This paper introduces XCSF extended with tile coding prediction: 
each classifier implements a tile coding approximator; the genetic algorithm is 
used to adapt both classifier conditions (i.e., to partition the problem) and 
the parameters of each approximator; thus XCSF evolves an ensemble of tile 
coding approximators instead of the typical monolithic approximator used in 
reinforcement learning. The paper reports a comparison between (i) XCSF with 
tile coding prediction and (ii) plain tile coding. The results show that XCSF 
with tile coding always reaches optimal performance, it usually learns as fast 
as the best parametrized tile coding, and it can be faster than the typical 
tile coding setting. In addition, the analysis of the evolved tile coding 
ensembles shows that XCSF actually adapts local approximators following what is 
currently considered the best strategy to adapt the tile coding parameters in a 
given problem.</blockquote> 
<p> </p> </dd> 
<dt> [548] </dt> 
<dd> Pier&nbsp;Luca Lanzi, Daniele Loiacono, Stewart&nbsp;W. Wilson, and 
David&nbsp;E. Goldberg. Prediction update algorithms for xcsf: Rls, kalman 
filter and gain adaptation. InGenetic and Evolutionary Computation -- GECCO-2006
, pages 1505-1512. ACM, 2006.
<blockquote> We study how different prediction update algorithms influence the 
performance of XCSF. We consider three classical parameter estimation 
algorithms (NLMS, RLS, and Kalman filter) and four gain adaptation algorithms 
(K1, K2, IDBD, and IDD). The latter have been shown to perform comparably to 
the best algorithms (RLS and Kalman), but they have a lower complexity. We 
apply these algorithms to update classifier prediction in XCSF and compare the 
performances of the seven versions of XCSF on a set of real functions. Our 
results show that the best known algorithms still perform best: XCSF with RLS 
and XCSF with Kalman perform significantly better than the others. In contrast, 
when added to XCSF, gain adaptation algorithms perform comparably to NLMS, the 
simplest estimation algorithm, the same used in the original XCSF. 
Nevertheless, algorithms that perform similarly generalize differently. For 
instance: XCSF with Kalman filter evolves more compact solutions than XCSF with 
RLS and gain adaptation algorithms allow better generalization than NLMS.
</blockquote> 
<p> </p> </dd> 
<dt> [549] </dt> 
<dd> P.L. Lanzi, M.V. Butz, and D.E. Goldberg. Empirical analysis of 
generalization and learning in XCS with gradient descent. In H.&nbsp;Lipson, 
editor,Genetic and Evolutionary Computation Conference, GECCO 2007, Proceedings
, volume&nbsp;2, pages 1814-1821. ACM, 2007.
<p> </p> </dd> 
<dt> [550] </dt> 
<dd> P.L. Lanzi, D.&nbsp;Loiacono, S.W. Wilson, and D.E. Goldberg. 
Generalization in the XCSF classifier system: analysis, improvement, and 
extension.Evolutionary Computation, 15(2):133-168, 2007. 
<p> </p> </dd> 
<dt> [551] </dt> 
<dd> Pier&nbsp;Luca Lanzi, Daniele Loiacono, and Matteo Zanini. Evolving 
classifiers ensembles with heterogeneous predictors. In Jaume Bacardit, Ester 
Bernad&oacute;-Mansilla, Martin Butz, Tim Kovacs, Xavier Llor&agrave;, and 
Keiki Takadama, editors,Learning Classifier Systems. 10th and 11th 
International Workshops (2006-2007), volume 4998/2008 of Lecture Notes in 
Computer Science, pages 218-234. Springer, 2008. 
<blockquote> XCS with computed prediction, namely XCSF, extends XCS by 
replacing the classifier prediction with a parametrized prediction function. 
Although several types of prediction functions have been introduced, so far 
XCSF models are still limited to evolving classifiers with the same prediction 
function. In this paper, we introduce XCSF with heterogeneous predictors, 
XCSFHP, which allows the evolution of classifiers with different types of 
prediction function within the same population. We compared XCSFHP to XCSF on 
several problems. Our results suggest that XCSFHP generally performs as XCSF 
with the most appropriate prediction function for the given problem. In 
particular, XCSFHP seems able to evolve, in each problem subspace, the most 
adequate type of prediction function.</blockquote> 
<p> </p> </dd> 
<dt> [552] </dt> 
<dd> Pier&nbsp;Luca Lanzi, Stefano Rocca, Kumara Sastry, and Stefania Solari. 
Analysis of population evolution in classifier systems using symbolic 
representations. In Jaume Bacardit, Ester Bernad&oacute;-Mansilla, Martin Butz, 
Tim Kovacs, Xavier Llor&agrave;, and Keiki Takadama, editors,Learning 
Classifier Systems. 10th and 11th International Workshops (2006-2007), volume 
4998/2008 ofLecture Notes in Computer Science, pages 22-45. Springer, 2008. 
<blockquote> This paper presents an approach to analyze population evolution 
in classifier systems using a symbolic representation. Given a sequence of 
populations, representing the evolution of a solution, the method simplifies 
the classifiers in the populations by reducing them to their &ldquo;canonical 
form&rdquo;. Then, it extracts all the subexpressions that appear in all the 
classifier conditions and, for each subexpression, it computes the number of 
occurrences in each population. Finally, it computes the trend of all the 
subexpressions considered. The expressions which show an increasing trend 
through the course of evolution are viewed as building blocks that the system 
has used to construct the solution.</blockquote> 
<p> </p> </dd> 
<dt> [553] </dt> 
<dd> Pier&nbsp;Luca Lanzi. A Model of the Environment to Avoid Local Learning 
(An Analysis of the Generalization Mechanism of XCS). Technical Report 97.46, 
Politecnico di Milano. Department of Electronic Engineering and Information 
Sciences, 1997. http://ftp.elet.polimi.it/people/lanzi/report46.ps.gz.
<blockquote> We analyze generalization with the XCS classifier system when the 
system is applied to animat problems in grid-worlds. The aim of the paper is to 
give an unified view of generalization with XCS, in order to explain some of 
the phenomena reported in the literature. Initially, we extend the results 
previously presented in the literature applying XCS to three environments. Our 
results confirm what already reported in the literature, showing that the 
generalization mechanism of XCS may prevent the system from converging to 
optimal performance. Accordingly, we study XCS generalization mechanism 
analyzing Wilson's generalization hypothesis and the conditions under which it 
may fail. We draw a hypothesis in order to explain the results we report. We 
hypothesize that XCS fails to learn an optimal solution when, due to the 
environment structure and to the exploration strategy employed, the system is 
not able to explore all the environmental niches frequently. We validate our 
hypothesis introducing a new exploration strategy which guarantees a frequent 
exploration of all the areas of the environment, we call it teletransportation. 
Teletransportation is not introduced as a real solution to the problems we 
evidenced, since it is not feasible for real applications; rather, we exploit 
teletransportation as a tool to validate our hypothesis. Nevertheless, as we 
subsequently show, the ideas which support teletransportation can be 
implemented integrating XCS with a model of the environment, learned by 
experience, in a dyna architecture. We end of the paper discussing another 
important aspect of generalization in XCS: the conditions under which XCS may 
fail to produce a compact representation of a learned task. We show this is 
likely to happen in environments where there is no direct relation between the 
number of don't care symbols a classifier condition has, and the number of 
environmental conditions the classifier matches. Accordingly, we discuss the 
role of subsumption deletion for the problem of evolving a compact 
representation of the learned task.</blockquote> 
<p> </p> </dd> 
<dt> [554] </dt> 
<dd> Pier&nbsp;Luca Lanzi. A Study of the Generalization Capabilities of XCS. 
InB&auml;ck [24], pages 418-425. 
http://ftp.elet.polimi.it/people/lanzi/icga97.ps.gz.
<blockquote> We analyze the generalization behavior of the XCS classifier 
system in environments in which only a few generalizations can be done. 
Experimental results presented in the paper evidence that the generalization 
mechanism of XCS can prevent it from learning even simple tasks in such 
environments. We present a new operator, named Specify, which contributes to 
the solution of this problem. XCS with the Specify operator, named XCSS, is 
compared to XCS in terms of performance and generalization capabilities in 
different types of environments. Experimental results show that XCSS can deal 
with a greater variety of environments and that it is more robust than XCS with 
respect to population size.</blockquote> 
<p> </p> </dd> 
<dt> [555] </dt> 
<dd> Pier&nbsp;Luca Lanzi. Solving Problems in Partially Observable 
Environments with Classifier Systems (Experiments on Adding Memory to XCS). 
Technical Report 97.45, Politecnico di Milano. Department of Electronic 
Engineering and Information Sciences, 1997. 
http://ftp.elet.polimi.it/people/lanzi/report45.ps.gz.
<blockquote> XCS is a classifier system recently introduced by Wilson that 
differs from Holland's framework in that classifier fitness is based on the 
accuracy of the prediction instead of the prediction itself. According to the 
original proposal, XCS has no internal message list as traditional classifier 
systems does; hence XCS learns only reactive input/output mappings that are 
optimal in Markovian environments. When the environment is partially 
observable, i.e. non-Markovian, XCS evolves suboptimal solutions; in order to 
evolve an optimal policy in such environments the system needs some sort of 
internal memory mechanism. In this paper, we add internal memory mechanism to 
the XCS classifier system. We then test XCS with internal memory, named XCSM, 
in non-Markovian environments of increasing difficulty. Experimental results, 
we present, show that XCSM is able to evolve optimal solutions in simple 
environments, while in more complex problems the system needs special operators 
or special exploration strategies. We show also that the performance of XCSM is 
very stable with respect to the size of the internal memory involved in 
learning. Accordingly, when complex non-Markovian environments are faced XCSM 
performance results to be more stable when more bits than necessary are 
employed. Finally, we extend some of the results presented in the literature 
for classifier system in non-Markovian problems, applying XCSM to environments 
which require the agent to perform sequences of actions in the internal memory. 
The results presented suggest that the exploration strategies currently 
employed in the study of XCS are too simple to be employed with XCSM; 
accordingly, other exploration strategies should be investigated in order to 
develop better classifier systems</blockquote> 
<p> </p> </dd> 
<dt> [556] </dt> 
<dd> Pier&nbsp;Luca Lanzi. Adding Memory to XCS. In Proceedings of the IEEE 
Conference on Evolutionary Computation (ICEC98). IEEE Press, 1998. 
http://ftp.elet.polimi.it/people/lanzi/icec98.ps.gz.
<blockquote> We add internal memory to the XCS classifier system. We then test 
XCS with internal memory, named XCSM, in non-Markovian environments with two 
and four aliasing states. Experimental results show that XCSM can easily 
converge to optimal solutions in simple environments; moreover, XCSM's 
performance is very stable with respect to the size of the internal memory 
involved in learning. However, the results we present evidence that in more 
complex non-Markovian environments, XCSM may fail to evolve an optimal 
solution. Our results suggest that this happens because, the exploration 
strategies current employed with XCS, are not adequate to guarantee the 
convergence to an optimal policy with XCSM, in complex non-Markovian 
environments.</blockquote> 
<p> </p> </dd> 
<dt> [557] </dt> 
<dd> Pier&nbsp;Luca Lanzi. An analysis of the memory mechanism of XCSM. In 
Koza et&nbsp;al. [529], pages 643-651. 
http://ftp.elet.polimi.it/people/lanzi/gp98.ps.gz.
<blockquote> We analyze the memory mechanism of XCSM, the extension of XCS 
with internal memory. Our aim is to explain some of the results reported in the 
literature, which show that XCSM fails to learn an optimal policy in complex 
partially observable environments. The analysis we present reveals that the 
XCSM's memory management strategy cannot guarantee the convergence to an 
optimal solution. We thus extend XCSM introducing a novel hierarchical 
exploration technique and modifying the technique used for updating internal 
memory. We apply the novel version of XCSM, called XCSMH, to a set of partially 
observable environments of different complexity. Our results show that XCSMH is 
able to learn an optimal policy in all the environments, outperforming XCSMH in 
more difficult problems.</blockquote> 
<p> </p> </dd> 
<dt> [558] </dt> 
<dd> Pier&nbsp;Luca Lanzi. Generalization in Wilson's XCS. In A.&nbsp;E. 
Eiben, T.&nbsp;B&auml;ck, M.&nbsp;Shoenauer, and H.-P. Schwefel, editors,
Proceedings of the Fifth International Conference on Parallel Problem Solving 
From Nature -- PPSN V, number 1498 in LNCS. Springer Verlag, 1998. 
<blockquote> We analyze generalization with the XCS classifier system when the 
system is applied to animat problems in grid-worlds. The aim of the paper is to 
give an unified view of generalization with XCS, in order to explain some of 
the phenomena reported in the literature. First, we extend the results 
previously presented in the literature applying XCS to two environments. Our 
results confirm what already reported in the literature, showing that the 
generalization mechanism of XCS may prevent the system from converging to 
optimal performance. Accordingly, we study XCS generalization mechanism 
analyzing the conditions under which it may fail to evolve an optimal solution. 
We draw a hypothesis in order to explain the results reported so far. Our 
hypothesis suggest that XCS fails to learn an optimal solution when, due to the 
environment structure and to the exploration strategy employed, the system is 
not able to explore all the environmental niches frequently. We test our 
hypothesis introducing a new exploration strategy which guarantees a frequent 
exploration of all the areas of the environment, we call it teletransportation. 
We then apply XCS with teletransportation the environments previously 
introduced in order to validate our hypothesis experimentally.</blockquote> 
<p> </p> </dd> 
<dt> [559] </dt> 
<dd> Pier&nbsp;Luca Lanzi. Reinforcement Learning by Learning Classifier 
Systems. PhD thesis, Politecnico di Milano, 1998. 
<blockquote> This thesis investigates a learning paradigm which merge together 
the concept of learning by interactions, which comes from the research field of 
reinforcement learning, with the concept of learning through evolution, which 
was introduced by John H. Holland, the father of genetic algorithms, in 1978 
who called this paradigm learning classifier systems. This work is devoted to 
the study of a particular model of learning classifier system called XCS, 
introduced by Stewart W. Wilson in 1995, in which the most interesting ideas of 
Holland's paradigm co-exist with more recent ideas borrowed from reinforcement 
learning. The aim of this thesis is to take XCS beyond the very first results 
presented by Wilson in his original paper and to investigate the peculiarities 
of this new model of learning classifier systems with respect to other learning 
paradigms that come from reinforcement learning and evolutionary computation. 
In doing this, I propose a number of extensions to the original Wilson's 
framework that improves its performance and its applicability to a larger 
number of problems. Initially, I take XCS beyond its very first environments 
and parameter settings, and I show that in certain difficult sequential 
environments, XCS performance can fail dramatically. I propose an extension to 
XCS that improve its performance in such types of applications. I present an 
experimental analysis of generalization in XCS to understand the failures in 
XCS performance I observed, and to justify the improvements that the extension 
I propose introduces. Then, I introduce an extension to XCS for dealing with 
the possible incomplete perceptions that the system may experience in certain 
applications. This is done in two steps. First, following an idea suggested by 
Wilson, I implement a simple extension to XCS for dealing with incomplete 
perception. I show that this is capable to learn optimal behaviors in 
particular cases but not in general ones. I analyze this result and present an 
experimental study which points out the reasons underlying the poor performance 
of this extension. I suggest how the system should be extended in order to 
evolve optimal solutions in a wider set of applications. I implement this new 
extension of XCS and present experimental results showing that indeed the new 
system can learn in more difficult applications. Finally, I analyze XCS 
behavior in those applications where the results of the agent actions can be 
affected by uncertainty. I show that Wilson's XCS can deal with these types of 
applications when the uncertainty on agent action is limited, other-wise the 
system may fail to converge to an optimal performance. I study this phenomenon 
and develop an explanation which results in an extension of XCS that is able to 
deal with higher degree of uncertainty. I end the thesis presenting some 
initial results of the research directions I am currently pursuing.</blockquote>
<p> </p> </dd> 
<dt> [560] </dt> 
<dd> Pier&nbsp;Luca Lanzi. An Analysis of Generalization in the XCS Classifier 
System.Evolutionary Computation, 7(2):125-149, 1999. 
<blockquote> The XCS classifier system represents a major advance in 
classifier systems research because (1) it has a sound and accurate 
generalization mechanism, and (2) its learning mechanism is based on 
Q-learning, a recognized learning technique. In taking XCS beyond its very 
first environments and parameter settings, we show that, in certain difficult 
sequential (``animat'') environments, performance is poor. We suggest that this 
occurs because in the chosen environments, some conditions for proper 
functioning of the generalization mechanism do not hold, resulting in overly 
general classifiers that cause reduced performance. We hypothesize that one 
such condition is a lack of sufficiently wide exploration of the environment 
during learning. We show that if XCS is forced to explore its environment more 
completely, performance improves dramatically. We propose a technique based on 
Sutton's Dyna concept, through which wider exploration would occur naturally. 
Separately, we demonstrate that the compactness of the representation evolved 
by XCS is limited by the number of instances of each generalization actually 
present in the environment. The paper shows that XCS's generalization mechanism 
is effective, but that the conditions under which it works must be clearly 
understood.</blockquote> 
<p> </p> </dd> 
<dt> [561] </dt> 
<dd> Pier&nbsp;Luca Lanzi. Extending the Representation of Classifier 
Conditions Part I: From Binary to Messy Coding. InBanzhaf et&nbsp;al. [32], 
pages 337-344.
<blockquote> We present an initial study on the alternative representations of 
classifier conditions. Instead of considering the representations that have 
been suggested in the literature, S-expressions or real-coding, we focus on 
messy representation of classifier conditions which has the interesting 
characteristic of being independent from the sensors position coding scheme. We 
develop an extension of the XCS classifier system in which variable-length 
messy chromosomes replace original bitstring representation. With a series of 
experiments we show that to reach optimal performance covering, matching, and 
mutation must be adequately defined in order to avoid overgeneralization due to 
underspecification of classifier conditions. These conclusions appear to be 
very general since they are independent of the messy representation scheme. 
Accordingly, they can be used as guidelines for general variable-length 
representations like S-Expressions.</blockquote> 
<p> </p> </dd> 
<dt> [562] </dt> 
<dd> Pier&nbsp;Luca Lanzi. Extending the Representation of Classifier 
Conditions Part II: From Messy Coding to S-Expressions. InBanzhaf et&nbsp;al. 
[32], pages 345-352. 
<blockquote> In this paper we present the results of the second part of our 
research which is aimed to the study of alternative representations of 
classifier conditions. In particular we introduce an extension of the XCS 
classifier system in which bitstring representation is replaced by 
S-expressions. We show that XCS with S-expressions, SXCS, can reach optimal 
performance in different types of applications with different complexity. The 
results we present also suggest that great care must be taken in choosing the 
representation language; in particular we show that in certain cases the use of 
``or'' clauses may lead to an unstable performance. Overall, our initial 
results show that this is a promising approach for a future development of a 
general purpose representation of classifier conditions and that there are 
still many issues which shall be investigated.</blockquote> 
<p> </p> </dd> 
<dt> [563] </dt> 
<dd> Pier&nbsp;Luca Lanzi. Adaptive Agents with Reinforcement Learning and 
Internal Memory. InSixth International Conference on the Simulation of Adaptive 
Behavior (SAB2000), pages 333-342, 2000. 
<blockquote> Perceptual aliasing is a serious problem for adaptive agents. 
Internal memory is a promising approach to extend reinforcement learning 
algorithms to problems involving perceptual aliasing. In this paper we 
investigate the effectiveness of internal memory for tackling perceptual 
aliasing problems with adaptive agents and reinforcement learning. 
Specifically, we try to give a unified view of some interesting results that 
have been presented in different frameworks, i.e.: tabular reinforcement 
learning and learning classifier systems.</blockquote> 
<p> </p> </dd> 
<dt> [564] </dt> 
<dd> Pier&nbsp;Luca Lanzi. Learning Classifier Systems from a Reinforcement 
Learning Perspective . Technical Report 00-03, Dipartimento di Elettronica e 
Informazione, Politecnico di Milano, 2000.
<blockquote> In this paper we approach the problem of defining learning 
classifier systems from the perspective of reinforcement learning. The 
peculiarity of this approach is that it does not assume any knowledge on 
learning classifier systems but try to develop classifier systems ``from 
scratch'', i.e., starting from one of the most known reinforcement learning 
technique: Q-learning. We begin considering some basic elements of 
reinforcement learning: a problem modelled as a Markov Decision Process and 
tabular Q-learning. We introduce a formal framework to define a general purpose 
rule-based representation which we use to implement tabular Q-learning. We 
analyze different methods to add generalization capabilities to the rule-based 
representation. We argue that genetic algorithms are probably the most general 
method for adding generalization to classifiers, although they might be not the 
only solution.</blockquote> 
<p> </p> </dd> 
<dt> [565] </dt> 
<dd> Pier&nbsp;Luca Lanzi. Mining interesting knowledge from data with the xcs 
classifier system. In Lee Spector, Erik&nbsp;D. Goodman, Annie Wu, W.B. 
Langdon, Hans-Michael Voigt, Mitsuo Gen, Sandip Sen, Marco Dorigo, Shahram 
Pezeshk, Max&nbsp;H. Garzon, and Edmund Burke, editors,Proceedings of the 
Genetic and Evolutionary Computation Conference (GECCO-2001), pages 958-965, 
San Francisco, California, USA, 7-11 July 2001. Morgan Kaufmann.
<p> </p> </dd> 
<dt> [566] </dt> 
<dd> Pier&nbsp;Luca Lanzi. Learning classifier systems from a reinforcement 
learning perspective.Journal of Soft Computing, 6(3-4):162-170, 2002. 
<p> </p> </dd> 
<dt> [567] </dt> 
<dd> Pier&nbsp;Luca Lanzi. Estimating classifier generalization and action's 
effect: A minimalist approach. In E.&nbsp;Cant&uacute;-Paz, J.&nbsp;A. Foster, 
K.&nbsp;Deb, D.&nbsp;Davis, R.&nbsp;Roy, U.-M. O'Reilly, H.-G. Beyer, 
R.&nbsp;Standish, G.&nbsp;Kendall, S.&nbsp;Wilson, M.&nbsp;Harman, 
J.&nbsp;Wegener, D.&nbsp;Dasgupta, M.&nbsp;A. Potter, A.&nbsp;C. Schultz, 
K.&nbsp;Dowsland, N.&nbsp;Jonoska, and J.&nbsp;Miller, editors,Genetic and 
Evolutionary Computation -- GECCO-2003, volume 2724 of LNCS, pages 1894-1905. 
Springer-Verlag, 2003.
<p> </p> </dd> 
<dt> [568] </dt> 
<dd> Pier&nbsp;Luca Lanzi. Using raw accuracy to estimate classifier fitness 
in XCS. In E.&nbsp;Cant&uacute;-Paz, J.&nbsp;A. Foster, K.&nbsp;Deb, 
D.&nbsp;Davis, R.&nbsp;Roy, U.-M. O'Reilly, H.-G. Beyer, R.&nbsp;Standish, 
G.&nbsp;Kendall, S.&nbsp;Wilson, M.&nbsp;Harman, J.&nbsp;Wegener, 
D.&nbsp;Dasgupta, M.&nbsp;A. Potter, A.&nbsp;C. Schultz, K.&nbsp;Dowsland, 
N.&nbsp;Jonoska, and J.&nbsp;Miller, editors,Genetic and Evolutionary 
Computation -- GECCO-2003, volume 2724 of LNCS, pages 1922-1923. 
Springer-Verlag, 2003.
<p> </p> </dd> 
<dt> [569] </dt> 
<dd> Pier&nbsp;Luca Lanzi. Learning classifier systems: then and now. 
Evolutionary Intelligence, 1(1):63-82, 2008. 
<p> </p> </dd> 
<dt> [570] </dt> 
<dd> Larry Bull, David Wyatt and Ian Parmee. Initial modifications to XCS for 
use in interactive evolutionary design. In H.-P.&nbsp;Schwefel J.-J. Merelo 
Guerv&oacute;s, P. Adamidis, H.-G. Beyer, J.-L. 
Fern&aacute;ndez-Villaca&ntilde;as, editor,Parallel Problem Solving from Nature 
- PPSN VII, 7th International Conference, Granada, Spain, September 7-11, 2002. 
Proceedings, number 2439 in Lecture Notes in Computer Science, LNCS, page 568 
ff. Springer-Verlag, 2002.
<p> </p> </dd> 
<dt> [571] </dt> 
<dd> Claude Lattaud. Non-Homogeneous Classifier Systems in a Macro-Evolution 
Process. In Wu [923], pages 266-271. 
<blockquote> The synthesis of artifacts reproducing behaviors and properties 
of living beings is one of the main goals of Artificial Life. These artificial 
entities often evolve according to algorithms based on models of modern 
genetics. Evolutionary algorithms generally produce micro-evolution in these 
entities, by mutation and crossover applied on their genome. The aim of this 
paper is to present Non-Homogeneous Classifier Systems, NHCS, integrating the 
process of macroevolution. A NHCS is a derived type of classical classifier 
systems, CS. In a standard CS, all classifiers are built on the same structure 
and own the same properties. With a NHCS, the behavior of an artificial 
creature is defined by the co-evolution between several differently structured 
classifiers making its organism. These agents, moving in a 2D discreet 
environment with obstacles and resources, must adapt themselves and breed to 
build viable populations. Finally, ecological niches and particular behaviors, 
individual and collective, appear according to initial parameters of agents and 
environment.</blockquote> 
<p> </p> </dd> 
<dt> [572] </dt> 
<dd> Claude Lattaud. Non-Homogeneous Classifier Systems in a Macro-Evolution 
Process. InLanzi et&nbsp;al. [544], pages 161-174. 
<blockquote> The synthesis of artifacts reproducing behaviors and properties 
of living beings is one of the main goals of Artificial Life. These artificial 
entities often evolve according to algorithms based on models of modern 
genetics. Evolutionary algorithms generally produce micro-evolution in these 
entities, by applying mutation and crossover on their genotype. The aim of this 
paper is to present Non-Homogenous Classifier Systems, NHCS, integrating the 
process of macro-evolution. A NHCS is a derived type of classical Classifier 
Systems, CS. In a CS, all classifiers are built on the same structure and own 
the same properties. With a NHCS, the behavior of artificial creatures is 
defined by the co-evolution between several differently structured classifiers. 
These agents, moving in a 2D environment with obstacles and resources, must 
adapt themselves and breed to build viable populations. Finally, ecological 
niches and specific behaviors, individual and collective, appear according to 
initial parameters of agents and environment.</blockquote> 
<p> </p> </dd> 
<dt> [573] </dt> 
<dd> Blake Lebaron, W.&nbsp;Brian Arthur, and R.&nbsp;Palmer. The Time Series 
Properties of an Artificial Stock Market.Journal of Economic Dynamics and 
Control, 23:1487-1516, 1999. 
<p> </p> </dd> 
<dt> [574] </dt> 
<dd> Martin Lettau and Harald Uhlig. Rules of Thumb and Dynamic Programming. 
Technical report, Department of Economics, Princeton University, 1994.
<p> </p> </dd> 
<dt> [575] </dt> 
<dd> Martin Lettau and Harald Uhlig. Rules of thumb versus dynamic programming.
American Economic Review, 89:148-174, 1999. 
<blockquote> This paper studies decision-making with rules of thumb in the 
context of dynamic decision problems and compares it to dynamic programming. A 
rule is a fixed mapping from a subset of states into actions. Rules are 
compared by averaging over past experiences. This can lead to favoring rules 
which are only applicable in good states. Correcting this good state bias 
requires solving the dynamic program. We provide a general framework and 
characterize the asymptotic properties. We apply it to provide a candidate 
explanation for the sensitivity of consumption to transitory income.
</blockquote> 
<p> </p> </dd> 
<dt> [576] </dt> 
<dd> Pen-Yang Liao and Jiah-Shing Chen. Dynamic trading strategey learning 
model using learning classifier systems. InProceedings of the 2001 Congress on 
Evolutionary Computation (CEC01) [186], pages 783-789. 
<blockquote> Current trading strategy learning models often proceed in three 
separate phases, i.e., training, validation, and application (testing). After a 
specific time span of application, a new learning process is started to adapt 
the trading strategy to the new environment states. The time span of 
application is usually fixed and determined according to experiences. This may 
result ni earning losses as compared to the perfect trading strategy which 
trades at each turning point of the stock price movement. Some learning 
methods, such as neural networks, are hard to explain intuitively and unstable 
in some dynamic environment states. Other learning models like simple genetic 
algorithms result in a single trading rule which is applied for a specific time 
span without being adapted even when the environment has changed. This paper 
adopts learning classifier systems (LCSs) technique to provide a dynamic 
trading strategy learning model (DTSLM), which makes continuous and instant 
learning while executing real prediction and prodcues a trading rule set to 
deal with different environment states. The simulation results show that this 
model could get a remarkable profit.</blockquote> 
<p> </p> </dd> 
<dt> [577] </dt> 
<dd> Gunar&nbsp;E. Liepins and Lori&nbsp;A. Wang. Classifier System Learning 
of Boolean Concepts. InBooker and Belew [74], pages 318-323. 
<blockquote> We investigate classifier system learning of Boolean concepts. We 
introduce a symmetric reward-penalty mechanism, speciation, generality 
thresholds and rule evaluation by queries. These enable the classifier system 
to learn the twenty multiplexor significantly faster than previously reported 
for classifier systems. Conversely, we provide theoretical analyses that 
suggest that classifier systems are not competitive with the best known 
learning algorithms for stationary deterministic Boolean problems. We suggest 
instead that they are particularly well suited to non-stationary problems for 
which the target concept evolves over time.</blockquote> 
<p> </p> </dd> 
<dt> [578] </dt> 
<dd> Gunar&nbsp;E. Liepins, Michael&nbsp;R. Hilliard, Mark Palmer, and Gita 
Rangarajan. Alternatives for Classifier System Credit Assignment. InProceedings 
of the Eleventh International Joint Conference on Artificial Intelligence 
(IJCAI-89), pages 756-761, 1989. 
<p> </p> </dd> 
<dt> [579] </dt> 
<dd> Gunar&nbsp;E. Liepins, M.&nbsp;R. Hillard, M.&nbsp;Palmer, and 
G.&nbsp;Rangarajan. Credit Assignment and Discovery in Classifier Systems.
International Journal of Intelligent Systems, 6:55-69, 1991. 
<p> </p> </dd> 
<dt> [580] </dt> 
<dd> Derek&nbsp;A. Linkens and H.&nbsp;Okola Nyongesah. Genetic Algorithms for 
fuzzy control - Part II: Off-line system development and application. Technical 
Report CTA/94/2387/1st MS, Department of Automatic Control and System 
Engineering, University of Sheffield, U.K., 1994.
<blockquote> Although fuzzy logic controllers and expert systems have been 
successfully applied in many complex industrial processes, they experience a 
deficiency in knowledge acquisition and rely to a great extent on empirical and 
heuristic knowledge, which in many cases cannot be objectively elicited. Among 
the problems to be resolved in fuzzy controller design are the determination of 
the linguistic state space, definition of the membership functions of each 
linguistic term and the derivation of the control rules. Some of these problems 
can be solved by application of machine learning. First, it is desirable to 
simplify and automate the specification of linguistic rules. Secondly, it is 
also desirable that modification of control rules be possible in order to cope 
with previously unknown, or changes in process dynamics. Machine learning 
methods have in recent years emerged from the use of learning algorithms 
modelled on natural and biological systems. These methods attempt to abstract 
the advanced mechanisms of learning exhibited by such systems, which can, 
consequently, be applied to intelligent control. One of these new algorithms is 
the genetic algorithm which is modelled on the processes of natural evolution. 
This paper develops the application of genetic algorithm techniques for fuzzy 
controller design. Genetic algorithms are used to automate and introduce 
objective criteria in defining fuzzy controller parameters.</blockquote> 
<p> </p> </dd> 
<dt> [581] </dt> 
<dd> Juliet&nbsp;Juan Liu and James Tin-Yau Kwok. An extended genetic rule 
induction algorithm. InProceedings of the 2000 Congress on Evolutionary 
Computation (CEC00) [185], pages 458-463. 
<blockquote> This paper describes an extension of a GA-based, 
separate-and-conquer propositional rule incuction algorithm called SIA. While 
the original algorithm is computationally attractive and is also able to handle 
both nominal and continuous attributes efficiently, our algorithm further 
improves it by taking into account of the recent advances in the rule induction 
and evolutionary computation communities. The refined system has been compared 
to other GA-based and non GA-based rule learning algorithms on a number of 
benchmark datasets from the UCI machine learning Repository. Results show that 
the proposed system can achieve higher performance while still produces a 
smaller number of rules.</blockquote> 
<p> </p> </dd> 
<dt> [582] </dt> 
<dd> Xavier Llor&agrave; and Josep&nbsp;M. Garrell. Automatic Classification 
and Artificial Life Models. InProceedings of the International Worshop on 
Learning (Learning00), 2000. 
<blockquote> ALE is a classication-oriented model based on cooperative agent 
aggregates spread over a two dimensional board. The model solves classi cation 
problems descrived by continuous-valued imputs. This paper describes ALE 
focussing on a key point, resources allocation. The main apportation is that 
using an accurate resources allocation we can clearly improve convergence speed 
at the same time that agents aggregate complexity reduces</blockquote> 
<p> </p> </dd> 
<dt> [583] </dt> 
<dd> Xavier Llor&agrave; and Josep&nbsp;M. Garrell. Evolution of Decision 
Trees. InForth Catalan Conference on Artificial Intelligence (CCIA'2001), page 
to appear. ACIA Press, 2001.
<p> </p> </dd> 
<dt> [584] </dt> 
<dd> Xavier Llor&agrave; and Josep&nbsp;M. Garrell. Evolving Partially-Defined 
Instances with Evolutionary Algorithms. InProceedings of the 18th International 
Conference on Machine Learning (ICML'2001), pages 337-344. Morgan Kaufmann 
Publishers, 2001.
<p> </p> </dd> 
<dt> [585] </dt> 
<dd> Xavier Llor&agrave; and Josep&nbsp;M. Garrell. Knowledge-Independent Data 
Mining with Fine-Grained Parallel Evolutionary Algorithms. In Lee Spector, 
Erik&nbsp;D. Goodman, Annie Wu, W.B. Langdon, Hans-Michael Voigt, Mitsuo Gen, 
Sandip Sen, Marco Dorigo, Shahram Pezeshk, Max&nbsp;H. Garzon, and Edmund 
Burke, editors,Proceedings of the Genetic and Evolutionary Computation 
Conference (GECCO'2001), pages 461-468. Morgan Kaufmann Publishers, 2001. 
<p> </p> </dd> 
<dt> [586] </dt> 
<dd> Xavier Llor&agrave; and Josep&nbsp;M. Garrell. Coevolving different 
knowledge representations with fine-grained parallel learning classifier 
systems. In W.&nbsp;B. Langdon, E.&nbsp;Cant&uacute;-Paz, K.&nbsp;Mathias, 
R.&nbsp;Roy, D.&nbsp;Davis, R.&nbsp;Poli, K.&nbsp;Balakrishnan, 
V.&nbsp;Honavar, G.&nbsp;Rudolph, J.&nbsp;Wegener, L.&nbsp;Bull, M.&nbsp;A. 
Potter, A.&nbsp;C. Schultz, J.&nbsp;F. Miller, E.&nbsp;Burke, and 
N.&nbsp;Jonoska, editors,GECCO 2002: Proceedings of the Genetic and 
Evolutionary Computation Conference, pages 934-941. Morgan Kaufmann Publishers, 
2002.
<p> </p> </dd> 
<dt> [587] </dt> 
<dd> Xavier Llor&agrave; and Stewart&nbsp;W. Wilson. Mixed Decision Trees: 
Minimizing Knowledge Representation Bias in LCS. In Kalyanmoy&nbsp;Deb 
et&nbsp;al., editor,Proceedings of the Genetic and Evolutionary Computation 
Conference (GECCO-2004), volume 3103 of Lecture Notes in Computer Science, 
pages 797-809. Springer, 2004.
<blockquote> Learning classifier systems tend to inherit -a priori- a given 
knowledge representation language for expressing the concepts to learn. Hence, 
even before getting started, this choice biases what can be learned, becoming 
critical for some real-world applications like data mining. However, such bias 
may be minimized by hybridizing different knowledge representations via 
evolutionary mixing. This paper presents a first attempt to produce an 
evolutionary framework that evolves mixed decision trees of heterogeneous 
knowledge representations.</blockquote> 
<p> </p> </dd> 
<dt> [588] </dt> 
<dd> Xavier Llor&agrave;, K.&nbsp;Sastry, and D.E. Goldberg. Binary rule 
encoding schemes: a study using the compact classifier system. In 
F.&nbsp;Rothlauf, editor,GECCO '05: Proceedings of the 2005 conference on 
genetic and evolutionary computation, workshop proceedings, pages 88-89. ACM 
Press, 2005.
<p> </p> </dd> 
<dt> [589] </dt> 
<dd> Xavier Llor&agrave;, K.&nbsp;Sastry, and D.E. Goldberg. The compact 
classifier system: scalability analysis and first results. In F.&nbsp;Rothlauf, 
editor,Proceedings of the IEEE congress on evolutionary computation, CEC 2005, 
pages 596-603. IEEE, 2005.
<p> </p> </dd> 
<dt> [590] </dt> 
<dd> Xavier Llor&agrave;, Kumara Sastry, Cl&aacute;udio&nbsp;F. Lima, 
Fernando&nbsp;G. Lobo, and David&nbsp;E. Goldberg. Linkage learning, rule 
representation, and the &Iuml;&#135;-ary extended compact classifier system. In 
Jaume Bacardit, Ester Bernad&oacute;-Mansilla, Martin Butz, Tim Kovacs, Xavier 
Llor&agrave;, and Keiki Takadama, editors,Learning Classifier Systems. 10th and 
11th International Workshops (2006-2007), volume 4998/2008 of Lecture Notes in 
Computer Science, pages 189-205. Springer, 2008. 
<blockquote> This paper reviews a competent Pittsburgh LCS that automatically 
mines important substructures of the underlying problems and takes problems 
that were intractable with first-generation Pittsburgh LCS and renders them 
tractable. Specifically, we propose a &Iuml;&#135;-ary extended compact 
classifier system (&Iuml;&#135;eCCS) which uses (1) a competent genetic 
algorithm (GA) in the form of &Iuml;&#135;-ary extended compact genetic 
algorithm, and (2) a niching method in the form restricted tournament 
replacement, to evolve a set of maximally accurate and maximally general rules. 
Besides showing that linkage exist on the multiplexer problem, and that 
&Iuml;&#135;eCCS scales exponentially with the number of address bits (building 
block size) and quadratically with the problem size, this paper also explores 
non-traditional rule encodings. Gene expression encodings, such as the Karva 
language, can also be used to build &Iuml;&#135;eCCS probabilistic models. 
However, results show that the traditional ternary encoding 0,1,# presents a 
better scalability than the gene expression inspired ones for problems 
requiring binary conditions</blockquote> 
<p> </p> </dd> 
<dt> [591] </dt> 
<dd> Xavier Llor&agrave;. Genetic Based Machine Learning using Fine-grained 
Parallelism for Data Mining. PhD thesis, Enginyeria i Arquitectura La Salle. 
Ramon Llull University, 2002.
<p> </p> </dd> 
<dt> [592] </dt> 
<dd> D.&nbsp;Loiacono, A.&nbsp;Marelli, and P.L. Lanzi. Support vector 
regression for classifier prediction. InGECCO '07: Proceedings of the 9th 
annual conference on Genetic and evolutionary computation, pages 1806-1813. 
ACM, 2007.
<blockquote> In this paper we introduce XCSF with support vector 
prediction:the problem of learning the prediction function is solved as a 
support vector regression problem and each classifier exploits a Support Vector 
Machine to compute the prediction. In XCSF with support vector prediction, 
XCSFsvm, the genetic algorithm adapts classifier conditions, classifier 
actions, and the SVM kernel parameters.We compare XCSF with support vector 
prediction to XCSF with linear prediction on the approximation of four test 
functions.Our results suggest that XCSF with support vector prediction compared 
to XCSF with linear prediction (i) is able to evolve accurate approximations of 
more difficult functions, (ii) has better generalization capabilities and (iii) 
learns faster.</blockquote> 
<p> </p> </dd> 
<dt> [593] </dt> 
<dd> Daniele Loiacono, Jan Drugowitsch, Alwyn Barry, and Pier&nbsp;Luca Lanzi. 
Analysis and improvements of the classifier error estimate in xcsf. In Jaume 
Bacardit, Ester Bernad&oacute;-Mansilla, Martin Butz, Tim Kovacs, Xavier 
Llor&agrave;, and Keiki Takadama, editors,Learning Classifier Systems. 10th and 
11th International Workshops (2006-2007), volume 4998/2008 of Lecture Notes in 
Computer Science, pages 117-135. Springer, 2008. 
<blockquote> The estimation of the classifier error plays a key role in 
accuracy-based learning classifier systems. In this paper we study the current 
definition of the classifier error in XCSF and discuss the limitations of the 
algorithm that is currently used to compute the classifier error estimate from 
online experience. Subsequently, we introduce a new definition for the 
classifier error and apply the Bayes Linear Analysis framework to find a more 
accurate and reliable error estimate. This results in two incremental error 
estimate update algorithms that we compare empirically to the performance of 
the currently applied approach. Our results suggest that the new estimation 
algorithms can improve the generalization capabilities of XCSF, especially when 
the action-set subsumption operator is used.</blockquote> 
<p> </p> </dd> 
<dt> [594] </dt> 
<dd> Sean Luke. Essentials of Metaheuristics. 2009. 
<p> </p> </dd> 
<dt> [595] </dt> 
<dd> Pattie Maes, Maja&nbsp;J. Mataric, Jean-Arcady Meyer, Jordan Pollack, and 
Stewart&nbsp;W. Wilson, editors.From Animals to Animats 4. Proceedings of the 
Fourth International Conference on Simulation of Adaptive Behavior (SAB96). A 
Bradford Book. MIT Press, 1996.
<p> </p> </dd> 
<dt> [596] </dt> 
<dd> Chikara Maezawa and Masayasu Atsumi. Collaborative Learning Agents with 
Structural Classifier Systems. InBanzhaf et&nbsp;al. [32], page 777. One page 
poster paper.
<blockquote> We propose a new learning agent architecture for collaborative 
learning. To learn any complicated task in multi-agent environment, simple 
reinforcement architectures have limitations on learning. Therefore, we propose 
splitting learning mechanism into three separate layers to learn required 
behavior, which are respectively organized by the Classifier System 
[Holland86]. It can learn to communicate with other agents, to make plans, and 
to select actions based on the plans and other agents' behavior. We show that 
these agents can select cooperative actions as a collaborative group.
</blockquote> 
<p> </p> </dd> 
<dt> [597] </dt> 
<dd> Bernard Manderick. Selectionist Categorization. In Schwefel and 
M&auml;nner [728], pages 326-330. 
<blockquote> A selectionist recognition system is presented that categorizes 
inputs generation by pattern generators.</blockquote> 
<p> </p> </dd> 
<dt> [598] </dt> 
<dd> Ester Bernad&oacute;&nbsp;I Mansilla and Josep Maria&nbsp;Garrell 
i&nbsp;Guiu. MOLeCS: A MultiObjective Learning Classifier System. InWhitely 
et&nbsp;al. [878], page 390. One page poster paper. 
<blockquote> This work has no abstract. </blockquote> 
<p> </p> </dd> 
<dt> [599] </dt> 
<dd> Ramon Marimon, Ellen McGrattan, and Thomas&nbsp;J. Sargent. Money as a 
Medium of Exchange in an Economy with Artificially Intelligent Agents.Journal 
of Economic Dynamics and Control, 14:329-373, 1990. Also Technical Report 
89-004, Santa Fe Institute, 1989.
<p> </p> </dd> 
<dt> [600] </dt> 
<dd> James A.&nbsp;R. Marshall and Tim Kovacs. A representational ecology for 
learning classifier systems. In Maarten Keijzer et al., editor,Proceedings of 
the 2006 Genetic and Evolutionary Computation Conference (GECCO 2006), pages 
1529-1536. ACM, 2006.
<p> </p> </dd> 
<dt> [601] </dt> 
<dd> James A.&nbsp;R. Marshall, Gavin Brown, and Tim Kovacs. Bayesian 
Estimation of Rule Accuracy in UCS. In Tina Yu, editor,To appear in the 
proceedings of the 2007 workshops on genetic and evolutionary computation. ACM, 
2007.
<p> </p> </dd> 
<dt> [602] </dt> 
<dd> Javier&nbsp;G. Mar&iacute;n-Bl&aacute;zquez and Sonia Schulenburg. A 
hyper-heuristic framework with xcs: Learning to create novel problem-solving 
algorithms constructed from simpler algorithmic ingredients. In Tim Kovacs, 
Xavier LL&ograve;ra, Keiki Takadama, Pier&nbsp;Luca Lanzi, Wolfgang Stolzmann, 
and Stewart&nbsp;W. Wilson, editors,Learning Classifier Systems. International 
Workshops, IWLCS 2003-2005, Revised Selected Papers, volume 4399 of LNCS, pages 
193-218. Springer, 2007.
<p> </p> </dd> 
<dt> [603] </dt> 
<dd> Maja&nbsp;J. Mataric. A comparative analysis of reinforcement learning 
methods. A.I. Memo No. 1322, Massachusetts Institute of Technology, 1991.
<blockquote> This paper analyzes the suitability of reinforcement learning for 
both programming and adapting situated agents. In the the first part of the 
paper we discuss two specific reinforcement learning algorithms: Q-learning and 
the Bucket Brigade. We introduce a special case of the Bucket Brigade, and 
analyze and compare its performance to Q- learning in a number of experiments. 
The second part of the paper discusses the key problems of reinforcement 
learning: time and space complexity, input generalization, sensitivity to 
parameter values, and selection of the reinforcement function. We address the 
tradeoff between the amount of built in and learned knowledge in the context of 
the number of training examples required by a learning algorithm. Finally, we 
suggest directions for future research.</blockquote> 
<p> </p> </dd> 
<dt> [604] </dt> 
<dd> Alaster&nbsp;D. McAulay and Jae&nbsp;Chan Oh. Image Learning Classifier 
System Using Genetic Algorithms. InProceedings IEEE NAECON '89, 1989. 
<p> </p> </dd> 
<dt> [605] </dt> 
<dd> John&nbsp;R. McDonnell. Control. In Thomas B&auml;ck, David&nbsp;B. 
Fogel, and Zbigniew Michalewicz, editors,Handbook of Evolutionary Computation, 
pages F1.3:1-F1.3:7. IOP Publishing Ltd and Oxford University Press, 1997.
<p> </p> </dd> 
<dt> [606] </dt> 
<dd> Chris Melhuish and Terence&nbsp;C. Fogarty. Applying A Restricted Mating 
Policy To Determine State Space Niches Using Immediate and Delayed 
Reinforcement. InFogarty [324], pages 224-237. 
<blockquote> Approaches for rule based control often rely heavily on the 
pre-classification of the state space for their success. In the pre-determined 
regions individual or groups of rules may be learned. Clearly, the success of 
such strategies depends on the quality of the partitioning of the state space. 
When no such a priori partitioning is available it is a significantly more 
difficult task to learn an appropriate division of the state space as well as 
the associated rules. Yet another layer of potential difficulty is the nature 
of the reinforcement applied to the rules since it is not always possible to 
generate an immediate reinforcement signal to supply judgement on the efficacy 
of activated rules. One approach to combine the joint goals of determining 
partitioning of the state space and discovery of associated rules is to use a 
genetic algorithm employing a restricted mating policy to generate rule 
clusters which dominate regions of the state space thereby effecting the 
required partitioning. Such rule clusters are termed niches. A niching 
algorithm, which includes a `creche' facility to protect `inexperienced' 
classifiers, and the results of determining a simple 2D state space using an 
immediate reward scheme are presented. Details of how the algorithm may 
modified to incorporate a delayed reinforcement scheme on a real-world beam 
balancing control problem are reported.</blockquote> 
<p> </p> </dd> 
<dt> [607] </dt> 
<dd> Drew Mellor. A first order logic classifier system. In F.&nbsp;Rothlauf, 
editor,GECCO '05: Proceedings of the 2005 conference on genetic and 
evolutionary computation, pages 1819-1826. ACM Press, 2005. 
<p> </p> </dd> 
<dt> [608] </dt> 
<dd> Drew Mellor. Policy transfer with a relational learning classifier 
system. InGECCO Workshops 2005, pages 82-84. ACM Press, 2005. 
<p> </p> </dd> 
<dt> [609] </dt> 
<dd> Drew Mellor. A learning classifier system approach to relational 
reinforcement learning. In Jaume Bacardit, Ester Bernad&oacute;-Mansilla, 
Martin Butz, Tim Kovacs, Xavier Llor&agrave;, and Keiki Takadama, editors,
Learning Classifier Systems. 10th and 11th International Workshops (2006-2007), 
volume 4998/2008 ofLecture Notes in Computer Science, pages 169-188. Springer, 
2008.
<blockquote> This article describes a learning classifier system (LCS) 
approach to relational reinforcement learning (RRL). The system, Foxcs-2, is a 
derivative of XCS that learns rules expressed as definite clauses over 
first-order logic. By adopting the LCS approach, Foxcs-2, unlike many RRL 
systems, is a general, model-free and &ldquo;tabula rasa&rdquo; system. The 
change in representation from bit-strings in XCS to first-order logic in 
Foxcs-2 necessitates modifications, described within, to support matching, 
covering, mutation and several other functions. Evaluation on inductive logic 
programming (ILP) and RRL tasks shows that the performance of Foxcs-2 is 
comparable to other systems. Further evaluation on RRL tasks highlights a 
significant advantage of Foxcs-2&rsquo;s rule language: in some environments it 
is able to represent policies that are genuinely scalable; that is, policies 
that are independent of the size of the environment.</blockquote> 
<p> </p> </dd> 
<dt> [610] </dt> 
<dd> Drew Mellor. A learning classifier system approach to relational 
reinforcement learning. PhD thesis, University of Newcastle, 2008. 
<blockquote> Machine learning methods usually represent knowledge and 
hypotheses using attribute-value languages, principally because of their 
simplicity and demonstrated utility over a broad variety of problems. However, 
attribute-value languages have limited expressive power and for some problems 
the target function can only be expressed as an exhaustive conjunction of 
specific cases. Such problems are handled better with inductive logic 
programming (ILP) or relational reinforcement learning (RRL), which employ more 
expressive languages, typically languages over first-order logic. Methods 
developed within these fields generally extend upon attribute-value algorithms; 
however, many attribute-value algorithms that are potentially viable for RRL, 
the younger of the two fields, remain to be extended. This thesis investigates 
an approach to RRL derived from the learning classifier system XCS. In brief, 
the new system, FOXCS, generates, evaluates, and evolves a population of 
``condition-action'' rules that are definite clauses over first-order logic. 
The rules are typically comprehensible enough to be understood by humans and 
can be inspected to determine the acquired principles. Key properties of FOXCS, 
which are inherited from XCS, are that it is general (applies to arbitrary 
Markov decision processes), model-free (rewards and state transitions are 
``black box'' functions), and ``tabula rasa'' (the initial policy can be 
unspecified). Furthermore, in contrast to decision tree learning, its 
rule-based approach is ideal for incrementally learning expressions over 
first-order logic, a valuable characteristic for an RRL system. Perhaps the 
most novel aspect of FOXCS is its inductive component, which synthesizes 
evolutionary computation and first-order logic refinement for incremental 
learning. New evolutionary operators were developed because previous 
combinations of evolutionary computation and first-order logic were 
non-incremental. The effectiveness of the inductive component was empirically 
demonstrated by benchmarking on ILP tasks, which found that FOXCS produced 
hypotheses of comparable accuracy to several well-known ILP algorithms. Further 
benchmarking on RRL tasks found that the optimality of the policies learnt were 
at least comparable to those of existing RRL systems. Finally, a significant 
advantage of its use of variables in rules was demonstrated: unlike RRL systems 
that did not use variables, FOXCS, with appropriate extensions, learnt scalable 
policies that were genuinely independent of the dimensionality of the task 
environment.</blockquote> 
<p> </p> </dd> 
<dt> [611] </dt> 
<dd> Drew Mellor. Reinforcement Learning, Logic and Evolutionary Computation: 
A Learning Classifier System Approach to Relational Reinforcement Learning. 
Lambert Academic Publishing, 2009.
<blockquote> Reinforcement learning (RL) consists of methods that 
automatically adjust behaviour based on numerical rewards and penalties. While 
use of the attribute-value framework is widespread in RL, it has limited 
expressive power. Logic languages, such as first-order logic, provide a more 
expressive framework, and their use in RL has led to the field of relational 
RL. This thesis develops a system for relational RL based on learning 
classifier systems (LCS). In brief, the system generates, evolves, and 
evaluates a population of condition-action rules, which take the form of 
definite clauses over first-order logic. Adopting the LCS approach allows the 
resulting system to integrate several desirable qualities: model-free and 
&quot;tabula rasa&quot; learning; a Markov Decision Process problem model; and 
importantly, support for variables as a principal mechanism for generalisation. 
The utility of variables is demonstrated by the system's ability to learn 
genuinely scalable behaviour - behaviour learnt in small environments that 
translates to arbitrarily large versions of the environment without the need 
for retraining.</blockquote> 
<p> </p> </dd> 
<dt> [612] </dt> 
<dd> Marc Metivier and Claud Lattaud. Imitation guided learning in learning 
classifier systems.Natural Computing, 8(1):29-56, 2009. 
<blockquote> In this paper, we study the means of developing an imitation 
process allowing to improve learning in the framework of learning classifier 
systems. We present three different approaches in the way a behavior observed 
may be taken into account through a guidance interaction: two approaches using 
a model of this behavior, and one without modelling. Those approaches are 
evaluated and compared in different environments when they are applied to three 
major classifier systems: ZCS, XCS and ACS. Results are analyzed and discussed. 
They highlight the importance of using a model of the observed behavior to 
enable an efficient imitation. Moreover, they show the advantages of taking 
this model into account by a specialized internal action. Finally, they bring 
new results of comparison between ZCS, XCS and ACS.</blockquote> 
<p> </p> </dd> 
<dt> [613] </dt> 
<dd> J.&nbsp;A. Meyer and S.&nbsp;W. Wilson, editors. From Animals to Animats 
1. Proceedings of the First International Conference on Simulation of Adaptive 
Behavior (SAB90). A Bradford Book. MIT Press, 1990. 
<p> </p> </dd> 
<dt> [614] </dt> 
<dd> Zbigniew Michalewicz. Genetic Algorithms + Data Structures = Evolution 
Programs. Springer-Verlag, 1996. Contains introductory chapter on LCS. 
<p> </p> </dd> 
<dt> [615] </dt> 
<dd> John&nbsp;H. Miller and Stephanie Forrest. The dynamical behavior of 
classifier systems. InSchaffer [718], pages 304-310. 
<blockquote> A methodology is described for studying the dynamical behavior of 
classifier systems. The methodology is useful because of the current lack of 
analytical results describing interactions among the various components of 
classifier systems. A mapping is defined between classifier systems and an 
equivalent dynamical system (Boolean networks). The mapping provides a way to 
understand and predict classifier system behaviors by observing the dynamical 
behavior of the Boolean networks. The paper reports initial results produced by 
the methodology and discusses the implications of this approach for classifier 
systems.</blockquote> 
<p> </p> </dd> 
<dt> [616] </dt> 
<dd> M.&nbsp;Mitchell and S.&nbsp;Forrest. Genetic Algorithms and Artificial 
Life. Technical Report 93-11-072, Santa Fe Institute, 1993. Contains a 2 page 
review of work on LCS.
<blockquote> Genetic algorithms are computational models of evolution that 
play a central role in many artificial-life models. We review the history and 
current scope of research on genetic algorithms in artificial life, using 
illustrative examples in which the genetic algorithm is used to study how 
learning and evolution interact, and to model ecosystems, immune system, 
cognitive systems, and social systems. We also outline a number of open 
questions and future directions for genetic algorithms in artificial-life 
research.</blockquote> 
<p> </p> </dd> 
<dt> [617] </dt> 
<dd> Johann Mitl&ouml;hner. Classifier systems and economic modelling. In APL 
'96. Proceedings of the APL 96 Conference on Designing the Future, volume 26 
(4), pages 77-86, 1996.
<blockquote> Human economic decisions are characterized by a number of factors 
which make them difficult to model with standard mathematical tools. Decisions 
can be more easily described by a set of rules, and some of them may be rules 
of thumb. Economic behaviour is adaptive, in that people are able to adjust to 
a changing environment. It is argued in this paper that the classifier system 
framework is a suitable means of modelling human economic decisions. A case of 
a simple economic decision of finding an optimal price is discussed, which is 
later made more complex by introducing an input variable that effects the 
optimal price. It is shown that classifier systems can be used in both tasks, 
and their performance is compared to human decisions in the same set of 
circumstances.</blockquote> 
<p> </p> </dd> 
<dt> [618] </dt> 
<dd> Chilukuri&nbsp;K. Mohan. Expert Systems: A Modern Overview. Kluwer, 2000. 
Contains an introductory survey chapter on LCS.
<p> </p> </dd> 
<dt> [619] </dt> 
<dd> Renan&nbsp;C. Moioli, Patricia&nbsp;A. Vargas, and Fernando J.&nbsp;Von 
Zuben. Analysing learning classifier systems in reactive and non-reactive 
robotic tasks. In Jaume Bacardit, Ester Bernad&oacute;-Mansilla, Martin Butz, 
Tim Kovacs, Xavier Llor&agrave;, and Keiki Takadama, editors,Learning 
Classifier Systems. 10th and 11th International Workshops (2006-2007), volume 
4998/2008 ofLecture Notes in Computer Science, pages 286-305. Springer, 2008. 
<blockquote> There are few contributions to robot autonomous navigation 
applying Learning Classifier Systems (LCS) to date. The primary objective of 
this work is to analyse the performance of the strength-based LCS and the 
accuracy-based LCS, named EXtended Learning Classifier System (XCS), when 
applied to two distinct robotic tasks. The first task is purely reactive, which 
means that the action to be performed can rely only on the current status of 
the sensors. The second one is non-reactive, which means that the robot might 
use some kind of memory to be able to deal with aliasing states. This work 
presents a rule evolution analysis, giving examples of evolved populations and 
their peculiarities for both systems. A review of LCS derivatives in robotics 
is provided together with a discussion of the main findings and an outline of 
future investigations.</blockquote> 
<p> </p> </dd> 
<dt> [620] </dt> 
<dd> D.&nbsp;Montanari. Classifier systems with a constant-profile bucket 
brigade. InCollected Abstracts for the First International Workshop on Learning 
Classifier System (IWLCS-92) [486]. October 6-8, NASA Johnson Space Center, 
Houston, Texas.
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [621] </dt> 
<dd> David&nbsp;E. Moriarty, Alan&nbsp;C. Schultz, and John&nbsp;J. 
Grefenstette.Evolutionary Algorithms for Reinforcement Learning. Journal of 
Artificial Intelligence Research, 11:199-229, 1999. 
http://www.ib3.gmu.edu/gref/papers/moriarty-jair99.html.
<blockquote> There are two distinct approaches to solving reinforcement 
learning problems, namely, searching in value function space and searching in 
policy space. Temporal difference methods and evolutionary algorithms are 
well-known examples of these approaches. Kaelbling, Littman and Moore recently 
provided an informative survey of temporal difference methods. This article 
focuses on the application of evolutionary algorithms to the reinforcement 
learning problem, emphasizing alternative policy representations, credit 
assignment methods, and problem-specific genetic operators. Strengths and 
weaknesses of the evolutionary approach to reinforcement learning are 
presented, along with a survey of representative applications.</blockquote> 
<p> </p> </dd> 
<dt> [622] </dt> 
<dd> R&eacute;mi Munos and Jocelyn Patinel. Reinforcement learning with 
dynamic covering of state-action space: Partitioning Q-learning. InCliff 
et&nbsp;al. [202], pages 354-363. 
<blockquote> This paper presents a reinforcement learning algorithm: 
``Partitioning Q-learning'', designed for generating an adaptive behavior of a 
reactive system with local perception in a complex and changing environment. 
This algorithm includes two dynamics: the learning algorithm based on the 
Q-learning and Bucket Brigade algorithms, and the structural dynamics (the 
partitioning of regions of the state-action space) that modelizes the 
acquisition of expert knowledge. The combination of these two dynamics intends 
to solve the problem of the combinatory explosion of the number of qualities to 
be estimated (the generalization problem), by dividing the state-action space 
into a minimal number of homogeneous regions using the formalism of Classifier 
Systems. This algorithm is applied to the simulation of a reactive robot which 
tries to cut weeds and to avoid plants in a cultivated field.</blockquote> 
<p> </p> </dd> 
<dt> [623] </dt> 
<dd> Tadahiko Murata, Shuhei Kawakami, Hiroyuki Nozawa, Mitsuo Gen, and Hisao 
Ishibuchi. Three-objective genetic algorithms for designing compact fuzzy 
rule-based systems for pattern classification problems. In Lee Spector, 
Erik&nbsp;D. Goodman, Annie Wu, W.B. Langdon, Hans-Michael Voigt, Mitsuo Gen, 
Sandip Sen, Marco Dorigo, Shahram Pezeshk, Max&nbsp;H. Garzon, and Edmund 
Burke, editors,Proceedings of the Genetic and Evolutionary Computation 
Conference (GECCO-2001), pages 485-492, San Francisco, California, USA, 7-11 
July 2001. Morgan Kaufmann.
<p> </p> </dd> 
<dt> [624] </dt> 
<dd> Jorge Muruz&aacute;bal and A.&nbsp;Mu&ntilde;oz. Diffuse pattern learning 
with Fuzzy ARTMAP and PASS. InDavidor and Schwefel [228], pages 376-385. 
<p> </p> </dd> 
<dt> [625] </dt> 
<dd> Jorge Muruz&aacute;bal. Fuzzy and Probabilistic Reasoning in Simple 
Learning Classifier Systems. InProceedings of the 2nd IEEE International 
Conference on Evolutionary Computation, volume&nbsp;1, pages 262-266. IEEE 
Press, 1995.
<p> </p> </dd> 
<dt> [626] </dt> 
<dd> Jorge Muruz&aacute;bal. Mining the space of generality with 
uncertainty-concerned cooperative classifiers. InBanzhaf et&nbsp;al. [32], 
pages 449-457.
<blockquote> Generality is a recurrent theme in automated inductive systems. 
Induction of general patterns/rules is of course complicated by several 
factors. For example, higher levels of uncertainty and error are naturally 
introduced by generality. Moreover, it is not clear what sort of trade-off 
should be sought between increasing generality and decreasing predictive power. 
As a result, specific criteria to guide the search for useful general rules do 
not abound. In this paper, I reconsider these issues in the context of the 
generalized, fuzzy-like classifier system first proposed by Frey and Slate 
(1991) and later equipped with a Bayesian learning component by Muruzabal 
(1998). A crucial feature of this approach is that uncertainty is 
probabilistically measured at each classifier in the population. A new 
reinforcement policy exploiting this probabilistic structure and priming 
cooperation among general classifiers is introduced and shown to promote the 
stability of niches of reasonably high predictive power. The underlying genetic 
algorithm contributes effectively to learning although it somehow counteracts 
the built-in bias towards generality.</blockquote> 
<p> </p> </dd> 
<dt> [627] </dt> 
<dd> Ichiro Nagasaka and Toshiharu Taura. 3D Geometric Representation for 
Shape Generation using Classifier System. InKoza et&nbsp;al. [528], pages 
515-520.
<blockquote> It is difficult to represent free-form shape features in a solid 
geometric model which is capable of holding and manipulating them after 
synthesis. In this paper, we propose a new model of representation of free-form 
shape features for this task. The key concept of this study is the Shape 
Feature Generation Process model (SFGP model) which consists of numerous sets 
of rules using a classifier system (CS). The idea of developmental biology is 
applied to a development of a computational model of the representation called 
the cell division model. In this model, the rules are evolved through 
interaction between cells and its growing free-form shapes. Finally, a computer 
program is developed for evaluation of the model by combination of two existing 
shapes for verification that the shape features are preserved in the combined 
shapes. It is demonstrated that the model can produce a variety of combined 
shapes with original, often exaggerated, features and the rules which hold 
features can be specified.</blockquote> 
<p> </p> </dd> 
<dt> [628] </dt> 
<dd> Filippo Neri and Attilio Giordana. A distributed genetic algorithm for 
concept learning. InEshelman [298], pages 436-443. 
<p> </p> </dd> 
<dt> [629] </dt> 
<dd> Filippo Neri and L.&nbsp;Saitta. Exploring the power of genetic search in 
learning symbolic classifiers.IEEE Trans. on Pattern Analysis and Machine 
Intelligence, PAMI-18:1135-1142, 1996. 
<blockquote> Abstract&iquest;In this paper we show, in a constructive way, 
that there are problems for which the use of genetic algorithm based learning 
systems can be at least as effective as traditional symbolic or connectionist 
approaches. To this aim, the system REGAL* is briefly described, and its 
application to two classical benchmarks for Machine Learning is discussed, by 
comparing the results with the best ones published in the literature.
</blockquote> 
<p> </p> </dd> 
<dt> [630] </dt> 
<dd> Filippo Neri. First Order Logic Concept Learning by means of a 
Distributed Genetic Algorithm. PhD thesis, University of Milano, Italy, 1997. 
<p> </p> </dd> 
<dt> [631] </dt> 
<dd> Filippo Neri. Comparing local search with respect to genetic evolution to 
detect intrusions in computer networks. InProceedings of the 2000 Congress on 
Evolutionary Computation (CEC00) [185], pages 238-243. 
<blockquote> The detection of intrusions over computer networks (i.e., network 
access by non-authorized users) can be cast to the task of detecting anomalous 
patterns of network traffic. In this case, models of normal traffic have to be 
determined and compared against the current network traffic. Data mining 
systems based on Genetic Algorithms can contribute powerful search techniques 
for the acquisition of patterns of the network traffic from the large amount of 
data made available by audit tools. We compare models of network traffic 
acquired by a system based on a distributed genetic algorithm with the ones 
acquired by a system based on greedy heuristics. Also we provide an empirical 
proof that representation change of the network data can result in a 
significant increase in the classification performances of the traffic models. 
Network data made available from the Information Exploration Shootout project 
and the 1998 DARPA Intrusion Detection Evaluation have been chosen as 
experimental testbed.</blockquote> 
<p> </p> </dd> 
<dt> [632] </dt> 
<dd> Filippo Neri. Relating two cooperative learning strategies to the 
features of the found concept description. In Lee Spector, Erik&nbsp;D. 
Goodman, Annie Wu, W.B. Langdon, Hans-Michael Voigt, Mitsuo Gen, Sandip Sen, 
Marco Dorigo, Shahram Pezeshk, Max&nbsp;H. Garzon, and Edmund Burke, editors,
Proceedings of the Genetic and Evolutionary Computation Conference (GECCO-2001)
, page 986, San Francisco, California, USA, 7-11 July 2001. Morgan Kaufmann.
<p> </p> </dd> 
<dt> [633] </dt> 
<dd> Filippo Neri. Cooperative concept learning by means of A distributed GA. 
In W.&nbsp;B. Langdon, E.&nbsp;Cant&uacute;-Paz, K.&nbsp;Mathias, R.&nbsp;Roy, 
D.&nbsp;Davis, R.&nbsp;Poli, K.&nbsp;Balakrishnan, V.&nbsp;Honavar, 
G.&nbsp;Rudolph, J.&nbsp;Wegener, L.&nbsp;Bull, M.&nbsp;A. Potter, A.&nbsp;C. 
Schultz, J.&nbsp;F. Miller, E.&nbsp;Burke, and N.&nbsp;Jonoska, editors,GECCO 
2002: Proceedings of the Genetic and Evolutionary Computation Conference, page 
953. Morgan Kaufmann Publishers, 2002.
<p> </p> </dd> 
<dt> [634] </dt> 
<dd> Volker Nissen and J&ouml;rg Biethahn. Determining a Good Inventory Policy 
with a Genetic Algorithm. In J&ouml;rg Biethahn and Volker Nissen, editors,
Evolutionary Algorithms in Management Applications, pages 240-249. Springer 
Verlag, 1995.
<p> </p> </dd> 
<dt> [635] </dt> 
<dd> M.&nbsp;O. Odetayo and D.&nbsp;R. McGregor. Genetic algorithm for 
inducing control rules for a dynamic system. InSchaffer [718], pages 177-182. 
It could be argued this is a GA as opposed to a classifier system approach.
<blockquote> We present a Genetic Algorithm (GA)-based method for 
automatically inducing control rules for a dynamic physical system. A GA is 
used to induce control rules for a dynamic physical system: a simulated 
pole-cart system. The task is to move a wheeled cart, with a rigid pole hinged 
on top of it, along a bounded straight track without the pole falling beyond a 
predefined vertical angle and without the cart going off the ends of the track 
limits. This is achieved by applying a force of fixed magnitude to the left or 
right of the cart. The dynamics of the system are unknown to the GA. The only 
information for evaluating performance is a failure signal indicating that the 
pole-cart system is out of control. This presents a genuinely difficult 
assignment problem. We compare the performance of the method with other 
learning algorithm for the same task. We also compare the ability of the 
algorithms to adapt to changing conditions. We conclude that genetic algorithm 
is both effective and robust.</blockquote> 
<p> </p> </dd> 
<dt> [636] </dt> 
<dd> T.&nbsp;O'Hara and L.&nbsp;Bull. Building anticipations in an 
accuracy-based learning classifier system by use of an artificial neural 
network. InIEEE Congress on Evolutionary Computation (CEC 2005), pages 
2046-2052. IEEE, 2005.
<p> </p> </dd> 
<dt> [637] </dt> 
<dd> T.&nbsp;O'Hara and L.&nbsp;Bull. A memetic accuracy-based neural learning 
classifier system. InProceedings of the IEEE congress on evolutionary 
computation (CEC 2005), pages 2040-2045. IEEE, 2005. 
<p> </p> </dd> 
<dt> [638] </dt> 
<dd> Toby O'Hara and Larry Bull. Backpropagation in accuracy-based neural 
learning classifier systems. In Tim Kovacs, Xavier LL&ograve;ra, Keiki 
Takadama, Pier&nbsp;Luca Lanzi, Wolfgang Stolzmann, and Stewart&nbsp;W. Wilson, 
editors,Learning Classifier Systems. International Workshops, IWLCS 2003-2005, 
Revised Selected Papers, volume 4399 of LNCS, pages 25-39. Springer, 2007. 
<p> </p> </dd> 
<dt> [639] </dt> 
<dd> Jae&nbsp;Chan Oh. Improved Classifier System Using Genetic Algorithms. 
Master's thesis, Wright State University, (year unknown -- pre-2000).
<p> </p> </dd> 
<dt> [640] </dt> 
<dd> Norihiko Ono and Adel&nbsp;T. Rahmani. Self-Organization of Communication 
in Distributed Learning Classifier Systems. InAlbrecht et&nbsp;al. [7], pages 
361-367.
<blockquote> In this paper, an application of learning classifier systems is 
presented. An artificial multi-agent environment has been designed. Mate 
finding problem, a learning task inspired by nature, is considered which needs 
cooperation by two distinct agents to achieve the goal. The main feature of our 
system is existence of two parallel learning subsystems which have to agree on 
a common communication protocol to succeed in accomplishing the task. Apart 
from standard learning algorithms, a unification mechanism has been introduced 
to encourage coordinated behavior among the agents belonging to the same class. 
Experimental results are presented which demonstrate the effectiveness of this 
mechanism and the learning capabilities of classifier systems.</blockquote> 
<p> </p> </dd> 
<dt> [641] </dt> 
<dd> G.&nbsp;Deon Oosthuizen. Machine Learning: A mathematical framework for 
neural network, symbolic and genetics-based learning. InSchaffer [718], pages 
385-390.
<blockquote> The relationship between genetics-based learning, neural network 
learning and typical AI-type symbolic learning approaches is highlighted by 
showing how each of the approaches can be mapped onto a common mathematical 
framework. This involves the mapping of the respective representations onto a 
structure called a lattice. We describe how the graphical representation of a 
lattice constructed and explain how it models the learning processes manifested 
in all three the approaches mentioned.</blockquote> 
<p> </p> </dd> 
<dt> [642] </dt> 
<dd> F.&nbsp;Oppacher and D.&nbsp;Deugo. The Evolution of Hierarchical 
Representations. InProceedings of the 3rd European Conference on Artificial Life
. Springer-Verlag, 1995.
<p> </p> </dd> 
<dt> [643] </dt> 
<dd> Albert Orriols-Puig and Ester Bernad&oacute;-Mansilla. The class 
imbalance problem in learning classifier systems: a preliminary study. InGECCO 
Workshops 2005, pages 74-78. ACM Press, 2005. 
<p> </p> </dd> 
<dt> [644] </dt> 
<dd> Albert Orriols-Puig and Ester Bernad&oacute;-Mansilla. The Class 
Imbalance Problem in UCS Classifier System: Fitness Adaptation. InProceedings 
of the 2005 Congress on Evolutionary Computation, volume&nbsp;1, pages 604-611. 
IEEE, 2005.
<p> </p> </dd> 
<dt> [645] </dt> 
<dd> A.&nbsp;Orriols-Puig and E.&nbsp;Bernad&oacute;-Mansilla. Bounding XCS's 
parameters for unbalanced datasets. In Maarten Keijzer et al., editor,
Proceedings of the 2006 Genetic and Evolutionary Computation Conference (GECCO 
2006), pages 1561-1568. ACM, 2006. 
<p> </p> </dd> 
<dt> [646] </dt> 
<dd> Albert Orriols-Puig and Ester Bernad&oacute;-Mansilla. Revisiting UCS: 
Description, Fitness Sharing, and Comparison with XCS. In Jaume Bacardit, Ester 
Bernad&oacute;-Mansilla, Martin Butz, Tim Kovacs, Xavier Llor&agrave;, and 
Keiki Takadama, editors,Learning Classifier Systems. 10th and 11th 
International Workshops (2006-2007), volume 4998/2008 of Lecture Notes in 
Computer Science, pages 96-111. Springer, 2008. 
<blockquote> This paper provides a deep insight into the learning mechanisms 
of UCS, a learning classifier system (LCS) derived from XCS that works under a 
supervised learning scheme. A complete description of the system is given with 
the aim of being useful as an implementation guide. Besides, we review the 
fitness computation, based on the individual accuracy of each rule, and 
introduce a fitness sharing scheme to UCS. We analyze the dynamics of UCS both 
with fitness sharing and without fitness sharing over five binary-input 
problems widely used in the LCSs framework. Also XCS is included in the 
comparison to analyze the differences in behavior between both systems. Results 
show the benefits of fitness sharing in all the tested problems, specially 
those with class imbalances. Comparison with XCS highlights the dynamics 
differences between both systems.</blockquote> 
<p> </p> </dd> 
<dt> [647] </dt> 
<dd> Albert Orriols-Puig and Ester Bernad&oacute;-Mansilla. The Class 
Imbalance Problem in UCS Classifier System: A Preliminary Study. In Tim Kovacs, 
Xavier LL&ograve;ra, Keiki Takadama, Pier&nbsp;Luca Lanzi, Wolfgang Stolzmann, 
and Stewart&nbsp;W. Wilson, editors,Learning Classifier Systems. International 
Workshops, IWLCS 2003-2005, Revised Selected Papers, volume 4399 of LNCS, pages 
161-180. Springer, 2007.
<p> </p> </dd> 
<dt> [648] </dt> 
<dd> A.&nbsp;Orriols-Puig, J.&nbsp;Casillas, and 
E.&nbsp;Bernad&ograve;-Mansilla. Fuzzy-UCS: preliminary results. In 
H.&nbsp;Lipson, editor,Genetic and Evolutionary Computation Conference, GECCO 
2007, Proceedings, pages 2871-2874. ACM, 2007. 
<p> </p> </dd> 
<dt> [649] </dt> 
<dd> A.&nbsp;Orriols-Puig, D.E. Goldberg, K.&nbsp;Sastry, and 
E.&nbsp;Bernad&oacute;-Mansilla. Modeling XCS in class imbalances: population 
size and parameter settings. In H.&nbsp;Lipson et&nbsp;al., editor,Genetic and 
evolutionary computation conference, GECCO 2007, pages 1838-1845. ACM, 2007. 
<p> </p> </dd> 
<dt> [650] </dt> 
<dd> A.&nbsp;Orriols-Puig, D.E. Goldberg, K.&nbsp;Sastry, and 
E.&nbsp;Bernad&oacute;-Mansilla. Modeling XCS in class imbalances: population 
size and parameter settings. In H.&nbsp;Lipson, editor,Genetic and Evolutionary 
Computation Conference, GECCO 2007, Proceedings, pages 1838-1845. ACM, 2007. 
<blockquote> This paper analyzes the scalability of the population size 
required in XCS to maintain nichesthat are infrequently activated.Facetwise 
models have been developed to predict the effect of the imbalance ratio-ratio 
betweenthe number of instances of the majority class and the minority class 
that are sampled to XCS-on population initialization, andon the creation and 
deletion of classifiers of the minority class. While theoretical models show 
that, ideally, XCS scales linearly with the imbalance ratio, XCS with standard 
configuration scales exponentially. The causes that are potentially responsible 
for this deviation from the ideal scalability are also investigated. 
Specifically, the inheritance procedure of classifiers' parameters, mutation, 
and subsumption are analyzed, and improvements in XCS's mechanisms are proposed 
to effectively and efficiently handle imbalanced problems. Once the 
recommendations are incorporated to XCS, empirical results show that the 
population size in XCS indeed scales linearly with the imbalance ratio.
</blockquote> 
<p> </p> </dd> 
<dt> [651] </dt> 
<dd> A.&nbsp;Orriols-Puig, K.&nbsp;Sastry, P.L. Lanzi, D.E. Goldberg, and 
E.&nbsp;Bernad&ograve;-Mansilla. Modeling selection pressure in xcs for 
proportionate and tournament selection. In H.&nbsp;Lipson, editor,Genetic and 
Evolutionary Computation Conference, GECCO 2007, Proceedings, page 
1846&acirc;&#128;&#147;1853. ACM, 2007.
<p> </p> </dd> 
<dt> [652] </dt> 
<dd> Albert Orriols-Puig, Jorge Casillas, and Ester Bernad&oacute;-Mansilla. 
Evolving fuzzy rules with ucs: Preliminary results. In Jaume Bacardit, Ester 
Bernad&oacute;-Mansilla, Martin Butz, Tim Kovacs, Xavier Llor&agrave;, and 
Keiki Takadama, editors,Learning Classifier Systems. 10th and 11th 
International Workshops (2006-2007), volume 4998/2008 of Lecture Notes in 
Computer Science, pages 57-76. Springer, 2008. 
<blockquote> This paper presents Fuzzy-UCS, a Michigan-style Learning 
Fuzzy-Classifier System designed for supervised learning tasks. Fuzzy-UCS 
combines the generalization capabilities of UCS with the good interpretability 
of fuzzy rules to evolve highly accurate and understandable rule sets. 
Fuzzy-UCS is tested on a large collection of real-world problems, and compared 
to UCS and three highly-used machine learning techniques: the decision tree 
C4.5, the support vector machine SMO, and the fuzzy boosting algorithm Fuzzy 
LogitBoost. The results show that Fuzzy-UCS is highly competitive with respect 
to the four learners in terms of performance, and that the fuzzy representation 
permits a much better understandability of the evolved knowledge. These 
promising results of the online architecture of Fuzzy-UCS allow for further 
research and application of the system to new challenging problems.</blockquote>
<p> </p> </dd> 
<dt> [653] </dt> 
<dd> Albert Orriols-Puig, Jorge Casillas, and Ester Bernad&oacute;-Mansilla. 
Genetic-based machine learning systems are competitive for pattern recognition.
Evolutionary Intelligence, 1(3):209-232, 2008. 
<blockquote> During the last decade, research on Genetic-Based Machine 
Learning has resulted in several proposals of supervised learning methodologies 
that use evolutionary algorithms to evolve rule-based classification models. 
Usually, these new GBML approaches are accompanied by little experimentation 
and there is a lack of comparisons among different proposals. Besides, the 
competitiveness of GBML systems with respect to non-evolutionary, highly-used 
machine learning techniques has only been partially studied. This paper reviews 
the state of the art in GBML, selects some of the best representatives of 
different families, and compares the accuracy and the interpretability of their 
models. The paper also analyzes the behavior of the GBML approaches with 
respect to some of the most influential machine learning techniques that belong 
to different learning paradigms such as decision trees, support vector 
machines, instance-based classifiers, and probabilistic classifiers. The 
experimental observations emphasize the suitability of GBML systems for 
performing classification tasks. Moreover, the analysis points out the 
strengths of the different systems, which can be used as recommendation 
guidelines on which systems should be employed depending on whether the user 
prefers to maximize the accuracy or the interpretability of the models.
</blockquote> 
<p> </p> </dd> 
<dt> [654] </dt> 
<dd> Albert Orriols-Puig, Kumara Sastry, David&nbsp;E. Goldberg, and Ester 
Bernad&oacute;-Mansilla. Substructural surrogates for learning decomposable 
classification problems. In Jaume Bacardit, Ester Bernad&oacute;-Mansilla, 
Martin Butz, Tim Kovacs, Xavier Llor&agrave;, and Keiki Takadama, editors,
Learning Classifier Systems. 10th and 11th International Workshops (2006-2007), 
volume 4998/2008 ofLecture Notes in Computer Science, pages 235-254. Springer, 
2008.
<blockquote> This paper presents a learning methodology based on a 
substructural classification model to solve decomposable classification 
problems. The proposed method consists of three important components: (1) a 
structural model, which represents salient interactions between attributes for 
a given data, (2) a surrogate model, which provides a functional approximation 
of the output as a function of attributes, and (3) a classification model, 
which predicts the class for new inputs. The structural model is used to infer 
the functional form of the surrogate. Its coefficients are estimated using 
linear regression methods. The classification model uses a maximally-accurate, 
least-complex surrogate to predict the output for given inputs. The structural 
model that yields an optimal classification model is searched using an 
iterative greedy search heuristic. Results show that the proposed method 
successfully detects the interacting variables in hierarchical problems, groups 
them in linkages groups, and builds maximally accurate classification models. 
The initial results on non-trivial hierarchical test problems indicate that the 
proposed method holds promise and also shed light on several improvements to 
enhance the capabilities of the proposed method.</blockquote> 
<p> </p> </dd> 
<dt> [655] </dt> 
<dd> Ramon&nbsp;Alfonso Palacios-Durazo and Manuel Valenzuela-Rendon. Lessons 
learned from LCSs: An incremental non-generational coevolutionary algorithm. In 
Bart Rylander, editor,Genetic and Evolutionary Computation Conference (GECCO) 
Late Breaking Papers, pages 248-254, 2003. 
<p> </p> </dd> 
<dt> [656] </dt> 
<dd> Alexandre Parodi and P.&nbsp;Bonelli. The Animat and the Physician. In 
Meyer and Wilson [613], pages 50-57. 
<p> </p> </dd> 
<dt> [657] </dt> 
<dd> Alexandre Parodi and Pierre Bonelli. A New Approach to Fuzzy Classifier 
Systems. InForrest [335], pages 223-230. 
<blockquote> In this article, we present a new approach to fuzzy classifier 
system learning, and experiment with it on three different functions. This new 
approach is generic in the sense that it not only allows learning of fuzzy 
rules, but also of membership functions and output weights. Moreover, our 
algorithm is simple and yet exhibits good results.</blockquote> 
<p> </p> </dd> 
<dt> [658] </dt> 
<dd> Mukesh&nbsp;J. Patel and Marco Dorigo. Adaptive Learning of a Robot Arm. 
InFogarty [324], pages 180-194. 
<blockquote> ALECSYS, an implementation of a learning classifier system (LCS) 
on a net of transputers was utilised to train a robot arm to solve a light 
approaching task. This task, as well as more complicated ones, has already been 
learnt by ALECSYS implemented on AutonoMouse, a small autonomous robot. The 
main difference between the present and previous applications are, one, the 
robot arm has asymmetric constraints on its effectors, and two, given its 
higher number of internal degrees of freedom, and its non anthropomorphic 
shape, it was not obvious, as it was with the AutonoMouse, where to place the 
visual sensors and what sort of proprioceptive (the angular position of the arm 
joints) information to provide to support learning. We report results of a 
number of exploratory simulations of the robot arm's relative success in 
learning to perform the light approaching task with a number of combinations of 
visual and proprioceptive sensors. On the bases of results of such trials it 
was possible to derive a near optimum combination of sensors which is now being 
implemented on a real robot arm (an IBM 7547 with a SCARA geometry). Finally, 
the implications these findings, particularly with reference to LCS based 
evolutionary approach to learning, are discussed.</blockquote> 
<p> </p> </dd> 
<dt> [659] </dt> 
<dd> Mukesh&nbsp;J. Patel and U.&nbsp;Schnepf. Concept Formation as Emergent 
Phenomena. In Francisco&nbsp;J. Varela and P.&nbsp;Bourgine, editors,
Proceedings First European Conference on Artificial Life, pages 11-20. MIT 
Press, 1992.
<p> </p> </dd> 
<dt> [660] </dt> 
<dd> Mukesh&nbsp;J. Patel, Marco Colombetti, and Marco Dorigo. Evolutionary 
Learning for Intelligent Automation: A Case Study.Intelligent Automation and 
Soft Computing, 1(1):29-42, 1995. 
<p> </p> </dd> 
<dt> [661] </dt> 
<dd> Ray&nbsp;C. Paton. Designing Adaptable Systems through the Study and 
Application of Biological Sources. In Vic Rayward-Smith, editor,Applications of 
Modern Heuristic Methods, pages 39-54. Alfred Waller Ltd, 1995. 
<blockquote> The adaptive capabilities of biological systems have provided the 
inspiration for numerous developments in computer science, this article focuses 
on evolutionary computation. Following a review the general selectionist agenda 
in evolutionary computing, a number of new biological sources ideas are 
discussed. Two experimental designs are discussed: directed adaptation and an 
enhancement to Genetic Based Learning in a Classifier System called the Life 
History GA. Some preliminary results using these ideas are then presented. The 
concluding section reflects on some general issues associated with the design 
of evolutionary systems.</blockquote> 
<p> </p> </dd> 
<dt> [662] </dt> 
<dd> Nicolas Pech-Gourg and Jin-Kao Hao. A genetic algorithm for the 
classification of natural corks. In Lee Spector, Erik&nbsp;D. Goodman, Annie 
Wu, W.B. Langdon, Hans-Michael Voigt, Mitsuo Gen, Sandip Sen, Marco Dorigo, 
Shahram Pezeshk, Max&nbsp;H. Garzon, and Edmund Burke, editors,Proceedings of 
the Genetic and Evolutionary Computation Conference (GECCO-2001), pages 
1382-1388, San Francisco, California, USA, 7-11 July 2001. Morgan Kaufmann.
<p> </p> </dd> 
<dt> [663] </dt> 
<dd> Rolf Pfeifer, Bruce Blumberg, Jean-Arcady Meyer, and Stewart&nbsp;W. 
Wilson, editors.From Animals to Animats 5. Proceedings of the Fifth 
International Conference on Simulation of Adaptive Behavior (SAB98). A Bradford 
Book. MIT Press, 1998.
<p> </p> </dd> 
<dt> [664] </dt> 
<dd> Steven&nbsp;E. Phelan. Using Artificial Adaptive Agents to Explore 
Strategic Landscapes. PhD thesis, School of Business, Faculty of Law and 
Management, La Trobe University, Australia, 1997.
<blockquote> Recent developments in computer science have made it possible to 
simulate whole populations of artificial agents within the confines of a single 
personal computer. These artificial agents can be programmed to act in ways 
that mimic the behaviour of physical, biological and economic agents. Such 
developments come at a time when researchers in strategic management have been 
complaining about a lack of data to test theoretical predictions. There is a 
perception that the ability to generate novel hypotheses has greatly exceeded 
the ability to empirically test them. This dissertation investigates whether 
agent-based simulation can be used to test hypotheses in strategic management. 
SELESTE is a highly-abstract artificial world that was developed using concepts 
from Amit and Schoemaker's (1993) integrated theory of strategy. SELESTE 
provided the environment, or strategic landscape, for our artificial agents to 
explore. The agents themselves were modelled using an algorithm from artificial 
intelligence known as a learning classifier system. Artificial agents in 
SELESTE were shown to behave in similar ways to human agents. Three studies 
were selected to showcase the range of problems that agent-based simulation can 
address. The first problem investigated whether differences in the cognitive 
capacity of firms led to sustainable differences in performance. The importance 
of differences in cognitive capacity was shown to decline as the absolute level 
of cognitive capacity increased. The second study investigated the conditions 
under which imitation proved a superior strategy to innovation. It was revealed 
that imitation was a powerful strategy under all but the most extreme 
conditions. The final study revealed that firms that divided their operations 
into multiple profit-centres or 'patches' performed better than firms organised 
as a single profit-centre. It was concluded that agent-based simulation 
represented a useful method for exploring problems in strategic management. 
Calls were made to establish a research program in agent-based simulation to 
build on these findings and to refine existing techniques.</blockquote> 
<p> </p> </dd> 
<dt> [665] </dt> 
<dd> Wolfgang&nbsp;Stolzmann Pier Luca&nbsp;Lanzi and Stewart W.&nbsp;Wilson 
(guest editors). Journal of evolutionary computing, special issue on learning 
classifier systems, 11(3), 2003.
<p> </p> </dd> 
<dt> [666] </dt> 
<dd> A.&nbsp;G. Pipe and Brian Carse. A Comparison between two Architectures 
for Searching and Learning in Maze Problems. InFogarty [324], pages 238-249. 
<blockquote> We present two architectures, each designed to search 
2-Dimensional mazes in order to locate a ``goal'' position, both of which 
perform on-line learning as the search proceeds. The first architecture is a 
form of Adaptive Heuristic Critic which uses a Genetic Algorithm to determine 
the Action Policy and a Radial Basis Function Neural Network to store the 
acquired knowledge of the Critic. The second is a stimulus-response Classifier 
System (CS) which uses a Genetic Algorithm, applied ``Michigan'' style, for 
rule generation and the ``Bucket Brigade'' algorithm for rule reinforcement. 
Experiments conducted using agents based upon each architectural model lead us 
to a comparison of performance, and some observations on the nature and 
relative levels of abstraction in the acquired knowledge.</blockquote> 
<p> </p> </dd> 
<dt> [667] </dt> 
<dd> A.&nbsp;G. Pipe and Brian Carse. Autonomous Acquisition of Fuzzy Rules 
for Mobile Robot Control: First Results from two Evolutionary Computation 
Approaches. InWhitely et&nbsp;al. [878], pages 849-856. 
<blockquote> We describe two architectures that autonomously acquire fuzzy 
control rules to provide reactive behavioural competencies in a simulated 
mobile robotics application. One architecture is a `Pittsburgh'-style Fuzzy 
Classifier System (Pitt1). The other architecture is a `Michigan'-style Fuzzy 
Classifier System (Mich1). We tested the architectures on the ability to 
acquire an ``investigative'' obstacle avoidance competency. We found that Mich1 
implemented a more local incremental search than the other architecture. In 
simpler environments Mich1 was typically able to find adequate solutions with 
significantly fewer fitness evaluations. Since fitness evaluation can be very 
time consuming in this application, it could be a strong positive factor. 
However, when the rule set must implement a competency in more complex 
environments, the situation is somewhat different. The superior ability of 
Pitt1 to retain a number of schema in the population during the process of 
optimisation, is then a crucial strength.</blockquote> 
<p> </p> </dd> 
<dt> [668] </dt> 
<dd> A.&nbsp;G. Pipe and B.&nbsp;Carse. Michigan and pittsburgh fuzzy 
classifier systems for learning mobile robot control rules: an experimental 
comparison. In14th Int. Conf. of Florida Artificial Intelligence Research 
Society FLAIRS-2001, pages 493-498. AAAI Press, 2001. 
<p> </p> </dd> 
<dt> [669] </dt> 
<dd> A.&nbsp;G. Pipe and B.&nbsp;Carse. First results from experiments in 
fuzzy classifier system architectures for mobile robotics. In 
H.-P.&nbsp;Schwefel J.-J. Merelo Guerv&oacute;s, P. Adamidis, H.-G. Beyer, 
J.-L. Fern&aacute;ndez-Villaca&ntilde;as, editor,Parallel Problem Solving from 
Nature - PPSN VII, 7th International Conference, Granada, Spain, September 
7-11, 2002. Proceedings, number 2439 in Lecture Notes in Computer Science, 
LNCS, page 578 ff. Springer-Verlag, 2002.
<p> </p> </dd> 
<dt> [670] </dt> 
<dd> R.&nbsp;Piroddi and R.&nbsp;Rusconi. A Parallel Classifier System to 
Solve Learning Problems. Master's thesis, Dipartimento di Elettronica e 
Informazione, Politecnico di Milano, Milano, Italy., 1992.
<p> </p> </dd> 
<dt> [671] </dt> 
<dd> Mitchell&nbsp;A. Potter, Kenneth A.&nbsp;De Jong, and John&nbsp;J. 
Grefenstette.A Coevolutionary Approach to Learning Sequential Decision Rules. In
Eshelman [298], pages 366-372. 
<blockquote> We present a coevolutionary approach to learning sequential 
decision rules which appears to have a number of advantages over 
non-coevolutionary approaches. The coevolutionary approach encourages the 
formation of stable niches representing simpler subbehaviors. The evolutionary 
direction of each subbehavior can be controlled independently, providing an 
alternative to evolving complex behavior using intermediate training steps. 
Results are presented showing a significant learning rate speedup over a 
noncoevolutionary approach in a simulated robot domain. In addition, the 
results suggest the coevolutionary approach may lead to emergent problem 
decompositions.</blockquote> 
<p> </p> </dd> 
<dt> [672] </dt> 
<dd> C.&nbsp;L. Ramsey and John&nbsp;J. Grefenstette. Case-based 
initialization of genetic algorithms. In Forrest [335], pages 84-91. 
http://www.ib3.gmu.edu/gref/.
<blockquote> In this paper, we introduce a case-based method of initializing 
genetic algorithms that are used to guide search in changing environments. This 
is incorporated in an anytime learning system. Anytime learning is a general 
approach to continuous learning in a changing environment. The agent's learning 
module continuously tests new strategies against a simulation model of the task 
environment, and dynamically updates the knowledge base used by the agent on 
the basis of the results. The execution module includes a monitor that can 
dynamically modify the simulation model based on its observations of the 
external environment; an update to the simulation model causes the learning 
system to restart learning. Previous work has shown that genetic algorithms 
provide an appropriate search mechanism for anytime learning. This paper 
extends the approach by including strategies, which are learned under similar 
environmental conditions, in the initial population of the genetic algorithm. 
Experiments show that case-based initialization of the population results in a 
significantly improved performance.</blockquote> 
<p> </p> </dd> 
<dt> [673] </dt> 
<dd> C.&nbsp;L. Ramsey and John&nbsp;J. Grefenstette. Case-based anytime 
learning.. In D.&nbsp;W. Aha, editor, Case-Based Reasoning: Papers from the 
1994 Workshop. AAAI Press: Menlo Park, CA, 1994. Also Technical Report WS-94-07 
http://www.ib3.gmu.edu/gref/.
<blockquote> We discuss a case-based method of initializing genetic algorithms 
that are used to guide search in changing environments. This is incorporated in 
an anytime learning system. Anytime learning is a general approach to 
continuous learning in a changing environment. A genetic algorithm with a 
case-based component provides an appropriate search mechanism for anytime 
learning. When the genetic algorithm is restarted, strategies which were 
previously learned under similar environmental conditions are included in the 
initial population of the genetic algorithm. We have evaluated the system by 
comparing performance with and without the case-based component, and case-based 
initialization of the population results in a significantly improved 
performance.</blockquote> 
<p> </p> </dd> 
<dt> [674] </dt> 
<dd> Gregory J.&nbsp;E. Rawlins, editor. Proceedings of the First Workshop on 
Foundations of Genetic Algorithms (FOGA91). Morgan Kaufmann: San Mateo, 1991. 
<p> </p> </dd> 
<dt> [675] </dt> 
<dd> Colin Reveley. A learning classifier system adapted for hold'em poker. 
Master's thesis, Birkbeck College, University of London, UK, 2002.
<blockquote> This paper stems from the observation that in a game of poker, if 
our opponents follow a strategy and do not play randomly, there must be some 
set of rules such that if we follow those rules we will maximise our profits. 
Perhaps a Genetic Algorithm would be able to discover such a set of rules. This 
report looks into how feasible such an approach might be, and after some 
analysis, makes an attempt at an implementation.</blockquote> 
<p> </p> </dd> 
<dt> [676] </dt> 
<dd> Robert&nbsp;A. Richards and Sheri&nbsp;D. Sheppard. Classifier System 
Based Structural Component Shape Improvement Utilizing I-DEAS. InIccon User's 
Conference Proceeding. Iccon, 1992. 
<p> </p> </dd> 
<dt> [677] </dt> 
<dd> Robert&nbsp;A. Richards and Sheri&nbsp;D. Sheppard. Learning Classifier 
Systems in Design Optimization. InDesign Theory and Methodology '92. The 
American Society of Mechanical Engineers, 1992.
<p> </p> </dd> 
<dt> [678] </dt> 
<dd> Robert&nbsp;A. Richards and Sheri&nbsp;D. Sheppard. Two-dimensional 
Component Shape Improvement via Classifier System. InArtificial Intelligence in 
Design '92. Kluwer Academic Publishers, 1992. 
<p> </p> </dd> 
<dt> [679] </dt> 
<dd> Robert&nbsp;A. Richards and Sheri&nbsp;D. Sheppard. A Learning Classifier 
System for Three-dimensional Shape Optimization. In H.&nbsp;M. Voigt, 
W.&nbsp;Ebeling, I.&nbsp;Rechenberg, and H.-P. Schwefel, editors,Parallel 
Problem Solving from Nature -- PPSN IV, volume 1141 of LNCS, pages 1032-1042. 
Springer-Verlag, 1996.
<blockquote> A learning classifier system complex is developed in order to 
accomplish the broader goal of developing a methodology to perform generalized 
zeroth-order two-and three-dimensional shape optimization. Specifically, the 
methodology has the objective of determining the optimal boundary to minimize 
mass while satisfying constraints on stress and geometry. Even with the 
enormous advances in shape optimization no method has proven to be satisfactory 
across the broad spectrum of optimization problems facing the modern engineer. 
Similarly the available software in the field of learning classifier systems is 
so embryonic that a new software package has to be developed for this 
application. The shape optimization via hypothesizing inductive classifier 
system complex (SPHINcsX) instantiates the methodology in a software package 
overcoming many of the limitations of today's conventional shape optimization 
techniques, while advancing the state-of-the-art in classifier system software 
tools.</blockquote> 
<p> </p> </dd> 
<dt> [680] </dt> 
<dd> Robert&nbsp;A. Richards and Sheri&nbsp;D. Sheppard. Three-Dimensional 
Shape Optimization Utilizing a Learning Classifier System. InKoza et&nbsp;al. 
[527], pages 539-546. 
<p> </p> </dd> 
<dt> [681] </dt> 
<dd> Robert&nbsp;A. Richards. Zeroth-Order Shape Optimization Utilizing a 
Learning Classifier System. PhD thesis, Stanford University, 1995. 
http://www-leland.stanford.edu/~buc/SPHINcsX/book.html.
<blockquote> A methodology to perform generalized zeroth-order two- and 
three-dimensional shape optimization utilizing a learning classifier system is 
developed and applied. To this end, the applicability of machine learning to 
mechanical engineering is investigated. Specifically, the methodology has the 
objective of determining the optimal boundary to minimize mass while satisfying 
constraints on stress and geometry. Even with the enormous advances in shape 
optimization no method has proven to be satisfactory across the broad spectrum 
of optimization problems facing the modern engineer. The methodology developed 
in this book is based upon a classifier system (CS) and exploits the CS's 
adaptability and generality. It thereby overcomes many of the limitations of 
today's conventional shape optimization techniques. A CS learns rules, 
postulated as if-then statements, in order to improve its performance in an 
arbitrary environment, (which for this investigation consists of stress and 
mass information from components). From this input, and from a population of 
initially randomly generated rules, the classifier system is expected to learn 
to make the appropriate component shape modifications to reach a minimum mass 
design while satisfying all stress constraints. The CS learns by utilizing the 
design improvement success or failure feedback. Nearly all shape optimization 
algorithms developed to date depend on sensitivity information in order to 
function. This research does not present sensitivity information to the 
classifier system. Thus, the classifier system must not only learn from a clean 
slate, but confronts the additional challenge of learning without information 
that most other shape optimization algorithms deem essential. Therefore, the 
main deliverable is a zeroth-order shape optimization methodology. After a 
review of mechanical engineering shape optimization methods, an explanatory 
presentation of CSs and their underlying genetic algorithm (GA) describes how 
classifier systems learn from feedback and the GA. With this foundation set, 
the coupling of the shape optimization domain with the classifier system 
proceeds to form, the Shape oPtimization via Hypothesizing Inductive classifier 
system compleX (SPHINcsX). The complex learns shape optimization by its 
application to a suite of sizing optimization problems. The most tangible 
artifact of this research is the successful development of the zeroth-order 
shape optimization complex. The complex proved adept at solving both two- and 
three-dimensional shape optimization problems. The research also provides a 
demonstrative example of the power and flexibility of machine learning in 
general and CSs in particular -- how they may be leveraged as tools for 
mechanical engineering design, and insights into their proper application.
</blockquote> 
<p> </p> </dd> 
<dt> [682] </dt> 
<dd> Robert&nbsp;A. Richards. Classifier System Metrics: Graphical Depictions. 
InKoza et&nbsp;al. [529], pages 652-657. 
<p> </p> </dd> 
<dt> [683] </dt> 
<dd> Rick&nbsp;L. Riolo. Bucket Brigade Performance: I. Long Sequences of 
Classifiers. InGrefenstette [391], pages 184-195. 
<blockquote> In Holland-type classifier systems the bucket brigade algorithm 
allocates strength (``credit'') to classifiers that lead to rewards from 
environment. This paper presents results that show the bucket brigade algorithm 
basically works as designed -- strength is passed down sequences of coupled 
classifiers from those classifiers that receive rewards directly from the 
environment to those that are stage setters. Results indicate it can take a 
fairly large number of trials for a classifier system to respond to changes in 
its environment by reallocating strength down competing sequences of 
classifiers that implement simple reflex and non-reflex behaviors. However, 
``bridging classifiers'' are shown to dramatically decrease the number of times 
a long sequence must be executed in order reallocate strength to all the 
classifiers in the sequence. Bridging classifiers also were shown to be one way 
to avoid problems caused by sharing classifiers across competing sequences.
</blockquote> 
<p> </p> </dd> 
<dt> [684] </dt> 
<dd> Rick&nbsp;L. Riolo. Bucket Brigade Performance: II. Default Hierarchies. 
InGrefenstette [391], pages 196-201. 
<blockquote> Learning systems that operate in environments with huge numbers 
of states must be able to categorize the states into equivalence classes that 
can be treated alike. Holland-type classifier systems can learn to categorize 
states by building default hierarchies of classifiers (rules). However, for 
default hierarchies to work properly classifiers that implement exception rules 
must be able to control the system when they are applicable, thus preventing 
the default rules from making mistakes. This paper presents results that show 
the standard bucket brigade algorithm does not lead to correct exception rules 
always winning the competition with the default rules they protect. A simple 
modification to the bucket brigade algorithm is suggested, and results are 
presented that show this modification works as desired: default hierarchies can 
be made to achieve payoff rates as near to optimal as desired.</blockquote> 
<p> </p> </dd> 
<dt> [685] </dt> 
<dd> Rick&nbsp;L. Riolo. CFS-C: A Package of Domain-Independent Subroutines 
for Implementing Classifier Systems in Arbitrary User-Defined Environments. 
Technical report, University of Michigan, 1988.
<p> </p> </dd> 
<dt> [686] </dt> 
<dd> Rick&nbsp;L. Riolo. Empirical Studies of Default Hierarchies and 
Sequences of Rules in Learning Classifier Systems. PhD thesis, University of 
Michigan, 1988.
<p> </p> </dd> 
<dt> [687] </dt> 
<dd> Rick&nbsp;L. Riolo. The Emergence of Coupled Sequences of Classifiers. In 
Schaffer [718], pages 256-264. 
<blockquote> Sequences of coupled classifiers are a basic component of higher 
level knowledge and control structures in classifier systems that follow the 
``Michigan'' approach. This paper explores mechanisms for promoting the 
emergence of coupled sequences in task domains that provide payoff only after a 
series of coordinated actions. The results indicate that useful coupled chains 
do emerge once some minor changes are made to the basic classifier system.
</blockquote> 
<p> </p> </dd> 
<dt> [688] </dt> 
<dd> Rick&nbsp;L. Riolo. The Emergence of Default Hierarchies in Learning 
Classifier Systems. InSchaffer [718], pages 322-327. 
<blockquote> Default hierarchies have been proposed as a way for classifier 
systems to categorize events efficiently and as accurately as necessary. This 
paper studies the emergence of default hierarchies for tasks that favor use of 
default hierarchies over homomorphic models. The results indicate that default 
hierarchies do rapidly emerge, but that they also tend to be replaced by 
homomorphic models.</blockquote> 
<p> </p> </dd> 
<dt> [689] </dt> 
<dd> Rick&nbsp;L. Riolo. Lookahead Planning and Latent Learning in a 
Classifier System. InMeyer and Wilson [613], pages 316-326. 
<blockquote> Classifier systems (CSs) have been used to simulate and describe 
the behavior of adaptive organisms, animats, and robots. However, classifier 
system implementations to date have all been reactive systems, which use simple 
S-R rules and which base their learning algorithms on trial-and-error 
reinforcement techniques similar to the Hullian Law of Effect. While these 
systems have exhibited interesting behavior and good adaptive capacity, they 
cannot do other types of learning which require having explicit internal models 
of the external world, e.g., using complex plans as humans do, or doing latent 
learning of the type observed in rats. This paper describes a classifier system 
that is able to learn and use internal models both to greatly decrease the time 
to learn general sequential decision tasks and to enable the system to exhibit 
latent learning.</blockquote> 
<p> </p> </dd> 
<dt> [690] </dt> 
<dd> Rick&nbsp;L. Riolo. Modelling Simple Human Category Learning with a 
Classifier System. InBooker and Belew [74], pages 324-333. 
<blockquote> A classifier system is used to model human performance on a 
simple deterministic discrimination task in which subjects must acquire 
categories based on their experience. The performance of the classifier system 
is compared to data from experiments with humans and to the performance of an 
adaptive neural net model described by Gluck and Bower. The classifier system 
is able to replicate data on human performance, including one observation not 
replicated by the neural net model. The classifier system also misses one 
prediction the neural net makes correctly. Three keys to the classifier 
system's performance are: (1) default hierarchies in which exceptions usually 
overrule more general rules; (2) a bucket brigade algorithm in which each 
classifier pays the average bid made by co-winning rules that produce the same 
message it does (rather than just paying its own bid) and receives an equal 
share of any payoff; and (3) the use of a bid tax.</blockquote> 
<p> </p> </dd> 
<dt> [691] </dt> 
<dd> Rick&nbsp;L. Riolo. The discovery and use of forward models for adaptive 
classifier systems. InCollected Abstracts for the First International Workshop 
on Learning Classifier System (IWLCS-92) [486]. October 6-8, NASA Johnson Space 
Center, Houston, Texas.
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [692] </dt> 
<dd> Joaquin Rivera and Roberto Santana. Improving the Discovery Component of 
Classifier Systems by the Application of Estimation of Distribution Algorithms. 
InProceedings of Student Sessions ACAI'99: Machine Learning and Applications, 
pages 43-44, Chania, Greece, July 1999.
<p> </p> </dd> 
<dt> [693] </dt> 
<dd> A.&nbsp;Robert, F.&nbsp;Chantemargue, and M.&nbsp;Courant. Grounding 
Agents in EMud Artificial Worlds. In Proceedings of the First International 
Conference on Virtual Worlds, Paris (France), July 1-3, 1998. 
<blockquote> This paper suggests that in the context of autonomous agents and 
generation of intelligent behavior for such agents, a more important focus 
should be held on the symbolic context that forms the basis of computer 
programs. Basically, software agents are symbolic entities living in a symbolic 
world and this has an effect on how one should think about designing frameworks 
for their evolution or learning. We will relate the problem of symbol grounding 
to that of sensory information available to agents. We will then introduce an 
experimental environment based on virtual worlds called EMuds, where both human 
and artificial agents can interact. Next, we show how it can be applied in the 
framework of multi-agent systems to address emergence based problems and report 
preliminary results. We then conclude with some ongoing and future work.
</blockquote> 
<p> </p> </dd> 
<dt> [694] </dt> 
<dd> Gary Roberts. A Rational Reconstruction of Wilson's Animat and Holland's 
CS-1. InSchaffer [718], pages 317-321. 
<blockquote> In the short history of Genetic Algorithms, there have been a 
plethora of techniques used. Even within the subfield of classifier systems, 
many differing implementation exist. It becomes difficult to compare ones 
results with others, and to determine the cause of actual performance 
differences. To that end I have attempted a rational reconstruction 
encompassing two systems described in the literature: Wilson's Animat and the 
CS-1 system of Holland and Reitman. The results obtained differ, sometimes 
markedly, from the published versions they attempt to duplicate.</blockquote> 
<p> </p> </dd> 
<dt> [695] </dt> 
<dd> Gary Roberts. Dynamic Planning for Classifier Systems. In Forrest [335], 
pages 231-237.
<blockquote> Classifier systems were developed as a scheme for applying 
genetic algorithms to problems where they would otherwise be difficult to 
utilize. The bucket brigade algorithm has been used to handle the credit 
assignment problem associated with classifier systems. This research 
demonstrates an alternative to bucket brigade based upon dynamic planning and 
Q-learning. The advantages of the new system, Dyna-Q-CS, include the 
construction of an explicit world model that speeds learning in the absence of 
plentiful reward information and is amenable to sophisticated planning 
techniques. The experimental results show that Dyna-Q-CS learns as fast, or 
faster than the particular bucket brigade system used (based upon Wilson's 
Animat), but that the asymptotic performance of Dyna-Q-CS needs improvement. 
Some form of annealing could solve this asymptotic performance problem.
</blockquote> 
<p> </p> </dd> 
<dt> [696] </dt> 
<dd> George&nbsp;G. Robertson and Rick&nbsp;L. Riolo. A Tale of Two Classifier 
Systems.Machine Learning, 3:139-159, 1988. 
<blockquote> This paper describes two classifier systems that learn. These are 
rulebased systems that use genetic algorithms, which are based on an analogy 
with natural selection and genetics, as their principal learning mechanism, and 
an economic model as their principal mechanism for apportioning credit. CFS-C 
is a domain independent learning system that has been widely tested on serial 
computers. *CFS is a parallel implementation of CFS-C that makes full use of 
the inherent parallelism of classifier systems and genetic algorithms, and that 
allows the exploration of large-scale tasks that were formerly impractical. As 
with other approaches to learning, classifier systems in their current form in 
their current form work well for moderately-sized tasks but break down for 
larger tasks. In order to shed light on this issue, we present several 
empirical studies of known issues in classifier systems, including the effects 
of population size, the actual contribution of genetic algorithms, the use of 
rule chaining in solving higher-order tasks, and issues of task representation 
and dynamic population convergence. We conclude with a discussion of some major 
unresolved issues in learning classifier systems and some possible approaches 
to making them more effective on complex tasks.</blockquote> 
<p> </p> </dd> 
<dt> [697] </dt> 
<dd> George&nbsp;G. Robertson. Parallel Implementation of Genetic Algorithms 
in a Classifier System. InGrefenstette [391], pages 140-147. Also Technical 
Report TR-159 RL87-5 Thinking Machines Corporation.
<p> </p> </dd> 
<dt> [698] </dt> 
<dd> George&nbsp;G. Robertson. Population Size in Classifier Systems. In 
Proceedings of the Fifth International Conference on Machine Learning, pages 
142-152. Morgan Kaufmann, 1988.
<p> </p> </dd> 
<dt> [699] </dt> 
<dd> George&nbsp;G. Robertson. Parallel Implementation of Genetic Algorithms 
in a Classifier System. InDavis [234], pages 129-140. 
<p> </p> </dd> 
<dt> [700] </dt> 
<dd> J.&nbsp;A. Meyer H.&nbsp;L. Roitblat and S.&nbsp;W. Wilson, editors. From 
Animals to Animats 2. Proceedings of the Second International Conference on 
Simulation of Adaptive Behavior (SAB92). A Bradford Book. MIT Press, 1992. 
<p> </p> </dd> 
<dt> [701] </dt> 
<dd> Wesley Rom&atilde;o, Alex&nbsp;A. Freitas, and Roberto C.&nbsp;S. 
Pacheco. A genetic algorithm for discovering interesting fuzzy prediction 
rules: Applications to science and technology data. In W.&nbsp;B. Langdon, 
E.&nbsp;Cant&uacute;-Paz, K.&nbsp;Mathias, R.&nbsp;Roy, D.&nbsp;Davis, 
R.&nbsp;Poli, K.&nbsp;Balakrishnan, V.&nbsp;Honavar, G.&nbsp;Rudolph, 
J.&nbsp;Wegener, L.&nbsp;Bull, M.&nbsp;A. Potter, A.&nbsp;C. Schultz, 
J.&nbsp;F. Miller, E.&nbsp;Burke, and N.&nbsp;Jonoska, editors,GECCO 2002: 
Proceedings of the Genetic and Evolutionary Computation Conference, pages 
1188-1195, New York, 9-13 July 2002. Morgan Kaufmann Publishers.
<p> </p> </dd> 
<dt> [702] </dt> 
<dd> Peter Ross, Sonia Schulenburg, Javier Mar&iacute;n-Bl&aacute;zquez, and 
Emma Hart. Hyper-heuristics: Learning to combine simple heuristics in 
bin-packing problems. In W.&nbsp;B. Langdon, E.&nbsp;Cant&uacute;-Paz, 
K.&nbsp;Mathias, R.&nbsp;Roy, D.&nbsp;Davis, R.&nbsp;Poli, 
K.&nbsp;Balakrishnan, V.&nbsp;Honavar, G.&nbsp;Rudolph, J.&nbsp;Wegener, 
L.&nbsp;Bull, M.&nbsp;A. Potter, A.&nbsp;C. Schultz, J.&nbsp;F. Miller, 
E.&nbsp;Burke, and N.&nbsp;Jonoska, editors,GECCO 2002: Proceedings of the 
Genetic and Evolutionary Computation Conference, pages 942-948. Morgan Kaufmann 
Publishers, 2002.
<p> </p> </dd> 
<dt> [703] </dt> 
<dd> S.&nbsp;Ross. Accurate Reaction or Reflective Action? Master's thesis, 
School of Cognitive and Computing Sciences, University of Sussex, 1994.
<p> </p> </dd> 
<dt> [704] </dt> 
<dd> S.&nbsp;E. Rouwhorst and A.&nbsp;P. Engelbrecht. Searching the forest: 
Using decision trees as building blocks for evolutionary search in 
classification databases. InProceedings of the 2000 Congress on Evolutionary 
Computation (CEC00) [185], pages 633-638. 
<blockquote> A new evolutionary search algorithm, called BGP, to be used for 
classification tasks in data mining, is introduced. It is different from 
existing evolutionary techniques in that it does not use indirect 
representations of a solution, such as bit strings or grammars. The algorithm 
uses decision trees of various sizes as individuals in the populations and 
operators, e.g. crossover, are performed directly on the trees. when compared 
to C4.5 and CN2 on a benchmark of problems, BGP shows very good results.
</blockquote> 
<p> </p> </dd> 
<dt> [705] </dt> 
<dd> A.&nbsp;Sanchis, J.&nbsp;M. Molina, P.&nbsp;Isasi, and J.&nbsp;Segovia. 
Knowledge acquisition including tags in a classifier system. InAngeline 
et&nbsp;al. [8], pages 137-144. 
<p> </p> </dd> 
<dt> [706] </dt> 
<dd> Adrian&nbsp;V. Sannier and Erik&nbsp;D. Goodman. Midgard: A Genetic 
Approach to Adaptive Load Balancing for Distributed Systems. In John&nbsp;E. 
Laird, editor,Proc. Fifth Int. Conf. Machine Learning (ICML), pages 174-180. 
Morgan Kaufmann, 1988.
<p> </p> </dd> 
<dt> [707] </dt> 
<dd> Manuel&nbsp;Filipe Santos. Learning Classifiers in Distributed 
Environments. PhD thesis, Departamento de Sistemas de Informa&ccedil;&atilde;o, 
Universidade do Minho, Portugal, 2000.
<blockquote> Over the last decade Learning Classifier Systems (LCS) have 
received increasing attention from researchers motivated to develop flexible 
machine learning devices. However, they were not scalable; i.e., if used to 
solve real world problems, LCS are outperformed. One has to deal with vast sets 
of classifiers with large bit length. Learning in distributed environments, on 
the other hand, constitutes another potential application area for the LCS, if 
one can dispose of conceptual models for LCS' distribution. One way to by-pass 
these problems is implementing LCS on parallel hardware, improving the systems 
performance, and the use of efficient structural organisational models to avoid 
complexity. Working on this direction an agent-oriented architecture based on 
the blackboard paradigm, a model that brings parallelism to the LCS 
functionalities and caters for the distribution of classifiers and associates 
processes, was object of study. The resulting system is a distributed 
processing system called DICE (A DIstributed Computational Environment for 
Genetic-Based Classifier Systems). To achieve these goals, various domains of 
knowledge were exploited including distributed processing systems, agent-based 
systems, blackboard-based systems, logic programming and parallel genetic 
algorithms. The DICE system is the consolidation of such knowledge, a 
computation medium that improves LCS' performance and allows for the 
parallelization and distribution of classifiers in a modular and flexible way, 
augmenting the scope of application of LCS.</blockquote> 
<p> </p> </dd> 
<dt> [708] </dt> 
<dd> C&eacute;dric Sanza, Christophe Destruel, and Yves Duthen. Agents 
autonomes pour l'interaction adaptative dans les mondes virtuels. In 
5&egrave;me Journ&eacute;es de l'Association Francaise d'Informatique 
Graphique. D&eacute;cembre 1997, Rennes, France, 1997. In French. 
<blockquote> Dans le domaine des interfaces pour les dispositifs de la 
r&eacute;alit&eacute; virtuelle, les p&eacute;riph&eacute;riques de dialogue 
perturbent les sens et augmentent les difficult&eacute;s de la communication 
homme/machine. Afin de minimiser cette perturbation et pour fournir une 
assistance efficace &agrave; chaque utilisateur, nous proposons d'utiliser un 
syst&egrave;me d'apprentissage bas&eacute; sur les outils de la vie 
artificielle.</blockquote> 
<p> </p> </dd> 
<dt> [709] </dt> 
<dd> C&eacute;dric Sanza, Christophe Destruel, and Yves Duthen. A learning 
method for adaptation and evolution in virtual environments. In 3rd 
International Conference on Computer Graphics and Artificial Intelligence, 
April 1998, Limoges, France, 1998. 
<blockquote> This document has no abstract </blockquote> 
<p> </p> </dd> 
<dt> [710] </dt> 
<dd> C&eacute;dric Sanza, Christophe Destruel, and Yves Duthen. Autonomous 
actors in an interactive real-time environment. In ICVC'99 International 
Conference on Visual Computing Feb. 1999, Goa, India, 1999. 
<blockquote> This paper presents a learning system based on artificial life 
that uses short-term memory and knowledge sharing. Inspired from classifier 
systems, the model allows to generate behaviors for agents integrated in a 
multi-task environment. The user, immersed in the scene, interacts through his 
clone with autonomous actors. By his own behavior, he influences the agents' 
one. An agent perceives the world through sensors and acts through effectors in 
order to produce rules (called classifiers). Rewards from the environment allow 
to adjust the strength of every rule that is used in order to define the best 
behavior. The ``sending message'' protocol has been included to increase the 
performances of t he system in complex environment. By combining communication 
and evolution, we then produce a realtime application (a virtual soccer) where 
the user plays with the other agents. After a short period of adaptation, the 
simulation gives some positive results: a coherent global behavior is built by 
the teams.</blockquote> 
<p> </p> </dd> 
<dt> [711] </dt> 
<dd> C&eacute;dric Sanza, Christophe Destruel, and Yves Duthen. Learning in 
real-time environment based on classifiers system. In 7th International 
Conference in Central Europe on Computer Graphics, Visualization and 
Interactive Digital Media'99, Plzen, Czech Republic, 1999. 
<blockquote> This paper presents a new architecture of a classifier system for 
learning in virtual environments. The model will be integrated in our 
multi-user platform to provide interaction between intelligent agents and user 
clones. An agent is an autonomous entity equipped with sensors and effectors. 
Its behavior is guided by rewards coming from the environment that produce 
rules called classifiers. The knowledge is shared between agents by using the 
``sending-message'' protocol to increase the global efficiency of the group. 
The classifier system is specially adapted to a multi-task environment and 
incorporates a short-term memory to record the recent events of the simulation. 
These ideas have been implemented and used to develop a virtual soccer where 
the user plays with autonomous agents that combine communication and evolution.
</blockquote> 
<p> </p> </dd> 
<dt> [712] </dt> 
<dd> C&eacute;dric Sanza, Cyril Panatier, Herv&eacute; Luga, and Yves Duthen. 
Adaptive Behavior for Cooperation: a Virtual Reality Application. In 8th IEEE 
International Workshop on Robot and Human Interaction September 1999, Pisa, 
Italy, 1999. 
<blockquote> In this paper, we present a behavioral system based on artificial 
life for animating actors in a virtual reality application. Through a virtual 
soccer game, we show how a set of autonomous players (called agents) can 
cooperate and communicate to perform common tasks. The user is immersed in the 
game. He interacts with the other agents and he is integrated in the 
cooperation and in the communication systems. Every entity reacts in real-time 
by using a classifiers system which is composed of a set of binary rules and a 
reward system. The originality of such method is the ability to build a 
behavior (by emergence) without initial knowledge. The analysis of the 
simulation gives interesting results: after convergence, the global behavior of 
the teams produces coherent movements. Moreover, the introduction of 
disturbances does not affect the performances of the classifiers system.
</blockquote> 
<p> </p> </dd> 
<dt> [713] </dt> 
<dd> Shaun Saxon and Alwyn Barry. XCS and the Monk's problem. In Wu [923], 
pages 272-281.
<blockquote> It has been known for some time that Learning Classifier Systems 
(Holland, 1986) have potential for application as Data Mining tools. Parodi and 
Bonelli (1990) applied the Boole LCS (Wilson, 1985) to a Lymphography data set 
and reported 82% classification rates. More recent work, such as GA-Miner 
(Flockhart,1995) has sought to extend the application of LCS to larger 
commercial data sets, introducing more complex attribute encoding techniques, 
static niching, and hybrid genetic operators in order to address the problems 
presented by large search spaces. Despite these results, the traditional LCS 
formulation has shown itself to be unreliable in the formation of accurate 
optimal generalisations, which are vital for the reduction of results to a 
human readable form. XCS (Wilson, 1995, 1998) has been shown to be capable of 
generating a complete and optimally accurate mapping of a test environment 
(Kovacs, 1996) and therefore presents a new opportunity for the application of 
Learning Classifier Systems to Data Mining. As part of a continuing research 
effort this paper presents some first results in the application of XCS to a 
Data Mining task. It demonstrates that XCS is able to produce a classification 
performance and rule set which exceeds the performance of most current Machine 
Learning techniques when applied to the Monk's problems (Thrun, 1991).
</blockquote> 
<p> </p> </dd> 
<dt> [714] </dt> 
<dd> Shaun Saxon and Alwyn Barry. XCS and the Monk's Problems. In Lanzi 
et&nbsp;al. [544], pages 223-242. 
<blockquote> It has been known for some time that Learning Classifier Systems 
(LCS) have potential for application as Data Mining tools. Parodi and Bonelli 
applied the Boole LCS to the Lymphography data set and reported 82 
classification rates. More recent work, such as GA-Miner has sought to extend 
the application of the GA-based classification system to larger commercial data 
sets, introducing more complex attribute encoding techniques, static niching, 
and hybrid genetic operators in order to address the problems presented by 
large search spaces. Despite these results, the traditional LCS formulation has 
shown itself to be unreliable in the formation of accurate optimal 
generalisations, which are vital for the reduction of results to a human 
readable form. XCS has been shown to be capable of generating a complete and 
optimally accurate mapping of a test environment and therefore presents a new 
opportunity for the application of Learning Classifier Systems to the 
classification task in Data Mining. As part of a continuing research effort 
this paper presents some first results in the application of XCS to a 
particular Data Mining task. It demonstrates that XCS is able to produce a 
classification performance and rule set which exceeds the performance of most 
current Machine Learning techniques when applied to the Monk's problems.
</blockquote> 
<p> </p> </dd> 
<dt> [715] </dt> 
<dd> Andreas Schachtner. A classifier system with integrated genetic 
operators. In H.-P. Schwefel and R.&nbsp;M&auml;nner, editors,Parallel Problem 
Solving from Nature, volume 496 of Lecture Notes in Computer Science, pages 
331-337, Berlin, 1990. Springer.
<blockquote> This text presents a classifier system (CS), which is able to 
adapt to an environment by adjusting th activation probabilities of the rules 
and changing the rules itself. The operators for changing the rules are 
incorporated into the CS, thus allowing for an adaption of the rates of change 
on-line during the search process for better rules. An age is attached to the 
rules. Removal of rules from the rule set is done according to age. Experiments 
show that this approach to adapting the rule set by means of internal genetic 
operators (GO) is superior to exogenous genetic operators.</blockquote> 
<p> </p> </dd> 
<dt> [716] </dt> 
<dd> J.&nbsp;David Schaffer. Some experiments in machine learning using vector 
evaluated genetic algorithms. PhD thesis, Vanderbilt University, Nashville, 
1984.
<p> </p> </dd> 
<dt> [717] </dt> 
<dd> J.&nbsp;David Schaffer. Learning Multiclass Pattern Discrimination. In 
Grefenstette [389], pages 74-79. 
<p> </p> </dd> 
<dt> [718] </dt> 
<dd> J.&nbsp;David Schaffer, editor. Proceedings of the 3rd International 
Conference on Genetic Algorithms (ICGA89), George Mason University, June 1989. 
Morgan Kaufmann.
<p> </p> </dd> 
<dt> [719] </dt> 
<dd> Sonia Schulenburg and Peter Ross. An Adaptive Agent Based Economic Model. 
InLanzi et&nbsp;al. [544], pages 263-282. 
<blockquote> In this paper we describe a simple model of adaptive agents of 
different types, represented by Learning Classifier Systems (LCS), which make 
investment decisions about a risk free bond and a risky asset under a well 
defined stock market environment. Our main aim is to explore the degree of 
reliability that artificially intelligent agents can have when applied to real 
life economic problems. We do this by evaluating whether an LCS is able to 
represent competent traders in a real market scenario in which daily stock 
prices and dividends are given to the agents exogenously, so permitting us to 
focus on the dynamics and evolution of the behavior of these evolving traders 
without having to be concerned about how their actions affect the market. We 
present results of adaptive and non-adaptive simulations over a period of ten 
years of real data of a specific stock and show that the artificial agents, by 
displaying different and rich behaviours evolved throughout the simulations, 
are able to discover and refine novel and successful sets of market strategies 
that can outperform baseline strategies such as buy-and-hold or merely keeping 
money in the bank at a good rate of interest, even though the agents pay 
commission on every trade.</blockquote> 
<p> </p> </dd> 
<dt> [720] </dt> 
<dd> Sonia Schulenburg and Peter Ross. Strength and Money: An LCS Approach to 
Increasing Returns. InProceedings of the International Workshop on Learning 
Classifier Systems (IWLCS-2000), in the Joint Workshops of SAB 2000 and PPSN 
2000 [487]. Extended abstract. 
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [721] </dt> 
<dd> Sonia Schulenburg and Peter Ross. Strength and money: An LCS approach to 
increasing returns. InLanzi et&nbsp;al. [545], pages 114-137. 
<blockquote> This paper reports on a number of experiments where three 
different groups of artificial agents learn, forecast and trade their holdings 
in a real stock market scenario given exogeneously in the form of 
easily-obtained stock statistics such as various price moving averages, first 
difference in prices, volume ratios, etc. These artificial agent-types trade 
while learning during -- in most cases -- a ten year period. They normally 
start at the beginning of the year 1990 with a fixed initial wealth to trade 
over two assets (a bond and a stock) and end in the second half of the year 
2000. The adaptive agents are represented as Learning Classifier Systems 
(LCSs), that is, as sets of bit-encoded rules. Each condition bit expresses the 
truth or falsehood of a certain real market condition. The actual conditions 
used differ between agents. The forecasting performance is then compared 
against the performance of the buy-and-hold strategy, and trend-following 
strategy and finally against the bank investment over the same period at a 
fixed compound interest rate. To make the experiments as real as possible, 
agents pay comissions on every trade. The results so far suggest that this is 
an excellent approach to make trading decisions in the stock market.
</blockquote> 
<p> </p> </dd> 
<dt> [722] </dt> 
<dd> Sonia Schulenburg and Peter Ross. Explorations in LCS models of stock 
trading. InLanzi et&nbsp;al. [546], pages 151-180. 
<p> </p> </dd> 
<dt> [723] </dt> 
<dd> Alan&nbsp;C. Schultz and John&nbsp;J. Grefenstette. Evolving Robot 
Behaviors. Poster at the 1994 Artificial Life Conference. (NCARAI Report: 
AIC-94-017) http://www.ib3.gmu.edu/gref/.
<blockquote> This paper discusses the use of evolutionary computation to 
evolve behaviors that exhibit emergent intelligent behavior. Genetic algorithms 
are used to learn navigation and collision avoidance behaviors for robots. The 
learning is performed under simulation, and the resulting behaviors are then 
used to control the actual robot. Some of the emergent behavior is described in 
detail.</blockquote> 
<p> </p> </dd> 
<dt> [724] </dt> 
<dd> Alan&nbsp;C. Schultz and John&nbsp;J. Grefenstette. Improving Tactical 
Plans with Genetic Algorithms. In Proceedings of the Second International 
Conference on Tools for Artificial Intelligence. IEEE, 1990. 
<p> </p> </dd> 
<dt> [725] </dt> 
<dd> Alan&nbsp;C. Schultz, Connie&nbsp;Logia Ramsey, and John&nbsp;J. 
Grefenstette. Simulation assisted learning by competition: Effects of noise 
differences between training model and target environment. InProceedings of 
Seventh International Conference on Machine Learning (ICML), pages 211-215. 
Morgan Kaufmann, 1990.
<blockquote> The problem of learning decision rules for sequential tasks is 
addressed, focusing on the problem of learning tactical plans from a simple 
flight simulator where a plane must avoid a missile. The learning method relies 
on the notion of competition and employs genetic algorithms to search the space 
of decision policies. Experiments are presented that address issues arising 
from differences between the simulation model on which learning occurs and the 
target environment on which the decision rules are ultimately tested. 
Specifically, either the model or the target environment may contain noise. 
These experiments examine the effect of learning tactical plans without noise 
and then testing the plans in a noisy environment, and the effect of learning 
plans in a noisy simulator and then testing the plans in a noise-free 
environment. Empirical results show that, while best result are obtained when 
the training model closely matches the target environment, using a training 
environment that is more noisy than the target environment is better than using 
using a training environment that has less noise than the target environment.
</blockquote> 
<p> </p> </dd> 
<dt> [726] </dt> 
<dd> Alan&nbsp;C. Schultz, John Grefenstette, and Kenneth&nbsp;De Jong. 
Learning to break things: adaptive testing of intelligent controllers. In 
Thomas B&auml;ck, David&nbsp;B. Fogel, and Zbigniew Michalewicz, editors,
Handbook of Evolutionary Computation, pages G3.4:1-G3.4:10. IOP Publishing Ltd 
and Oxford University Press, 1997.
<p> </p> </dd> 
<dt> [727] </dt> 
<dd> Dale Schuurmans and Jonathan Schaeffer. Representational Difficulties 
with Classifier Systems. In Schaffer [718], pages 328-333. 
http://www.cs.ualberta.ca/&nbsp;jonathan/Papers/Papers/classifier.ps.
<blockquote> Classifier systems are currently in vogue as a way of using 
genetic algorithms to demonstrate machine learning. However, there are a number 
of difficulties with the formalization that can influence how knowledge is 
represented and the rate at which the system can learn. Some of the problems 
are inherent in classifier systems, and one must learn to cope with them, while 
others are pitfalls waiting to catch the unsuspecting implementor. This paper 
identifies some of these difficulties, suggesting directions for the further 
evolution of classifier systems.</blockquote> 
<p> </p> </dd> 
<dt> [728] </dt> 
<dd> Hans-Paul Schwefel and Reinhard M&auml;nner, editors. Parallel Problem 
Solving from Nature: Proceedings of the First International Workshop. Dortmund, 
FRG, 1-3 Oct 1990, number 496 in Lecture Notes in Computer Science, Heidelberg, 
1990. Springer.
<p> </p> </dd> 
<dt> [729] </dt> 
<dd> Tod&nbsp;A. Sedbrook, Haviland Wright, and Richard Wright. Application of 
a Genetic Classifier for Patient Triage. InBooker and Belew [74], pages 334-338.
<blockquote> This research develops and applies a genetic classifier system 
(CS) to triage patients presenting with symptoms of upper respiratory 
infections (URIs). The CS searches among 66 dichotomous patient signs and 
symptoms to evolve classifiers that best explain care provider triage 
decisions. The systems search is directed by specifying relative costs of false 
positives and false negatives. The model achieved a sensitivity and specificity 
of 100% and 42%, respectively, when applied to a triage case base of URI 
patients. A split-sample validation of the system shows its accuracy is 
comparable to that achieved with a triage protocol developed by Infectious 
Disease Specialists.</blockquote> 
<p> </p> </dd> 
<dt> [730] </dt> 
<dd> Sandip Sen and Mahendra Sekaran. Multiagent Coordination with Learning 
Classifier Systems. In Gerhard Wei&szlig; and Sandip Sen, editors,Proceedings 
of the IJCAI Workshop on Adaption and Learning in Multi-Agent Systems, volume 
1042 ofLNAI, pages 218-233. Springer Verlag, 1996. 
<p> </p> </dd> 
<dt> [731] </dt> 
<dd> Sandip Sen. Classifier system learning of multiplexer function. Dept. of 
Electrical Engineering, University of Alabama, Tuscaloosa, Alabama. Class 
Project, 1988.
<p> </p> </dd> 
<dt> [732] </dt> 
<dd> Sandip Sen. Sequential Boolean Function Learning by Classifier System. In 
Proc. of 1st International Conference on Industrial and Engineering 
Applications of Artificial Intelligence and Expert Systems, 1988. 
<p> </p> </dd> 
<dt> [733] </dt> 
<dd> Sandip Sen. Noise Sensitivity in a simple classifier system. In Proc. 5th 
Conf. on Neural Networks &amp; Parallel Distributed Processing, 1992. 
<p> </p> </dd> 
<dt> [734] </dt> 
<dd> Sandip Sen. Improving classification accuracy through performance 
history. InForrest [335], pages 652-652. 
<p> </p> </dd> 
<dt> [735] </dt> 
<dd> Sandip Sen. A Tale of two representations. In Proc. 7th International 
Conference on Industrial and Engineering Applications of Artificial 
Intelligence and Expert Systems, pages 245-254, 1994. 
<p> </p> </dd> 
<dt> [736] </dt> 
<dd> Sandip Sen. Modelling human categorization by a simple classifier system. 
InWSC1: 1st Online Workshop on Soft Computing. Aug 19-30, 1996. 
http://www.bioele.nuee.nagoya-u.ac.jp/wsc1/papers/p020.html, 1996. 
<blockquote> NEWBOOLE is a simple stimulus-response classifier system that has 
been used successfully in a number of supervised concept learning and 
classification problems. In this paper we use NEWBOOLE on a relatively simple 
categorization problem involving medical diagnosis, and compare its performance 
to that of human subjects on the same problem. The system is provided with the 
relevant rules and learning involves generating appropriate strengths for the 
different rules so as to categorize both seen and unseen examples. Results 
obtained with the simple classifier system exhibit the same trends as 
demonstrated by the humans. We present an analysis explaining the working of 
the system on the given task. Other experiments presented in this paper include 
experiments to replicate human performance on filtering and condensation tasks 
as described by Kruschke Kruschke92:ALCOVE, and experiments involving learning 
to attend to relevant dimensions for proper categorization Shepard61:Learning. 
In the latter task, the system is not provided the relevant rule set, and hence 
has to discover the appropriate rules as well as learn to assign credit to the 
useful ones.</blockquote> 
<p> </p> </dd> 
<dt> [737] </dt> 
<dd> Tiago Sepulveda and Mario&nbsp;Rui Gomes. A Study on the Evolution of 
Learning Classifier Systems. InProceedings of the International Workshop on 
Learning Classifier Systems (IWLCS-2000), in the Joint Workshops of SAB 2000 
and PPSN 2000 [487]. Extended abstract. 
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [738] </dt> 
<dd> F.&nbsp;Seredynski and C.&nbsp;Z. Janikow. Learning nash equilibria by 
coevolving distributed classifier systems. InAngeline et&nbsp;al. [8], pages 
1619-1626.
<p> </p> </dd> 
<dt> [739] </dt> 
<dd> F.&nbsp;Seredynski, Pawel Cichosz, and G.&nbsp;P. Klebus. Learning 
classifier systems in multi-agent environments. InProceedings of the First 
IEE/IEEE International Conference on Genetic Algorithms in Engineering Systems: 
Innovations and Applications (GALESIA'95), 1995. 
<blockquote> The paper is devoted to the problem of learning decision policies 
in multi-agent games. This problem is a simple, but appealing computational 
model of several important real-world problems in such domains as parallel 
computing, optimization, and control on one hand, and economy, social, and 
political sciences on the other hand. We describe a general framework for 
studying games of intelligent agents, extending the basic model of games with 
limited interactions, and its specific realization based on learning classifier 
systems. Simulation results are presented that illustrate the convergence 
properties of the resulting system. Avenues for future work in this area are 
outlined.</blockquote> 
<p> </p> </dd> 
<dt> [740] </dt> 
<dd> S.&nbsp;Sette and L.&nbsp;Boullart. An implementation of genetic 
algorithms for rule based machine learning.Engineering Applications of 
Artificial Intelligence, 13(4):381-390, 2000. 
<blockquote> Genetic algorithms have given rise to two new fields of research 
where (global) optimisation is of crucial importance: `Genetic Programming' and 
`Genetic based Machine Learning' (GBML). In this paper the second domain (GBML) 
will be introduced. An overview of one of the first GBML implementations by 
Holland, also known as the Learning Classifier Systems (LCS) will be given. 
After describing and solving a well-known basic (educational) problem a more 
complex application of GBML is presented. The goal of this application is the 
automatic development of a rule set for an industrial production process. To 
this end, the case study on generating a rule set for predicting the 
spinnability in the fibre-to-yarn production process will be presented. A 
largely modified LCS, called Fuzzy Efficiency based Classifier System (FECS), 
originally designed by one of the authors, is used to solve this problem 
successfully.</blockquote> 
<p> </p> </dd> 
<dt> [741] </dt> 
<dd> Kamran Shafi and Hussein&nbsp;A. Abbass. An Adaptive Genetic-Based 
Signature Learning System for Intrusion Detection.Expert Systems With 
Applications, 37, 2009. In Press. 
<p> </p> </dd> 
<dt> [742] </dt> 
<dd> Kamran Shafi, Hussein&nbsp;A. Abbass, and Weiping Zhu. The Role of Early 
Stopping and Population Size in XCS for Intrusion Detection. InProceedings of 
the 6th International Conference on Simulated Evolution and Learning, Lecture 
Notes in Computer Science (LNCS), 4247, pages 50-57. Springer, Heidelberg, 2006.
<p> </p> </dd> 
<dt> [743] </dt> 
<dd> Kamran Shafi, Hussein&nbsp;A. Abbass, and Weiping Zhu. Real Time 
Signature Extraction From a Supervised Classifier System. InProceedings of the 
2007 Congress on Evolutionary Computation, 2007. 
<p> </p> </dd> 
<dt> [744] </dt> 
<dd> Kamran Shafi, Tim Kovacs, Hussein&nbsp;A. Abbass, and Weiping Zhu. 
Intrusion Detection with Evolutionary Learning Classifier Systems.Natural 
Computing, 8(1):3-27, 2009. 
<blockquote> Evolutionary Learning Classifier Systems (LCSs) combine 
reinforcement learning or supervised learning with effective genetics-based 
search techniques. Together these two mechanisms enable LCSs to evolve 
solutions to decision problems in the form of easy to interpret rules called 
classifiers. Although LCSs have shown excellent performance on some data mining 
tasks, many enhancements are still needed to tackle features like high 
dimensionality, huge data sizes, non-uniform distribution of classes, etc. 
Intrusion detection is a real world problem where such challenges exist and to 
which LCSs have not previously been applied. An intrusion detection problem is 
characterised by huge network traffic volumes, difficult to realize decision 
boundaries between attacks and normal activities and highly imbalanced attack 
class distribution. Moreover, it demands high accuracy, fast processing times 
and adaptability to a changing environment. We present the results and analysis 
of two classifier systems (XCS and UCS) on a subset of a publicly available 
benchmark intrusion detection dataset which features serious class imbalances 
and two very rare classes. We introduce a better approach for handling the 
situation when no rules match an input on the test set and recommend this be 
adopted as a standard part of XCS and UCS. We detect little sign of overfitting 
in XCS but somewhat more in UCS. However, both systems tend to reach near-best 
performance in very few passes over the training data. We improve the accuracy 
of these systems with several modifications and point out aspects that can 
further enhance their performance. We also compare their performance with other 
machine learning algorithms and conclude that LCSs are a competitive approach 
to intrusion detection.</blockquote> 
<p> </p> </dd> 
<dt> [745] </dt> 
<dd> Jiefu Shi. Genetic Algorithms for Game Playing. In C.&nbsp;Karr and 
L.&nbsp;M. Freeman, editors,Industrial Applications of Genetic Algorithms, 
pages 321-338. CRC Press, 1998.
<blockquote> This chapter examines genetic algorithms (GA) and machine 
learning using the game of tic-tac-toe. After `learning' acceptable strategies 
for playing the game, the GA-driven computer player is able to play a competent 
game of tic-tac-toe. Results obtained using a GA are compared to results 
obtained using alternative AI techniques.</blockquote> 
<p> </p> </dd> 
<dt> [746] </dt> 
<dd> Sotaro Shimada and Yuichiro Anzai. Component-Based Adaptive Architecture 
with Classifier Systems. InPfeifer et&nbsp;al. [663]. 
<p> </p> </dd> 
<dt> [747] </dt> 
<dd> Sotaro Shimada and Yuichiro Anzai. Fast and Robust Convergence of Chained 
Classifiers by Generating Operons through Niche Formation. InBanzhaf et&nbsp;al.
[32], page 810. One page poster paper. 
<blockquote> This work has no abstract </blockquote> 
<p> </p> </dd> 
<dt> [748] </dt> 
<dd> Sotaro Shimada and Yuichiro Anzai. On Niche Formation and Corporation in 
Classifier System. InTakadama [815]. 
<p> </p> </dd> 
<dt> [749] </dt> 
<dd> Takayuki Shiose and Tetsuo Sawaragi. Extended learning classifier systems 
by dual referencing mechanism. InTakadama [815]. 
<p> </p> </dd> 
<dt> [750] </dt> 
<dd> Lingyan Shu and Jonathan Schaeffer. VCS: Variable Classifier System. In 
Schaffer [718], pages 334-339. 
http://www.cs.ualberta.ca/~jonathan/Papers/Papers/vcs.ps.
<blockquote> Genetic-algorithms-based learning classifier systems suffer from 
a number of problems that cause system instability, resulting in poor 
performance. These problems include genetic operation disruptions and 
difficulties in maintaining good classifiers and classifier structures in the 
population. A method is proposed in which structural ties are used to achieve 
coherence, impose cooperation and encourage co-adaptation among classifiers. A 
hierarchically structured classifier system (HCS) has been implemented to show 
the effect of this structuring. At the lowest level, classifiers (individuals) 
are grouped into families. Higher-order structures, such as a community of 
families, can be introduced if necessary. The experimental results show a 
significant improvement in system performance and stability. The relationships 
between the HCS framework and the Michigan and Pittsburgh approaches are 
discussed.</blockquote> 
<p> </p> </dd> 
<dt> [751] </dt> 
<dd> Lingyan Shu and Jonathan Schaeffer. Improving the Performance of Genetic 
Algorithm Learning by Choosing a Good Initial Population. Technical Report 
TR-90-22, University of Alberta, CS DEPT, Edmonton, Alberta, Canada, 1990.
<p> </p> </dd> 
<dt> [752] </dt> 
<dd> Lingyan Shu and Jonathan Schaeffer. HCS: Adding Hierarchies to Classifier 
Systems. InBooker and Belew [74], pages 339-345. 
<blockquote> Genetic-algorithms-based learning classifier systems suffer from 
a number of problems that cause instability, resulting in poor performance. 
These problems include genetic operation disruptions and difficulties in 
maintaining good classifiers and classifier structures in the population. A 
method is proposed in which structural ties are used to achieve coherence, 
impose cooperation and encourage co-adaptation among classifiers. A 
hierarchically structured classifier system (HCS) has been implemented to show 
the effect of this structuring. At the lowest level, classifiers (individuals) 
are grouped into families. Higher-order structures, such as communities of 
families, can be introduced if necessary. The experimental results show a 
significant improvement in system performance and stability. The relationships 
between the HCS framework and the Michigan and Pittsburgh approaches are 
discussed.</blockquote> 
<p> </p> </dd> 
<dt> [753] </dt> 
<dd> Olivier Sigaud and Pierre Gerard. Being reactive by exchanging roles: an 
empirical study. InBalancing reactivity and Social Deliberation in Multiagent 
Systems, volume 2103 of LNAI, pages 150-172. Springer-Verlag, 2001. 
<p> </p> </dd> 
<dt> [754] </dt> 
<dd> Olivier Sigaud and Pierre Gerard. Using classifier systems as adaptive 
expert systems for control. InAdvances in Classifier Systems, number 1996 in 
LNAI, pages 138-157. Springer-Verlag, 2001.
<p> </p> </dd> 
<dt> [755] </dt> 
<dd> Olivier Sigaud. On the usefulness of a semi-automated Classifier System: 
the engineering perspective. InProceedings of the International Workshop on 
Learning Classifier Systems (IWLCS-2000), in the Joint Workshops of SAB 2000 
and PPSN 2000 [487]. Extended abstract. 
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [756] </dt> 
<dd> Michael&nbsp;C. Simon. Using XCS to form hyper-heuristics for the set 
covering problem. In Alwyn&nbsp;M. Barry, editor,GECCO 2003: Proceedings of the 
Bird of a Feather Workshops, Genetic and Evolutionary Computation Conference, 
pages 246-249. AAAI, 2003.
<p> </p> </dd> 
<dt> [757] </dt> 
<dd> M.G. Smith and L.&nbsp;Bull. Genetic programming with a genetic algorithm 
for feature construction and selection.Genetic Programming and Evolvable 
Machines, 6(3):265-281, 2005. 
<p> </p> </dd> 
<dt> [758] </dt> 
<dd> Robert&nbsp;E. Smith and H.&nbsp;Brown Cribbs. Is a Learning Classifier 
System a Type of Neural Network?Evolutionary Computation, 2(1):19-36, 1994. 
<blockquote> This paper suggests a simple analogy between learning classifier 
systems (LCSs) and neural networks (NNs). By clarifying the relationship 
between LCSs and NNs, the paper indicates how techniques from one can he 
utilized in the other. The paper points out that the primary distinguishing 
characteristic of the LCS is its use of a co-adaptive genetic algorithm (GA), 
where the end product of evolution is a diverse population of individuals that 
cooperate to perform useful computation. This stands in contrast to typical 
GA/NN schemes, where a population of networks is employed to evolve a single, 
optimized network. To fully illustrate the LCS/NN analogy used in this paper, 
an LCS-like NN is implemented and tested. The test is constructed to run 
parallel to a similar GA/NN study that did not employ a co-adaptive GA. The 
test illustrates the LCS/NN analogy and suggests an interesting new method for 
applying GAs in NNs. Final comments discuss extensions of this work and suggest 
how LCS and NN studies can further benefit each other.</blockquote> 
<p> </p> </dd> 
<dt> [759] </dt> 
<dd> Robert&nbsp;E. Smith and Bruce&nbsp;A. Dike. An application of genetic 
algorithms to air combat maneuvering. In Thomas B&auml;ck, David&nbsp;B. Fogel, 
and Zbigniew Michalewicz, editors,Handbook of Evolutionary Computation, pages 
G3.1:1-G3.1:14. IOP Publishing Ltd and Oxford University Press, 1997.
<p> </p> </dd> 
<dt> [760] </dt> 
<dd> Robert&nbsp;E. Smith and David&nbsp;E. Goldberg. Reinforcement Learning 
with Classifier Systems: Adaptive Default Hierarchy Formation. Technical Report 
90002, TCGA, University of Alabama, 1990.
<p> </p> </dd> 
<dt> [761] </dt> 
<dd> Robert&nbsp;E. Smith and David&nbsp;E. Goldberg. Variable Default 
Hierarchy Separation in a Classifier System. InRawlins [674], pages 148-170. 
<blockquote> A learning classifier system (LCS) is a machine learning system 
that incorporates a production-system framework and a genetic algorithm (GA) 
for rule discovery (Goldberg, 1989; Holland, 1975). A primary feature of LCSs 
is their potential to exploit overlapping sets of rules called default 
hierarchies. Default hierarchies increase rule set parsimony, enlarge the 
solution set, and lend themselves to graceful refinement by the GA (Holland, 
Holyoak, Nisbett, &amp; Thagard, 1986). Traditionally, auction-based, 
specificity-biased credit allocation (CA) and conflict resolution (CR) schemes 
have been used to encourage default hierarchy formation in an LCS. Analyses 
presented in this paper suggest that these schemes cannot be expected to 
perform adequately in arbitrary LCS environments. This paper presents an 
alternate CA/CR that associates two measures with each classifier in place of 
the single, traditional strength measure. The first measure is a payoff 
estimate, which is tuned by the linear-update scheme usually used for strength. 
The second measure is a priority factor that is tuned to control the outcome of 
a necessity auction. In the necessity auction the winning classifier pays out 
the payoff estimate of its nearest competitor, rather than a fraction of its 
own payoff estimate. Results and analyses are presented that show that this 
CA/CR scheme can induce variable bid separation that responds to the demands of 
the LCS environment. Additional analyses show that this scheme allows an LCS to 
adequately exploit a broader class of default hierarchies than traditional 
schemes. Several avenues are suggested for further study.</blockquote> 
<p> </p> </dd> 
<dt> [762] </dt> 
<dd> Robert&nbsp;E. Smith and David&nbsp;E. Goldberg. Reinforcement learning 
with classifier systems: adaptative default hierarchy formation.Applied 
Artificial Intelligence, 6, 1992. 
<p> </p> </dd> 
<dt> [763] </dt> 
<dd> S.&nbsp;F. Smith and D.&nbsp;P. Greene. Cooperative Diversity using 
Coverage as a Constraint. InCollected Abstracts for the First International 
Workshop on Learning Classifier System (IWLCS-92) [486]. October 6-8, NASA 
Johnson Space Center, Houston, Texas.
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [764] </dt> 
<dd> Robert&nbsp;E. Smith and H.&nbsp;B.&nbsp;Cribbs III. Cooperative Versus 
Competitive System Elements in Coevolutionary Systems. InMaes et&nbsp;al. [595]
, pages 497-505.
<p> </p> </dd> 
<dt> [765] </dt> 
<dd> Robert&nbsp;E. Smith and H.&nbsp;B.&nbsp;Cribbs III. Combined biological 
paradigms.Robotics and Autonomous Systems, 22(1):65-74, 1997. 
<blockquote> This paper introduces an autonomous systems strategy that 
combines two biological inspirations: neural networks and genetic algorithms 
(GAs). These ideas have been combined in a variety of ways in other systems, 
but the scheme presented here has several unique features. The system presented 
is based on an analogy between learning classifier systems (LCSs) and neural 
networks first presented by Smith and Cribbs [Evolutionary Computation 2(1) 
(1994) 19-36]. However, Smith and Cribbs focused on supervised learning. The 
work presented in this paper transfers these ideas to the realm of autonomous 
systems by considering reinforcement learning. In the new system, a neural 
network is used to map environmental states to Q value. The neural network 
structure is based on an LCS. The GA acts to shape neural connectivity, and the 
number of hidden layer nodes. The GAs action is similar to its action in the 
LCS. The suggested system is evaluated in a simulated mobile robot test 
environment. Experimental results suggest that the system is effective in 
learning and evolving parsimonious strategy representations for autonomous 
systems. Future directions for investigation of this system are discussed.
</blockquote> 
<p> </p> </dd> 
<dt> [766] </dt> 
<dd> Robert&nbsp;Elliott Smith and Max&nbsp;Kun Jiang. A learning classifier 
system with mutual-information-based fitness. In Jaume Bacardit, Ester 
Bernad&oacute;-Mansilla, Martin Butz, Tim Kovacs, Xavier Llor&agrave;, and 
Keiki Takadama, editors,Learning Classifier Systems. 10th and 11th 
International Workshops (2006-2007), volume 4998/2008 of Lecture Notes in 
Computer Science, pages 136-153. Springer, 2008. 
<blockquote> This paper introduces a new variety of learning classifier system 
(LCS), called MILCS, which utilizes mutual information as fitness feedback. 
Unlike most LCSs, MILCS is specifically designed for supervised learning. We 
present preliminary results, and contrast them to results from XCS. We discuss 
the explanatory power of the resulting rule sets and introduce a new technique 
for visualizing explanatory power. Final comments include future directions of 
this research, including investigations in neural networks and other systems.
</blockquote> 
<p> </p> </dd> 
<dt> [767] </dt> 
<dd> Robert&nbsp;E. Smith and Manuel Valenzuela-Rend&oacute;n. A Study of Rule 
Set Development in a Learning Classifier System. InSchaffer [718], pages 
340-346.
<blockquote> In this paper a set of simultaneous equations is used to examine 
the development of rule sets in a classifier system using a genetic algorithm 
(GA) as its primary discovery device. These equations are developed for a 
stimulus-response classifier system with a single, two-bit condition and a 
binary action. Computations are presented that show the importance of niching 
operators in a classifier system's GA. Further experiments compare and contrast 
the effects of fitness sharing and mating restriction as niching and speciation 
operators in the classifier system.</blockquote> 
<p> </p> </dd> 
<dt> [768] </dt> 
<dd> Robert&nbsp;E. Smith, Stephanie Forrest, and Alan&nbsp;S. Perelson. 
Population Diversity in an Immune System Model: Implications for Genetic Search
. In L.&nbsp;Darrell Whitley, editor,Foundations of Genetic Algorithms 2, pages 
153-165. Morgan Kaufmann, 1992.
<p> </p> </dd> 
<dt> [769] </dt> 
<dd> Robert&nbsp;E. Smith, Stephanie Forrest, and A.&nbsp;S. Perelson. 
Searching for diverse, cooperative subpopulations with Genetic Algorithms. 
Evolutionary Computation, 1(2):127-149, 1993. 
<p> </p> </dd> 
<dt> [770] </dt> 
<dd> George&nbsp;D. Smith, Nigel&nbsp;C. Steele, and Rudolf&nbsp;F. Albrecht, 
editors.Artificial Neural Networks and Genetic Algorithms. Springer, 1997. 
<p> </p> </dd> 
<dt> [771] </dt> 
<dd> Robert&nbsp;E. Smith, B.&nbsp;A. Dike, B.&nbsp;Ravichandran, 
A.&nbsp;El-Fallah, and R.&nbsp;K. Mehra.The Fighter Aircraft LCS: A Case of 
Different LCS Goals and Techniques. In Wu [923], pages 282-289. 
<blockquote> There are a number of common difficulties and open issues that 
pertain to the ``traditional'' LCS model. Many of these topics were central at 
The First International Workshop on Learning Classifier Systems (Houston, 
Texas, 1992). Since the first workshop, several significant, 
theoretically-supported advances in LCS practice have addressed these issues. 
However, a system employed by the authors to acquire novel fighter aircraft 
maneuvers from combat simulation is more akin to the traditional LCS model than 
to more recent systems. Given the difficulties often experienced in LCS 
research on simple problems, one must ask how a relatively primitive LCS has 
had consistent success in the complex domain of fighter aircraft maneuvering? 
This paper overviews the troublesome issues discussed at the first workshop, 
and recent advances. It then presents the fighter aircraft LCS, in greater 
detail than in previous publications. Positive results from the system are 
discussed. The paper then focuses on the primary reasons the fighter aircraft 
LCS has avoided the difficulties of the traditional LCS. The authors believe 
the system's success has three primary origins: differences in credit 
assignment, differences in action encoding, and (possibly most importantly) a 
difference in system goals. In the fighter aircraft system, the goal has been 
simply the discovery of innovative, novel tactics, rather than online control. 
The paper concludes by discussing the most salient features of the fighter 
aircraft learning system, and how those features may be profitably combined 
with other LCS developments.</blockquote> 
<p> </p> </dd> 
<dt> [772] </dt> 
<dd> Robert&nbsp;E. Smith, B.&nbsp;A. Dike, R.&nbsp;K. Mehra, 
B.&nbsp;Ravichandran, and A.&nbsp;El-Fallah. Classifier Systems in Combat: 
Two-sided Learning of Maneuvers for Advanced Fighter Aircraft.Computer Methods 
in Applied Mechanics and Engineering, 186(2-4):421-437, 2000. 
<p> </p> </dd> 
<dt> [773] </dt> 
<dd> Robert&nbsp;E. Smith, B.&nbsp;A. Dike, B.&nbsp;Ravichandran, 
A.&nbsp;El-Fallah, and R.&nbsp;K. Mehra. The Fighter Aircraft LCS: A Case of 
Different LCS Goals and Techniques. InLanzi et&nbsp;al. [544], pages 283-300. 
<blockquote> A system employed by the authors to acquire novel fighter 
aircraft manoeuvres from combat simulation is more akin to the traditional LCS 
model than to more recent systems. Given the difficulties often experienced in 
LCS research on simple problems, one must ask how a relatively primitive LCS 
has had consistent success in the complex domain of fighter aircraft 
manoeuvering. This paper presents the fighter aircraft LCS, in greater detail 
than in previous publications. Positive results from the system are discussed. 
The paper then focuses on the primary reasons the fighter aircraft LCS has 
avoided the difficulties of the traditional LCS. The authors believe the 
system's success has three primary origins: differences in credit assignment, 
differences in action encoding, and (possibly most important) a difference in 
system goals. In the fighter aircraft system, the goal has been simply the 
discovery of innovative, novel tactics, rather than online control. The paper 
concludes by discussing the most salient features of the fighter aircraft 
system, and how those features may be profitably combined with other LCS 
developments.</blockquote> 
<p> </p> </dd> 
<dt> [774] </dt> 
<dd> S.&nbsp;F. Smith. A Learning System Based on Genetic Adaptive Algorithms. 
PhD thesis, University of Pittsburgh, 1980.
<p> </p> </dd> 
<dt> [775] </dt> 
<dd> S.&nbsp;F. Smith. Flexible Learning of Problem Solving Heuristics through 
Adaptive Search. InProceedings Eight International Joint Conference on 
Artificial Intelligence, pages 422-425, 1983. 
<p> </p> </dd> 
<dt> [776] </dt> 
<dd> S.&nbsp;F. Smith. Adaptive learning systems. In R.&nbsp;Forsyth, editor, 
Expert Systems: Principles and Case Studies, pages 169-189. Chapman and Hall, 
1984.
<p> </p> </dd> 
<dt> [777] </dt> 
<dd> Robert&nbsp;E. Smith. Default Hierarchy Formation and Memory Exploitation 
in Learning Classifier Systems. PhD thesis, University of Alabama, 1991. 
<p> </p> </dd> 
<dt> [778] </dt> 
<dd> Robert&nbsp;E. Smith. A Report on The First International Workshop on 
Learning Classifier Systems (IWLCS-92). NASA Johnson Space Center, Houston, 
Texas, Oct. 6-9. 
ftp://lumpi.informatik.uni-dortmund.de/pub/LCS/papers/lcs92.ps.gz or from 
ENCORE, The Electronic Appendix to the Hitch-Hiker's Guide to Evolutionary 
Computation (ftp://ftp.krl.caltech.edu/pub/EC/Welcome.html) in the section on 
Classifier Systems, 1992.
<blockquote> This paper has no abstract </blockquote> 
<p> </p> </dd> 
<dt> [779] </dt> 
<dd> Robert&nbsp;E. Smith. Is a classifier system a type of neural network? In 
Collected Abstracts for the First International Workshop on Learning Classifier 
System (IWLCS-92) [486]. October 6-8, NASA Johnson Space Center, Houston, Texas.
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [780] </dt> 
<dd> Robert&nbsp;E. Smith. Memory exploitation in learning classifier systems. 
InCollected Abstracts for the First International Workshop on Learning 
Classifier System (IWLCS-92) [486]. October 6-8, NASA Johnson Space Center, 
Houston, Texas.
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [781] </dt> 
<dd> Robert&nbsp;E. Smith. Genetic Learning in Rule-Based and Neural Systems. 
InProceedings of the Third International Workshop on Neural Networks and Fuzzy 
Logic, volume&nbsp;1, page 183. NASA. Johnson Space Center, January 1993. 
<blockquote> The design of neural networks and fuzzy systems can involve 
complex, nonlinear, and ill-conditioned optimization problems. Often, 
traditional optimization schemes are inadequate or inapplicable for such tasks. 
Genetic Algorithms (GA's) are a class of optimization procedures whose 
mechanics are based on those of natural genetics. Mathematical arguments show 
how GAs bring substantial computational leverage to search problems, without 
requiring the mathematical characteristics often necessary for traditional 
optimization schemes (e.g., modality, continuity, availability of derivative 
information, etc.). GA's have proven effective in a variety of search tasks 
that arise in neural networks and fuzzy systems. This presentation begins by 
introducing the mechanism and theoretical underpinnings of GA's. GA's are then 
related to a class of rule-based machine learning systems called learning 
classifier systems (LCS's). An LCS implements a low-level production-system 
that uses a GA as its primary rule discovery mechanism. This presentation 
illustrates how, despite its rule-based framework, an LCS can be thought of as 
a competitive neural network. Neural network simulator code for an LCS is 
presented. In this context, the GA is doing more than optimizing and objective 
function. It is searching for an ecology of hidden nodes with limited 
connectivity. The GA attempts to evolve this ecology such that effective neural 
network performance results. The GA is particularly well adapted to this task, 
given its naturally-inspired basis. The LCS/neural network analogy extends 
itself to other, more traditional neural networks. Conclusions to the 
presentation discuss the implications of using GA's in ecological search 
problems that arise in neural and fuzzy systems.</blockquote> 
<p> </p> </dd> 
<dt> [782] </dt> 
<dd> Robert&nbsp;E. Smith. Memory Exploitation in Learning Classifier Systems. 
Evolutionary Computation, 2(3):199-220, 1994. 
<blockquote> Learning classifier systems (LCSs) offer a unique opportunity to 
study the adaptive exploitation of memory. Because memory is manipulated in the 
form of simple internal messages in the LCS, one can easily and carefully 
examine the development of a system of internal memory symbols. This study 
examines the LCS applied to a problem whose only performance goal is the 
effective exploitation of memory. Experimental results show that the genetic 
algorithm forms a relatively effective set of internal memory symbols, but that 
this effectiveness is directly limited by the emergence of parasite rules. The 
results indicate that the emergence of parasites may be an inevitable 
consequence in a system that must evolve its own set of internal memory 
symbols. The paper's primary conclusion is that the emergence of parasites is a 
fundamental obstacle in such problems. To overcome this obstacle, it is 
suggested that the LCS must form larger, multirule structures. In such 
structures, parasites can be more accurately evaluated and thus eliminated. 
This effect is demonstrated through a preliminary evaluation of a classifier 
corporation scheme. Final comments present future directions for research on 
memory exploitation in the LCS and similar evolutionary computing systems.
</blockquote> 
<p> </p> </dd> 
<dt> [783] </dt> 
<dd> George&nbsp;D. Smith. Economic Applications of Genetic Algorithms. In Vic 
Rayward-Smith, editor,Applications of Modern Heuristic Methods, pages 71-90. 
Alfred Waller Ltd, 1995. Contains 2 pages on LCS.
<blockquote> This work has no abstract </blockquote> 
<p> </p> </dd> 
<dt> [784] </dt> 
<dd> Robert&nbsp;E. Smith. Derivative Methods: Learning Classifier Systems. In 
B&auml;ck et&nbsp;al. [22], pages B1.2:6-B1.5:11. 
http://www.iop.org/Books/Catalogue/.
<p> </p> </dd> 
<dt> [785] </dt> 
<dd> Lee Spector, Erik&nbsp;D. Goodman, Annie Wu, W.&nbsp;B. Langdon, 
Hans-Michael Voigt, Mitsuo Gen, Sandip Sen, Marco Dorigo, Shahram Pezeshk, 
Max&nbsp;H. Garzon, and Edmund Burke, editors.Proceedings of the Genetic and 
Evolutionary Computation Conference (GECCO-2001). Morgan Kaufmann, 2001. 
<p> </p> </dd> 
<dt> [786] </dt> 
<dd> Piet Spiessens. PCS: A Classifier System that Builds a Predictive 
Internal World Model. InPROC of the 9th European Conference on Artificial 
Intelligence, Stockholm, Sweden, Aug. 6-10, pages 622-627, 1990. 
<p> </p> </dd> 
<dt> [787] </dt> 
<dd> Bryan&nbsp;G. Spohn and Philip&nbsp;H. Crowley. Complexity of Strategies 
and the Evolution of Cooperation. InKoza et&nbsp;al. [528], pages 521-528. 
<blockquote> We address the complexity of strategies that simulate those used 
in repeated pairwise social interactions by individuals capable of cooperating 
(C) or defecting (D). Strategies are composed of some number of interacting 
rules, each specifying a response (C or D) to the recent history of previous 
responses by the two individuals. Here we consider the extent of memory and 
especially the number of rules as components of complexity. Using a classifier 
system based on small populations playing the Iterated Prisoner's Dilemma game, 
we show that mutual cooperation (and thus fitness) is maximized for strategies 
of about 20 rules when the number of rules is fixed; that less memory generally 
yields more mutual cooperation; and that longer interaction sequences generate 
more mutual cooperation -- all in accord with previous work. Allowing rule 
number to evolve with short interaction sequences produces mutual cooperation 
near or below the low levels associated with random responses. But even with 
these short sequences, weak selection on rule number can be detected. Selection 
seems to favor fewer rules (approximately 7) when rule number can evolve than 
the fixed number of rules that maximzes mutual cooperation. We expect stronger 
selection on rule number for longer interaction sequences and larger population 
sizes.</blockquote> 
<p> </p> </dd> 
<dt> [788] </dt> 
<dd> Wolfgang Stolzmann and Martin Butz. Latent Learning and Action-Planning 
in Robots with Anticipatory Classifier Systems. InLanzi et&nbsp;al. [544], 
pages 301-317.
<blockquote> Two applications of Anticipatory Classifier Systems (ACS) in 
robotics are discussed. The first one is a simulation of an experiment about 
latent learning in rats with a mobile robot. It shows than an ACS is able to 
learn latently, i.e. in the absence of environmental reward and that ACS can do 
action planning. The second one is about learning of the hand-eye coordination 
of a robot arm in conjunction with a camera. Goal-directed learning will be 
introduced. This combination of action planning and latent learning leads to a 
substantial reduction of the number of trials which are required to learn a 
complete model of a prototypical environment.</blockquote> 
<p> </p> </dd> 
<dt> [789] </dt> 
<dd> Wolfgang Stolzmann, Martin Butz, J.&nbsp;Hoffmann, and D.&nbsp;E. 
Goldberg. First cognitive capabilities in the anticipatory classifier system. In
et&nbsp;al. [299], pages 287-296. Also Technical Report 2000008 of the Illinois 
Genetic Algorithms Laboratory.
<blockquote> This paper adds a new viewpoint to the Anticipatory Classifier 
System (ACS). It approaches the system from a psychological perspective and 
thus provides new insights to the current system. By simulating previously 
published rat experiments, the paper compares the behavior of the ACS with the 
behavior of the rats. Two further cognitive mechanisms are introduced to the 
ACS resulting in an animal-like behavior in the presented simulations. 
Moreover, the paper gives empirical evidence that the evolving generalized, 
internal environmental model is usable in the ACS for the mental adaptation of 
actions and thus enables reinforcement learning by mental simulation.
</blockquote> 
<p> </p> </dd> 
<dt> [790] </dt> 
<dd> Wolfgang Stolzmann. Learning Classifier Systems using the Cognitive 
Mechanism of Anticipatory Behavioral Control, detailed version.. In Proceedings 
of the First European Workshop on Cognitive Modelling, pages 82-89. Berlin: TU, 
1996. http://www.psychologie.uni-wuerzburg.de/stolzmann/.
<blockquote> A classifier system is a machine learning system that learns a 
collection of rules, called classifiers. Mostly, classifiers can be regarded as 
simple stimulus-response rules. A first level of learning called credit 
assignment level, consists of reinforcement learning on these classifiers. A 
classifier is reinforced in dependence on the result of an interaction between 
the CS and its environment. A second level that is independent of the first one 
consists of rule discovery. For that a CS usually uses genetic algorithms that 
can only use very indirect information about the interaction between the system 
and the environment in the form of rule strengths. It is often the problem with 
CSs that hierarchical chunks of classifiers are destroyed when the rule 
discovery is applied. Therefore in some applications CSs don't use the rule 
discovery level or don't delete classifiers (e.g. Riolo 1991). This paper gives 
an introduction to a new kind of CSs that learn with anticipatory behavioral 
control. These classifier systems are called anticipatory classifier systems 
(ACSs). Anticipatory behavioral control is a development of reinforcement 
learning on stimulus-response units and enables us to learn an internal model 
of an external environment. The main difference between ACSs and other CSs is 
that in an ACS the rule discovery level is integrated into the credit 
assignment level. The rule discovery algorithm of an ACS uses immediate 
environmental information, i.e. it's a kind of intentional rule discovery. This 
is a particular feature of ACSs. For example, there are no problems with 
hierarchical chunks of classifiers. After the introduction we prove the 
performance of ACSs by comparing them with other CSs. A simulation of an 
experiment about the latent learning of rats is then discussed and it is shown 
that ACSs solve the locality/globality dilemma for reactive classifier systems.
</blockquote> 
<p> </p> </dd> 
<dt> [791] </dt> 
<dd> Wolfgang Stolzmann. Antizipative Classifier Systeme. PhD thesis, 
Fachbereich Mathematik/Informatik, University of Osnabr&uuml;ck, 1997.
<blockquote> Abstract: Antizipative Classifier Systems oder kurz ACSs sind 
Classifier Systems, die mittels antizipativer Verhaltenssteuerung lernen. 
Classifier Systems wurden 1978 von J. Holland eingef&uuml;hrt und bilden neben 
k&uuml;nstlichen neuronalen Netzen und Multi-Agenten-Systemen eine wichtige 
Klasse lernender Systeme in der K&uuml;nstlichen Intelligenz. Antizipative 
Verhaltenssteuerung, wie sie 1992 von J. Hoffmann postuliert wurde, ist eine 
psychologische Lerntheorie, bei der Verhalten eine Grundvoraussetzung f&uuml;r 
Lernen ist. In der vorliegenden Arbeit ist es gelungen, antizipative 
Verhaltenssteuerung in Classifier Systems zu integrieren und somit zu einem 
Lernalgorithmus weiterzuentwickeln. Dabei wurde das Ziel verfolgt, die Ideen 
der antizipativen Verhaltenssteuerung m&ouml;glichst unmittelbar im Algorithmus 
wiederzufinden. Im einzelnen gliedert sich die Arbeit in 5 Kapitel. In Kapitel 
1 wird eine kurze Einf&uuml;hrung in die Theorie der antizipativen 
Verhaltenssteuerung gegeben. Kapitel 2 umfa&szlig;t eine ausf&uuml;hrliche 
Diskussion verschiedener Varianten von Cassifier Systems. Der Kern der Arbeit 
besteht aus Kapitel 3. Hier werden auf der Grundlage von Kapitel 1 und Kapitel 
2 ACSs formal definiert. Das 4. Kapitel dient der Evaluation von ACSs. Dazu 
werden zwei Anwendungen antizipativer Classifier Systems diskutiert. Zum einen 
wird ein Tierexperiment aus der Verhaltensforschung und zum anderen eine 
Lernaufgabe f&uuml;r einen Roboter simuliert. Im 5. Kapitel werden Grenzen und 
Erweiterungsm&ouml;glichkeiten von ACSs diskutiert.</blockquote> 
<p> </p> </dd> 
<dt> [792] </dt> 
<dd> Wolfgang Stolzmann. Two Applications of Anticipatory Classifier Systems 
(ACSs). In Proceedings of the 2nd European Conference on Cognitive Science, 
pages 68-73. Manchester, U.K., 1997. 
http://www.psychologie.uni-wuerzburg.de/stolzmann/.
<blockquote> Anticipatory classifier systems (ACSs) are a new kind of 
classifier systems (CSs) that learn by using the cognitive mechanism of 
anticipatory behavioral control. At first this paper gives a brief introduction 
to ACSs. Then two applications of ACSs are discussed. The first one is a 
simulation of an experiment about latent learning that was done by Seward 
(1949) and first simulated by Riolo (1991). The second one consists of a 
simulation of a robot that has to learn its eye-hand coordination, starting 
without any knowledge, that was described and simulated by Birk (1995) using 
Drescher's schemata (Drescher, 1991 p.9).</blockquote> 
<p> </p> </dd> 
<dt> [793] </dt> 
<dd> Wolfgang Stolzmann. Anticipatory classifier systems. In Proceedings of 
the Third Annual Genetic Programming Conference, pages 658-664. Morgan 
Kaufmann, 1998. http://www.psychologie.uni-wuerzburg.de/stolzmann/gp-98.ps.gz.
<blockquote> Anticipatory Classifier Systems (ACS) are a new kind of 
classifier system (CS) that learn by using the cognitive mechanism of 
anticipatory behavioral control that was introduced in cognitive psychology by 
Hoffmann (1992). This paper gives at first a brief introduction to Hoffmann's 
learning mechanism. Then ACS are introduced. To prove the performance of ACS 
they are compared to Riolo's CFSC2(1991). In addition to a theoretical 
comparison a simulation of an experiment about latent learning in rats is 
discussed that was developed by Seward (1949).</blockquote> 
<p> </p> </dd> 
<dt> [794] </dt> 
<dd> Wolfgang Stolzmann. Untersuchungen zur ad&auml;quatheit des postulats 
einer antizipativen verhaltenssteuerung zur erkl&auml;rung von verhalten mit 
ACSs. In W.&nbsp;Krause and U.&nbsp;Kotkamp, editors,Intelligente 
Informationsverarbeitung, pages 130-138. Deutscher Universit&auml;ts Verlag, 
1998.
<p> </p> </dd> 
<dt> [795] </dt> 
<dd> Wolfgang Stolzmann. Latent Learning in Khepera Robots with Anticipatory 
Classifier Systems. In Wu [923], pages 290-297. 
<blockquote> Seward (1949) developed an experiment about latent learning in 
rats. During a learning phase rats learn the topology of a T-maze without 
getting any reward. This experiment is replicated with a Khepera robot that 
latently learns by using an Anticipatory Classifier System (ACS). The robot and 
its environment are simulated with the Open Mobile Robots Simulator Webots. 
Latent learning is defined as learning in the absence of reinforcement. 
Therefore this experiment cannot be simulated with usual reinforcement learning 
techniques. A mobile robot can observe its environment only partially, so that 
the Markov property is not necessarily given. Indeed, the T-maze used here is a 
Non-Markov environment for a Khepera robot. Non-Markov environments can be 
learned by adding memory to Learning Classifier Systems (cf. Cliff &amp; Ross 
1995, Lanzi 1998). An alternative for ACS is to use classifiers with behavioral 
sequences. This alternative is discussed. Besides it must be possible to test 
whether the topology of the T-maze is learned or not. For this purpose the 
robot is told to reach a certain point in the maze. If the robot needs more 
than one behavioral act to do this, then it is necessary to have a mechanism 
that enables the robot to do look ahead planning (cf. Riolo 1991). Such a 
mechanism is introduced.</blockquote> 
<p> </p> </dd> 
<dt> [796] </dt> 
<dd> Wolfgang Stolzmann. An Introduction to Anticipatory Classifier Systems. In
Lanzi et&nbsp;al. [544], pages 175-194. 
<blockquote> Anticipatory Classifier Systems (ACS) are classifier systems that 
learn by using the cognitive mechanism of anticipatory behavioral control which 
was introduced in cognitive psychology by Hoffmann. They can learn in 
deterministic multi-step environments. A stepwise introduction to ACS is given. 
We start with the basic algorithm and apply it in simple ``woods'' 
environments. It will be shown that this algorithm can only learn in a special 
kind of deterministic multi-step environments. Two extensions are discussed. 
The first one enables an ACS to learn in any deterministic multi-step 
environment. The second one allows an ACS to deal with a special kind of 
non-Markov state.</blockquote> 
<p> </p> </dd> 
<dt> [797] </dt> 
<dd> Chris Stone and Larry Bull. For real! XCS with continuous-valued inputs. 
Evolutionary Computation, 11(3):298-336, 2003. 
<p> </p> </dd> 
<dt> [798] </dt> 
<dd> Christopher Stone and Larry Bull. Towards learning classifier systems for 
continuous-valued online environments. In E.&nbsp;Cant&uacute;-Paz, J.&nbsp;A. 
Foster, K.&nbsp;Deb, D.&nbsp;Davis, R.&nbsp;Roy, U.-M. O'Reilly, H.-G. Beyer, 
R.&nbsp;Standish, G.&nbsp;Kendall, S.&nbsp;Wilson, M.&nbsp;Harman, 
J.&nbsp;Wegener, D.&nbsp;Dasgupta, M.&nbsp;A. Potter, A.&nbsp;C. Schultz, 
K.&nbsp;Dowsland, N.&nbsp;Jonoska, and J.&nbsp;Miller, editors,Genetic and 
Evolutionary Computation -- GECCO-2003, pages 1924-1925, Berlin, 2003. 
Springer-Verlag.
<p> </p> </dd> 
<dt> [799] </dt> 
<dd> K.&nbsp;Takadama and T.&nbsp;Terano. Good solutions will emerge without a 
global objective function: Applying organizational-learning oriented classifier 
system to printed circuit board design. InThe IEEE 1997 International 
Conference On Systems, Man and Cybernetics (SMC'97), pages 3355-3360, 1997. 
<p> </p> </dd> 
<dt> [800] </dt> 
<dd> Keiki Takadama, S.&nbsp;Nakasuka, and Takao Terano. On the credit 
assignment algorithm for organizational-learning oriented classifier system. In
The 1997 System/information joint Symposium of SICE (The Society of Instrument 
and Control Engineers), pages 41-46, 1997. In Japanese. 
<p> </p> </dd> 
<dt> [801] </dt> 
<dd> Keiki Takadama, S.&nbsp;Nakasuka, and Takao Terano. 
Organizational-learning oriented classifier system. InThe 11th Annual 
Conference of JSAI (Japanese Society for Artificial Intelligence), pages 
201-204, 1997. In Japanese.
<p> </p> </dd> 
<dt> [802] </dt> 
<dd> Keiki Takadama, S.&nbsp;Nakasuka, and Takao Terano. 
Organizational-learning oriented classifier system for intelligent multiagent 
systems. InThe 6th Multi Agent and Cooperative Computation (MACC '97) of JSSST 
(Japan Society for Software Science and Technology), 1997. In Japanese. 
<p> </p> </dd> 
<dt> [803] </dt> 
<dd> K.&nbsp;Takadama, S.&nbsp;Nakasuka, and T.&nbsp;Terano. Multiagent 
reinforcement learning with organizational-learning oriented classifier system. 
InThe IEEE 1998 International Conference On Evolutionary Computation (ICEC'98), 
pages 63-68, 1998.
<p> </p> </dd> 
<dt> [804] </dt> 
<dd> Keiki Takadama, S.&nbsp;Nakasuka, and Takao Terano. Analyzing the roles 
of problem solving and learning in organizational-learning oriented classifier 
system. In H.&nbsp;Y. Lee and H.&nbsp;Motoda, editors,Lecture Notes in 
Artificial Intelligence, volume 1531, pages 71-82. Springer-Verlag, 1998. 
<p> </p> </dd> 
<dt> [805] </dt> 
<dd> Keiki Takadama, Takao Terano, and Katsunori Shimohara. Agent-based model 
toward organizational computing: From organizational learning to genetics-based 
machine learning. InThe IEEE 1999 International Conference On Systems, Man and 
Cybernetics (SMC'99), volume&nbsp;2, pages 604-609, 1999. 
<p> </p> </dd> 
<dt> [806] </dt> 
<dd> Keiki Takadama, Takao Terano, and Katsunori Shimohara. Can multiagents 
learn in organization? -- analyzing organizational learning-oriented classifier 
system. InIJCAI'99 Workshop on Agents Learning about, from and other Agents, 
1999.
<p> </p> </dd> 
<dt> [807] </dt> 
<dd> Keiki Takadama, Takao Terano, Katsunori Shimohara, H.&nbsp;Hori, and 
S.&nbsp;Nakasuka. Making Organizational Learning Operational: Implications from 
Learning Classifier System.Computational and Mathematical Organization Theory 
(CMOT), 5(3):229-252, 1999. 
<p> </p> </dd> 
<dt> [808] </dt> 
<dd> Keiki Takadama, Takao Terano, Katsunori Shimohara, H.&nbsp;Hori, and 
S.&nbsp;Nakasuka. Toward emergent problem solving by distributed classifier 
systems based on organizational learning.Transactions of SICE (the Society of 
Instrument and Control Engineers), 35(11):1486-1495, 1999. In Japanese. 
<p> </p> </dd> 
<dt> [809] </dt> 
<dd> K.&nbsp;Takadama, H.&nbsp;Inoue, and K.&nbsp;Shimohara. How to 
autonomously decide boundary between self and others? InThe Third Asia-Pacific 
Conference on Simulated Evolution And Learning (SEAL'2000), 2000. 
<p> </p> </dd> 
<dt> [810] </dt> 
<dd> K.&nbsp;Takadama, T.&nbsp;Terano, and K.&nbsp;Shimohara. Designing 
multiple agents using learning classifier systems. InThe 4th Japan-Australia 
Joint Workshop on Intelligent and Evolutionary Systems (JA'2000), 2000. 
<p> </p> </dd> 
<dt> [811] </dt> 
<dd> Keiki Takadama, Shinichi Nakasuka, and Kasunori Shimohara. Designing 
multiple agents using learning classifier systems - suggestions from three 
levels analyses. InTakadama [815]. 
<p> </p> </dd> 
<dt> [812] </dt> 
<dd> Keiki Takadama, Takao Terano, and Katsunori Shimohara. Learning 
Classifier Systems meet Multiagent Environments. InProceedings of the 
International Workshop on Learning Classifier Systems (IWLCS-2000), in the 
Joint Workshops of SAB 2000 and PPSN 2000 [487]. Extended abstract. 
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [813] </dt> 
<dd> K.&nbsp;Takadama, H.&nbsp;Inoue, M.&nbsp;Okada, K.&nbsp;Shimohara, , and 
O.&nbsp;Katai. Agent architecture based on interactive self-reflection 
classifier system.International Journal of Artificial Life and Robotics (AROB), 
2001.
<p> </p> </dd> 
<dt> [814] </dt> 
<dd> K.&nbsp;Takadama, S.&nbsp;Nakasuka, and K.&nbsp;Shimhara. Robustness in 
Organizational-learning Oriented Classifier System.Journal of Soft Computing, 
6(3-4):229-239, 2002.
<p> </p> </dd> 
<dt> [815] </dt> 
<dd> Keiki Takadama, editor. Exploring New Potentials in Learning Classifier 
Systems. A Session of the 4th Japan-Australia Joint Workshop on Intelligent and 
Evolutionary Systems. Ashikaga Institute of Technology, 2000. 
<p> </p> </dd> 
<dt> [816] </dt> 
<dd> Keiki Takadama. Organizational-learning oriented classifier system. 
Technical Report TR-H-290, ATR, 2000. In Japanese.
<p> </p> </dd> 
<dt> [817] </dt> 
<dd> K.&nbsp;Tammee, L.&nbsp;Bull, and P.&nbsp;Ouen. Towards clustering with 
learning classifier systems. In L.&nbsp;Bull, E.&nbsp;Bernad&ograve;-Mansilla, 
and J.&nbsp;Holmes, editors,Learning Classifier Systems in Data Mining, pages 
191-204. Springer, 2008.
<p> </p> </dd> 
<dt> [818] </dt> 
<dd> Takao Terano and Z.&nbsp;Muro. On-the-fly knowledge base refinement by a 
classifier system.AI Communications, 4(2), 1994. 
<p> </p> </dd> 
<dt> [819] </dt> 
<dd> Takao Terano and Keiki Takadama. An organizational learning model of 
multiagents with a learning classifier system. InThe 1997 Fall Conference of 
JASMIN (Japan Society for Management Information), pages 128-131, 1997. In 
Japanese.
<p> </p> </dd> 
<dt> [820] </dt> 
<dd> K.&nbsp;Tharakannel and D.&nbsp;Goldberg. XCS with average reward 
criterion in multi-step environment. Technical report, Illinois Genetic 
Algorithms Laboratory, University of Illinois at Urbana-Champaign, 2002.
<p> </p> </dd> 
<dt> [821] </dt> 
<dd> Kurian&nbsp;K. Tharakunnel, Martin&nbsp;V. Butz, and David&nbsp;E. 
Goldberg. Towards building block propagation in XCS: A negative result and its 
implications. In E.&nbsp;Cant&uacute;-Paz, J.&nbsp;A. Foster, K.&nbsp;Deb, 
D.&nbsp;Davis, R.&nbsp;Roy, U.-M. O'Reilly, H.-G. Beyer, R.&nbsp;Standish, 
G.&nbsp;Kendall, S.&nbsp;Wilson, M.&nbsp;Harman, J.&nbsp;Wegener, 
D.&nbsp;Dasgupta, M.&nbsp;A. Potter, A.&nbsp;C. Schultz, K.&nbsp;Dowsland, 
N.&nbsp;Jonoska, and J.&nbsp;Miller, editors,Genetic and Evolutionary 
Computation -- GECCO-2003, volume 2724 of LNCS, pages 1906-1917. 
Springer-Verlag, 2003.
<p> </p> </dd> 
<dt> [822] </dt> 
<dd> P.&nbsp;Thrift. Fuzzy logic synthesis with genetic algorithms. In 
Lashon&nbsp;B. Booker and Richard&nbsp;K. Belew, editors,Proceedings of 4th 
international conference on genetic algorithms (ICGA'91), pages 509-513. Morgan 
Kaufmann, 1991.
<p> </p> </dd> 
<dt> [823] </dt> 
<dd> S.&nbsp;Tokinaga and A.&nbsp;B. Whinston. Applying Adaptive Credit 
Assignment Algorithm for the Learning Classifier System Based upon the Genetic 
Algorithm.IEICE Transactions on Fundamentals of Electronics Communications and 
Computer Sciences, VE75A(5):568-577, May 1992. 
<p> </p> </dd> 
<dt> [824] </dt> 
<dd> Andy Tomlinson and Larry Bull. A Corporate Classifier System. In 
A.&nbsp;E. Eiben, T.&nbsp;B&auml;ck, M.&nbsp;Shoenauer, and H.-P. Schwefel, 
editors,Proceedings of the Fifth International Conference on Parallel Problem 
Solving From Nature -- PPSN V, number 1498 in LNCS, pages 550-559. Springer 
Verlag, 1998.
<blockquote> Based on the proposals of Wilson and Goldberg we introduce a 
macro-level evolutionary operator which creates structural links between rules 
in the ZCS model and thus forms ``corporations'' of rules within the classifier 
system population. Rule co-dependencies influence both the behaviour of the 
discovery components of the system and the production system, where a 
corporation can take control for a number of time-steps. The system is compared 
to ZCS and also ZCSM in a number of maze environments which include Woods1 and 
Woods7. The corporate classifier system is shown to be the most suitable design 
to tackle a range of these types of problems.</blockquote> 
<p> </p> </dd> 
<dt> [825] </dt> 
<dd> Andy Tomlinson and Larry Bull. A Corporate XCS. In Wu [923], pages 
298-305.
<blockquote> Previously we have applied rule linkage to ZCS and shown that the 
resultant system demonstrates performance improvements over ZCS in a series of 
sequential tasks, particularly tasks which present ambiguous stimuli to the 
system. In this paper we show that similar benefits can be gained by applying 
rule linkage to the more complex XCS. We then show that the benefits of 
rule-linkage can be increased by further XCS specific modifications to the 
system's rule-linkage mechanisms.</blockquote> 
<p> </p> </dd> 
<dt> [826] </dt> 
<dd> Andy Tomlinson and Larry Bull. On Corporate Classifier Systems: 
Increasing the Benefits of Rule Linkage. InBanzhaf et&nbsp;al. [32], pages 
649-656.
<blockquote> Our previous implementation of a Corporate Classifier System 
(CCS), which introduces rule-linkage to a ZCS-based system, has been shown to 
demonstrate performance improvements over ZCS in a series of sequential tasks, 
particularly those which present arbitrary sensory ambiguities to the system. 
In this paper, the functionality of our CCS is enhanced to provide increased 
benefits regarding the same class of sequential evaluation tasks.</blockquote> 
<p> </p> </dd> 
<dt> [827] </dt> 
<dd> Andy Tomlinson and Larry Bull. A zeroth level corporate classifier system
. InWu [923], pages 306-313. 
<blockquote> It has long been recognised that increased co-operation amongst 
the classifiers in a Michigan-style classifier system may resolve some of the 
established difficulties associated with the design. One approach to this was 
proposed by Wilson and Goldberg -- the ``corporate'' classifier system. In this 
paper we implement the ``corporate'' classifier system design, within Wilson's 
ZCS, in such a way that it complies with their theoretical proposals. In the 
resultant system , a zeroth-level corporate classifier system, all classifiers 
initially stand alone but during the course of evolution, a mutation-type 
operator is used to couple together classifiers by means of structural links. 
Linked classifiers are considered to represent a corporation, and are treated 
as a unit by the discovery mechanism of the system. This is achieved by the use 
of a macro-level evolutionary operator called ``corporate crossover''. In this 
design the production system remains oblivious to corporations and operates as 
ZCS. A technique referred to as concept analysis is introduced which is used to 
clarify the effects of such rule associations, as implemented here, within a 
Michigan-style classifier system.</blockquote> 
<p> </p> </dd> 
<dt> [828] </dt> 
<dd> Andy Tomlinson and Larry Bull. A Corporate XCS. In Lanzi et&nbsp;al. [544]
, pages 194-208.
<blockquote> Previously we have applied rule linkage to ZCS and shown that the 
resultant system demonstrates performance improvements over ZCS in a series of 
sequential tasks, particularly tasks which present ambiguous stimuli to the 
system. In this paper we show that similar benefits can be gained by applying 
rule linkage to the more complex XCS. We then show that the benefits of 
rule-linkage can be increased by further XCS specific modifications to the 
system's rule-linkage mechanisms.</blockquote> 
<p> </p> </dd> 
<dt> [829] </dt> 
<dd> Andy Tomlinson and Larry Bull. Cxcs: Improvements and corporate 
generalization. In Lee Spector, Erik&nbsp;D. Goodman, Annie Wu, W.B. Langdon, 
Hans-Michael Voigt, Mitsuo Gen, Sandip Sen, Marco Dorigo, Shahram Pezeshk, 
Max&nbsp;H. Garzon, and Edmund Burke, editors,Proceedings of the Genetic and 
Evolutionary Computation Conference (GECCO-2001), pages 966-973, San Francisco, 
California, USA, 7-11 July 2001. Morgan Kaufmann.
<p> </p> </dd> 
<dt> [830] </dt> 
<dd> Andy Tomlinson and Larry Bull. An accuracy-based corporate classifier 
system.Journal of Soft Computing, 6(3-4):200-215, 2002. 
<p> </p> </dd> 
<dt> [831] </dt> 
<dd> Andy Tomlinson. Corporate Classifier Systems. PhD thesis, University of 
the West of England, 1999.
<p> </p> </dd> 
<dt> [832] </dt> 
<dd> Dave Toney. Evolutionary Reinforcement Learning of Spoken Dialogue 
Strategies. PhD thesis, University of Edinburgh, 2007. 
<blockquote> From a system developer's perspective, designing a spoken 
dialogue system can be a time-consuming and difficult process. A developer may 
spend a lot of time anticipating how a potential user might interact with the 
system and then deciding on the most appropriate system response. These 
decisions are encoded in a dialogue strategy, essentially a mapping between 
anticipated user inputs and appropriate system outputs. To reduce the time and 
effort associated with developing a dialogue strategy, recent work has 
concentrated on modelling the development of a dialogue strategy as a 
sequential decision problem. Using this model, reinforcement learning 
algorithms have been employed to generate dialogue strategies automatically. 
These algorithms learn strategies by interacting with simulated users. Some 
progress has been made with this method but a number of important challenges 
remain. For instance, relatively little success has been achieved with the 
large state representations that are typical of real-life systems. Another 
crucial issue is the time and effort associated with the creation of simulated 
users. In this thesis, I propose an alternative to existing reinforcement 
learning methods of dialogue strategy development. More specifically, I explore 
how XCS, an evolutionary reinforcement learning algorithm, can be used to find 
dialogue strategies that cover large state spaces. Furthermore, I suggest that 
hand-coded simulated users are sufficient for the learning of useful dialogue 
strategies. I argue that the use of evolutionary reinforcement learning and 
hand-coded simulated users is an effective approach to the rapid development of 
spoken dialogue strategies. Finally, I substantiate this claim by evaluating a 
learned strategy with real users. Both the learned strategy and a 
state-of-the-art hand-coded strategy were integrated into an end-to-end spoken 
dialogue system. The dialogue system allowed real users to make flight 
enquiries using a live database for an Edinburgh-based airline. The performance 
of the learned and hand-coded strategies were compared. The evaluation results 
show that the learned strategy performs as well as the hand-coded one (81% and 
77% task completion respectively) but takes much less time to design (two days 
instead of two weeks). Moreover, the learned strategy compares favourably with 
previous user evaluations of learned strategies.</blockquote> 
<p> </p> </dd> 
<dt> [833] </dt> 
<dd> T.H. Tran, C.&nbsp;Sanza, Y.&nbsp;Duthen, and T.D. Nguyen. XCSF with 
computed continuous action. InGenetic and evolutionary computation conference 
(GECCO 2007), pages 1861-1869. ACM, 2007. 
<p> </p> </dd> 
<dt> [834] </dt> 
<dd> Kwok&nbsp;Ching Tsui and Mark Plumbley. A New Hillclimber for Classifier 
Systems. InGALESI97, 1997. 
<blockquote> Multi-state artificial environments such as mazes represent a 
class of tasks that can be solved by many different multi-step methods. When 
different rewards are available in different places of the maze, a problem 
solver is required to evaluate different positions effectively and remembers 
the best one. A new hillclimbing strategy for the Michigan style classifier 
system is suggested which is able to find the shortest path and discarding 
sub-optimal solutions. Knowledge reuse is also shown to be possible.
</blockquote> 
<p> </p> </dd> 
<dt> [835] </dt> 
<dd> Patrick Tufts. Evolution of a Clustering Scheme for Classifier Systems: 
Beyond the Bucket Brigade. PhD Thesis proposal. 
http://www.cs.brandeis.edu/~zippy/papers.htm, 1994.
<blockquote> The Classifier System is a learning mechanism that explores the 
space of steps leading to a reward. It credits rules leading to a reward 
through a temporal difference method called a bucket brigade in which each step 
passes some of its reward to the step that preceded it. The bucket brigade 
rewards all the steps in a chain, given enough time. However, the classifiers 
in a population are in competition with each other, so delays in rewarding key 
steps may result in those steps being crowded out by others. The main 
hypothesis of this proposal is that the combination of a clustering operator 
with a classifier system will aid in the formation of long chains. This 
combination has potential applications for discovering useful variable-length 
representations for classifier systems, further enhancing their ability to 
learn, and can be applied to the field of Genetic Programming to discover 
useful building blocks.</blockquote> 
<p> </p> </dd> 
<dt> [836] </dt> 
<dd> Patrick Tufts. Dynamic Classifiers: Genetic Programming and Classifier 
Systems. In E.&nbsp;V. Siegel and J.&nbsp;R. Koza, editors, Working Notes for 
the AAAI Symposium on Genetic Programming, pages 114-119, MIT, Cambridge, MA, 
USA, 1995. AAAI.
<blockquote> The Dynamic Classifier System extends the traditional classifier 
system by replacing its fixed-width ternary representation with Lisp 
expressions. Genetic programming applied to the classifiers allows the system 
to discover building blocks in a flexible, fitness directed manner. In this 
paper, I describe the prior art of problem decomposition using genetic 
programming and classifier systems. I then show how the proposed system builds 
on work in these two areas, extending them in a way that provides for flexible 
representation and fitness directed discovery of useful building blocks.
</blockquote> 
<p> </p> </dd> 
<dt> [837] </dt> 
<dd> Kirk Twardowski. Implementation of a Genetic Algorithm based Associative 
Classifier System (ACS). InProceedings International Conference on Tools for 
Artificial Intelligence, 1990. 
<p> </p> </dd> 
<dt> [838] </dt> 
<dd> Kirk Twardowski. Credit Assignment for Pole Balancing with Learning 
Classifier Systems. InForrest [335], pages 238-245. 
<blockquote> Effective reinforcement learning methods are essential for credit 
assignment in learning classifier systems in order to guide the structural 
rule-base modifications performed by genetic algorithms. Currently, a number of 
algorithms have been proposed to fulfill this fundamental need; the most 
frequently employed being the bucket-brigade algorithm. In this paper, an 
experimental evaluation of a number of reinforcement learning algorithms for a 
variety of parameter settings is presented. A simplified learning classifier 
system is used in order to minimize system complexity in order to isolate the 
behavior of the reinforcement learning algorithms. The problem domain tackled 
is that of the control of an unstable dynamic system. It was discovered that 
exploitation of current information is highly favored over exploration for new 
information and that a hybrid bucket brigade-backward averaging algorithm 
produced the fastest convergence to a solution.</blockquote> 
<p> </p> </dd> 
<dt> [839] </dt> 
<dd> Kirk Twardowski. An Associative Architecture for Genetic Algorithm-Based 
Machine Learning.Computer, 27(11):27-38, November 1994. 
<blockquote> Machine-based learning will eventually be applied to solve 
real-world problems. Here, an associative architecture teams with hybrid AI 
algorithms to solve a letter prediction problem with promising results.
</blockquote> 
<p> </p> </dd> 
<dt> [840] </dt> 
<dd> Olgierd Unold and Grzegorz Dabrowski. Use of learning classifier system 
for inferring natural language grammar. In Tim Kovacs, Xavier LL&ograve;ra, 
Keiki Takadama, Pier&nbsp;Luca Lanzi, Wolfgang Stolzmann, and Stewart&nbsp;W. 
Wilson, editors,Learning Classifier Systems. International Workshops, IWLCS 
2003-2005, Revised Selected Papers, volume 4399 of LNCS, pages 17-24. Springer, 
2007.
<p> </p> </dd> 
<dt> [841] </dt> 
<dd> J.&nbsp;Urzelai, Dario Floreano, Marco Dorigo, and Marco Colombetti. 
Incremental Robot Shaping.Connection Science, 10(3-4):341-360, 1998. 
<p> </p> </dd> 
<dt> [842] </dt> 
<dd> J.&nbsp;Urzelai, Dario Floreano, Marco Dorigo, and Marco Colombetti. 
Incremental Robot Shaping. InKoza et&nbsp;al. [529], pages 832-840. 
<p> </p> </dd> 
<dt> [843] </dt> 
<dd> Manuel Valenzuela-Rend&oacute;n and Eduardo Uresti-Charre. A Non-Genetic 
Algorithm for Multiobjective Optimization. InB&auml;ck [24], pages 658-665. 
<blockquote> This paper describes a non-generational genetic algorithm for 
multiobjective optimisation. The fitness of each individual in the population 
is calculated incrementally based on the degree in which it is dominated in the 
Pareto sense, or close to other individuals. The closeness of individuals is 
measured using a sharing function. The performance of the algorithm presented 
is compared to previous efforts on three multiobjective problems of growing 
difficulty. The behavior of each algorithm is analyzed with regard to the 
visited search space, the quality of the final population attained,and the 
percentage of non-dominated individuals in the population through time. 
According to all these performance measures, the algorithm presented clearly 
outperforms previous efforts based on genetic algorithms.</blockquote> 
<p> </p> </dd> 
<dt> [844] </dt> 
<dd> Manuel Valenzuela-Rend&oacute;n. Boolean Analysis of Classifier Sets. In 
Schaffer [718], pages 351-358. 
<blockquote> In this paper a new analysis tool for classifier systems is 
presented: the Boolean analysis of classifier sets. This tool is applied to 
determine the minimal classifier sets that perform a general learning task in 
stimulus-response mode. Modifications to classical Boolean minimization 
techniques to accommodate for the minimization of default hierarchies are 
studied. This Boolean analysis is used to determine the relation between the 
size of a Boolean function and the minimal number of levels required in its 
minimal default hierarchy. Finally, the concept of parsimony or savings of 
rules produced by the formation of default hierarchies is discussed.
</blockquote> 
<p> </p> </dd> 
<dt> [845] </dt> 
<dd> Manuel Valenzuela-Rend&oacute;n. Two analysis tools to describe the 
operation of classifier systems. PhD thesis, University of Alabama, 1989. Also 
TCGA technical report 89005.
<blockquote> This document has no abstract. </blockquote> 
<p> </p> </dd> 
<dt> [846] </dt> 
<dd> Manuel Valenzuela-Rend&oacute;n. The Fuzzy Classifier System: a 
Classifier System for Continuously Varying Variables. InBooker and Belew [74], 
pages 346-353.
<blockquote> This paper presents the fuzzy classifier system which merges the 
ideas behind classifier systems and fuzzy controllers. The fuzzy classifier 
system learns by creating fuzzy rules which relate the values of the input 
variables to internal or output variables. It has credit assignment mechanisms 
which reassemble those of common classifier systems, but with a fuzzy nature. 
The fuzzy classifier system employs a genetic algorithm to evolve adequate 
fuzzy rules. Preliminary results show that the fuzzy classifier system can 
effectively create fuzzy rules that imitate the behavior of simple static 
systems.</blockquote> 
<p> </p> </dd> 
<dt> [847] </dt> 
<dd> Manuel Valenzuela-Rend&oacute;n. The Fuzzy Classifier System: Motivations 
and First Results. In Hans-Paul Schwefel and Reinhard M&auml;nner, editors,
Parallel Problem Solving from Nature (PSSN-1), volume 496 of Lecture Notes in 
Computer Science, pages 338-342, 1991. 
<p> </p> </dd> 
<dt> [848] </dt> 
<dd> Manuel Valenzuela-Rend&oacute;n. Reinforcement learning in the fuzzy 
classifier system. InCollected Abstracts for the First International Workshop 
on Learning Classifier System (IWLCS-92) [486]. October 6-8, NASA Johnson Space 
Center, Houston, Texas.
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [849] </dt> 
<dd> Manuel Valenzuela-Rend&oacute;n. Reinforcement learning in the fuzzy 
classifier system.Expert Systems Applications, 14:237-247, 1998. 
<p> </p> </dd> 
<dt> [850] </dt> 
<dd> R.&nbsp;Vallim, D.&nbsp;Goldberg, X.&nbsp;Llor&agrave;, T.&nbsp;Duque, 
and A.&nbsp;Carvalho. A new approach for multi-label classification based on 
default hierarchies and organizational learning. InProceedings of the Genetic 
and Evolutionary Computation Conference, Worrkshop Sessions: Learning 
Classifier Systems, pages 2017-2022, 2003. 
<p> </p> </dd> 
<dt> [851] </dt> 
<dd> Terry van Belle. A New Approach to Genetic-Based Automatic Feature 
Discovery. Master's thesis, University of Alberta, 1995. 
http://www.cs.ualberta.ca/~jonathan/.
<blockquote> Systems which take raw data and categorize them into discrete 
classes are ubiquitous in computer science, having applications in fields such 
as vision, expert systems, and game playing. These systems work by extracting 
features from the data and then combining the values of the features to form a 
judgement. While much work has been done on ways to automatically combine 
feature values, the task of automatic discovery of these features is recognized 
to be much more difficult, and so has become one of the holy grails of machine 
learning. Classifier systems, an outgrowth of genetic algorithms, seemed a 
promising approach to automatic feature discovery, but it is difficult to get 
the full power of the classifier system from existing implementations. This 
thesis simplifies the classifier system into a variant of the genetic 
algorithm, called the Population Genetic Algorithm (PGA). PGAs are used to 
automatically discover features for tic-tac-toe and checkers endgame positions, 
and these features are automatically combined using Bayesian statistics to 
classify each position as won, lost, or drawn. The theoretical maximum 
performance of the PGAs is determined by using an exhaustive enumeration 
technique to serve as a baseline comparison. The results indicate that while 
PGAs can be made to perform at near-optimal levels, the optimal solution is 
insufficient to perfectly classify any of the domains studied.</blockquote> 
<p> </p> </dd> 
<dt> [852] </dt> 
<dd> Patricia&nbsp;Amancio Vargas, Christiano&nbsp;Lyra Filho, and Fernando 
J.&nbsp;Von Zuben. On-line approach for loss reduction in electric power 
distribution networks using learning classifier systems. InLanzi et&nbsp;al. 
[546], pages 181-196. 
<p> </p> </dd> 
<dt> [853] </dt> 
<dd> G.&nbsp;Venturini. SIA: A supervised inductive algorithm with genetic 
search for learning attributes based concepts. In P.B. Brazdil, editor,ECML-93 
- Proc. of the European Conference on Machine Learning, pages 280-296. 
Springer-Verlag, 1993.
<p> </p> </dd> 
<dt> [854] </dt> 
<dd> Gilles Venturini. Apprentissage Adaptatif et Apprentissage 
Supervis&eacute; par Algorithme G&eacute;n&eacute;tique. PhD thesis, 
Universit&eacute; de Paris-Sud., 1994.
<p> </p> </dd> 
<dt> [855] </dt> 
<dd> Nickolas Vriend. Self-Organization of Markets: An Example of a 
Computational Approach.Computational Economics, 8(3):205-231, 1995. 
<blockquote> A model of decentralized trade is simulated with firms that 
produce a given commodity, and consumers who repeatedly wish to purchase one 
unit of that commodity. Consumers 'shop around', while firms may attract the 
attention of potential customers by sending information signals and offering 
good service. The main objective of this paper is to present an example of a 
computational approach to address the following question: How do self-organized 
markets emerge in the economy, and what are their characteristics?</blockquote> 
<p> </p> </dd> 
<dt> [856] </dt> 
<dd> A.&nbsp;Wada, K.&nbsp;Takadama, K.&nbsp;Shimohara, and O.&nbsp;Katai. 
Learning classifier systems with convergence and generalization. In 
L.&nbsp;Bull and T.&nbsp;Kovacs, editors,Foundations of learning classifier 
systems, pages 285-304. Springer, 2005. 
<p> </p> </dd> 
<dt> [857] </dt> 
<dd> Atsushi Wada, Keiki Takadama, and Katsunori Shimohara. Counter example 
for q-bucket-brigade under prediction problem. InGECCO Workshops 2005, pages 
94-99. ACM Press, 2005.
<blockquote> Aiming to clarify the convergence or divergence conditions for 
Learning Classifier System (LCS), this paper explores: (1) an extreme condition 
where the reinforcement process of LCS diverges; and (2) methods to avoid such 
divergence. Based on our previous work that showed equivalence between LCS's 
reinforcement process and Reinforcement Learning (RL) with Function 
approximation (FA) method, we present a counter-example for LCS with 
Q-bucket-brigade based on the 11-state star problem, a counter-example 
originally proposed to show the divergence of Q-learning with linear FA. 
Furthermore, the empirical results applying the counter-example to LCS verified 
the results predicted from the theory: (1) LCS with Q-bucket-brigade diverged 
under the prediction problem, where the action selection policy was fixed; and 
(2) such divergence was avoided by using implicit-bucket-brigade or applying 
residual gradient algorithm to Q-bucket-brigade.</blockquote> 
<p> </p> </dd> 
<dt> [858] </dt> 
<dd> Atsushi Wada, Keiki Takadama, and Katsunori Shimohara. Learning 
classifier system equivalent with reinforcement learning with function 
approximation. InGECCO Workshops 2005, pages 92-93. ACM Press, 2005. 
<blockquote> We present an experimental comparison of the reinforcement 
process between Learning Classifier System (LCS) and Reinforcement Learning 
(RL) with function approximation (FA) method, regarding their generalization 
mechanisms. To validate our previous theoretical analysis that derived 
equivalence of reinforcement process between LCS and RL, we introduce a simple 
test environment named Gridworld, which can be applied to both LCS and RL with 
three different classes of generalization: (1) tabular representation; (2) 
state aggregation; and (3) linear approximation. From the simulation 
experiments comparing LCS with its GA-inactivated and corresponding RL method, 
all the cases regarding the class of generalization showed identical results 
with the criteria of performance and temporal difference (TD) error, thereby 
verifying the equivalence predicted from the theory.</blockquote> 
<p> </p> </dd> 
<dt> [859] </dt> 
<dd> Atsushi Wada, Keiki Takadama, and Katsunori Shimohara. Counter example 
for q-bucket-brigade under prediction problem. In Tim Kovacs, Xavier 
LL&ograve;ra, Keiki Takadama, Pier&nbsp;Luca Lanzi, Wolfgang Stolzmann, and 
Stewart&nbsp;W. Wilson, editors,Learning Classifier Systems. International 
Workshops, IWLCS 2003-2005, Revised Selected Papers, volume 4399 of LNCS, pages 
128-143. Springer, 2007.
<p> </p> </dd> 
<dt> [860] </dt> 
<dd> Atsushi Wada, Keiki Takadama, Katsunori Shimohara, and Osamu Katai. 
Analyzing parameter sensitivity and classifier representations for real-valued 
xcs. In Tim Kovacs, Xavier LL&ograve;ra, Keiki Takadama, Pier&nbsp;Luca Lanzi, 
Wolfgang Stolzmann, and Stewart&nbsp;W. Wilson, editors,Learning Classifier 
Systems. International Workshops, IWLCS 2003-2005, Revised Selected Papers, 
volume 4399 ofLNCS, pages 1-16. Springer, 2007. 
<p> </p> </dd> 
<dt> [861] </dt> 
<dd> David Walter and Chilukuri&nbsp;K. Mohan. ClaDia: A Fuzzy Classifier 
System for Disease Diagnosis. InProceedings of the 2000 Congress on 
Evolutionary Computation (CEC00) [185], pages 1429-1435. 
<blockquote> This paper describes ClaDia, a learning classifier system applied 
to the Wisconsin breast cancer data set, using a fuzzy representation of the 
rules, a median-based fuzzy combination rule, and separate subpopulations for 
each class. The system achieves a classification rate of over 90%, for many 
sets of system parameter values.</blockquote> 
<p> </p> </dd> 
<dt> [862] </dt> 
<dd> L.&nbsp;A. Wang. Classifier System Learning of the Boolean Multiplexer 
Function. Master's thesis, Computer Science Department, University of 
Tennessee, Knoxville, TN, 1990.
<p> </p> </dd> 
<dt> [863] </dt> 
<dd> Gerhard Weiss. Action-oriented learning in classifier systems. Technical 
Report FKI-158-91, Technical Univ. M&uuml;nchen (TUM), 1991.
<p> </p> </dd> 
<dt> [864] </dt> 
<dd> Gerhard Weiss. The Action-Oriented Bucket Brigade. Technical Report 
FKI-156-91, Technical Univ. M&uuml;nchen (TUM), 1991.
<p> </p> </dd> 
<dt> [865] </dt> 
<dd> Gerhard Weiss. Hierarchical chunking in classifier systems. In 
Proceedings of the 12th National Conference on Artificial Intelligence, pages 
1335-1340. AAAI Press/MIT Press, 1994.
<p> </p> </dd> 
<dt> [866] </dt> 
<dd> Gerhard Weiss. Learning by chunking in reactive classifier systems. 
Technical report, Technical Univ. M&uuml;nchen (TUM), 1994.
<p> </p> </dd> 
<dt> [867] </dt> 
<dd> Gerhard Weiss. The locality/globality dilemma in classifier systems and 
an approach to its solution. Technical Report FKI-187-94, Technical Univ. 
M&uuml;nchen (TUM), 1994.
<p> </p> </dd> 
<dt> [868] </dt> 
<dd> Gerhard Weiss. An action-oriented perspective of learning in classifier 
systems. Journal of Experimental and Theoretical Artificial Intelligence, 
8:43-62, 1996.
<blockquote> Classifier systems constitute a general model of low-level 
rule-based systems that are capable of environmental interaction and learning. 
A central characteristic and drawback of the traditional approaches to learning 
in such systems is that they exclusively work on the rule level, without taking 
into consideration that the individual rules possess a very complex activity 
behavior. This article investigates an alternative, action-oriented perspective 
of learning in classifier systems which does not suffer from this drawback. 
According to this perspective learning is realized on the finer action level 
instead of the coarser rule level. Comparative theoretical and experimental 
results are presented that show the advantages of the action-oriented over the 
traditional perspective.</blockquote> 
<p> </p> </dd> 
<dt> [869] </dt> 
<dd> Thomas&nbsp;H. Westerdale. The bucket brigade is not genetic. In 
Grefenstette [389], pages 45-59. 
<p> </p> </dd> 
<dt> [870] </dt> 
<dd> Thomas&nbsp;H. Westerdale. A Reward Scheme for Production Systems with 
Overlapping Conflict Sets.IEEE Transactions on Systems, Man and Cybernetics, 
SMC-16(3):369-383, 1986.
<p> </p> </dd> 
<dt> [871] </dt> 
<dd> Thomas&nbsp;H. Westerdale. Altruism in the bucket brigade. In Grefenstette
[391], pages 22-26. 
<p> </p> </dd> 
<dt> [872] </dt> 
<dd> Thomas&nbsp;H. Westerdale. A Defence of the Bucket Brigade. In Schaffer 
[718], pages 282-290. 
<blockquote> The bucket brigade does indeed suffer from detrimental biases. 
Profit sharing can avoid these only if productions are properly penalized for 
eligibility, and more importantly, if the span over which profit is shared is 
long enough. Such a long span introduces much sampling noise, with its often 
unacceptable danger of premature convergence. The bucket brigade is designed to 
reduce this noise.</blockquote> 
<p> </p> </dd> 
<dt> [873] </dt> 
<dd> Thomas&nbsp;H. Westerdale. Quasimorphisms or Queasymorphisms? Modelling 
Finite Automaton Environments. InRawlins [674], pages 128-147. 
<blockquote> The paper examines models that are homomorphic images of the 
first component of a particular two component cascade decomposition of the 
environment. The bucket brigade is used to estimate model state values. The 
discussion is limited to finite automaton environments whose successive input 
symbols are selected by the system probabilistically, with independent 
probabilities, according to a probability distribution over the input symbols.
</blockquote> 
<p> </p> </dd> 
<dt> [874] </dt> 
<dd> Thomas&nbsp;H. Westerdale. Redundant Classifiers and Prokaryote Genomes. 
InBooker and Belew [74], pages 354-360. 
<blockquote> Redundant classifiers waste space. This paper suggests an 
approach to the problem of classifier redundancy based on the cost of gene 
replication. The approach stems from the view that reduction and simplification 
are the essence of the evolutionary creative process, and that the most 
advanced organisms are Prokaryotes, not Eukaryotes.</blockquote> 
<p> </p> </dd> 
<dt> [875] </dt> 
<dd> Thomas&nbsp;H. Westerdale. Classifier Systems - No Wonder They Don't 
Work. InKoza et&nbsp;al. [528], pages 529-537. 
<blockquote> Classifier system formalism provides valuable conceptual test 
beds that help us come to grips with fundamental problems of credit assignment 
in learning systems. Here we discuss the horizon problem, the sampling noise 
problem, the problem of removing redundancy to save space, and the freeloader 
problem, this last being a collection of problems including the problem of ill 
formed conditions. Classifier systems can help provide answers. But until we 
have some answers, experimental systems will remain flawed.</blockquote> 
<p> </p> </dd> 
<dt> [876] </dt> 
<dd> Thomas&nbsp;H. Westerdale. An Approach to Credit Assignment in Classifier 
Systems.Complexity, 4(2), 1999. 
<p> </p> </dd> 
<dt> [877] </dt> 
<dd> Thomas&nbsp;H. Westerdale. Wilson's Error Measurement and the Markov 
Property -- Identifying Detrimental Classifiers. In Wu [923], pages 314-321. 
<blockquote> Wilson's error measurement is an important conceptual tool in the 
study of classifier system reward schemes. It tests classifiers to see where 
the Markov property detrimentally fails. Incorporating this test directly into 
a reward scheme involves difficulties. But the use of the error measurement in 
analysis, and indeed in experimentation, should help advance our understanding 
of credit assignment issues.</blockquote> 
<p> </p> </dd> 
<dt> [878] </dt> 
<dd> Darrell Whitely, David Goldberg, Erick Cant&uacute;-Paz, Lee Spector, Ian 
Parmee, and Hans-Georg Beyer, editors.Proceedings of the Genetic and 
Evolutionary Computation Conference (GECCO-2000). Morgan Kaufmann, 2000. 
<p> </p> </dd> 
<dt> [879] </dt> 
<dd> Jason&nbsp;R. Wilcox. Organizational Learning within a Learning 
Classifier System. Master's thesis, University of Illinois, 1995. Also 
Technical Report No. 95003 IlliGAL.
<blockquote> This thesis recasts the debate between Michigan-style and 
Pitt-style classifier systems to a debate on appropriately sizing organizations 
within a learning classifier system. Motivated by the economic study of 
transaction costs, an organizational classifier system (OCS) combining explicit 
use of multiple reputation values and organization sizing operators better 
distinguishes parasitic (less than optimal) classifiers than a simple 
classifier system (SCS). The results show that by building a system that 
autonomously adjusts the degree of individual to collective behavior, it is 
possible for it to be both efficient and resilient to problem difficulty.
</blockquote> 
<p> </p> </dd> 
<dt> [880] </dt> 
<dd> Stewart&nbsp;W. Wilson and David&nbsp;E. Goldberg. A Critical Review of 
Classifier Systems. In Schaffer [718], pages 244-255. 
http://prediction-dynamics.com/.
<blockquote> The current state of classifier system development is examined 
with emphasis on challenges and unsolved problems. Suggestions related to the 
bucket-brigade architecture, the mechanics of bidding and payments, and 
classifier syntax follow a review of past research.</blockquote> 
<p> </p> </dd> 
<dt> [881] </dt> 
<dd> Stewart&nbsp;W. Wilson. Aubert processing and intelligent vision. 
Technical report, Polaroid Corporation, 1981.
<p> </p> </dd> 
<dt> [882] </dt> 
<dd> Stewart&nbsp;W. Wilson. On the retino-cortical mapping. International 
Journal of Man-Machine Studies, 18:361-389, 1983. 
<blockquote> Based on Hubel &amp; Wiesel's physiological findings on the 
projection from retina to cortex, a schematic model of that stage of visual 
processing is constructed and its properties investigated. The projection or 
mapping appears to carry out an automatic ``normalization of description'' for 
the same object independent of retinal image size. This property suggests new 
concepts regarding (1) contrast sensitivity, (2) the nature and role of 
indirect vision, (3) the role of eye movements and (4) the recognition of 
patterns and the analysis of scenes.</blockquote> 
<p> </p> </dd> 
<dt> [883] </dt> 
<dd> Stewart&nbsp;W. Wilson. Adaptive ``cortical'' pattern recognition. In 
Grefenstette [389], pages 188-196. 
<blockquote> It is shown that a certain model of the primate retino-cortical 
mapping ``sees'' all centered objects with the same ``object-resolution'', or 
number of distinct signals, independent of apparent size. In an artificial 
system, this property would permit recognition of patterns using templates in a 
cortex-like space. It is suggested that with an adaptive production system such 
as Holland's classifier system, the recognition process could be made 
self-organizing.</blockquote> 
<p> </p> </dd> 
<dt> [884] </dt> 
<dd> Stewart&nbsp;W. Wilson. Knowledge Growth in an Artificial Animal. In 
Grefenstette [389], pages 16-23. Also appeared in Proceedings of the 4th Yale. 
<blockquote> Results are presented of experiments with a simple artificial 
animal model acting in a simulated environment containing food and other 
objects. Procedures within the model that lead to improved performance and 
perceptual generalization are discussed. The model is designed in the light of 
an explicit definition of intelligence which appears to apply to all animal 
life. It is suggested that study of artificial animal models of increasing 
complexity would contribute to understanding of natural and artificial 
intelligence.</blockquote> 
<p> </p> </dd> 
<dt> [885] </dt> 
<dd> Stewart&nbsp;W. Wilson. Knowledge Growth in an Artificial Animal. In 
Proceedings of the 4th Yale Workshop on Applications of Adaptive Systems Theory
, pages 98-104, 1985.
<p> </p> </dd> 
<dt> [886] </dt> 
<dd> Stewart&nbsp;W. Wilson. Classifier System Learning of a Boolean Function. 
Technical Report RIS 27r, The Rowland Institute for Science, 1986.
<blockquote> A Simplified classifier system was given the task of learning a 
relatively difficult boolean function drawn from the machine learning 
literature. The system solved the problem in times comparable to or less than 
times required by a network method. Classifiers present in the final 
populations corresponded closely to terms of an efficient boolean 
representation of the solution. Achievement of the results depended on a 
selection regime that emphasized classifiers which were both general and 
accurate. The theoretically predicted superiority of the crossover genetic 
operator to the point mutation operator was observed. Most experiments used a 
fixed crossover rate, but in one series the system itself advantageously 
controlled the rate based on an environment-independent definition of 
classifier system entropy.</blockquote> 
<p> </p> </dd> 
<dt> [887] </dt> 
<dd> Stewart&nbsp;W. Wilson. Knowledge Growth in an Artificial Animal. In 
K.&nbsp;S. Narenda, editor,Adaptive and learning systems: Theory and 
applications, pages 255-264. Plenum Press: New York, 1986. 
<p> </p> </dd> 
<dt> [888] </dt> 
<dd> Stewart&nbsp;W. Wilson. Classifier Systems and the Animat Problem. 
Machine Learning, 2:199-228, 1987. Also Research Memo RIS-36r, the Rowland 
Institute for Science, Cambridge, MA, 1986.
<blockquote> This paper characterizes and investigates, from the perspective 
of machine learning and, particularly, classifier systems, the learning problem 
faced by animals and autonomous robots (here collectively termed animats). We 
suggest that, to survive in their environments, animats must in effect learn 
multiple disjunctive concepts incrementally under payoff (needs-satisfying) 
feedback. A review of machine learning techniques indicates that most relax at 
least one of these constraints. In theory, classifier systems satisfy the 
constraints, but tests have been limited. We show how the standard classifier 
system model applies to the animat learning problem. Then, in the experimental 
part of the paper, we specialize the model and test it in a problem environment 
satisfying the constraints and consisting of a difficult, disjunctive Boolean 
function drawn from the machine learning literature. Results include: learning 
the function in significantly fewer trials than a neural-network method; 
learning under payoff regimes that include both noisy payoff and partial reward 
for suboptimal performance; demonstration, in a classifier system, of a 
theoretically predicted property of genetic algorithms: the superiority of 
crossovers to point mutations; and automatic control of variation (search) rate 
based on system entropy. We conclude that the results support the classifier 
system approach to the animat problem, but suggest work aimed at the emergence 
of behavioral hierarchies of classifiers to offset slower learning rates in 
larger problems.</blockquote> 
<p> </p> </dd> 
<dt> [889] </dt> 
<dd> Stewart&nbsp;W. Wilson. Hierarchical Credit Allocation in a Classifier 
System. InProceedings Tenth International Joint Conference on AI (IJCAI-87), 
pages 217-220. Morgan Kaufmann Publishers, 1987. Also Research Memo RIS-37r, 
the Rowland Institute for Science, Cambridge, MA, 1986.
<blockquote> Learning systems which engage in sequential activity face the 
problem of properly allocating credit to steps or actions which make possible 
later steps that result in environmental payoff. In the classifier systems 
studied by Holland and others, credit is allocated by means of a 
``bucket-brigade'' algorithm through which, over time, environmental payoff in 
effect flows back to classifiers which take early, stage-setting actions. The 
algorithm has advantages of simplicity and locality, but may not adequately 
reinforce long action sequences. We suggest an alternative form for the 
algorithm and the system's operating principles designed to induce behavioral 
hierarchies in which modularity of the hierarchy would keep all bucket-brigade 
chains short, thus more reinforceable and more rapidly learned, but overall 
action sequences could be long.</blockquote> 
<p> </p> </dd> 
<dt> [890] </dt> 
<dd> Stewart&nbsp;W. Wilson. Quasi-Darwinian Learning in a Classifier System. 
InProceedings of the Fourth International Workshop on Machine Learning, pages 
59-65. Morgan Kaufmann, 1987.
<blockquote> Classifier systems (Holland, 1986) have a distinct Darwinian 
flavor, and in this respect contrast sharply with most other learning systems. 
In this paper we bring out various aspects of the contrast, and provide an 
example of classifier system learning which illustrates its quasi-Darwinian 
operation.</blockquote> 
<p> </p> </dd> 
<dt> [891] </dt> 
<dd> Stewart&nbsp;W. Wilson. The genetic algorithm and biological development. 
InGrefenstette [391], pages 247-251. 
<p> </p> </dd> 
<dt> [892] </dt> 
<dd> Stewart&nbsp;W. Wilson. Bid Competition and Specificity Reconsidered. 
Complex Systems, 2(6):705-723, 1988. 
<blockquote> Experiments were conducted with respect to two classifier system 
mechanisms: the bid competition and the use of classifier specificity in 
bidding and payments. The experiments employed a simplified classifier system 
and so may not accurately reflect the behavior of the standard system. 
Nevertheless, the results indicated that, in general, (1) specificity should 
not be factored into amounts deducted from a classifier's strength, (2) the bid 
competition does not improve performance and does not encourage default 
hierarchies, and (3) default hierarchies will form under a somewhat different 
algorithm than the standard one.</blockquote> 
<p> </p> </dd> 
<dt> [893] </dt> 
<dd> Stewart&nbsp;W. Wilson. Hierarchical Credit Assignment in a Classifier 
System. In M.&nbsp;Elzas, T.&nbsp;Oren, and B.&nbsp;P. Zeigler, editors,
Modelling and Simulation Methodology: Knowledge Systems Paradigms. North 
Holland, 1988.
<p> </p> </dd> 
<dt> [894] </dt> 
<dd> Stewart&nbsp;W. Wilson. Hierarchical Credit Allocation in a Classifier 
System. InDavis [234], pages 104-115. 
<blockquote> Learning systems which engage in sequential activity face the 
problem of properly allocating credit to steps or actions which make possible 
later steps that result in environmental payoff. In the classifier systems 
studied by Holland and others, credit is allocated by means of a 
``bucket-brigade'' algorithm through which, over time, environmental payoff in 
effect flows back to classifiers which take early, stage-setting actions. The 
algorithm has advantages of simplicity and locality, but may not adequately 
reinforce long action sequences. We suggest an alternative form for the 
algorithm and the system's operating principles designed to induce behavioral 
hierarchies in which modularity of the hierarchy would keep all bucket-brigade 
chains short, thus more reinforceable and more rapidly learned, but overall 
action sequences could be long.</blockquote> 
<p> </p> </dd> 
<dt> [895] </dt> 
<dd> Stewart&nbsp;W. Wilson. Hierarchical credit allocation in a classifier 
system. In M.&nbsp;S. Elzas, T.&nbsp;I. Oren, and B.&nbsp;P. Zeigler, editors,
Modelling and simulation methodology, pages 351-357. North-Holland: New York, 
1989.
<p> </p> </dd> 
<dt> [896] </dt> 
<dd> Stewart&nbsp;W. Wilson. The Genetic Algorithm and Simulated Evolution. In 
Chris Langton, editor,Artificial Life: Proceedings of an Interdisciplinary 
Workshop on the Synthesis and Simulation of Living Systems, volume&nbsp;VI of 
Santa Fe Institute Studies in the Sciences of Complexity. Addison-Wesley: 
Reading, MA, 1989.
<blockquote> A scheme is described for simulating the evolution of 
multicellular systems. The scheme is based on a representation for biological 
development in which the genotypes are sets of production-like growth rules 
that are executed to produce cell aggregates-the phenotypes. Evolution of 
populations, through phenotype selection and genotype variation, occurs 
according to the method of the genetic algorithm. Some examples of the 
development representation in 1-dimensional creatures are given.</blockquote> 
<p> </p> </dd> 
<dt> [897] </dt> 
<dd> Stewart&nbsp;W. Wilson. Perceptron redux: Emergence of structure. In 
Special issue of Physica D (Vol. 42) [292], pages 249-256. Republished in 
Emergent Computation, S. Forrest (ed.), MIT Press/Bradford Books.
<blockquote> Perceptrons were evolved that computed a rather difficult 
nonlinear Boolean function. The results with this early and basic form of 
emergent computation suggested that when genetic search is applied to its 
structure, a perceptron can learn more complex tasks than is sometimes 
supposed. The results also suggested, in the light of recent work on classifier 
systems, that to hasten the emergence of an emergent computation it is 
desirable to provide evaluative feedback at a level as close as possible to 
that of the constituent local computations.</blockquote> 
<p> </p> </dd> 
<dt> [898] </dt> 
<dd> Stewart&nbsp;W. Wilson. The Animat Path to AI. In Meyer and Wilson [613], 
pages 15-21. http://prediction-dynamics.com/.
<blockquote> A research methodology is proposed for understanding intelligence 
through simulation of artificial animals (``animats'') in progressively more 
challenging environments while retaining characteristics of holism, pragmatism, 
perception, categorization, and adaptation that are often underrepresented in 
standard AI approaches to intelligence. It is suggested that basic elements of 
the methodology should include a theory/taxonomy of environments by which they 
can be ordered in difficulty-one is offered-and a theory of animat efficiency. 
It is also suggested that the methodology offers a new approach to the problem 
of perception.</blockquote> 
<p> </p> </dd> 
<dt> [899] </dt> 
<dd> Stewart&nbsp;W. Wilson. Classifier System mapping of real vectors. In 
Collected Abstracts for the First International Workshop on Learning Classifier 
System (IWLCS-92) [486]. October 6-8, NASA Johnson Space Center, Houston, Texas.
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [900] </dt> 
<dd> Stewart&nbsp;W. Wilson. Toward a GA solution of the discovery problem. In 
Collected Abstracts for the First International Workshop on Learning Classifier 
System (IWLCS-92) [486]. October 6-8, NASA Johnson Space Center, Houston, Texas.
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [901] </dt> 
<dd> Stewart&nbsp;W. Wilson. ZCS: A zeroth level classifier system. 
Evolutionary Computation, 2(1):1-18, 1994. http://prediction-dynamics.com/. 
<blockquote> A basic classifier system, ZCS, is presented that keeps much of 
Holland's original framework but simplifies it to increase understandability 
and performance. ZCS's relation to Q-learning is brought out, and their 
performances compared in environments of two difficulty levels. Extensions to 
ZCS are proposed for temporary memory, better action selection, more efficient 
use of the genetic algorithm, and more general classifier representation
</blockquote> 
<p> </p> </dd> 
<dt> [902] </dt> 
<dd> Stewart&nbsp;W. Wilson. Classifier Fitness Based on Accuracy. 
Evolutionary Computation, 3(2):149-175, 1995. http://prediction-dynamics.com/. 
<blockquote> In many classifier systems, the classifier strength parameter 
serves as a predictor of future payoff and as the classifier's fitness for the 
genetic algorithm. We investigate a classifier system, XCS, in which each 
classifier maintains a prediction of expected payoff, but the classifier's 
fitness is given by a measure of the prediction's accuracy. The system executes 
the genetic algorithm in niches defined by the match sets, instead of 
panmictically. These aspects of XCS result in its population tending to form a 
complete and accurate mapping X x A -&gt; P from inputs and actions to payoff 
predictions. Further, XCS tends to evolve classifiers that are maximally 
general, subject to an accuracy criterion. Besides introducing a new direction 
for classifier system research, these properties of XCS make it suitable for a 
wide range of reinforcement learning situations where generalization over 
states is desirable.</blockquote> 
<p> </p> </dd> 
<dt> [903] </dt> 
<dd> Stewart&nbsp;W. Wilson. Explore/exploit strategies in autonomy. In Maes 
et&nbsp;al. [595], pages 325-332. 
<blockquote> Within a reinforcement learning framework, ten strategies for 
autonomous control of the explore/exploit decision are reviewed, with 
observations from initial experiments on four of them. Control based on 
prediction error or its rate of change appears promising. Connections are made 
with explore/exploit work by Holland (1975), Thrun (1992), and Schmidhuber 
(1995).</blockquote> 
<p> </p> </dd> 
<dt> [904] </dt> 
<dd> Stewart&nbsp;W. Wilson. Generalization in XCS. Unpublished contribution 
to the ICML '96 Workshop on Evolutionary Computing and Machine Learning. 
http://prediction-dynamics.com/, 1996.
<p> </p> </dd> 
<dt> [905] </dt> 
<dd> Stewart&nbsp;W. Wilson. Generalization in evolutionary learning. 
Presented at the Fourth European Conference on Artificial Life (ECAL97), 
Brighton, UK, July 27-31. http://prediction-dynamics.com/, 1997.
<p> </p> </dd> 
<dt> [906] </dt> 
<dd> Stewart&nbsp;W. Wilson. Generalization in the XCS classifier system. In 
Koza et&nbsp;al. [529], pages 665-674. http://prediction-dynamics.com/. 
<blockquote> This paper studies two changes to XCS, a classifier system in 
which fitness is based on prediction accuracy and the genetic algorithm takes 
place in environmental niches. The changes were aimed at increasing XCS's 
tendency to evolve accurate, maximally general classifiers and were tested on 
previously employed ``woods'' and multiplexer tasks. Together the changes bring 
XCS close to evolving populations whose high-fitness classifiers form a 
near-minimal, accurate, maximally general cover of the input and action product 
space. In addition, results on the multiplexer, a difficult categorization 
task, suggest that XCS's learning complexity is polynomial in the input length 
and thus may avoid the ``curse of dimensionality'', a notorious barrier to 
scale-up. A comparison between XCS and genetic programming in solving the 
6-multiplexer suggests that XCS's learning rate is about three orders of 
magnitude faster in terms of the number of input instances processed.
</blockquote> 
<p> </p> </dd> 
<dt> [907] </dt> 
<dd> Stewart&nbsp;W. Wilson. Get real! XCS with continuous-valued inputs. In 
L.&nbsp;Booker, Stephanie Forrest, M.&nbsp;Mitchell, and Rick&nbsp;L. Riolo, 
editors,Festschrift in Honor of John H. Holland, pages 111-121. Center for the 
Study of Complex Systems, 1999. http://prediction-dynamics.com/.
<blockquote> Classifier systems have traditionally taken binary strings as 
inputs, yet in many real problems such as data inference, the inputs have real 
components. A modified XCS classifier system is described that learns a 
non-linear real-vector classification task.</blockquote> 
<p> </p> </dd> 
<dt> [908] </dt> 
<dd> Stewart&nbsp;W. Wilson. State of XCS classifier system research. In Wu 
[923], pages 322-334. Also Technical Report 99.1.1, Prediction Dynamics, 
Concord MA. http://prediction-dynamics.com/.
<blockquote> XCS is a new kind of learning classifier system that differs from 
the traditional one primarily in its definition of classifier fitness and its 
relation to contemporary reinforcement learning. Advantages of XCS include 
improved performance and an ability to form accurate maximal generalizations. 
This paper reviews recent research on XCS with respect to representation, 
predictive modelling, internal state, noise, and underlying theory and 
technique. A notation for environmental regularities is introduced.</blockquote>
<p> </p> </dd> 
<dt> [909] </dt> 
<dd> Stewart&nbsp;W. Wilson. Get Real! XCS with Continuous-Valued Inputs. In 
Lanzi et&nbsp;al. [544], pages 209-219. 
<blockquote> Classifier systems have traditionally taken binary strings as 
inputs, yet in many real problems such as data inference, the inputs have real 
components. A modified XCS classifier system is described that learns a 
non-linear real-vector classification task.</blockquote> 
<p> </p> </dd> 
<dt> [910] </dt> 
<dd> Stewart&nbsp;W. Wilson. Mining Oblique Data with XCS. In Proceedings of 
the International Workshop on Learning Classifier Systems (IWLCS-2000), in the 
Joint Workshops of SAB 2000 and PPSN 2000 [487]. Extended abstract. 
<blockquote> Paper is an extended abstract </blockquote> 
<p> </p> </dd> 
<dt> [911] </dt> 
<dd> Stewart&nbsp;W. Wilson. Mining Oblique Data with XCS. Technical Report 
2000028, University of Illinois at Urbana-Champaign, 2000.
<blockquote> The classifier system XCS was investigated for data mining 
applications where the dataset discrimination surface (DS) is generally oblique 
to the attribute axes. Despite the classifiers' hyper-rectangular predicates, 
XCS reached 100% performance on synthetic problems with diagonal DS's and, in a 
train/test experiment, competitive performance on the Wisconsin Breast Cancer 
dataset. Final classifiers in an extended WBC learning run were interpretable 
to suggest dependencies on one or a few attributes. For data mining of numeric 
datasets with partially oblique discrimination surfaces, XCS shows promise from 
both performance and pattern discovery viewpoints.</blockquote> 
<p> </p> </dd> 
<dt> [912] </dt> 
<dd> Stewart&nbsp;W. Wilson. State of XCS Classifier System Research. In Lanzi 
et&nbsp;al. [544], pages 63-82. 
<blockquote> XCS is a new kind of learning classifier system that differs from 
the traditional kind primarily in its definition of classifier fitness and its 
relation to contemporary reinforcement learning. Advantages of XCS include 
improved performance and an ability to form accurate maximal generalizations. 
This paper reviews recent research on XCS with respect to representation, 
internal state, predictive modelling, noise, and underlying theory and 
technique. A notation for environmental regularities is introduced.</blockquote>
<p> </p> </dd> 
<dt> [913] </dt> 
<dd> S.&nbsp;W. Wilson. Mining oblique data with xcs. In P.L. Lanzi, 
W.&nbsp;Stolzmann, and S.W. Wilson, editors,Advances in learning classifier 
systems, third international workshop, IWLCS 2000, volume 1996 of LNCS, pages 
158-176. Springer, 2001.
<p> </p> </dd> 
<dt> [914] </dt> 
<dd> Stewart&nbsp;W. Wilson. Function approximation with a classifier system. 
In Lee Spector, Erik&nbsp;D. Goodman, Annie Wu, W.B. Langdon, Hans-Michael 
Voigt, Mitsuo Gen, Sandip Sen, Marco Dorigo, Shahram Pezeshk, Max&nbsp;H. 
Garzon, and Edmund Burke, editors,Proceedings of the Genetic and Evolutionary 
Computation Conference (GECCO-2001), pages 974-981, San Francisco, California, 
USA, 7-11 July 2001. Morgan Kaufmann.
<p> </p> </dd> 
<dt> [915] </dt> 
<dd> Stewart&nbsp;W. Wilson. Classifiers that approximate functions. Natural 
Computing, 1(2-3):211-234, 2002. 
<p> </p> </dd> 
<dt> [916] </dt> 
<dd> Stewart&nbsp;W. Wilson. Compact rulesets from xcsi. In Lanzi et&nbsp;al. 
[546], pages 196-208. 
<p> </p> </dd> 
<dt> [917] </dt> 
<dd> Stewart&nbsp;W. Wilson. Three architectures for continuous action. In Tim 
Kovacs, Xavier LL&ograve;ra, Keiki Takadama, Pier&nbsp;Luca Lanzi, Wolfgang 
Stolzmann, and Stewart&nbsp;W. Wilson, editors,Learning Classifier Systems. 
International Workshops, IWLCS 2003-2005, Revised Selected Papers, volume 4399 
ofLNCS, pages 239-257. Springer, 2007. 
<p> </p> </dd> 
<dt> [918] </dt> 
<dd> Stewart&nbsp;W. Wilson. Classifier conditions using gene expression 
programming. In Jaume Bacardit, Ester Bernad&oacute;-Mansilla, Martin Butz, Tim 
Kovacs, Xavier Llor&agrave;, and Keiki Takadama, editors,Learning Classifier 
Systems. 10th and 11th International Workshops (2006-2007), volume 4998/2008 of 
Lecture Notes in Computer Science, pages 206-217. Springer, 2008. 
<blockquote> The classifier system XCSF was modified to use gene expression 
programming for the evolution and functioning of the classifier conditions. The 
aim was to fit environmental regularities better than is typically possible 
with conventional rectilinear conditions. An initial experiment approximating a 
nonlinear oblique environment showed excellent fit to the regularities.
</blockquote> 
<p> </p> </dd> 
<dt> [919] </dt> 
<dd> Mark&nbsp;S. Withall, Chris&nbsp;J. Hinde, and Roger&nbsp;G. Stone. 
Evolving readable Perl. In W.&nbsp;B. Langdon, E.&nbsp;Cant&uacute;-Paz, 
K.&nbsp;Mathias, R.&nbsp;Roy, D.&nbsp;Davis, R.&nbsp;Poli, 
K.&nbsp;Balakrishnan, V.&nbsp;Honavar, G.&nbsp;Rudolph, J.&nbsp;Wegener, 
L.&nbsp;Bull, M.&nbsp;A. Potter, A.&nbsp;C. Schultz, J.&nbsp;F. Miller, 
E.&nbsp;Burke, and N.&nbsp;Jonoska, editors,GECCO 2002: Proceedings of the 
Genetic and Evolutionary Computation Conference. Morgan Kaufmann Publishers, 
2002.
<p> </p> </dd> 
<dt> [920] </dt> 
<dd> M.L. Wong and K.S. Leung. Data mining using grammar based genetic 
programming and applications. Kluwer, 2000. 
<p> </p> </dd> 
<dt> [921] </dt> 
<dd> Ian Wright. Reinforcement Learning and Animat Emotions. In Maes 
et&nbsp;al. [595], pages 272-281. 
<blockquote> Emotional states, such as happiness or sadness, pose particular 
problems for information processing theories of mind. Hedonic components of 
states, unlike cognitive components, lack representational content. Research 
within Artificial Life, in particular the investigation of adaptive agent 
architectures, provides insights into the dynamic relationship between 
motivation, the ability of control sub-states to gain access to limited 
processing resources, and prototype emotional states. Holland's learning 
classifier system provides a concrete example of this relationship, 
demonstrating simple `emotion-like' states, much as a thermostat demonstrates 
simple `belief-like' and `desire-like' states. This leads to the conclusion 
that valency, a particular form of pleasure or displeasure, is a self-monitored 
process of credit-assignment. The importance of the movement of a 
domain-independent representation of utility within adaptive architectures is 
stressed. Existing information processing theories of emotion can be enriched 
by a `circulation of value' design hypothesis. Implications for the development 
of emotional animats are considered.</blockquote> 
<p> </p> </dd> 
<dt> [922] </dt> 
<dd> Ian Wright. Reinforcement learning and animat emotions. Technical Report 
CSRP-96-4, School of Computer Science. University of Birmingham, 1996. 
ftp://ftp.cs.bham.ac.uk/pub/tech-reports/1996/CSRP-96-04.ps.gz.
<blockquote> Emotional states, such as happiness or sadness, pose particular 
problems for information processing theories of mind. Hedonic components of 
states, unlike cognitive components, lack representational content. Research 
within Artificial Life, in particular the investigation of adaptive agent 
architectures, provides insights into the dynamic relationship between 
motivation, the ability of control sub-states to gain access to limited 
processing resources, and prototype emotional states. Holland's learning 
classifier system provides a concrete example of this relationship, 
demonstrating simple `emotion-like' states, much as a thermostat demonstrates 
simple `belief-like' and `desire-like' states. This leads to the conclusion 
that valency, a particular form of pleasure or displeasure, is a self-monitored 
process of credit-assignment. The importance of the movement of a 
domain-independent representation of utility within adaptive architectures is 
stressed. Existing information processing theories of emotion can be enriched 
by a `circulation of value' design hypothesis. Implications for the development 
of emotional animats are considered.</blockquote> 
<p> </p> </dd> 
<dt> [923] </dt> 
<dd> Annie&nbsp;S. Wu, editor. Proceedings of the 1999 Genetic and 
Evolutionary Computation Conference Workshop Program, 1999. 
<p> </p> </dd> 
<dt> [924] </dt> 
<dd> David Wyatt and Larry Bull. A memtic learning classifier system for for 
describing continuous-valued problem spaces. In William&nbsp;E. Hart, 
N.&nbsp;Krasnogor, and J.E. Smith, editors,Recent Advances in Memetic Algorithms
, Studies in Fuzziness and Soft Computing, pages 355-396. Springer, 2004.
<p> </p> </dd> 
<dt> [925] </dt> 
<dd> Kumara&nbsp;Sastry Xavier&nbsp;Llor&aacute; and David&nbsp;E. Goldberg. 
Binary rule encoding schemes: A study using the compact classifier system. In 
Tim Kovacs, Xavier LL&ograve;ra, Keiki Takadama, Pier&nbsp;Luca Lanzi, Wolfgang 
Stolzmann, and Stewart&nbsp;W. Wilson, editors,Learning Classifier Systems. 
International Workshops, IWLCS 2003-2005, Revised Selected Papers, volume 4399 
ofLNCS, pages 40-58. Springer, 2007. 
<p> </p> </dd> 
<dt> [926] </dt> 
<dd> Derek&nbsp;F. Yates and Andrew Fairley. An Investigation into Possible 
Causes of, and Solutions to, Rule Strength Distortion Due to the Bucket Brigade 
Algorithm. InForrest [335], pages 246-253. 
<p> </p> </dd> 
<dt> [927] </dt> 
<dd> Derek&nbsp;F. Yates and Andrew Fairley. Evolutionary Stability in Simple 
Classifier Systems. InFogarty [324], pages 28-37. 
<blockquote> In this paper, the relatively new branch of mathematics known as 
Evolutionary Game Theory is proposed as a potentially useful tool when seeking 
to resolve certain of the more global, unanswered questions related to 
classifier systems. In particular, it is proved that, under certain mild 
assumptions, the performance of a classifier system plans will, if the Bucket 
Brigade Algorithm is adopted, conform to what is referred to as `an 
evolutionary stable state'. A simple example is also provided to confirm the 
theoretical findings.</blockquote> 
<p> </p> </dd> 
<dt> [928] </dt> 
<dd> Takahiro Yoshimi and Toshiharu Taura. Hierarchical Classifier System 
Based on the Concept of Viewpoint. InKoza et&nbsp;al. [529], pages 675-678. 
<p> </p> </dd> 
<dt> [929] </dt> 
<dd> Takahiro Yoshimi and Toshiharu Taura. A Computational Model of a 
Viewpoint-Forming Process in a Hierarchical Classifier System. InBanzhaf 
et&nbsp;al. [32], pages 758-766. 
<blockquote> In an environment where input information to machine learning 
(ML) systems using production rules has many ``properties'' and the amount is 
huge enough, the authors aim for an ML systems with effective performance in 
finding solutions. When finding solutions, all of the properties of the input 
information are not always required. Therefore, the authors assume that a 
certain mechanism which can select specific properties to be focused on will 
contribute to this purpose. For the realization and discussion of this 
mechanism, the authors have focused on the Classifier System (CS) which has 
more advantages than other ML systems. From the author's point of view, 
operation processes in the CS are thought to involve this mechanism. However, 
the CS also involves such ``duality'' that both the optimization processes of 
rules for solution finding and the abstraction processes of input information 
are in a single process, which may lead to problems. In this paper, the authors 
propose a computational model in which these two processes are explicitly 
separated. The key concept of the proposed model is the Viewpoint-Forming 
Process for the purpose of using rules for selecting properties to be focused 
on. This is separate from the standard rules for finding solutions. A computer 
system is developed to evaluate the utility of this model. The results acquired 
by applying the model to an example problem are reported here.</blockquote> 
<p> </p> </dd> 
<dt> [930] </dt> 
<dd> Z.V. Zatuchna and A.J. Bagnall. Classifier system: Self-adjusting vs. 
gradual approach. InProceedings of the 2005 Congress on Evolutionary Computation
. IEEE, 2005.
<p> </p> </dd> 
<dt> [931] </dt> 
<dd> Z.V. Zatuchna and A.J. Bagnall. Modelling of temperament in an 
associative reinforcement learning agent. In T.&nbsp;Kovacs and J.A.R. 
Marshall, editors,AISB'06: Adaptation in Artificial and Biological Systems. 
AISB, 2006.
<p> </p> </dd> 
<dt> [932] </dt> 
<dd> Z.V. Zatuchna and A.J. Bagnall. A reinforcement learning agent with 
associative perception. In T.&nbsp;Kovacs and J.A.R. Marshall, editors,AISB'06: 
Adaptation in Artificial and Biological Systems. AISB, 2006. 
<p> </p> </dd> 
<dt> [933] </dt> 
<dd> Z.V. Zatuchna and A.J. Bagnall. Towards the axioms of consciousness: 
Modelling the rat in a maze. In T.&nbsp;Kovacs and J.A.R. Marshall, editors,
AISB'06: Adaptation in Artificial and Biological Systems. AISB, 2006. 
<p> </p> </dd> 
<dt> [934] </dt> 
<dd> Z.V. Zatuchna. AgentP model: Learning Classifer System with Associative 
Perception. In8th Parallel Problem Solving from Nature International Conference 
(PPSN VIII), pages 1172-1182, 2004. 
<p> </p> </dd> 
<dt> [935] </dt> 
<dd> Zhanna&nbsp;V. Zatuchna. AgentP: a learning classifier system with 
associative perception in maze environments. PhD thesis, University of East 
Anglia, 2005.
<blockquote> First we introduce new metrics for classifying the complexity of 
mazes based on agent-independent and agent-dependent characteristics of maze 
environments. We analyze 50 mazes used in the literature by the metrics and 
then introduce 351 new maze environments, including 271 aliasing mazes of 
increased difficulty. The purpose of preparing the extensive set of maze 
environments is to provide a suitable evaluation environment for alternative 
learning agent architectures. To fulfil our second goal we analyze the major 
learning theories, design the psychological model of Associative Perception 
Learning, integrate it into the Reinforcement Learning framework and define a 
new Learning Classifier System (LCS), AgentP, that utilizes explicitly 
imprinted images of the environment states. AgentP is designed specifically to 
find the shortest route through aliasing mazes with rewards only on transitions 
to terminal states. Such mazes contain the areas that look alike for a learning 
agent but may be associated with different optimal actions. The mazes represent 
a form of Partially Observable Markov Decision Processes (POMDP). Unlike many 
other LCS, AgentP does not generalize over the states. It learns a one-step 
transition model of the environment and uses two deterministic heuristics. 
AgentP has a rule structure similar to Anticipatory Classifier Systems. 
However, unlike them, AgentP perceives consecutive environmental states not 
only as a cause-effect time vector, but also as a single perceptive image, 
which is compared with previously memorized images for differentiation 
purposes. As a result AgentP is able to recognize aliasing in both the initial 
and resulting environment states, while ACS is meant to recognize aliasing in 
the initial state only. Each classifier in AgentP is supplemented with an ID 
system for a refined differentiation of aliasing squares. AgentP uses a 
distance-based reinforcement process where the expected difference between two 
successive learning coefficients remains the same with increased distance to 
food. It eliminates the disadvantages associated with the behaviour of the 
Q-learning based reinforcement procedure, commonly employed by LCS, in 
long-distanced mazes. The distance-based reinforcement procedure introduces 
certain limitations as AgentP is only able to handle specific kinds of reward 
function. The environment should be discrete and the agent is not able to 
operate on multi-motivational tasks. However, the reinforcement procedure in 
its present form provides simple and reliable test facilities for our main 
purpose, development of the operators for refined differentiation of aliasing 
squares, while the limitation can be overcome in future versions of AgentP when 
it is necessary. While experimenting with two versions of AgentP, we discover 
the phenomenon of aliasing clones, i.e. aliasing conglomerates of a similar 
graphic pattern that include more than two aliasing states and are located in 
different areas of the maze. We investigate the impact which makes the presence 
of aliasing clones in a maze on the ability of AgentP to solve mazes. We find 
that AgentP is able to solve optimally extensive mazes with dozens of aliasing 
squares and numerous aliasing conglomerates, provided they are free from 
aliasing clones. At the same time, for a maze containing at least three 
aliasing states that are grouped into an aliasing clone, the risk of an error 
for both versions of AgentP becomes non zero. We analyze the performance of 
AgentP in detail and show that it is able to solve optimally the majority of 
aliasing mazes used in the experiments and may be performing better than other 
LCS agents. We then discuss the potential of the learning model, possible 
improvements into the agent's structure and the most promising approaches to 
future research.</blockquote> 
<p> </p> </dd> 
<dt> [936] </dt> 
<dd> Zhaohua Zhang, Stan Franklin, and Dipankar Dasgupta. Metacognition in 
Software Agents Using Classifier Systems. InAAAI-98. Proceedings of the 
Fifteenth National Conference on Artificial Intelligence, pages 83-88, Madison 
(WI), 1998. AAAI-Press and MIT Press.
<p> </p> </dd> 
<dt> [937] </dt> 
<dd> Hayong&nbsp;Harry Zhou and John&nbsp;J. Grefenstette. Learning by Analogy 
in Genetic Classifier Systems. InSchaffer [718], pages 291-297. 
<blockquote> This paper presents an extension to the classifier system model 
that provides mechanisms to store solutions to learned tasks in a long term 
memory, to match the stored units against new problems as they arise, and to 
use the stored knowledge to learn new tasks in an increasingly efficient 
manner. The extended model has been implemented in a system called CSM 
(Classifier System with Memory). Experimental results with CSM demonstrate the 
benefits of learning by analogy in a robot navigation task domain and show 
significant improvements compared with the current classifier system model.
</blockquote> 
<p> </p> </dd> 
<dt> [938] </dt> 
<dd> Hayong&nbsp;Harry Zhou. Classifier systems with long term memory. In 
Grefenstette [389], pages 178-182. 
<p> </p> </dd> 
<dt> [939] </dt> 
<dd> Hayong&nbsp;Harry Zhou. CSM: A genetic classifier system with memory for 
learning by analogy. PhD thesis, Department of Computer Science, Vanderbilt 
University, Nashville, TN, 1987.
<p> </p> </dd> 
<dt> [940] </dt> 
<dd> Hayong&nbsp;Harry Zhou. CSM: A Computational Model of Cumulative Learning.
Machine Learning, 5(4):383-406, 1990. 
<p> </p> </dd> 
<dt> [941] </dt> 
<dd> Raed&nbsp;Abu Zitar and Mohammad&nbsp;H. Hassoun. Regulator Control via 
Genetic Search Assisted Reinforcement. InForrest [335], pages 254-263. 
<p> </p> </dd> </dl> 
</body>