<!doctype html>
<meta charset="utf-8">
<title>PHM | Full text | Random forests for verbal autopsy analysis: multisite validation study using clinical diagnostic gold standards</title>
<body>
 pophealthmetrics.com/article/10.1186/1478/7954/9/29 <br>
 Bottom,Top 
<dl> 
<dt></dt> 
<dd> </dd> </dl> 
<dl> 
<dt></dt> 
<dd> </dd> </dl> 
<ul> 
<li><strong>Welcome Carnegie Mellon University[NERL]</strong></li> 
<li>Log on</li> </ul> 
<ul> 
<li> &nbsp; BioMed Central </li> 
<li>Journals</li> 
<li> Gateways </li> </ul> 
<h1> </h1> 1.46 <br>
 Search this journal BioMed Central  for Go<br>
Advanced 
search <br>

<ul> 
<li>Home</li> 
<li>Articles</li> 
<li>Authors</li> 
<li>Reviewers</li> 
<li>About this journal</li> 
<li>My PHM</li> </ul> 
<ul> 
<ul> 
<li> Top </li> 
<li> Abstract </li> 
<li> Introduction </li> 
<li> Methods </li> 
<li> Results </li> 
<li> Discussion </li> 
<li> Conclusions </li> 
<li> Abbreviations </li> 
<li> Competing interests </li> 
<li> Authors' contributions </li> 
<li> Acknowledgements </li> 
<li> References </li> </ul> </ul> 
<dl> 
<dl> 
<dt> Advertisement </dt> 
<dd> </dd> </dl> 
<dl> 
<dt> Advertisement </dt> 
<dd> </dd> </dl> </dl> 
<h5><strong>Population Health Metrics</strong></h5> 
<ul> 
<li>Volume 9</li> </ul> 
<h5>Viewing options</h5> 
<ul> 
<li> Abstract </li> 
<li> <strong>Full text</strong> </li> 
<li> PDF (563KB) </li> 
<li> Additional files </li> </ul> 
<h5>Associated material</h5> 
<ul> 
<li> PubMed record </li> 
<li>About this article</li> 
<li> Readers' comments </li> 
<li> Pre-publication history </li> </ul> 
<h5>Related literature</h5> 
<ul> 
<li> 
<h6>Cited by</h6></li> 
<h6>Other articles by authors</h6> 
<li> <i>&nbsp;</i>on Google Scholar 
<ul> 
<li> Flaxman AD </li> 
<li> Vahdatpour A </li> 
<li> Green S </li> 
<li> James SL </li> 
<li> Murray CJL </li> </ul> </li> 
<li> <i>&nbsp;</i>on PubMed 
<ul> 
<li>Flaxman AD </li> 
<li>Vahdatpour A </li> 
<li>Green S </li> 
<li>James SL </li> 
<li>Murray CJL </li> </ul> </li> </ul> 
<h6>Related articles/pages</h6> 
<ul> 
<li>on Google</li> 
<li>on Google Scholar</li> 
<li>on PubMed</li> </ul> 
<h5>Tools</h5> 
<ul> 
<li> Download references </li> 
<li>Download XML</li> 
<li> Email to a friend </li> 
<li>Order reprints</li> 
<li> Post a comment </li> </ul> 
<h5>Share this article</h5> 
<ul> 
<li> </li> 
<li> Tweet </li> 
<li> </li> 
<li> &nbsp;More options... 
<ul> 
<li> Citeulike </li> 
<li> Connotea </li> 
<li> Del.icio.us </li> 
<li> Email </li> 
<li> Facebook </li> 
<li> <br>
Google+ </li> 
<li> Mendeley </li> 
<li> Twitter </li> </ul> </li> </ul> 
<h4> 
<p>This article is part of the series Verbal autopsy: innovations, 
applications, opportunities - Improving cause of death measurement.</p> </h4> 
Research 
<h1>Random forests for verbal autopsy analysis: multisite validation study 
using clinical diagnostic gold standards</h1> 
<p> <strong>Abraham D Flaxman</strong>1*, <strong>Alireza Vahdatpour</strong>1,
<strong>Sean Green</strong>2, <strong>Spencer L James</strong>1, <strong>
Christopher JL Murray</strong>1 and <strong>the Population Health Metrics 
Research Consortium (PHMRC)</strong> </p> 
<ul> 
<li> 
<p> * Corresponding author: Abraham D Flaxman abie@uw.edu </p> </li> </ul> 
<p><i></i>Author Affiliations</p> 
<p> 1 Institute for Health Metrics and Evaluation, University of Washington, 
2301 Fifth Ave., Suite 600, Seattle, WA 98121, USA</p> 
<p> 2 Bill &amp; Melinda Gates Foundation, Seattle, USA </p> 
<p> For all author emails, please log on. </p> 
<p><em>Population Health Metrics</em> 2011, <strong>9</strong>:29&nbsp;
doi:10.1186/1478-7954-9-29</p> <br>

<p>The electronic version of this article is the complete one and can be found 
online at:http://www.pophealthmetrics.com/content/9/1/29</p> <br>
Received: 14 
April 2011 <br>
Accepted: 4 August 2011 <br>
Published: 4 August 2011 <br>
<br>

<br> 
<p> &copy; 2011 Flaxman et al; licensee BioMed Central Ltd. <br>
</p> 
<p> This is an Open Access article distributed under the terms of the Creative 
Commons Attribution License (http://creativecommons.org/licenses/by/2.0), which 
permits unrestricted use, distribution, and reproduction in any medium, 
provided the original work is properly cited.</p> 
<h3>Abstract</h3> 
<h4>Background</h4> 
<p>Computer-coded verbal autopsy (CCVA) is a promising alternative to the 
standard approach of physician-certified verbal autopsy (PCVA), because of its 
high speed, low cost, and reliability. This study introduces a new CCVA 
technique and validates its performance using defined clinical diagnostic 
criteria as a gold standard for a multisite sample of 12,542 verbal autopsies 
(VAs).</p> 
<h4>Methods</h4> 
<p>The Random Forest (RF) Method from machine learning (ML) was adapted to 
predict cause of death by training random forests to distinguish between each 
pair of causes, and then combining the results through a novel ranking 
technique. We assessed quality of the new method at the individual level using 
chance-corrected concordance and at the population level using cause-specific 
mortality fraction (CSMF) accuracy as well as linear regression. We also 
compared the quality of RF to PCVA for all of these metrics. We performed this 
analysis separately for adult, child, and neonatal VAs. We also assessed the 
variation in performance with and without household recall of health care 
experience (HCE).</p> 
<h4>Results</h4> 
<p>For all metrics, for all settings, RF was as good as or better than PCVA, 
with the exception of a nonsignificantly lower CSMF accuracy for neonates with 
HCE information. With HCE, the chance-corrected concordance of RF was 3.4 
percentage points higher for adults, 3.2 percentage points higher for children, 
and 1.6 percentage points higher for neonates. The CSMF accuracy was 0.097 
higher for adults, 0.097 higher for children, and 0.007 lower for neonates. 
Without HCE, the chance-corrected concordance of RF was 8.1 percentage points 
higher than PCVA for adults, 10.2 percentage points higher for children, and 
5.9 percentage points higher for neonates. The CSMF accuracy was higher for RF 
by 0.102 for adults, 0.131 for children, and 0.025 for neonates.</p> 
<h4>Conclusions</h4> 
<p>We found that our RF Method outperformed the PCVA method in terms of 
chance-corrected concordance and CSMF accuracy for adult and child VA with and 
without HCE and for neonatal VA without HCE. It is also preferable to PCVA in 
terms of time and cost. Therefore, we recommend it as the technique of choice 
for analyzing past and current verbal autopsies.</p> 
<h5>Keywords: </h5>Verbal autopsy; cause of death certification; validation; 
machine learning; random forests 
<h3>Introduction</h3> 
<p>Verbal autopsy (VA) is a technique for measuring the cause-specific 
mortality burden for deaths that occur outside of hospitals. In VA, a trained 
interviewer collects detailed information on signs and symptoms of illness from 
laypeople familiar with the deceased. These interviews are analyzed by experts 
or by computer to estimate 1) the cause of death for each individual and 2) the 
distribution of causes of death in a population. This information can then be 
used by policy developers, donors, governments, or decision-makers to choose 
wisely in developing, requesting, and allocating health resources. For VA to 
provide useful information to individuals or to society, it is essential that 
the results of these interviews be mapped to the underlying cause of death 
accurately and quickly. Physician-certified verbal autopsy (PCVA) is currently 
the most common approach to mapping VA interviews to underlying cause of death, 
but this approach is expensive and time-consuming[1]. </p> 
<p>Machine learning (ML) methods are computer algorithms that infer patterns 
from examples[2]. In a classification task like VA analysis, an ML method 
processes a set of examples (&quot;training data&quot;) that has gold standard 
classifications, and develops a model to classify additional data. Developing 
and refining ML methods is a vibrant area of research in computer science, and 
numerous new methods have been introduced over the past 50 years. One 
influential ML method, the artificial neural network (ANN), was applied to VA 
10 years ago[3]. This approach was deemed potentially useful, pending further 
evaluation. By casting VA analysis as an application of general ML methods, 
incremental advances in ML techniques can be directly applied to improve the 
accuracy of VA analysis.</p> 
<p>The Random Forest (RF) is an exciting innovation in ML technology [4]. The 
RF has been used extensively in many domains for classification tasks, and is 
consistently one of the top approaches[5]. Examples of using ML techniques in 
various domains include gene selection and classification of microarray data[6
], modeling structural activity of pharmaceutical molecules[7], and protein 
interaction prediction[8]. For this study, we developed an application of the 
RF Method to VA analysis and compared the performance of RF to PCVA.</p> 
<h3>Methods</h3> 
<h4>An overview of random forests</h4> 
<p>Our RF Method for VA analysis seems complicated at first, but is actually a 
combination of several simple ideas. The first of these is the &quot;decision 
tree,&quot; a structure for representing a complex logical function concisely 
as branching decisions[9]. The decision trees in Breiman's Random Forest method 
are generated by a randomized algorithm from bootstrap-resampled training data, 
but the resulting trees are somewhat analogous to the expert algorithms used in 
early approaches to automatic VA analysis. In Figure1, Panel a shows a 
decision-tree representation of an expert algorithm for deciding if a child 
death was due to malaria or other causes[10], while Panel b depicts decision 
trees generated as part of the random forest for distinguishing maternal sepsis 
from HIV deaths. In each, the decision between two possibilities is made by 
starting from the top level, and progressing to the next level following the 
branch to the right if the symptom at the current level was endorsed and to the 
left otherwise. For example, the expert algorithm in Figure1a will only predict 
that the cause was malaria if the respondent said that the decedent had fever 
and convulsions and no stiff neck, no bulging fontanelle, and no measles.</p> 
<p><strong>Figure 1.</strong> <strong>Expert algorithm and RF decision trees
</strong>. A right branch from a node represents &quot;yes&quot; and a left 
branch represents &quot;no.&quot; a) Decision tree representation of expert 
algorithm to identify malaria deaths in child VAs (one-versus-all approach); b) 
Two random decision trees generated by RF to distinguish AIDS deaths from 
maternal sepsis deaths (one-versus-one approach).</p> 
<p>Unlike expert algorithms, however, the decision trees in Breiman's Random 
Forest are generated automatically from labeled examples (the training 
dataset), without guidance from human experts. Instead, a random resampling of 
the training dataset is generated by drawing examples with replacement from the 
training dataset, and then a decision tree is constructed sequentially from 
this, starting from the root. At each node, the algorithm selects a random 
subset of signs and symptoms to consider branching on, and then branches on the 
one that best distinguishes between the labels for examples relevant to that 
node, halting when all relevant examples have the same label. Because of the 
randomness in this process, running the approach repeatedly on the same 
training dataset yields different trees, and two such trees are depicted in 
Figure1b. </p> 
<p>Breiman's original formulation of RF proposed generating hundreds or 
thousands of decision trees this way, and then using them for prediction by 
calculating the prediction of each tree and taking a vote between their 
predictions. However, because of the long length of the cause list in verbal 
autopsy, we followed the &quot;pairwise coupling&quot; approach developed by 
Hastie[11]. We considered every pair of causes on the cause list, and generated 
100 decision trees to distinguish between each pair. This resulted in a table 
of random forests, depicted schematically in Figure2. The size of the forest 
was thus a function of the length of the cause list; for example, for the child 
VA module, the 21 causes produced a random forest of trees. </p> 
<p><strong>Figure 2.</strong> <strong>Schematic representation of RF</strong>. 
</p> 
<p>To aggregate the predictions of all of these trees, we tallied 
cause-specific scores by counting the number of trees that predicted each 
cause. We then normalized the score for each cause using a novel ranking 
procedure. The complete process of mapping from scores through ranks to 
predictions is demonstrated in Figure3, where, for example, Test C is predicted 
to be caused by Cause 1, which is not the highest scored cause for this 
example, but is the highest<em>ranked </em>cause. The full process is as 
follows: the Test Score Matrix is converted to a Test Rank Matrix on an 
entry-by-entry basis, by finding the rank of each entry among the corresponding 
column in the Train Score Matrix. For example, Test A, Cause 3 has score 20, 
which is the second-highest score when compared with the Cause 3 column of the 
Train Score Matrix, so it has a rank of 2 in the Test Rank Matrix. After Test A 
had Cause 1 and Cause 2 ranked similarly, the procedure predicted that Test A 
was caused by Cause 3 because this is the cause that was highest ranked for A. 
This is a nonparametric form of whitening, which makes the scores for different 
causes directly comparable. This approach has a natural generalization to 
predicting multiple causes for a single death, where the second-highest ranked 
cause is predicted as the second most likely, etc.</p> 
<p><strong>Figure 3.</strong> <strong>Schematic representation of 
&quot;ranking&quot; technique for cause prediction from random forest scores
</strong>. </p> 
<h4>Validation using the PHMRC gold standard test/train datasets</h4> 
<p>The Population Health Metrics Research Consortium (PHMRC) gold standard 
verbal autopsy validation study provides a large multisite dataset to assess 
the performance of new or existing verbal autopsy methods. The PHMRC study 
identified deaths that met defined clinical diagnostic criteria for cause of 
death. Then, interviewers visited the households of the deceased to conduct 
full verbal autopsies. Thus, the gold standard cause of death is paired with 
the responses from a verbal autopsy. The numbers of records from each site are 
provided in Table1. As part of the PHMRC study, all variables including 
free-text were converted into a series of dichotomous items. All aspects of the 
study are described elsewhere in more detail[12]. Additional files 1, 2, and 3 
list the 40 most informative variables for each cause in the adult, child, and 
neonatal modules after this data preparation phase was completed.</p> 
<p><strong>Table 1.</strong> Numbers of VAs collected by site and gold 
standard level</p> 
<p><strong>Additional file 1.</strong> <strong>Top 40 items based on Tariff 
Method for adult causes (Items that are extracted from open text field are 
marked with *, other HCE variables are marked with +)</strong>.</p> 
<p> Format: XLSX Size: 56KB Download file</p> 
<p><strong>Additional file 2.</strong> <strong>Top 40 items based on Tariff 
Method for child causes (Items that are extracted from open text field are 
marked with *, other HCE variables are marked with +)</strong>.</p> 
<p> Format: XLSX Size: 31KB Download file</p> 
<p><strong>Additional file 3.</strong> <strong>Top 40 items based on Tariff 
Method for neonate causes (Items that are extracted from open text field are 
marked with *, other HCE variables are marked with +)</strong>.</p> 
<p> Format: XLSX Size: 22KB Download file</p> 
<p>Murray et al. have shown that many traditional metrics of performance, such 
as specificity or relative and absolute error in CSMFs, are sensitive to the 
CSMF composition of the test dataset[13] and recommend that robust assessment 
of performance be undertaken on a range of test datasets with widely varying 
CSMF compositions. Further, metrics of individual concordance need to be 
corrected for chance to adequately capture how well a method does over random 
or equal assignment across causes.</p> 
<p>The PHMRC has developed a set of 500 test/train splits of the data, which 
we analyzed. The splits were generated randomly, stratified by cause. Each has 
a random 75% of examples of each cause in the training set and 25% in the test 
set. For each split, we used the training data to generate random forests for 
each pair of causes and then we applied these forests to the test dataset. We 
never allowed contamination between the training data and the test data - they 
were kept strictly separate in all steps of the analysis. Further, the cause 
composition of the test dataset is based on a random draw from an uninformative 
Dirichlet distribution. The Dirichlet distribution specifies random fractions 
that sum to 1. Each test split is resampled with replacement to meet the cause 
fractions specified by a Dirichlet draw. Consequently, each test split has a 
different distribution of cause fractions, and the cause composition of the 
training data and test data are always different.</p> 
<p>We assessed the performance of RF at assigning individual causes of death 
using median chance-corrected concordance by cause across the 500 test datasets 
and the median average chance-corrected concordance across causes in the 500 
test datasets, following the recommendations of Murray et al[13]. For assessing 
the performance of RF in estimating CSMFs, we calculated the median CSMF 
accuracy as well as slope, intercept, and root mean squared error (RMSE) of a 
linear regression for each cause as a summary of the relationship between 
estimated CSMFs for a cause and the true CSMF in a particular test dataset[13]. 
We benchmark RF against PCVA on the same dataset using the results reported by 
Lozano et al[14]. </p> 
<p>Murray et al. analyzed data in China two ways: including all items and 
excluding items that reflected the decedent's health care experience (HCE)[15]. 
The purpose of excluding the HCE items is to assess how RF would perform on VA 
for communities without access to health care. They found, for example, that a 
considerable component of PCVA performance was related to the household recall 
of hospital experience or availability of a death certificate or other records 
from the hospital. We assessed the performance of RF in adults, children, and 
neonates both with and without the free-response items and the structured 
questions that require contact with health care to answer (marked in Additional 
files1, 2, and 3). </p> 
<p>There are many potential variations in implementing RF. Specifically:</p> 
<p>&bull; Continuous and categorical variables can be included as is, or can 
be dichotomized to reduce noise</p> 
<p>&bull; The training data can be reweighted so that all causes are 
represented equally or left as is</p> 
<p>&bull; Decision trees can compare cause <em>j </em>to all other causes at 
once, or compare cause<em>j </em>to each other individual cause to come up with 
&quot;votes&quot;</p> 
<p>&bull; The signal-to-noise ratio can be improved by removing 
low-information items using the Tariff Method[16], or all items can be used </p>
<p>&bull; Different numbers of signs and symptoms can be used at each decision 
node</p> 
<p>&bull; Different numbers of trees can be used in the forest</p> 
<p>&bull; Cause assignment can be based on the highest scoring cause for each 
death or on ranking the scores and assigning to the cause with the highest rank
</p> 
<p>We conducted an extensive sensitivity analysis to understand the importance 
of decisions between levels of Tariff-based item reduction, the choice of 
number of signs and symptoms at every decision node (<em>m</em>), the choice of 
number of trees (<em>n</em>) in each one-versus-one cause classification, and 
the difference between max-score and max-rank cause assignment. To avoid 
overfitting the data when selecting between the model variants, we conducted 
our sensitivity analysis using splits 1 to 100 and repeated the analysis using 
splits 101 to 200 and a random subset of 50 splits. The results of the 
sensitivity analysis are included in Additional file4 and show that cause 
assignment by rank is superior to assignment by score but that the other 
parameters do not affect chance-corrected concordance or CSMF accuracy. The 
results shown in the next section are all for the one-versus-one model, with 
dichotomized variables, with training data reweighted to have equal class 
sizes, using the 40 most important Tariff-based symptoms per cause,<em>m </em>= 
5,<em>n </em>= 100, and the max-rank cause assignment, which produced the 
highest CSMF accuracy for seven of the first 200 splits of the child VA data 
with HCE and the highest chance-corrected concordance for 14.</p> 
<p><strong>Additional file 4.</strong> <strong>Sensitivity analysis for 54 
variants of the RF algorithm applied to 200 splits of the child VA data with HCE
</strong>.</p> 
<p> Format: XLS Size: 44KB Download file</p> 
<p>This file can be viewed with: Microsoft Excel Viewer</p> 
<h3>Results</h3> 
<h4>Individual cause assignment compared to PCVA</h4> 
<p>Table 2 shows that, for RF over 500 splits, the median value of average 
chance-corrected concordance for adult VAs without HCE was 37.7% (95% 
uncertainty interval [UI]: 37.6%, 38%), and for adult VAs with HCE it was 48% 
(47.8%, 48.2%); for child VAs without HCE it was 46.5% (46.1%, 47%), and for 
child VAs with HCE it was 51.1% (50.7%, 51.6%). For neonatal VAs without HCE 
the median average chance-corrected concordance was 33.5% (33%, 33.9%), and for 
neonatal VAs with HCE it was 34.9% (34.5%, 35.4%). Note that the neonate VAs 
results presented in the tables for PCVA are for a shorter cause list that only 
includes six causes, where all the preterm delivery causes are grouped 
together. This is due to the fact that PCVA performed very poorly on a cause 
list with 11 causes.</p> 
<p><strong>Table 2.</strong> Median chance-corrected concordance (%) for RF 
and PCVA, by age group with and without HCE</p> 
<p>The differential value of HCE to RF in adult VA is more substantial than in 
child or neonatal VAs. Including HCE responses yields a significant relative 
increase of 10.3% in median chance-corrected concordance for adult VA. This 
could be because adults have more substantial experience with health care, and 
hence more relevant information is generated that aids in VA analysis, or it 
could be confounded by the differences between the adult, child, and neonate 
cause lists. In PCVA, however, including HCE responses produces a large 
increase in median chance-corrected concordance for all modules. In all six of 
these settings, the median chance-corrected concordance is significantly higher 
for RF than for PCVA.</p> 
<p>Figure 4 shows that partial-cause assignment increases the partial-cause 
chance-corrected concordance for all age groups with and without HCE. The 
increasing partial-cause chance-corrected concordance as a function of the 
number of causes shows that RF contains additional information in the second, 
third, etc., most likely causes. However, as the partial-cause assignment 
continues, the added value from new cause assignment decreases due to the 
chance-correcting element in the partial-chance-corrected concordance formula, 
as demonstrated by the decreasing slope.</p> 
<p><strong>Figure 4.</strong> <strong>Partial-cause assignment increases 
partial chance-corrected concordance for adult, child, and neonate VAs with and 
without HCE</strong>. Slope of increase is higher between one and two cause 
assignments.</p> 
<p>Figures 5, 6, and 7 show the chance-corrected concordance of RF on a 
cause-by-cause basis for adult, child, and neonatal VAs with and without HCE 
(also see Additional file5). Figure 8 shows that on a cause-by-cause basis, RF 
is better than PCVA with HCE by at least 10 percentage points of 
chance-corrected concordance for 13 causes for adult deaths (lung cancer, 
fires, renal failure, pneumonia, homicide, drowning, cirrhosis 
leukemia/lymphomas, breast cancer, prostate cancer, epilepsy, cervical cancer, 
and poisonings). On the other hand, PCVA performed substantially better in 
detecting suicide, acute myocardial infarction, stomach cancer, other 
noncommunicable diseases, and AIDS. In addition, as depicted in Figure9, in 
five causes of child deaths, RF concordance is at least 10 percentage points 
higher with HCE (falls, sepsis, fires, other cardiovascular diseases, and 
measles). Among causes of child deaths, PCVA performed better in detecting 
other cancers, drowning, encephalitis, violent death, diarrhea/dysentery, and 
other defined causes of child deaths. Head-to-head comparison of the neonatal 
performance between PCVA and RF is not possible though, as PCVA utilized a 
shorter cause list.</p> 
<p><strong>Figure 5.</strong> <strong>Median chance-corrected concordance (%) 
for RF across 500 splits, by cause, for adult VA, with and without HCE</strong>.
</p> 
<p><strong>Figure 6.</strong> <strong>Median chance-corrected concordance (%) 
for RF across 500 splits, by cause, for child VA, with and without HCE</strong>.
</p> 
<p><strong>Figure 7.</strong> <strong>Median chance-corrected concordance (%) 
for RF across 500 splits, by cause, for neonatal VA, with and without HCE
</strong>. </p> 
<p><strong>Additional file 5.</strong> <strong>Median chance-corrected 
concordance (%) across 500 splits, by age group and cause with and without HCE
</strong>.</p> 
<p> Format: XLSX Size: 14KB Download file</p> 
<p><strong>Figure 8.</strong> <strong>Scatter of median chance-corrected 
concordance of RF versus PCVA, for adult module</strong>. </p> 
<p><strong>Figure 9.</strong> <strong>Scatter of median chance-corrected 
concordance of RF versus PCVA, for child module</strong>. </p> 
<p>Another advantage of RF over PCVA is its relatively consistent performance 
in the presence and absence of HCE variables. PCVA concordances vary 
significantly with absence of HCE variables (e.g., for 22 causes of adult 
deaths, without HCE, concordance decreased by more than 10 percentage points). 
On the other hand, RF concordance only decreases substantially in 15 adult 
causes. In addition, RF shows more consistency among all causes. For example, 
its minimum median chance-corrected concordance in adult causes is 7.9% 
(without HCE) and 10.7% (with HCE), while minimum median chance-corrected 
concordance for PCVA without HCE is negative for two causes (meaning PCVA did 
worse than chance). RF does benefit substantially from HCE variables for 
certain important causes, however. For example, for adult deaths due to 
tuberculosis, AIDS, diabetes, and asthma, chance-corrected concordance 
increased by more than 20 percentage points when HCE variables were included.
</p> 
<h4>CSMF estimation compared to PCVA</h4> 
<p>Table 3 compares the median CSMF accuracy for RF and PCVA. Over 500 splits, 
the median value of CSMF accuracy for RF for adult VAs with HCE was 0.772 
(0.769, 0.776), and for adult VAs without HCE it was 0.726 (0.721, 0.730); for 
child VAs with HCE it was 0.779 (0.775, 0.785), and for child VAs without HCE 
it was 0.763 (0.755, 0.769); for neonatal VAs with HCE it was 0.726 (0.717, 
0.734), and for neonatal VAs without HCE it was 0.720 (0.71, 0.732). The 
patterns for this population-level estimation quality metric are qualitatively 
the same as those observed in the individual-level metric above. The value of 
HCE information is more substantial for adult VA, although it yielded a smaller 
increase, changing the median CSMF accuracy by 0.046. For child VA, the value 
is small, where it yields an increase of 0.016, and for neonate, the HCE value 
is not significant (increase of 0.006). In all of these settings except for 
neonates with HCE, the median CSMF accuracy was significantly higher for RF 
than for PCVA. For the neonates with HCE, the difference was not statistically 
significant, and the comparison was done for a six cause list for PCVA and a 
more challenging 11 cause list for RF.</p> 
<p><strong>Table 3.</strong> Median CSMF accuracy for RF and PCVA, by age 
group with and without HCE</p> 
<p>Figure 10 shows scatter plots of the estimated versus true CSMF for four 
select causes of adult deaths (each of the 500 splits contributes a single 
point to the scatter). The figure shows how RF estimation quality tends to be 
different for different causes. As depicted, RF estimations for AIDS, maternal, 
and ischemic heart disease (IHD) are closely correlated with the true CSMFs. 
However, for colorectal cancer, estimations are noisier, and regardless of the 
true CSMF, RF assigns similar CSMFs in all 500 splits. To summarize the quality 
of RF estimation for each cause for all age groups, Additional file6 shows the 
slope, intercept, and RMSE from linear regression of estimated versus true 
CSMFs. This population-level metric of analysis quality gave results 
qualitatively similar to the individual-level metric on a cause-specific basis. 
The RF CSMF slopes range from 0.097 to 0.904 for adult VAs, 0.105 to 0.912 for 
child VAs, and 0.079 to 0.845 for neonatal VAs. PCVA has similar ranges for the 
three age groups. However, on a cause-by-cause basis, PCVA and RF show 
different characteristics. A comparison revealed that, for the same causes that 
the methods have high chance-corrected concordance, the CSMF regression slope 
is higher for RF. This shows that RF attains higher cause-specific 
chance-corrected concordances as a result of better classification, not simply 
by assigning a higher portion of deaths to some causes.</p> 
<p><strong>Figure 10.</strong> <strong>Estimated versus true CSMFs for 500 
Dirichlet splits, showing that for selected causes of adult mortality (AIDS, 
colorectal cancer, maternal, and IHD), the performance of RF varies</strong>. 
For AIDS and IHD, RF tends to overestimate the cause fraction when the true 
CSMF is small and underestimate otherwise. For colorectal cancer, RF mostly 
assigns the same CSMF regardless of true CSMF, and for maternal causes, RF is 
more accurate.</p> 
<p><strong>Additional file 6.</strong> <strong>Slope, intercept, and RMSE for 
linear regression of true versus estimated CSMF</strong>.</p> 
<p> Format: XLSX Size: 18KB Download file</p> 
<p>The results of performing RF with a higher number of trees in each 
one-versus-one cause classifier showed that the method is stable by only using 
100 trees per classifier. It should be noted that, while in the literature it 
is suggested that increasing the number of trees increases the classification 
precision, as our overall RF Method includes an ensemble of one-versus-one 
classifiers (e.g., for adult VAs, RF has one-versus-one classifiers, each 
including 100 trees), the overall number of trees is high, which results in 
stable performance.</p> 
<h3>Discussion</h3> 
<p>We found that the RF Method outperforms PCVA for all metrics and settings, 
with the exception of having slightly lower CSMF accuracy in neonates when HCE 
was available. Even in this single scenario, the difference in CSMF accuracy is 
not statistically significant, and furthermore, the PCVA analysis for neonates 
was limited to a six cause list, while the RF analysis was done on the full 11 
cause list. The degree of the improvement varies among metrics, among age 
modules, and with the presence or absence of HCE variables. When the analysis 
is conducted without HCE variables, RF is particularly dominant.</p> 
<p>The superior performance of RF compared to PCVA with respect to all of our 
quality metrics is excellent because this method also reduces cost, speeds up 
the analysis process, and increases reliability. While it may take days for a 
team of physicians to complete a VA survey analysis, a computer approach 
requires only seconds of processing on hardware that is currently affordably 
available. In addition, using machine learning leads to reliability, since the 
same interview responses will lead to the same cause assignment every time. 
This is an important advantage over PCVA, which can produce results of widely 
varying quality among different physicians, according to their training and 
experience[14]. </p> 
<p>Despite these strengths of RF, the method does have weaknesses in 
individual-level prediction of certain causes. For example, chance-corrected 
concordances for malaria and pneumonia in adults are around 25% even with HCE. 
Chance-corrected concordances for encephalitis, sepsis, and meningitis in 
children are in the 15% to 25% range. However, in many applications, it is the 
population-level estimates that are most important, and the linear regression 
of true versus estimated cause fraction shows that for these causes, RF has a 
RMSE of at most 0.009 for the adult causes and 0.02 for the child causes. It 
may be possible to use these RMSEs together with the slopes and intercepts to 
yield an adjusted CSMF with uncertainty.</p> 
<p>While the ANN method used by Boulle et al. 10 years ago [3] showed the 
potential of using ML techniques, the RF Method we have validated here has 
proven that ML is ready to be put into practice as a VA analysis method. ML is 
an actively developing subdiscipline of computer science, so we expect that 
future advances in ML classification will be invented over the coming years, 
and VA analysis techniques will continue to benefit from this innovation. 
During the development of our approach, we considered many variants of RF. 
However, the possibilities are endless, and even some other variant of RF may 
improve on the method presented here. For example, nonuniformly increasing the 
number of trees in the forest to have proportionately more for select causes 
(in the spirit of Boosting[17]) is a potential direction for future exploration.
</p> 
<p>For any ML classifier to be successful, several requirements should be met. 
As discussed earlier, the accuracy of classification relies considerably on the 
quality of the training data (deaths with gold standard cause known to meet 
clinical diagnostic criteria). While the PHMRC study design collected VA 
interviews distributed among a wide array of causes from a variety of settings, 
certain causes were so rare that too few cases occurred to train any ML 
classifier to recognize them. Future studies could focus on collecting 
additional gold standard VAs for priority diseases to complement the PHMRC 
dataset. These additional data could improve the accuracy of RF and other ML 
models on certain selected causes. Future research should also focus on 
assessing VA's performance in different settings. For example, users in India 
may be interested specifically in how RF performs in India instead of across 
all of the PHRMC sites, particularly if it is possible to train the model only 
on validation deaths from India.</p> 
<p>All VA validation studies depend critically on the quality of validation 
data, and this RF validation is no exception. A unique feature of the PHMRC 
validation dataset, the clinical diagnostic criteria, ensures that the 
validation data are very precise about the underlying cause of death. However, 
this clinical diagnosis also requires that the deceased have some contact with 
the health system. The validity of the method therefore depends critically on 
the assumption that the signs and symptoms observed in the deaths that occur in 
hospitals for a given cause are not substantially different than deaths from 
that cause that occur in communities without access to hospitals. We have 
investigated this assumption by conducting our analysis with and without HCE 
items, which gives some indication of the potential differences.</p> 
<p>The machine learning technique described in this paper will be released as 
free open source software, both as stand-alone software to run on a PC and also 
as an application for Android phones and tablets, integrated into an electronic 
version of the VA instrument.</p> 
<h3>Conclusions</h3> 
<p>We presented an ML technique for assigning cause of death in VA studies. 
The optimization steps taken to improve the accuracy of RF classifiers in VA 
application were presented. We found that our RF Method outperformed PCVA in 
chance-corrected concordance and CSMF accuracy for adult and child VA with and 
without HCE and for neonatal VA without HCE. In addition, it is preferable to 
PCVA in terms of both cost and time. Therefore, we recommend it as the 
technique of choice for analyzing past and current verbal autopsies.</p> 
<h3>Abbreviations</h3> 
<p>ANN: artificial neural network; CCVA: computer-coded verbal autopsy; CSMF: 
cause-specific mortality fraction; VA: verbal autopsy; ML: machine learning; 
PCVA: physician-certified verbal autopsy; PHRMC: Population Health Metrics 
Research Consortium; RF: Random Forest; RMSE: root mean squared error; HCE: 
health care experience; IHD: ischemic heart disease.</p> 
<h3>Competing interests</h3> 
<p>The authors declare that they have no competing interests.</p> 
<h3>Authors' contributions</h3> 
<p>ADF, AV, and SG performed analyses. AV and CJLM edited the manuscript. SLJ 
helped prepare the data and results. ADF drafted the manuscript and approved 
the final version. ADF accepts full responsibility for the work and the conduct 
of the study, had access to the data, and controlled the decision to publish. 
All authors have read and approved the final manuscript.</p> 
<h3>Acknowledgements</h3> 
<p><strong>This research was conducted as part of the Population Health 
Metrics Research Consortium:</strong>Christopher JL Murray, Alan D Lopez, 
Robert Black, Ramesh Ahuja, Said Mohd Ali, Abdullah Baqui, Lalit Dandona, Emily 
Dantzer, Vinita Das, Usha Dhingra, Arup Dutta, Wafaie Fawzi, Abraham D Flaxman, 
Sara Gomez, Bernardo Hernandez, Rohina Joshi, Henry Kalter, Aarti Kumar, 
Vishwajeet Kumar, Rafael Lozano, Marilla Lucero, Saurabh Mehta, Bruce Neal, 
Summer Lockett Ohno, Rajendra Prasad, Devarsetty Praveen, Zul Premji, Dolores 
Ram&iacute;rez-Villalobos, Hazel Remolador, Ian Riley, Minerva Romero, Mwanaidi 
Said, Diozele Sanvictores, Sunil Sazawal, Veronica Tallo. The authors would 
like to additionally thank Charles Atkinson for managing the PHMRC verbal 
autopsy database and Michael K Freeman, Benjamin Campbell, and Charles Atkinson 
for intellectual contributions to the analysis.</p> 
<p>This work was funded by a grant from the Bill &amp; Melinda Gates 
Foundation through the Grand Challenges in Global Health initiative. The 
funders had no role in study design, data collection and analysis, 
interpretation of data, decision to publish, or preparation of the manuscript. 
The corresponding author had full access to all data analyzed and had final 
responsibility for the decision to submit this original research paper for 
publication.</p> 
<h3>References</h3> 
<ol> 
<li> 
<p> Soleman N, Chandramohan D, Shibuya K: <strong> Verbal autopsy: current 
practices and challenges.</strong></p>
<p><em>Bull World Health Organ</em> 2006, <strong>84</strong><strong>:</strong>
239-245.PubMed&nbsp;Abstract | Publisher&nbsp;Full&nbsp;Text | 
PubMed&nbsp;Central&nbsp;Full&nbsp;Text </p> 
<p></p> 
<p></p> </li> 
<li> 
<p> Mitchell TM: <em>Machine Learning</em>. 1st edition. New York, NY: 
McGraw-Hill Science/Engineering/Math; 1997.</p> 
<p></p> 
<p></p> </li> 
<li> 
<p> Boulle A, Chandramohan D, Weller P: <strong> A case study of using 
artificial neural networks for classifying cause of death from verbal autopsy.
</strong></p>
<p><em>Int J Epidemiol</em> 2001, <strong>30</strong><strong>:</strong>515-520.
PubMed&nbsp;Abstract | Publisher&nbsp;Full&nbsp;Text </p> 
<p></p> 
<p></p> </li> 
<li> 
<p> Breiman L: <strong> Random Forests. </strong></p>
<p><em>Machine Learning</em> 2001, <strong>45</strong><strong>:</strong>5-32. 
Publisher&nbsp;Full&nbsp;Text </p> 
<p></p> 
<p></p> </li> 
<li> 
<p> Caruana R, Karampatziakis N, Yessenalina A: <strong> An empirical 
evaluation of supervised learning in high dimensions.</strong></p>
<p><em>Proceedings of the 25th International Conference on Machine Learning - 
ICML '08, Helsinki, Finland</em> 2008, 96-103. </p> 
<p></p> 
<p></p> </li> 
<li> 
<p> Diaz-Uriarte R, Alvarez de Andres S: <strong> Gene selection and 
classification of microarray data using random forest.</strong></p>
<p><em>BMC Bioinformatics</em> 2006, <strong>7</strong><strong>:</strong>3. 
PubMed&nbsp;Abstract | BioMed&nbsp;Central&nbsp;Full&nbsp;Text | 
PubMed&nbsp;Central&nbsp;Full&nbsp;Text </p> 
<p></p> 
<p></p> </li> 
<li> 
<p> Svetnik V, Liaw A, Tong C, Wang T: <strong> Application of Breiman's 
Random Forest to modeling Structure-Activity Relationships of pharmaceutical 
molecules.</strong>In <em>Multiple Classier Systems, Fifth International 
Workshop, MCS 2004, 9-11 June 2004, Proceedings, Cagliari, Italy</em>. <em> 
Volume 3077</em>. Edited by Roli F, Kittler J, Windeatt T. Lecture Notes in 
Computer Science, Berlin: Springer; 2004:334-343.</p> 
<p></p> 
<p></p> </li> 
<li> 
<p> Qi Y, Klein-Seetharaman J, Bar-Joseph Z: <strong> Random forest similarity 
for protein-protein interaction prediction from multiple sources.</strong></p>
<p><em>Pac Symp Biocomput</em> 2005, 531-542. </p> 
<p></p> 
<p></p> </li> 
<li> 
<p> Breiman L, Friedman J, Olshen R, Stone C: <em>Classification and 
Regression Trees</em>. 1st edition. Wadsworth and Brooks, Monterey, CA; 1984. 
</p> 
<p></p> 
<p></p> </li> 
<li> 
<p> Anker M, Black RE, Coldham C, Kalter HD, Quigley MA, Ross D, Snow RW: <em>
A Standard Verbal Autopsy Method for Investigating Causes of Death in Infants 
and Children.</em> Geneva: World Health Organization; 1999.</p> 
<p></p> 
<p></p> </li> 
<li> 
<p> Hastie T, Tibshirani R: <strong> Classification by pairwise coupling. 
</strong></p>
<p><em>Ann Statist</em> 1998, <strong>26</strong><strong>:</strong>451-471. 
</p> 
<p></p> 
<p></p> </li> 
<li> 
<p> Murray CJL, Lopez AD, Black R, Ahuja R, Ali SM, Baqui A, Dandona L, 
Dantzer E, Das V, Dhingra U, Dutta A, Fawzi W, Flaxman AD, G&oacute;mez S, 
Hern&aacute;ndez B, Joshi R, Kalter H, Kumar A, Kumar V, Lozano R, Lucero M, 
Mehta S, Neal B, Ohno SL, Prasad R, Praveen D, Premji Z, 
Ram&iacute;rez-Villalobos D, Remolador H, Riley I, Romero M, Said M, 
Sanvictores D, Sazawal S, Tallo V:<strong> Population Health Metrics Research 
Consortium gold standard verbal autopsy validation study: design, 
implementation, and development of analysis datasets.</strong></p>
<p><em>Popul Health Metr</em> 2011, <strong>9</strong><strong>:</strong>27. 
PubMed&nbsp;Abstract | BioMed&nbsp;Central&nbsp;Full&nbsp;Text </p> 
<p></p> 
<p></p> </li> 
<li> 
<p> Murray CJL, Lozano R, Flaxman AD, Vahdatpour A, Lopez AD: <strong> Robust 
metrics for assessing the performance of different verbal autopsy cause 
assignment methods in validation studies.</strong></p>
<p><em>Popul Health Metr</em> 2011, <strong>9</strong><strong>:</strong>28. 
PubMed&nbsp;Abstract | BioMed&nbsp;Central&nbsp;Full&nbsp;Text </p> 
<p></p> 
<p></p> </li> 
<li> 
<p> Lozano R, Lopez AD, Atkinson C, Naghavi M, Flaxman AD, Murray CJL, the 
Population Health Metrics Research Consortium (PHMRC):<strong> Performance of 
physician-certified verbal autopsies: multisite validation study using clinical 
diagnostic gold standards.</strong></p>
<p><em>Popul Health Metr</em> 2011, <strong>9</strong><strong>:</strong>32. 
PubMed&nbsp;Abstract | BioMed&nbsp;Central&nbsp;Full&nbsp;Text </p> 
<p></p> 
<p></p> </li> 
<li> 
<p> Murray CJL, Lopez AD, Feehan DM, Peter ST, Yang G: <strong> Validation of 
the symptom pattern method for analyzing verbal autopsy data.</strong></p>
<p><em>PLoS Med</em> 2007, <strong>4</strong><strong>:</strong>e327. 
PubMed&nbsp;Abstract | Publisher&nbsp;Full&nbsp;Text | 
PubMed&nbsp;Central&nbsp;Full&nbsp;Text </p> 
<p></p> 
<p></p> </li> 
<li> 
<p> James SL, Flaxman AD, Murray CJL, the Population Health Metrics Research 
Consortium (PHMRC):<strong> Performance of the Tariff Method: validation of a 
simple additive algorithm for analysis of verbal autopsies.</strong></p>
<p><em>Popul Health Metr</em> 2011, <strong>9</strong><strong>:</strong>31. 
PubMed&nbsp;Abstract | BioMed&nbsp;Central&nbsp;Full&nbsp;Text </p> 
<p></p> 
<p></p> </li> 
<li> 
<p> Schapire RE, Freund Y, Bartlett P, Lee WS: <strong> Boosting the Margin: A 
New Explanation for the Effectiveness of Voting Methods.</strong></p>
<p><em>The Annals of Statistics</em> 1998, <strong>26</strong><strong>:
</strong>1651-1686. </p> 
<p></p> 
<p></p> </li> </ol> 
<dl> 
<dt> Advertisement </dt> 
<dd> </dd> </dl> 
<dl> 
<dt> Advertisement </dt> 
<dd> </dd> </dl> <br>

<ul> 
<li>Terms and Conditions</li> 
<li>Privacy statement</li> 
<li>Press</li> 
<li>Information for advertisers</li> 
<li>Jobs at BMC</li> 
<li>Support</li> 
<li>Contact us</li> </ul> 
<p>&copy; 2012 BioMed Central Ltd unless otherwise stated. Part of Springer 
Science+Business Media.</p> <br>
<br>

</body>